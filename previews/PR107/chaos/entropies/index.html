<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Entropies and Dimensions · DynamicalSystems.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DynamicalSystems.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DynamicalSystems.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../contents/">Contents</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">DelayEmbeddings</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../embedding/dataset/">Numerical Data</a></li><li><a class="tocitem" href="../../embedding/reconstruction/">Delay Coordinates Embedding</a></li><li><a class="tocitem" href="../../embedding/estimate/">Estimating Delay Embedding Parameters</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">DynamicalSystemsBase</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../ds/general/">Dynamical System Definition</a></li><li><a class="tocitem" href="../../ds/evolve/">Time Evolution</a></li><li><a class="tocitem" href="../../ds/predefined/">Predefined Dynamical Systems</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox" checked/><label class="tocitem" for="menuitem-5"><span class="docs-label">ChaosTools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../orbitdiagram/">Orbit Diagrams &amp; PSOS</a></li><li><a class="tocitem" href="../lyapunovs/">Lyapunov Exponents</a></li><li><a class="tocitem" href="../chaos_detection/">Detecting &amp; Categorizing Chaos</a></li><li class="is-active"><a class="tocitem" href>Entropies and Dimensions</a><ul class="internal"><li><a class="tocitem" href="#Generalized-Entropy-1"><span>Generalized Entropy</span></a></li><li><a class="tocitem" href="#Attractor-Dimension-Estimation-1"><span>Attractor Dimension Estimation</span></a></li><li><a class="tocitem" href="#Example-1"><span>Example</span></a></li><li><a class="tocitem" href="#Permutation-Entropy-1"><span>Permutation Entropy</span></a></li><li><a class="tocitem" href="#Kaplan-Yorke-Dimension-1"><span>Kaplan-Yorke Dimension</span></a></li></ul></li><li><a class="tocitem" href="../nlts/">Nonlinear Timeseries Analysis</a></li><li><a class="tocitem" href="../periodicity/">Periodicity</a></li><li><a class="tocitem" href="../choosing/">Choosing a solver</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">RecurrenceAnalysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../rqa/rplots/">Recurrence Plots</a></li><li><a class="tocitem" href="../../rqa/quantification/">Recurrence Quantification Analysis</a></li><li><a class="tocitem" href="../../rqa/windowed/">Windowed RQA</a></li></ul></li><li><a class="tocitem" href="../../advanced/">Advanced Documentation</a></li><li><a class="tocitem" href="../../contributors_guide/">Contributor Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">ChaosTools</a></li><li class="is-active"><a href>Entropies and Dimensions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Entropies and Dimensions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/DynamicalSystems.jl/blob/master/docs/src/chaos/entropies.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Entropies-and-Dimensions-1"><a class="docs-heading-anchor" href="#Entropies-and-Dimensions-1">Entropies and Dimensions</a><a class="docs-heading-anchor-permalink" href="#Entropies-and-Dimensions-1" title="Permalink"></a></h1><h2 id="Generalized-Entropy-1"><a class="docs-heading-anchor" href="#Generalized-Entropy-1">Generalized Entropy</a><a class="docs-heading-anchor-permalink" href="#Generalized-Entropy-1" title="Permalink"></a></h2><p>In the study of dynamical systems there are many quantities that identify as &quot;entropy&quot;. Notice that these quantities are not the more commonly known <a href="https://en.wikipedia.org/wiki/Entropy">thermodynamic ones</a>, used in Statistical Physics. Rather, they are more like the to the entropies of <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">information theory</a>, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.</p><hr/><p>One way of computing entropies in <strong>DynamicalSystems.jl</strong> is the &quot;generalized entropy&quot;:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.genentropy" href="#ChaosTools.genentropy"><code>ChaosTools.genentropy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">genentropy(α, ε, dataset::AbstractDataset; base = e)</code></pre><p>Compute the <code>α</code> order generalized (Rényi) entropy [1] of a dataset, by first partitioning it into boxes of length <code>ε</code> using <a href="#ChaosTools.non0hist"><code>non0hist</code></a>.</p><pre><code class="language-julia">genentropy(α, p::AbstractArray; base = e)</code></pre><p>Compute the entropy of an array <code>p</code> directly, assuming that <code>p</code> is sum-normalized.</p><p>Optionally use <code>base</code> for the logarithms.</p><p><strong>Description</strong></p><p>Let <span>$p$</span> be an array of probabilities (summing to 1). Then the Rényi entropy is</p><div>\[H_\alpha(p) = \frac{1}{1-\alpha} \log \left(\sum_i p[i]^\alpha\right)\]</div><p>and generalizes other known entropies, like e.g. the information entropy (<span>$\alpha = 1$</span>, see [2]), the maximum entropy (<span>$\alpha=0$</span>, also known as Hartley entropy), or the correlation entropy (<span>$\alpha = 2$</span>, also known as collision entropy).</p><p><strong>References</strong></p><p>[1] : A. Rényi, <em>Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability</em>, pp 547 (1960)</p><p>[2] : C. E. Shannon, Bell Systems Technical Journal <strong>27</strong>, pp 379 (1948)</p></div></section></article><hr/><p>Basically, given a <a href="../../embedding/dataset/#DelayEmbeddings.Dataset"><code>Dataset</code></a> you can partition it into boxes to calculate an entropy. See below for a detailed example.</p><div class="admonition is-success"><header class="admonition-header">Worried about memory overflow? Don&#39;t be!</header><div class="admonition-body"><p>Partitioning the dataset (i.e. doing a <em>histogram</em>) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size <code>ε</code>.</p><p>However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!</p></div></div><p>The function used internally by <code>genentropy</code> is <code>non0hist</code>:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.non0hist" href="#ChaosTools.non0hist"><code>ChaosTools.non0hist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">non0hist(ε, dataset::AbstractDataset)</code></pre><p>Partition a dataset into tabulated intervals (boxes) of size <code>ε</code> and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements and bin edge information.</p><p><strong>Performances Notes</strong></p><p>This method has a linearithmic time complexity (<code>n log(n)</code> for <code>n = length(data)</code>) and a linear space complexity (<code>l</code> for <code>l = dimension(data)</code>). This allows computation of entropies of high-dimensional datasets and with small box sizes <code>ε</code> without memory overflow.</p><p>Use e.g. <code>fit(Histogram, ...)</code> from <a href="http://juliastats.github.io/StatsBase.jl/stable/"><code>StatsBase</code></a> if you wish to keep information about the edges of the binning as well as the zero elements.</p></div></section></article><hr/><h2 id="Attractor-Dimension-Estimation-1"><a class="docs-heading-anchor" href="#Attractor-Dimension-Estimation-1">Attractor Dimension Estimation</a><a class="docs-heading-anchor-permalink" href="#Attractor-Dimension-Estimation-1" title="Permalink"></a></h2><p>There are numerous methods that one can use to calculate a so-called &quot;dimension&quot; of a dataset, like for example the <a href="https://en.wikipedia.org/wiki/Fractal_dimension">Fractal dimension</a>. This real number can offer a lot of information about the object that the dataset represents.</p><p>Based on the definition of the <a href="#ChaosTools.genentropy">generalized entropy</a>, one can calculate an appropriate dimension, called <em>generalized dimension</em>:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.generalized_dim" href="#ChaosTools.generalized_dim"><code>ChaosTools.generalized_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">generalized_dim(α, dataset [, sizes]) -&gt; D_α</code></pre><p>Return the <code>α</code> order generalized dimension of the <code>dataset</code>, by calculating the <a href="#ChaosTools.genentropy"><code>genentropy</code></a> for each <code>ε ∈ sizes</code>.</p><p><strong>Description</strong></p><p>The returned dimension is approximated by the (inverse) power law exponent of the scaling of the <a href="#ChaosTools.genentropy"><code>genentropy</code></a> versus the box size <code>ε</code>, where <code>ε ∈ sizes</code>.</p><p>Calling this function performs a lot of automated steps:</p><ol><li>A vector of box sizes is decided by calling <code>sizes = estimate_boxsizes(dataset)</code>, if <code>sizes</code> is not given.</li><li>For each element of <code>sizes</code> the appropriate entropy is calculated, through <code>d = genentropy.(α, sizes, dataset)</code>. Let <code>x = -log.(sizes)</code>.</li><li>The curve <code>d(x)</code> is decomposed into linear regions, using <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a><code>(x, d)</code>.</li><li>The biggest linear region is chosen, and a fit for the slope of that region is performed using the function <a href="#ChaosTools.linear_region"><code>linear_region</code></a>. This slope is the return value of <code>generalized_dim</code>.</li></ol><p>By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.</p><p>The following aliases are provided:</p><ul><li>α = 0 : <code>boxcounting_dim</code>, <code>capacity_dim</code></li><li>α = 1 : <code>information_dim</code></li></ul></div></section></article><hr/><div class="admonition is-danger"><header class="admonition-header">Be wary when using `generalized_dim`</header><div class="admonition-body"><p>As stated clearly by the documentation string, calling <code>generalized_dim</code> performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.</p></div></div><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.estimate_boxsizes" href="#ChaosTools.estimate_boxsizes"><code>ChaosTools.estimate_boxsizes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">estimate_boxsizes(dataset::AbstractDataset; k::Int = 12, z = -1, w = 1)</code></pre><p>Return <code>k</code> exponentially spaced values: <code>10 .^ range(lower+w, upper+z, length = k)</code>.</p><p><code>lower</code> is the magnitude of the minimum pair-wise distance between datapoints while <code>upper</code> is the magnitude of the maximum difference between greatest and smallest number among each timeseries.</p><p>&quot;Magnitude&quot; here stands for order of magnitude, i.e. <code>round(log10(x))</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linear_regions" href="#ChaosTools.linear_regions"><code>ChaosTools.linear_regions</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">linear_regions(x, y; dxi::Int = 1, tol = 0.2) -&gt; (lrs, tangents)</code></pre><p>Identify regions where the curve <code>y(x)</code> is linear, by scanning the <code>x</code>-axis every <code>dxi</code> indices (e.g. at <code>x[1] to x[5], x[5] to x[10], x[10] to x[15]</code> and so on if <code>dxi=5</code>).</p><p>If the slope (calculated using <code>LsqFit</code>) of a region of width <code>dxi</code> is approximatelly equal to that of the previous region, within tolerance <code>tol</code>, then these two regions belong to the same linear region.</p><p>Return the indices of <code>x</code> that correspond to linear regions, <code>lrs</code>, and the approximated <code>tangents</code> at each region. <code>lrs</code> is a vector of <code>Int</code>. Notice that <code>tangents</code> is <em>not</em> accurate: it is not recomputed at every step, but only when its error exceeds the tolerance <code>tol</code>! Use <a href="#ChaosTools.linear_region"><code>linear_region</code></a> to obtain a correct estimate for the slope of the largest linear region.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linear_region" href="#ChaosTools.linear_region"><code>ChaosTools.linear_region</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">linear_region(x, y; dxi::Int = 1, tol = 0.2) -&gt; ([ind1, ind2], slope)</code></pre><p>Call <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a>, identify the largest linear region and approximate the slope of the entire region using <code>linreg</code>. Return the indices where the region starts and stops (<code>x[ind1:ind2]</code>) as well as the approximated slope.</p></div></section></article><hr/><h2 id="Example-1"><a class="docs-heading-anchor" href="#Example-1">Example</a><a class="docs-heading-anchor-permalink" href="#Example-1" title="Permalink"></a></h2><p>For an example of using entropies to compute the dimension of an attractor let&#39;s use everyone&#39;s favorite system:</p><pre><code class="language-julia">using DynamicalSystems, PyPlot
lor = Systems.lorenz()</code></pre><pre><code class="language-none">3-dimensional continuous dynamical system
 state:       [0.0, 10.0, 0.0]
 e.o.m.:      loop
 in-place?    false
 jacobian:    loop_jac
 parameters:  [10.0, 28.0, 2.6666666666666665]</code></pre><p>Our goal is to compute entropies for many different partition sizes <code>ε</code>, so let&#39;s get down to it:</p><pre><code class="language-julia">tr = trajectory(lor, 100.0; Ttr = 10.0)

ες = ℯ .^ (-3.5:0.5:3.5) # semi-random guess
Hs = genentropy.(1, ες, Ref(tr))</code></pre><pre><code class="language-none">15-element Array{Float64,1}:
 9.210440366976329 
 9.208499748932574 
 9.195140334192946 
 9.136445496766951 
 8.998905310194775 
 8.705004397152349 
 8.1305312663553   
 7.331853533923082 
 6.408657913235563 
 5.453352354803625 
 4.485476740802795 
 3.5260626238745894
 2.6067548710932336
 1.8789633825490644
 0.5375831514462662</code></pre><pre><code class="language-julia">xs = @. -log(ες)
figure()
plot(xs, Hs)
ylabel(&quot;\$H_1\$&quot;)
xlabel(&quot;\$-\\log (\\epsilon)\$&quot;);</code></pre><p><img src="../genentropy1.png" alt/></p><p>The slope of the linear scaling region of the above plot is the generalized dimension (of order α = 2) for the attractor of the Lorenz system.</p><p>Given that we <em>see</em> the plot, we can estimate where the linear scaling region starts and ends. However, we can use the function <a href="#ChaosTools.linear_region"><code>linear_region</code></a> to get an estimate of the result as well. First let&#39;s visualize what it does:</p><pre><code class="language-julia">lrs, slopes = linear_regions(xs, Hs, tol = 0.25)

figure()
for i in 1:length(lrs)-1
    plot(xs[lrs[i]:lrs[i+1]], Hs[lrs[i]:lrs[i+1]], marker = &quot;o&quot;)
end
ylabel(&quot;\$H_1\$&quot;)
xlabel(&quot;\$-\\log (\\epsilon)\$&quot;);</code></pre><p><img src="../genentropy2.png" alt/></p><p>The <a href="#ChaosTools.linear_region"><code>linear_region</code></a> function  computes the slope of the largest region:</p><pre><code class="language-julia">linear_region(xs, Hs)[2]</code></pre><pre><code class="language-none">1.833384047211349</code></pre><p>This result is an approximation of the information dimension (because we used <code>α = 1</code>) of the Lorenz attractor.</p><hr/><p>The above pipeline is bundled in <a href="#ChaosTools.generalized_dim"><code>generalized_dim</code></a>. For example, the dimension of the strange attractor of the <a href="../../ds/predefined/#DynamicalSystemsBase.Systems.henon"><code>Systems.henon</code></a> map, following the above approach but taking automated steps, is:</p><pre><code class="language-julia">using DynamicalSystems
hen = Systems.henon()
ts = trajectory(hen, 200000)
D_hen = generalized_dim(1, ts)</code></pre><pre><code class="language-none">1.215884931528749</code></pre><p>As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D <strong>56</strong>, pp 185-187 (1992)).</p><hr/><h2 id="Permutation-Entropy-1"><a class="docs-heading-anchor" href="#Permutation-Entropy-1">Permutation Entropy</a><a class="docs-heading-anchor-permalink" href="#Permutation-Entropy-1" title="Permalink"></a></h2><p>The permutation entropy is introduced by C. Bandt and B. Pompe as a &quot;A Natural Complexity Measure for Timeseries&quot;, which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.permentropy" href="#ChaosTools.permentropy"><code>ChaosTools.permentropy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">permentropy(x::AbstractVector, order [, interval=1]; base = e)</code></pre><p>Compute the permutation entropy [1] of given <code>order</code> from the <code>x</code> timeseries.</p><p>Optionally, <code>interval</code> can be specified to use <code>x[t0:interval:t1]</code> when calculating permutation of the sliding windows between <code>t0</code> and <code>t1 = t0 + interval * (order - 1)</code>.</p><p>Optionally use <code>base</code> for the logarithms.</p><p><strong>References</strong></p><p>[1] : C. Bandt, &amp; B. Pompe, <a href="http://doi.org/10.1103/PhysRevLett.88.174102">Phys. Rev. Lett. <strong>88</strong> (17), pp 174102 (2002)</a></p></div></section></article><hr/><p>For example, we will compute and compare the <a href="../lyapunovs/#ChaosTools.lyapunov"><code>lyapunov</code></a> exponent of the logistic map with the order-6 permutation entropy, like in the original paper.</p><pre><code class="language-julia">using DynamicalSystems, PyPlot
ds = Systems.logistic()
rs = 3.5:0.001:4
ls = Float64[]; hs = Float64[]
for r in rs
    ds.p[1] = r
    push!(ls, lyapunov(ds, 100000))
    # For 1D systems `trajectory` returns a vector
    push!(hs, permentropy(trajectory(ds, 10000), 6))
end

f = figure(figsize = (10,6))
a1 = subplot(211)
plot(rs, ls); ylim(-2, log(2)); ylabel(&quot;\$\\lambda\$&quot;)
a1.axes.get_xaxis().set_ticklabels([])
xlim(rs[1], rs[end]);

a2 = subplot(212)
plot(rs, hs; color = &quot;C1&quot;); ylabel(&quot;\$h_6\$&quot;)
xlim(rs[1], rs[end]); xlabel(&quot;\$r\$&quot;)
tight_layout()</code></pre><p><img src="../permentropy.png" alt/></p><div class="admonition is-info"><header class="admonition-header">Permutation Entropy performance</header><div class="admonition-body"><p>Even though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue <a href="https://github.com/JuliaDynamics/ChaosTools.jl/issues/22">ChaosTools.jl#22</a> keeps track of this, and contains information on how to improve performance.</p></div></div><h2 id="Kaplan-Yorke-Dimension-1"><a class="docs-heading-anchor" href="#Kaplan-Yorke-Dimension-1">Kaplan-Yorke Dimension</a><a class="docs-heading-anchor-permalink" href="#Kaplan-Yorke-Dimension-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.kaplanyorke_dim" href="#ChaosTools.kaplanyorke_dim"><code>ChaosTools.kaplanyorke_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kaplanyorke_dim(lyapunovs::AbstractVector)</code></pre><p>Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].</p><p><strong>Description</strong></p><p>The Kaplan-Yorke dimension is simply the point where <code>cumsum(lyapunovs)</code> becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.</p><p>Useful in combination with <a href="../lyapunovs/#ChaosTools.lyapunovs"><code>lyapunovs</code></a>.</p><p><strong>References</strong></p><p>[1] :  J. Kaplan &amp; J. Yorke, <em>Chaotic behavior of multidimensional difference equations</em>, Lecture Notes in Mathematics vol. <strong>730</strong>, Springer (1979)</p></div></section></article><hr/><p>Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:</p><pre><code class="language-julia">using DynamicalSystems
hen = Systems.henon()
D_kp = kaplanyorke_dim(lyapunovs(hen, 100000))</code></pre><pre><code class="language-none">1.25870326894443</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../chaos_detection/">« Detecting &amp; Categorizing Chaos</a><a class="docs-footer-nextpage" href="../nlts/">Nonlinear Timeseries Analysis »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 12 March 2020 20:24">Thursday 12 March 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
