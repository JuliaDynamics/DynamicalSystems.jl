var documenterSearchIndex = {"docs":
[{"location":"embedding/estimate/#Estimating-Delay-Embedding-Parameters-1","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"","category":"section"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"The following functions can estimate good values that can be used in reconstruct for either the delay time or the number of temporal neighbors.","category":"page"},{"location":"embedding/estimate/#Delay-Time-1","page":"Estimating Delay Embedding Parameters","title":"Delay Time","text":"","category":"section"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"estimate_delay\nexponential_decay_fit","category":"page"},{"location":"embedding/estimate/#DelayEmbeddings.estimate_delay","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.estimate_delay","text":"estimate_delay(s, method::String [, τs = 1:2:100]; kwargs...) -> τ\n\nEstimate an optimal delay to be used in reconstruct or embed. The method can be one of the following:\n\n\"ac_zero\" : first delay at which the auto-correlation function becomes <0.\n\"ac_min\" : delay of first minimum of the auto-correlation function.\n\"mi_min\" : delay of first minimum of mutual information of s with itself (shifted for various τs). Keywords nbins, binwidth are propagated into mutualinformation.\n\"exp_decay\" : exponential_decay_fit of the correlation function rounded  to an integer (uses least squares on c(t) = exp(-t/τ) to find τ).\n\"exp_extrema\" : same as above but the exponential fit is done to the absolute value of the local extrema of the correlation function.\n\nBoth the mutual information and correlation function (autocor) are computed only for delays τs. This means that the min methods can never return the first value of τs!\n\nThe method mi_min is significantly more accurate than the others and also returns good results for most timeseries. It is however the slowest method (but still quite fast!).\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#DelayEmbeddings.exponential_decay_fit","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.exponential_decay_fit","text":"exponential_decay_fit(x, y, weight = :equal) -> τ\n\nPerform a least square fit of the form y = exp(-x/τ) and return τ. Taken from:  http://mathworld.wolfram.com/LeastSquaresFittingExponential.html. Assumes equal lengths of x, y and that y ≥ 0.\n\nTo use the method that gives more weight to small values of y, use weight = :small.\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#Mutual-Information-1","page":"Estimating Delay Embedding Parameters","title":"Mutual Information","text":"","category":"section"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"mutualinformation","category":"page"},{"location":"embedding/estimate/#DelayEmbeddings.mutualinformation","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.mutualinformation","text":"mutualinformation(s, τs[; nbins, binwidth])\n\nCalculate the mutual information between the time series s and its images delayed by τ points for τ ∈ τs, using an improvement of the method outlined by Fraser & Swinney in [1].\n\nDescription\n\nThe joint space of s and its τ-delayed image (sτ) is partitioned as a rectangular grid, and the mutual information is computed from the joint and marginal frequencies of s and sτ in the grid as defined in [1]. The mutual information values are returned in a vector of the same length as τs.\n\nIf any of the optional keyword parameters is given, the grid will be a homogeneous partition of the space where s and sτ are defined. The margins of that partition will be divided in a number of bins equal to nbins, such that the width of each bin will be binwidth, and the range of nonzero values of s will be in the centre. If only of those two parameters is given, the other will be automatically calculated to adjust the size of the grid to the area where s and sτ are nonzero.\n\nIf no parameter is given, the space will be partitioned by a recursive bisection algorithm based on the method given in [1].\n\nNotice that the recursive method of [1] evaluates the joint frequencies of s and sτ in each cell resulting from a partition, and stops when the data points are uniformly distributed across the sub-partitions of the following levels. For performance and stability reasons, the automatic partition method implemented in this function is only used to divide the axes of the grid, using the marginal frequencies of s.\n\nReferences\n\n[1]: Fraser A.M. & Swinney H.L. \"Independent coordinates for strange attractors from mutual information\" Phys. Rev. A 33(2), 1986, 1134:1140.\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"","category":"page"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"Besides the above method, there also exists code that computes mutual information in two other ways. Both ways are in the file DelayEmbedding\\src\\old_mutual_info.jl. The first way is the original algorithm of Fraser, while the second is the algorithm of Kraskov. Both of these implementations are inferior to the one exposed here (performance-wise).","category":"page"},{"location":"embedding/estimate/#Embedding-Dimension-1","page":"Estimating Delay Embedding Parameters","title":"Embedding Dimension","text":"","category":"section"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"estimate_dimension","category":"page"},{"location":"embedding/estimate/#DelayEmbeddings.estimate_dimension","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.estimate_dimension","text":"estimate_dimension(s::AbstractVector, τ::Int, γs = 1:5, method = \"afnn\"; kwargs...)\n\nCompute a quantity that can estimate an optimal amount of temporal neighbors γ to be used in reconstruct or embed.\n\nDescription\n\nGiven the scalar timeseries s and the embedding delay τ compute a quantity for each γ ∈ γs based on the \"nearest neighbors\" in the embedded time series.\n\nThe quantity that is calculated depends on the algorithm defined by the string method:\n\n\"afnn\" (default) is Cao's \"Averaged False Nearest Neighbors\" method [1], which   gives a ratio of distances between nearest neighbors. This ratio saturates   around 1.0 near the optimal value of γ (see afnn).\n\"fnn\" is Kennel's \"False Nearest Neighbors\" method [2], which gives the   number of points that cease to be \"nearest neighbors\" when the dimension   increases. This number drops down to zero near the optimal value of γ.   This method accepts the keyword arguments rtol and atol, which stand   for the \"tolerances\" required by Kennel's algorithm (see fnn).\n\"f1nn\" is Krakovská's \"False First Nearest Neighbors\" method [3], which   gives the ratio of pairs of points that cease to be \"nearest neighbors\"   when the dimension increases. This number drops down to zero near the   optimal value of γ (see f1nn).\n\n\"afnn\" and \"f1nn\" also support the metric keyword, which can be any of Cityblock(), Euclidean(), Chebyshev(). This metric is used both for computing the nearest neighbors (KDTrees) as well as the distances necessary for Cao's method (eqs. (2, 3) of [1]). Defaults to Euclidean() (note that [1] used Chebyshev).\n\nPlease be aware that in DynamicalSystems.jl γ stands for the amount of temporal neighbors and not the embedding dimension (D = γ + 1, see also embed).\n\nReferences\n\n[1] : Liangyue Cao, Physica D, pp. 43-50 (1997)\n\n[2] : M. Kennel et al., Phys. Review A 45(6), 3403-3411 (1992).\n\n[3] : Anna Krakovská et al., J. Complex Sys. 932750 (2015)\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#Example-1","page":"Estimating Delay Embedding Parameters","title":"Example","text":"","category":"section"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"using DynamicalSystems, PyPlot\n\nds = Systems.roessler()\ntr = trajectory(ds, 1000.0; dt = 0.05)\n\nτ = estimate_delay(tr[:, 1], \"mi_min\") # first minimum of mutual information\n\nfigure();\nfor method in [\"afnn\", \"fnn\", \"f1nn\"]\n    Ds = estimate_dimension(tr[:, 1], τ, 1:6, method)\n    plot(1:6, Ds ./ maximum(Ds), label = method, marker = \"o\")\nend\nlegend(); xlabel(\"\\$\\\\gamma\\$ (temporal neighbors)\")\ntight_layout()\nsavefig(\"estimateD.png\"); nothing # hide","category":"page"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"(Image: )","category":"page"},{"location":"embedding/estimate/#Functions-1","page":"Estimating Delay Embedding Parameters","title":"Functions","text":"","category":"section"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"DelayEmbeddings.fnn\nDelayEmbeddings.afnn\nDelayEmbeddings.f1nn\nstochastic_indicator","category":"page"},{"location":"embedding/estimate/#DelayEmbeddings.fnn","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.fnn","text":"fnn(s::AbstractVector, τ:Int, γs = 1:5; rtol=10.0, atol=2.0)\n\nCalculate the number of \"false nearest neighbors\" (FNN) of the datasets created from s with a sequence of τ-delayed temporal neighbors.\n\nDescription\n\nGiven a dataset made by embedding s with γ temporal neighbors and delay τ, the \"false nearest neighbors\" (FNN) are the pairs of points that are nearest to each other at dimension γ, but are separated at dimension γ+1. Kennel's criteria for detecting FNN are based on a threshold for the relative increment of the distance between the nearest neighbors (rtol, eq. 4 in [1]), and another threshold for the ratio between the increased distance and the \"size of the attractor\" (atol, eq. 5 in [1]). These thresholds are given as keyword arguments.\n\nThe returned value is a vector with the number of FNN for each γ ∈ γs. The optimal value for γ is found at the point where the number of FNN approaches zero.\n\nSee also: estimate_dimension, afnn, f1nn.\n\nReferences\n\n[1] : M. Kennel et al., \"Determining embedding dimension for phase-space reconstruction using a geometrical construction\", Phys. Review A 45(6), 3403-3411 (1992).\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#DelayEmbeddings.afnn","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.afnn","text":"afnn(s::AbstractVector, τ:Int, γs = 1:5, metric=Euclidean())\n\nCompute the parameter E₁ of Cao's \"averaged false nearest neighbors\" method for determining the minimum embedding dimension of the time series s, with a sequence of τ-delayed temporal neighbors [1].\n\nDescription\n\nGiven the scalar timeseries s and the embedding delay τ compute the values of E₁ for each γ ∈ γs, according to Cao's Method (eq. 3 of [1]).\n\nThis quantity is a ratio of the averaged distances between the nearest neighbors of the reconstructed time series, which quantifies the increment of those distances when the number of temporal neighbors changes from γ to γ+1.\n\nReturn the vector of all computed E₁s. To estimate a good value for γ from this, find γ for which the value E₁ saturates at some value around 1.\n\nNote: This method does not work for datasets with perfectly periodic signals.\n\nSee also: estimate_dimension, fnn, f1nn.\n\nReferences\n\n[1] : Liangyue Cao, Physica D, pp. 43-50 (1997)\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#DelayEmbeddings.f1nn","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.f1nn","text":"f1nn(s::AbstractVector, τ:Int, γs = 1:5, metric = Euclidean())\n\nCalculate the ratio of \"false first nearest neighbors\" (FFNN) of the datasets created from s with a sequence of τ-delayed temporal neighbors.\n\nDescription\n\nGiven a dataset made by embedding s with γ temporal neighbors and delay τ, the \"first nearest neighbors\" (FFNN) are the pairs of points that are nearest to each other at dimension γ that cease to be nearest neighbors at dimension γ+1 [1].\n\nThe returned value is a vector with the ratio between the number of FFNN and the number of points in the dataset for each γ ∈ γs. The optimal value for γ is found at the point where this ratio approaches zero.\n\nSee also: estimate_dimension, afnn, fnn.\n\nReferences\n\n[1] : Anna Krakovská et al., \"Use of false nearest neighbours for selecting variables and embedding parameters for state space reconstruction\", J Complex Sys 932750 (2015), DOI: 10.1155/2015/932750\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#DelayEmbeddings.stochastic_indicator","page":"Estimating Delay Embedding Parameters","title":"DelayEmbeddings.stochastic_indicator","text":"stochastic_indicator(s::AbstractVector, τ:Int, γs = 1:4) -> E₂s\n\nCompute an estimator for apparent randomness in a reconstruction with γs temporal neighbors.\n\nDescription\n\nGiven the scalar timeseries s and the embedding delay τ compute the values of E₂ for each γ ∈ γs, according to Cao's Method (eq. 5 of [1]).\n\nUse this function to confirm that the input signal is not random and validate the results of estimate_dimension. In the case of random signals, it should be E₂ ≈ 1 ∀ γ.\n\nReferences\n\n[1] : Liangyue Cao, Physica D, pp. 43-50 (1997)\n\n\n\n\n\n","category":"function"},{"location":"embedding/estimate/#","page":"Estimating Delay Embedding Parameters","title":"Estimating Delay Embedding Parameters","text":"","category":"page"},{"location":"contributors_guide/#Contributor-Guide-1","page":"Contributor Guide","title":"Contributor Guide","text":"","category":"section"},{"location":"contributors_guide/#","page":"Contributor Guide","title":"Contributor Guide","text":"The ultimate goal for DynamicalSystems.jl is to be a useful library for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.","category":"page"},{"location":"contributors_guide/#","page":"Contributor Guide","title":"Contributor Guide","text":"For this to be achieved, many of us should try to work together to improve the library!","category":"page"},{"location":"contributors_guide/#","page":"Contributor Guide","title":"Contributor Guide","text":"If you want to help the cause, there are many ways to contribute to the DynamicalSystems.jl library:","category":"page"},{"location":"contributors_guide/#","page":"Contributor Guide","title":"Contributor Guide","text":"Just use it. If you encountered unexpected behavior simply report it either on our gitter chatroom or using the DynamicalSystems.jl Issues page.\nSuggest methods that you think should be included in our library. This should be done by opening a new issue that describes the method, gives references to papers using the method and also justifies why the method should be included.\nContribute code by solving issues. The easiest issues to tackle are the ones with label \"good first issue\".\nContribute code by implementing new methods! That is the most awesome way to contribute! The individual packages that compose DynamicalSystems.jl have plenty of issues with the tag \"wanted feature\", which can get you started on a big contribution!\nContribute code by defining a new pre-defined dynamical system that you found useful.","category":"page"},{"location":"contributors_guide/#Contributing-Code-1","page":"Contributor Guide","title":"Contributing Code","text":"","category":"section"},{"location":"contributors_guide/#","page":"Contributor Guide","title":"Contributor Guide","text":"When contributing code, you should keep these things in mind:","category":"page"},{"location":"contributors_guide/#","page":"Contributor Guide","title":"Contributor Guide","text":"In general, the speed of the implementation is important, but not as important as the reliability of the implementation. One of cornerstones of all of DynamicalSystems.jl is to have clear and readable source code. Fortunately, Julia allows you to have perfectly readable code but also super fast ;)\nFor the documentation strings of new methods and systems please follow the convention of the documentation strings of JuliaDynamics. Specifically, the first section should describe the function in a couple of sentences, its positional arguments and its return value. The next section ## Keyword Arguments describes the keywords. The next section ## Description describes the algorithm in detail if need be. A mandatory ## References section lists the related literature that is cited.\nHave enough comments in your code so that somebody that knows the method, can also understand the code immediately.\nAlways have a reference to the original work that introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in a similar manner.","category":"page"},{"location":"contents/#Contents-1","page":"Contents","title":"Contents","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"The module DynamicalSystems re-exports all following functionality, grouped into different packages.","category":"page"},{"location":"contents/#DynamicalSystemsBase-1","page":"Contents","title":"DynamicalSystemsBase","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Intuitive, consistent APIs for the definition of general dynamical systems under a unified struct DynamicalSystem. The following combinations are possible:\nContinuous or Discrete systems. Continuous systems use DifferentialEquations.jl for solving the ODE problem.\nIn-place or out-of-place (large versus small systems).\nAuto-differentiated or not (for the Jacobian function).","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\nRobust implementations of all kinds of integrators, that evolve the system, many states of the system, or even deviation vectors. See the Advanced documentation for this.\nLibrary of Predefined Dynamical Systems that have been used extensively in scientific research.","category":"page"},{"location":"contents/#DelayEmbeddings-1","page":"Contents","title":"DelayEmbeddings","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Is a package for performing delay coordinate embeddings and finding optimal parameters for doing so.","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Unified & dedicated interface for numerical data: Dataset.\nSimple and extendable neighborhood estimation by interfacing NearestNeighbors.\nFlexible, super-efficient and abstracted Delay Coordinates Embedding interface.\nSupports multiple dimensions and multiple timescales.","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Methods that estimate optimal embedding parameters: the delay time (estimate_delay) and the number of temporal neighbors  (estimate_dimension).","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Fast calculation of mutual information: mutualinformation.","category":"page"},{"location":"contents/#ChaosTools-1","page":"Contents","title":"ChaosTools","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Is a package that has many algorithms for chaotic dynamical systems. All algorithms are independent of each other but they are also not expansive enough to be a standalone package.","category":"page"},{"location":"contents/#[Orbit-Diagrams-and-PSOS](@ref)-1","page":"Contents","title":"Orbit Diagrams & PSOS","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Orbit diagrams (aka bifurcation diagrams) of maps: orbitdiagram.\nPoincaré surfaces of section for continuous systems: poincaresos.\nAutomated production of orbit diagrams for continuous systems: produce_orbitdiagram.","category":"page"},{"location":"contents/#[Lyapunov-Exponents](@ref)-1","page":"Contents","title":"Lyapunov Exponents","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"The following treat systems where the equations of motion are known:","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Maximum Lyapunov exponent for both discrete and continuous systems: lyapunov.\nLyapunov spectrum for both discrete and continuous systems: lyapunovs.","category":"page"},{"location":"contents/#[Detecting-and-Categorizing-Chaos](@ref)-1","page":"Contents","title":"Detecting & Categorizing Chaos","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"The Generalized Alignment Index: textGALI_k : gali.\nImplemented for both discrete and continuous systems.\nA test to categorize strong chaos, partially predictable chaos and regular behavior: predictability.\nImplemented for both discrete and continuous systems.\nThe 0-1 test for chaos: testchaos01\nThe expansion entropy: expansionentropy.","category":"page"},{"location":"contents/#[Entropies-and-Dimensions](@ref)-1","page":"Contents","title":"Entropies and Dimensions","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Generalized (Renyi) entropy: genentropy.\nPermutation entropy: permentropy.\nFast and cheap (memory-wise) method for computing entropies of large datasets.\nGeneralized dimensions (e.g. capacity dimension, information dimension, etc.): generalized_dim.\nKaplan-Yorke dimension: kaplanyorke_dim.","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"And, in order to automatically deduce dimensions, we also offer methods for:","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Partitioning a function y(x) vs. x into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See linear_regions.\nDetection of largest linear region of a function y(x) vs. x and extraction of the slope of this region.","category":"page"},{"location":"contents/#[Nonlinear-Timeseries-Analysis](@ref)-1","page":"Contents","title":"Nonlinear Timeseries Analysis","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Broomhead-King coordinates: broomhead_king.\nNumerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries: numericallyapunov.","category":"page"},{"location":"contents/#[Periodicity](@ref)-1","page":"Contents","title":"Periodicity","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Numerical method to find unstable and stable fixed points of any order n of a discrete map (of any dimensionality): periodicorbits.\nConvenience functions for defining and realizing all possible combinations of mathbfLambda_k matrices required in the above method.\nEstimating the period of a timeseries: estimate_period.","category":"page"},{"location":"contents/#RecurrenceAnalysis-1","page":"Contents","title":"RecurrenceAnalysis","text":"","category":"section"},{"location":"contents/#","page":"Contents","title":"Contents","text":"RecurrenceAnalysis offers tools to compute and analyze Recurrence Plots, a field called Recurrence Quantification Analysis.","category":"page"},{"location":"contents/#","page":"Contents","title":"Contents","text":"Recurrence Plots, with cross-recurrence and joint-recurrence.\nRecurrence Quantification Analysis (RQA):\nRecurrence rate, determinism, average/maximum diagonal length, divergence, laminarity, trend, entropy, trapping time, average/maximum vertical length.\nFine-tuning of the algorithms that compute the above (e.g. Theiler window and many more)\nWindowed RQA of the above","category":"page"},{"location":"chaos/orbitdiagram/#Orbit-Diagrams-and-PSOS-1","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"","category":"section"},{"location":"chaos/orbitdiagram/#Orbit-Diagrams-of-Maps-1","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams of Maps","text":"","category":"section"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"An orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"orbitdiagram","category":"page"},{"location":"chaos/orbitdiagram/#ChaosTools.orbitdiagram","page":"Orbit Diagrams & PSOS","title":"ChaosTools.orbitdiagram","text":"orbitdiagram(ds::DiscreteDynamicalSystem, i, p_index, pvalues; kwargs...)\n\nCompute the orbit diagram (also called bifurcation diagram) of the given system, saving the i variable(s) for parameter values pvalues. The p_index specifies which parameter of the equations of motion is to be changed.\n\ni can be Int or AbstractVector{Int}. If i is Int, returns a vector of vectors. Else it returns vectors of vectors of vectors. Each entry are the points at each parameter value.\n\nKeyword Arguments\n\nTtr::Int = 1000 : Transient steps; each orbit is evolved for Ttr first before saving output.\nn::Int = 100 : Amount of points to save for each initial condition.\ndt = 1 : Stepping time. Changing this will give you the orbit diagram of the dt order map.\nu0 = get_state(ds) : Initial condition. Besides a vector you can also give a vector of vectors such that length(u0) == length(pvalues). Then each parameter has a different initial condition.\n\nSee also poincaresos and produce_orbitdiagram.\n\n\n\n\n\n","category":"function"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"For example, let's compute the famous orbit diagram of the logistic map:","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"using DynamicalSystems\nusing PyPlot\n\nds = Systems.logistic()\ni = 1\npvalues = 3:0.001:4\nics = [rand() for m in 1:10]\nn = 2000\nTtr = 2000\np_index = 1\noutput = orbitdiagram(ds, i, p_index, pvalues; n = n, Ttr = Ttr)\n\nL = length(pvalues)\nx = Vector{Float64}(undef, n*L)\ny = copy(x)\nfor j in 1:L\n    x[(1 + (j-1)*n):j*n] .= pvalues[j]\n    y[(1 + (j-1)*n):j*n] .= output[j]\nend\n\nfigure()\nPyPlot.title(\"total points: $(L*n)\")\nplot(x, y, ls = \"None\", ms = 0.5, color = \"black\", marker = \"o\", alpha = 0.05)\nxlim(pvalues[1], pvalues[end]); ylim(0,1)\nxlabel(\"\\$r\\$\"); ylabel(\"\\$x\\$\")\ntight_layout()\nsavefig(\"logostic_od.png\"); nothing # hide","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"(Image: )","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"Notice that if you are using PyPlot, the plotting process will be slow, since it is slow at plotting big numbers of points.","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"The function is not limited to 1D maps, and can be applied just as well to any discrete system.","category":"page"},{"location":"chaos/orbitdiagram/#Poincaré-Surface-of-Section-1","page":"Orbit Diagrams & PSOS","title":"Poincaré Surface of Section","text":"","category":"section"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"Also called Poincaré map is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"poincaresos","category":"page"},{"location":"chaos/orbitdiagram/#ChaosTools.poincaresos","page":"Orbit Diagrams & PSOS","title":"ChaosTools.poincaresos","text":"poincaresos(ds::ContinuousDynamicalSystem, plane, tfinal = 1000.0; kwargs...)\n\nCalculate the Poincaré surface of section (also called Poincaré map) [1, 2] of the given system with the given plane. The system is evolved for total time of tfinal.\n\nIf the state of the system is mathbfu = (u_1 ldots u_D) then the equation defining a hyperplane is\n\na_1u_1 + dots + a_Du_D = mathbfacdotmathbfu=b\n\nwhere mathbfa b are the parameters of the hyperplane.\n\nIn code, plane can be either:\n\nA Tuple{Int, <: Number}, like (j, r) : the plane is defined as when the j variable of the system equals the value r.\nA vector of length D+1. The first D elements of the vector correspond to mathbfa while the last element is b.\n\nReturns a Dataset of the points that are on the surface of section.\n\nKeyword Arguments\n\ndirection = -1 : Only crossings with sign(direction) are considered to belong to the surface of section. Positive direction means going from less than b to greater than b.\nidxs = 1:dimension(ds) : Optionally you can choose which variables to save. Defaults to the entire state.\nTtr = 0.0 : Transient time to evolve the system before starting to compute the PSOS.\nu0 = get_state(ds) : Specify an initial state.\nwarning = true : Throw a warning if the Poincaré section was empty.\nrootkw = (xrtol = 1e-6, atol = 1e-6) : A NamedTuple of keyword arguments passed to find_zero from Roots.jl.\ndiffeq... : All other extra keyword arguments are propagated into init of DifferentialEquations.jl. See trajectory for examples.\n\nPerformance Notes\n\nThis function uses a standard integrator. For loops over initial conditions and/or parameters you should use the low level method that accepts an integrator and reinit! to new initial conditions. See the \"advanced documentation\" for more.\n\nThe low level call signature is:\n\npoincaresos(integ, planecrossing, tfinal, Ttr, idxs, rootkw)\n\nwhere\n\nplanecrossing = PlaneCrossing(plane, direction > 0)\n\nand idxs must be Int or SVector{Int}.\n\nReferences\n\n[1] : H. Poincaré, Les Methods Nouvelles de la Mécanique Celeste, Paris: Gauthier-Villars (1892)\n\n[2] : M. Tabor, Chaos and Integrability in Nonlinear Dynamics: An Introduction, §4.1, in pp. 118-126, New York: Wiley (1989)\n\nSee also orbitdiagram, produce_orbitdiagram.\n\n\n\n\n\n","category":"function"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"Here is an example of the Henon-Heiles system showing the mixed nature of the phase space","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"using DynamicalSystems, PyPlot\n\nhh = Systems.henonheiles()\n\nplane = (1, 0.0)\nu0s = [[0.0, -0.25, 0.42081, 0.0],\n[0.0, -0.31596, 0.354461, 0.0591255],\n[0.0, 0.1, 0.5, 0.0],\n[0.0, -0.0910355, 0.459522, -0.173339],\n[0.0, -0.205144, 0.449328, -0.0162098]]\n\nfigure()\nfor u0 in u0s\n    psos = poincaresos(hh, plane, 20000.0; u0 = u0)\n    scatter(psos[:, 2], psos[:, 4], s = 2.0)\nend\nxlabel(\"\\$q_2\\$\"); ylabel(\"\\$p_2\\$\")\nsavefig(\"hhpsos.png\"); nothing # hide","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"(Image: )","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"Here the surface of section was the (hyper-) plane that q_1 = 0. Some chaotic and regular orbits can be seen in the plot. You can tell the regular orbits apart because they look like a single connected curve. This is the result of cutting a 2-torus by a plane!","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"Finally here is one more example with a more complex hyperplane:","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"gis = Systems.gissinger([2.32865, 2.02514, 1.98312])\n\n# Define appropriate hyperplane for gissinger system\nconst ν = 0.1\nconst Γ = 0.9 # default parameters of the system\n\n# I want hyperperplane defined by these two points:\nNp(μ) = SVector{3}(sqrt(ν + Γ*sqrt(ν/μ)), -sqrt(μ + Γ*sqrt(μ/ν)), -sqrt(μ*ν))\nNm(μ) = SVector{3}(-sqrt(ν + Γ*sqrt(ν/μ)), sqrt(μ + Γ*sqrt(μ/ν)), -sqrt(μ*ν))\n\n# Create hyperplane passing through Np, Nm and 0:\nusing LinearAlgebra\ngis_plane(μ) = [cross(Np(μ), Nm(μ))..., 0]\n\nμ = 0.119\nset_parameter!(gis, 1, μ)\nfigure(figsize = (8,6))\npsos = poincaresos(gis, gis_plane(μ), 10000.0, Ttr = 200.0,)\nplot3D(columns(psos)..., marker = \"o\", ls = \"None\", ms = 2.0);\nxlabel(\"Q\"); ylabel(\"D\"); zlabel(\"V\");\nsavefig(\"gispsos.png\"); nothing # hide","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"(Image: )","category":"page"},{"location":"chaos/orbitdiagram/#Stroboscopic-Map-1","page":"Orbit Diagrams & PSOS","title":"Stroboscopic Map","text":"","category":"section"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"A special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the Systems.duffing oscillator.","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"A \"cut\" through the phase-space can be produced at every period T = 2piomega. There is no reason to use poincaresos for this though, because you can simply use trajectory and get the solution with a certain time sampling rate. For example, this piece of code:","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"using DynamicalSystems, Plots\n\nds = Systems.duffing(β = -1, ω = 1, f = 0.3) # non-autonomous chaotic system\n\nframes=120\na = trajectory(ds, 100000.0, dt = 2π/frames, Ttr=20π) # every period T = 2π/ω\n\norbit_length = div(size(a)[1], frames)\na = Matrix(a)\n\n@gif for i in 1:frames\n    orbit_points = i:frames:(orbit_length*frames)\n    scatter(a[orbit_points, 1], a[orbit_points, 2], markersize=1, html_output_format=:png,\n        leg=false, framestyle=:none, xlims=extrema(a[:,1]), ylims=extrema(a[:,2]))\nend","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"Produces this nice animation:","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"(Image: )","category":"page"},{"location":"chaos/orbitdiagram/#Producing-Orbit-Diagrams-for-Flows-1","page":"Orbit Diagrams & PSOS","title":"Producing Orbit Diagrams for Flows","text":"","category":"section"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"The orbitdiagram does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for orbitdiagram to have meaning one must have a map.","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"If only there was a way to turn a continuous system into a map... OH WAIT! That is what poincaresos does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"We have bundled this process in the following function:","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"produce_orbitdiagram","category":"page"},{"location":"chaos/orbitdiagram/#ChaosTools.produce_orbitdiagram","page":"Orbit Diagrams & PSOS","title":"ChaosTools.produce_orbitdiagram","text":"produce_orbitdiagram(ds::ContinuousDynamicalSystem, plane, i::Int,\n                     p_index, pvalues; kwargs...)\n\nProduce an orbit diagram (also called bifurcation diagram) for the i variable(s) of the given continuous system by computing Poincaré surfaces of section using plane for the given parameter values (see poincaresos).\n\ni can be Int or AbstractVector{Int}. If i is Int, returns a vector of vectors. Else it returns a vector of vectors of vectors. Each entry are the points at each parameter value.\n\nKeyword Arguments\n\nprintparams::Bool = false : Whether to print the parameter used during computation in order to keep track of running time.\ndirection, warning, Ttr, rootkw, diffeq... : Propagated into poincaresos.\nu0 = get_state(ds) : Initial condition. Besides a vector you can also give a vector of vectors such that length(u0) == length(pvalues). Then each parameter has a different initial condition.\n\nDescription\n\nFor each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for the i variable of the system, just like it is done in orbitdiagram.\n\nThe parameter change is done as p[p_index] = value taking values from pvalues and thus you must use a parameter container that supports this (either Array, LMArray, dictionary or other).\n\nSee also poincaresos, orbitdiagram.\n\n\n\n\n\n","category":"function"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"For example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"ds = Systems.shinriki([-2, 0, 0.2])\n\npvalues = range(19, stop = 22, length = 401)\ni = 1\nplane = (2, 0.0)\ntf = 200.0\np_index = 1\n\noutput = produce_orbitdiagram(ds, plane, i, p_index, pvalues;\n                              tfinal = tf, Ttr = 200.0)\n\nfigure()\nfor (j, p) in enumerate(pvalues)\n    plot(fill(p, length(output[j])), output[j], lw = 0,\n    marker = \"o\", ms = 0.2, color = \"black\")\nend\nxlabel(\"\\$R_1\\$\"); ylabel(\"\\$V_1\\$\")\ntight_layout()\nsavefig(\"shinriki.png\"); nothing # hide","category":"page"},{"location":"chaos/orbitdiagram/#","page":"Orbit Diagrams & PSOS","title":"Orbit Diagrams & PSOS","text":"(Image: )","category":"page"},{"location":"chaos/periodicity/#Periodicity-1","page":"Periodicity","title":"Periodicity","text":"","category":"section"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"In this page we describe methods related to the periodic behavior of dynamical systems or univariate timeseries.","category":"page"},{"location":"chaos/periodicity/#Stable-and-Unstable-Periodic-Orbits-of-Maps-1","page":"Periodicity","title":"Stable and Unstable Periodic Orbits of Maps","text":"","category":"section"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the periodic orbits of a dynamical system.","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Finding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher & Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at unstable ones.","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"The functions periodicorbits and lambdamatrix implement the algorithm:","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"periodicorbits\nlambdamatrix\nlambdaperms","category":"page"},{"location":"chaos/periodicity/#ChaosTools.periodicorbits","page":"Periodicity","title":"ChaosTools.periodicorbits","text":"periodicorbits(ds::DiscreteDynamicalSystem,\n               o, ics [, λs, indss, singss]; kwargs...) -> FP\n\nFind fixed points FP of order o for the map ds using the algorithm due to Schmelcher & Diakonos [1]. ics is a collection of initial conditions (container of vectors) to be evolved.\n\nOptional Arguments\n\nThe optional arguments λs, indss, singss must be containers of appropriate values, besides λs which can also be a number. The elements of those containers are passed to: lambdamatrix(λ, inds, sings), which creates the appropriate mathbfLambda_k matrix. If these arguments are not given, a random permutation will be chosen for them, with λ=0.001.\n\nKeyword Arguments\n\nmaxiters::Int = 100000 : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\ndisttol = 1e-10 : Distance tolerance. If the 2-norm of a previous state with  the next one is ≤ disttol then it has converged to a fixed point.\ninftol = 10.0 : If a state reaches norm(state) ≥ inftol it is assumed that  it has escaped to infinity (and is thus abandoned).\nroundtol::Int = 4 : The found fixed points are rounded  to roundtol digits before pushed into the list of returned fixed points FP,  if they are not already contained in FP.  This is done so that FP doesn't contain duplicate fixed points (notice  that this has nothing to do with disttol). Turn this to typemax(Int)  to get the full precision of the algorithm.\n\nDescription\n\nThe algorithm used can detect periodic orbits by turning fixed points of the original map ds to stable ones, through the transformation\n\nmathbfx_n+1 = mathbfx_n +\nmathbfLambda_kleft(f^(o)(mathbfx_n) - mathbfx_nright)\n\nwith f = eom. The index k counts the various possible mathbfLambda_k.\n\nPerformance Notes\n\nAll initial conditions are evolved for all mathbfLambda_k which can very quickly lead to long computation times.\n\nReferences\n\n[1] : P. Schmelcher & F. K. Diakonos, Phys. Rev. Lett. 78, pp 4733 (1997)\n\n\n\n\n\n","category":"function"},{"location":"chaos/periodicity/#ChaosTools.lambdamatrix","page":"Periodicity","title":"ChaosTools.lambdamatrix","text":"lambdamatrix(λ, inds::Vector{Int}, sings) -> Λk\n\nReturn the matrix mathbfLambda_k used to create a new dynamical system with some unstable fixed points turned to stable in the function periodicorbits.\n\nArguments\n\nλ<:Real : the multiplier of the C_k matrix, with 0<λ<1.\ninds::Vector{Int} : The ith entry of this vector gives the row of the nonzero element of the ith column of C_k.\nsings::Vector{<:Real} : The element of the ith column of C_k is +1 if signs[i] > 0 and -1 otherwise (sings can also be Bool vector).\n\nCalling lambdamatrix(λ, D::Int) creates a random mathbfLambda_k by randomly generating an inds and a signs from all possible combinations. The collections of all these combinations can be obtained from the function lambdaperms.\n\nDescription\n\nEach element of inds must be unique such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.\n\nDeciding the appropriate values for λ, inds, sings is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for λ, one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.\n\nReferences\n\n[2] : D. Pingel et al., Phys. Rev. E 62, pp 2119 (2000)\n\n[3] : F. K. Diakonos et al., Phys. Rev. Lett. 81, pp 4349 (1998)\n\n\n\n\n\n","category":"function"},{"location":"chaos/periodicity/#ChaosTools.lambdaperms","page":"Periodicity","title":"ChaosTools.lambdaperms","text":"lambdaperms(D) -> indperms, singperms\n\nReturn two collections that each contain all possible combinations of indices (total of D) and signs (total of 2^D) for dimension D (see lambdamatrix).\n\n\n\n\n\n","category":"function"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"","category":"page"},{"location":"chaos/periodicity/#Standard-Map-example-1","page":"Periodicity","title":"Standard Map example","text":"","category":"section"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"For example, let's find the fixed points of the Systems.standardmap of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the signs but only one for the inds. We will also only use one λ value, and a 21×21 density of initial conditions.","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"First, initialize everything","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"using DynamicalSystems, PyPlot, StaticArrays\n\nds = Systems.standardmap()\nxs = range(0, stop = 2π, length = 21); ys = copy(xs)\nics = [SVector{2}(x,y) for x in xs for y in ys]\n\n# All permutations of [±1, ±1]:\nsingss = lambdaperms(2)[2] # second entry are the signs\n\n# I know from personal research I only need this `inds`:\nindss = [[1,2]] # <- must be container of vectors!!!\n\nλs = 0.005 # <- only this allowed to not be vector (could also be vector)\n\norders = [2, 3, 4, 5, 6, 8]\nALLFP = Dataset{2, Float64}[];","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Then, do the necessary computations for all orders","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"for o in orders\n    FP = periodicorbits(ds, o, ics, λs, indss, singss)\n    push!(ALLFP, FP)\nend","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Plot the phase space of the standard map","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"iters = 1000\ndataset = trajectory(ds, iters)\nfor x in xs\n    for y in ys\n        append!(dataset, trajectory(ds, iters, SVector{2}(x, y)))\n    end\nend\nfigure(figsize = (12,12))\nm = Matrix(dataset)\nPyPlot.scatter(view(m, :, 1), view(m, :, 2), s= 1, color = \"black\")\nPyPlot.xlim(xs[1], xs[end])\nPyPlot.ylim(ys[1], ys[end]);","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"and finally, plot the fixed points","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"markers = [\"D\", \"^\", \"s\", \"p\", \"h\", \"8\"]\ncolors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"grey\"]\n\nfor i in 1:6\n    FP = ALLFP[i]\n    o = orders[i]\n    PyPlot.plot(columns(FP)...,\n    marker=markers[i], color = colors[i], markersize=10.0 + (8-o), linewidth=0.0,\n    label = \"order $o\", markeredgecolor = \"yellow\", markeredgewidth = 0.5)\nend\nlegend(loc=\"upper right\", framealpha=0.9)\nxlabel(\"\\$\\\\theta\\$\")\nylabel(\"\\$p\\$\")\nsavefig(\"fixedpoints.png\"); nothing # hide","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"(Image: Fixed points of the standard map)","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"You can confirm for yourself that this is correct, for many reasons:","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"It is the same fig. 12 of this publication.\nFixed points of order n are also fixed points of order 2n 3n 4n \nBesides fixed points of previous orders, original fixed points of order n come in (possible multiples of) 2n-sized pairs (see e.g. order 5). This is a direct consequence of the Poincaré–Birkhoff theorem.","category":"page"},{"location":"chaos/periodicity/#Determining-Periodicity-1","page":"Periodicity","title":"Determining Periodicity","text":"","category":"section"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Once you have determined that your system is periodic, you might want to find out what its period is.  Fortunately, the function estimate_period from ChaosTools offers many ways for you to do this, given the system's timeseries as an input.","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"We offer five methods to estimate periods, some of which work on evenly sampled data only, and others which accept any data.  The figure below summarizes this: (Image: )","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"estimate_period","category":"page"},{"location":"chaos/periodicity/#ChaosTools.estimate_period","page":"Periodicity","title":"ChaosTools.estimate_period","text":"estimate_period(v, method, t=0:length(v)-1;, method_specific_kwargs...)\n\nEstimate the period of the signal v, with accompanying time vector t, using the given method.\n\nIf t is an AbstractArray, then it is iterated through to ensure that it's evenly sampled (if necessary for the algorithm).  To avoid this, you can pass any AbstractRange, like a UnitRange or a LinRange, which are defined to be evenly sampled.\n\nMethods requiring evenly sampled data\n\nThese methods are faster, but some are error-prone.\n\n:periodogram or :pg: Use the fast Fourier transform to compute a  periodogram (power-spectrum) of the given data.  Data must be evenly sampled.\n:multitaper or mt: The multitaper method reduces estimation bias by using multiple independent estimates from the same sample. Data tapers are then windowed and the power spectra are obtained.  Available keywords follow: nw is the time-bandwidth product, and ntapers is the number of tapers. If window is not specified, the signal is tapered with ntapers discrete prolate spheroidal sequences with time-bandwidth product nw. Each sequence is equally weighted; adaptive multitaper is not (yet) supported. If window is specified, each column is applied as a taper. The sum of periodograms is normalized by the total sum of squares of window.\n:autocorrelation or :ac: Use the autocorrelation function (AC). The value where the AC first comes back close to 1 is the period of the signal. The keyword L = length(v)÷10 denotes the length of the AC (thus, given the default setting, this method will fail if there less than 10 periods in the signal). The keyword ϵ = 0.2 (\\epsilon) means that 1-ϵ counts as \"1\" for the AC.\n\nMethods not requiring evenly sampled data\n\nThese methods tend to be slow, but versatile and low-error.\n\n:lombscargle or :ls: Use the Lomb-Scargle algorithm to compute a periodogram.  The advantage of the Lomb-Scargle method is that it does not require an equally sampled dataset and performs well on undersampled datasets. Constraints have been set on the period, since Lomb-Scargle tends to have false peaks at very low frequencies.  That being said, it's a very flexible method.  It is extremely customizable, and the keyword arguments that can be passed to it are given in the documentation.\n:zerocrossing or :zc: Find the zero crossings of the data, and use the average difference between zero crossings as the period.  This is a naïve implementation, with only linear interpolation; however, it's useful as a sanity check.  The keyword line controls where the \"crossing point\" is. It deffaults to mean(v).\n\nFor more information on the periodogram methods, see the documentation of DSP.jl and LombScargle.jl.\n\n\n\n\n\n","category":"function"},{"location":"chaos/periodicity/#Example-1","page":"Periodicity","title":"Example","text":"","category":"section"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Here we will use a modified FitzHugh-Nagumo system that results in periodic behavior, and then try to estimate its period. First, let's see the trajectory:","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"using DynamicalSystems, PyPlot\n\nfunction FHN(u, p, t)\n    e, b, g = p\n    v, w = u\n    dv = min(max(-2 - v, v), 2 - v) - w\n    dw = e*(v - g*w + b)\n    return SVector(dv, dw)\nend\n\ng, e, b  = 0.8, 0.04, 0.0\np0 = [e, b, g]\n\nfhn = ContinuousDynamicalSystem(FHN, SVector(-2, -0.6667), p0)\nT, dt = 1000.0, 0.1\nv = trajectory(fhn, T; dt = dt)[:, 1]\nt = 0:dt:T\n\nfigure()\nplot(0:dt:T, v)\nsavefig(\"fhn_trajectory.png\"); nothing # hide","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"(Image: A periodic trajectory)","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"Examining the figure, one can see that the period of the system is around 91 time units. To estimate it numerically let's use some of the methods:","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"estimate_period(v, :autocorrelation, t)","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"estimate_period(v, :periodogram, t)","category":"page"},{"location":"chaos/periodicity/#","page":"Periodicity","title":"Periodicity","text":"estimate_period(v, :zerocrossing, t)","category":"page"},{"location":"ds/predefined/#Predefined-Dynamical-Systems-1","page":"Predefined Dynamical Systems","title":"Predefined Dynamical Systems","text":"","category":"section"},{"location":"ds/predefined/#","page":"Predefined Dynamical Systems","title":"Predefined Dynamical Systems","text":"Predefined systems exist in the Systems submodule in the form of functions that return a DynamicalSystem. They are accessed like:","category":"page"},{"location":"ds/predefined/#","page":"Predefined Dynamical Systems","title":"Predefined Dynamical Systems","text":"using DynamicalSystems # or DynamicalSystemsBase\nds = Systems.lorenz(ρ = 32.0)","category":"page"},{"location":"ds/predefined/#","page":"Predefined Dynamical Systems","title":"Predefined Dynamical Systems","text":"So far, the predefined systems that exist in the Systems sub-module are:","category":"page"},{"location":"ds/predefined/#","page":"Predefined Dynamical Systems","title":"Predefined Dynamical Systems","text":"Modules = [Systems]\nOrder   = [:function]","category":"page"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.antidots","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.antidots","text":"antidots(u; B = 1.0, d0 = 0.3, c = 0.2)\n\nAn antidot \"superlattice\" is a Hamiltonian system that corresponds to a smoothened periodic Sinai billiard with disk diameter d0 and smooth factor c [1].\n\nThis version is the two dimensional classical form of the system, with quadratic equations of motion and a perpendicular magnetic field. Notice that the equations of motion are with respect to the velocity instead of momentum, i.e.:\n\nbeginaligned\ndotx = v_x \ndoty = v_y \ndotv_x = B*v_y - U_x \ndotv_y = -B*v_x - U_X \nendaligned\n\nwith U the potential energy:\n\nU = left(tfrac1c^4right) lefttfracd_02 + c - r_aright^4\n\nif r_a = sqrt(x1)^2 + (y1)^2  fracd_02 + c and 0 otherwise. I.e. the potential is periodic with period 1 in both x y and normalized such that for energy value of 1 it is a circle of diameter d0. The magnetic field is also normalized such that for value B=1 the cyclotron diameter is 1.\n\nFo more details see [1].\n\n[1] : G. Datseris et al, arXiv:1711.05833v3\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.arnoldcat","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.arnoldcat","text":"arnoldcat(u0 = rand(2))\n\nf(xy) = (2x+yx+y) mod 1\n\nArnold's cat map. A chaotic map from the torus into itself, discovered by Vladimir Arnold in the 1960s. [1]\n\n[1] : Arnol'd, V. I., & Avez, A. (1968). Ergodic problems of classical mechanics.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.chua","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.chua","text":"chua(u0 = [0.7, 0.0, 0.0]; a = 15.6, b = 25.58, m0 = -8/7, m1 = -5/7)\n\nbeginaligned\ndotx = alpha (y - h(x))\ndoty = x - y+z \ndotz = beta y\nendaligned\n\nwhere h(x) is defined by\n\nh(x) = m_1 x + frac 1 2 (m_0 - m_1)(x + 1 - x - 1)\n\nThis is a 3D continuous system that exhibits chaos.\n\nChua designed an electronic circuit with the expressed goal of exhibiting chaotic motion, and this system is obtained by rescaling the circuit units to simplify the form of the equation. [1]\n\nThe parameters are a, b, m0 and m1. Setting a = 15.6, m0 = -8/7 and m1 = -5/7, and varying the parameter b from b = 25 to b = 51, one observes a classic period-doubling bifurcation route to chaos. [2]\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : Chua, Leon O. \"The genesis of Chua's circuit\", 1992.\n\n[2] : Leon O. Chua (2007) \"Chua circuit\", Scholarpedia, 2(10):1488.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.coupledstandardmaps","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.coupledstandardmaps","text":"coupledstandardmaps(M::Int, u0 = 0.001rand(2M); ks = ones(M), Γ = 1.0)\n\nbeginaligned\ntheta_i = theta_i + p_i \np_i = p_i + k_isin(theta_i) - Gamma left\nsin(theta_i+1 - theta_i) + sin(theta_i-1 - theta_i)\nright\nendaligned\n\nA discrete system of M nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The total dimension of the system is 2M. The maps are coupled through Γ and the i-th map has a nonlinear parameter ks[i].\n\nThe first M entries of the state are the angles, the last M are the momenta.\n\n[1] : H. Kantz & P. Grassberger, J. Phys. A 21, pp 127–133 (1988)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.double_pendulum","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.double_pendulum","text":"double_pendulum(u0 = [π/2, 0, 0, rand()];\n                G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\nThe variables order is [θ1, dθ1/dt, θ2, dθ2/dt].\n\nJacobian is created automatically (thus methods that use the Jacobian will be slower)!\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.duffing","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.duffing","text":"duffing(u0 = [rand(), rand(), 0]; ω = 2.2, f = 27.0, d = 0.2, β = 1)\n\nThe (forced) duffing oscillator, that satisfies the equation\n\nddotx + dcdotdotx + β*x + x^3 = fcos(omega t)\n\nwith f, ω the forcing strength and frequency and d the dampening.\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.gissinger","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.gissinger","text":"gissinger(u0 = 3rand(3); μ = 0.119, ν = 0.1, Γ = 0.9)\n\nbeginaligned\ndotQ = mu Q - VD \ndotD = -nu D + VQ \ndotV = Gamma -V + QD\nendaligned\n\nA continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : C. Gissinger, Eur. Phys. J. B 85, 4, pp 1-12 (2012)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.henon","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.henon","text":"henon(u0=zeros(2); a = 1.4, b = 0.3)\n\nbeginaligned\nx_n+1 = 1 - ax^2_n+y_n \ny_n+1  = bx_n\nendaligned\n\nThe Hénon map is a two-dimensional mapping due to Hénon [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : M. Hénon, Commun.Math. Phys. 50, pp 69 (1976)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.henonheiles","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.henonheiles","text":"henonheiles(u0=[0, -0.25, 0.42081,0])\n\nbeginaligned\ndotx = p_x \ndoty = p_y \ndotp_x = -x -2 xy \ndotp_y = -y - (x^2 - y^2)\nendaligned\n\nThe Hénon–Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.\n\nThe default initial condition is a typical chaotic orbit. The function Systems.henonheiles_ics(E, n) generates a grid of n×n initial conditions, all having the same energy E.\n\n[1] : Hénon, M. & Heiles, C., The Astronomical Journal 69, pp 73–79 (1964)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.labyrinth","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.labyrinth","text":"labyrinth(u0 = [1.0, 0, 0])\n\nbeginaligned\ndotx = sin(y) \ndoty = sin(z) \ndotV = sin(x)\nendaligned\n\nThree dimensional conservative continuous system, whose evolution in 3D space looks like a speudo-random walk, the orbit moving around like in a labyrinth.\n\nFirst proposed by René Thomas (1999). [1] See discussion in Section 4.4.3 of \"Elegant Chaos\" by J. C. Sprott. [2]\n\n[1] : Thomas, R. (1999). International Journal of Bifurcation and Chaos, 9(10), 1889-1905.\n\n[2] : Sprott, J. C. (2010). Elegant chaos: algebraically simple chaotic flows. World Scientific.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.logistic","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.logistic","text":"logistic(x0 = rand(); r = 4.0)\n\nx_n+1 = rx_n(1-x_n)\n\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensely complex graph that that was shown be universal by Feigenbaum [2].\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : R. M. May, Nature 261, pp 459 (1976)\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. 19, pp 25 (1978)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.lorenz","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.lorenz","text":"lorenz(u0=[0.0, 10.0, 0.0]; σ = 10.0, ρ = 28.0, β = 8/3) -> ds\n\nbeginaligned\ndotX = sigma(Y-X) \ndotY = -XZ + rho X -Y \ndotZ = XY - beta Z\nendaligned\n\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : E. N. Lorenz, J. atmos. Sci. 20, pp 130 (1963)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.lorenz96","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.lorenz96","text":"lorenz96(N::Int, u0 = rand(M); F=0.01)\n\nfracdx_idt = (x_i+1-x_i-2)x_i-1 - x_i + F\n\nN is the chain length, F the forcing. Jacobian is created automatically. (parameter container only contains F)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.magnetic_pendulum","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.magnetic_pendulum","text":"magnetic_pendulum(u=[cos(θ),sin(θ),0,0]; γ=1, d=0.3, α=0.2, ω=0.5, N=3)\n\nCreate a pangetic pendulum with N magnetics, equally distributed along the unit circle, with equations of motion\n\nbeginaligned\nddotx = -omega ^2x - alpha dotx - sum_i=1^N fracgamma (x - x_i)D_i^3 \nddoty = -omega ^2y - alpha doty - sum_i=1^N fracgamma (y - y_i)D_i^3 \nD_i = sqrt(x-x_i)^2  + (y-y_i)^2 + d^2\nendaligned\n\nwhere α is friction, ω is eigenfrequency, d is distance of pendulum from the magnet's plane and γ is the magnetic strength. A random initial condition is initialized by default somewhere along the unit circle with zero velocity.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.nosehoover","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.nosehoover","text":"nosehoover(u0 = [0, 0.1, 0])\n\nbeginaligned\ndotx = y \ndoty = yz - x \ndotz = 1 - y^2\nendaligned\n\nThree dimensional conservative continuous system, discovered in 1984 during investigations in thermodynamical chemistry by Nosé and Hoover, then rediscovered by Sprott during an exhaustive search as an extremely simple chaotic system. [1]\n\nSee Chapter 4 of \"Elegant Chaos\" by J. C. Sprott. [2]\n\n[1] : Hoover, W. G. (1995). Remark on ‘‘Some simple chaotic flows’’. Physical Review E, 51(1), 759.\n\n[2] : Sprott, J. C. (2010). Elegant chaos: algebraically simple chaotic flows. World Scientific.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.pomeau_manneville","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.pomeau_manneville","text":"pomaeu_manneville(u0 = 0.2; z = 2.5)\n\nThe Pomeau-Manneville map is a one dimensional discrete map which is characteristic for displaying intermittency [1]. Specifically, for z > 2 the average time between chaotic bursts diverges, while for z > 2.5, the map iterates are long range correlated [2].\n\nNotice that here we are providing the \"symmetric\" version:\n\nx_n+1 = begincases\n-4x_n + 3  quad x_n in (05 1 \nx_n(1 + 2x_n^z-1)  quad x_n le 05 \n-4x_n - 3  quad x_n in -1 05)\nendcases\n\n[1] : Manneville & Pomeau, Comm. Math. Phys. 74 (1980)\n\n[2] : Meyer et al., New. J. Phys 20 (2019)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.qbh","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.qbh","text":"qbh([u0]; A=1.0, B=0.55, D=0.4)\n\nbeginaligned\ndotq_0 = A p_0 \ndotq_2 = A p_2 \ndotp_0 = -A q_0 -3 fracBsqrt2 (q_2^2 - q_1^2) - D q_1 (q_1^2 + q_2^2) \ndotp_2 = -q_2 (A + 3sqrt2 B q_1 + D (q_1^2 + q_2^2)) (x^2 - y^2)\nendaligned\n\nThese equations of motion correspond to a Hamiltonian used in nuclear physics to study the quadrupole vibrations of the nuclear surface [1,2].\n\nH(p_0 p_2 q_0 q_2) = fracA2left(p_0^2+p_2^2right)+fracA2left(q_0^2+q_2^2right)\n\t\t\t +fracBsqrt2q_0left(3q_2^2-q_0^2right) +fracD4left(q_0^2+q_2^2right)^2\n\nThe Hamiltonian has a similar structure with the Henon-Heiles one, but it has an added fourth order term and presents a nontrivial dependence of chaoticity with the increase of energy [3]. The default initial condition is chaotic.\n\n[1]: Eisenberg, J.M., & Greiner, W., Nuclear theory 2 rev ed. Netherlands: North-Holland pp 80 (1975)\n\n[2]: Baran V. and Raduta A. A., International Journal of Modern Physics E, 7, pp 527–551 (1998)\n\n[3]: Micluta-Campeanu S., Raportaru M.C., Nicolin A.I., Baran V., Rom. Rep. Phys. 70, pp 105 (2018)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.rikitake","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.rikitake","text":"rikitake(u0 = [1, 0, 0.6]; μ = 1.0, α = 1.0)\n\nbeginaligned\ndotx = -mu x +yz \ndoty = -mu y +x(z-alpha) \ndotz = 1 - xz\nendaligned\n\nRikitake's dynamo is a system that tries to model the magnetic reversal events by means of a double-disk dynamo system.\n\n[1] : T. Rikitake Math. Proc. Camb. Phil. Soc. 54, pp 89–105, (1958)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.roessler","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.roessler","text":"roessler(u0=rand(3); a = 0.2, b = 0.2, c = 5.7)\n\nbeginaligned\ndotx = -y-z \ndoty = x+ay \ndotz = b + z(x-c)\nendaligned\n\nThis three-dimensional continuous system is due to Rössler [1]. It is a system that by design behaves similarly to the lorenz system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : O. E. Rössler, Phys. Lett. 57A, pp 397 (1976)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.shinriki","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.shinriki","text":"shinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)\n\nShinriki oscillator with all other parameters (besides R1) set to constants. This is a stiff problem, be careful when choosing solvers and tolerances.\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.standardmap","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.standardmap","text":"standardmap(u0=0.001rand(2); k = 0.971635)\n\nbeginaligned\ntheta_n+1 = theta_n + p_n+1 \np_n+1 = p_n + ksin(theta_n)\nendaligned\n\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\nThe map corresponds to the  Poincaré's surface of section of the kicked rotor system. Changing the non-linearity parameter k transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\nThe default parameter k is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable θ to be the first, and the angular momentum p to be the second, while both variables are always taken modulo 2π (the mapping is on the [0,2π)² torus).\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n[1] : B. V. Chirikov, Preprint N. 267, Institute of Nuclear Physics, Novosibirsk (1969)\n\n[2] : J. M. Greene, J. Math. Phys. 20, pp 1183 (1979)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.towel","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.towel","text":"towel(u0 = [0.085, -0.121, 0.075])\n\nbeginaligned\nx_n+1 = a x_n (1-x_n) -005 (y_n +035) (1-2z_n) \ny_n+1 = 01 left( left( y_n +035 right)left( 1+2z_nright) -1 right)\nleft( 1 -19 x_n right) \nz_n+1 = 378 z_n (1-z_n) + b y_n\nendaligned\n\nThe folded-towel map is a hyperchaotic mapping due to Rössler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.\n\nDefault values are the ones used in the original paper.\n\n[1] : O. E. Rössler, Phys. Lett. 71A, pp 155 (1979)\n\n\n\n\n\n","category":"function"},{"location":"ds/predefined/#DynamicalSystemsBase.Systems.ueda","page":"Predefined Dynamical Systems","title":"DynamicalSystemsBase.Systems.ueda","text":"ueda(u0 = [3.0, 0]; k = 0.1, B = 12.0)\n\nddotx + k dotx + x^3 = Bcost\n\nNonautonomous Duffing-like forced oscillation system, discovered by Ueda in\n\nIt is one of the first chaotic systems to be discovered.\n\nThe stroboscopic plot in the (x, ̇x) plane with period 2π creates a \"broken-egg attractor\" for k = 0.1 and B = 12. Figure 5 of [1] is reproduced by\n\nusing Plots\nds = Systems.ueda()\na = trajectory(ds, 2π*5e3, dt = 2π)\nscatter(a[:, 1], a[:, 2], markersize = 0.5, title=\"Ueda attractor\")\n\nFor more forced oscillation systems, see Chapter 2 of \"Elegant Chaos\" by J. C. Sprott. [2]\n\n[1] : Ruelle, David, ‘Strange Attractors’, The Mathematical Intelligencer, 2.3 (1980), 126–37\n\n[2] : Sprott, J. C. (2010). Elegant chaos: algebraically simple chaotic flows. World Scientific.\n\n\n\n\n\n","category":"function"},{"location":"advanced/#Advanced-documentation-1","page":"Advanced Documentation","title":"Advanced documentation","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"This section overviews the various integrators available from DynamicalSystemsBase, as well as gives some insight into the internals, so that other developers that want to use this library can build upon it.","category":"page"},{"location":"advanced/#Integrators-1","page":"Advanced Documentation","title":"Integrators","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"integrator\nparallel_integrator\ntangent_integrator","category":"page"},{"location":"advanced/#DynamicalSystemsBase.integrator","page":"Advanced Documentation","title":"DynamicalSystemsBase.integrator","text":"integrator(ds::DynamicalSystem [, u0]; diffeq...) -> integ\n\nReturn an integrator object that can be used to evolve a system interactively using step!(integ [, Δt]). Optionally specify an initial state u0.\n\nThe state of this integrator is a vector.\n\ndiffeq... are keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems.\n\n\n\n\n\n","category":"function"},{"location":"advanced/#DynamicalSystemsBase.parallel_integrator","page":"Advanced Documentation","title":"DynamicalSystemsBase.parallel_integrator","text":"parallel_integrator(ds::DynamicalSystem, states; kwargs...)\n\nReturn an integrator object that can be used to evolve many states of a system in parallel at the exact same times, using step!(integ [, Δt]).\n\nstates are expected as vectors of vectors.\n\nKeyword Arguments\n\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems. These keywords can also include callback for event handling.\n\nIt is heavily advised to use the functions get_state and set_state! to manipulate the integrator. Provide i as a second argument to change the i-th state.\n\n\n\n\n\n","category":"function"},{"location":"advanced/#DynamicalSystemsBase.tangent_integrator","page":"Advanced Documentation","title":"DynamicalSystemsBase.tangent_integrator","text":"tangent_integrator(ds::DynamicalSystem, Q0 | k::Int; kwargs...)\n\nReturn an integrator object that evolves in parallel both the system as well as deviation vectors living on the tangent space, also called linearized space.\n\nQ0 is a matrix whose columns are initial values for deviation vectors. If instead of a matrix Q0 an integer k is given, then k random orthonormal vectors are choosen as initial conditions.\n\nKeyword Arguments\n\nu0 : Optional different initial state.\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems. These keywords can also include callback for event handling.\n\nIt is heavily advised to use the functions get_state, get_deviations, set_state!, set_deviations! to manipulate the integrator.\n\nDescription\n\nIf J is the jacobian of the system then the tangent dynamics are the equations that evolve in parallel the system as well as a deviation vector (or matrix) w:\n\nbeginaligned\ndotu = f(u p t) \ndotw = J(u p t) times w\nendaligned\n\nwith f being the equations of motion and u the system state. Similar equations hold for the discrete case.\n\n\n\n\n\n","category":"function"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"Notice that the state type integrator.u of each integrator is quite different and does change between the possible versions of a DynamicalSystem!","category":"page"},{"location":"advanced/#Integrator-state-functions-1","page":"Advanced Documentation","title":"Integrator state functions","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"There are four functions associated with the integrators that we export:","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"get_state\nset_state!\nget_deviations\nset_deviations!","category":"page"},{"location":"advanced/#DynamicalSystemsBase.get_state","page":"Advanced Documentation","title":"DynamicalSystemsBase.get_state","text":"get_state(ds::DynamicalSystem)\n\nReturn the state of ds.\n\nget_state(integ [, i::Int = 1])\n\nReturn the state of the integrator, in the sense of the state of the dynamical system.\n\nIf the integrator is a parallel_integrator, passing i will return the i-th state. The function also correctly returns the true state of the system for tangent integrators.\n\n\n\n\n\n","category":"function"},{"location":"advanced/#DynamicalSystemsBase.set_state!","page":"Advanced Documentation","title":"DynamicalSystemsBase.set_state!","text":"set_state!(integ, u [, i::Int = 1])\n\nSet the state of the integrator to u, in the sense of the state of the dynamical system. Works for any integrator (normal, tangent, parallel).\n\nFor parallel integrator, you can choose which state to set (using i).\n\nAutomatically does u_modified!(integ, true).\n\n\n\n\n\n","category":"function"},{"location":"advanced/#DynamicalSystemsBase.get_deviations","page":"Advanced Documentation","title":"DynamicalSystemsBase.get_deviations","text":"get_deviations(tang_integ)\n\nReturn the deviation vectors of the tangent_integrator in a form of a matrix with columns the vectors.\n\n\n\n\n\n","category":"function"},{"location":"advanced/#DynamicalSystemsBase.set_deviations!","page":"Advanced Documentation","title":"DynamicalSystemsBase.set_deviations!","text":"set_deviations!(tang_integ, Q)\n\nSet the deviation vectors of the tangent_integrator to Q, which must be a matrix with each column being a deviation vector.\n\nAutomatically does u_modified!(tang_integ, true).\n\n\n\n\n\n","category":"function"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"note: Note\nThese functions work with any possible integrator and it is best to use the to change states robustly!","category":"page"},{"location":"advanced/#Re-initializing-an-integrator-1","page":"Advanced Documentation","title":"Re-initializing an integrator","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"It is more efficient to re-initialize an integrator using reinit! than to create a new one. This can be very helpful when looping over initial conditions and/or parameter values.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"All high-level functions from ChaosTools have a set-up part that creates an integrator, and a low-level part that does the computation. The low level part is your friend! Use it! See the Using GALI page for an example as well as the section below.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"The reinit! call signature is the same for continuous and discrete systems. In the following, state is supposed to be a D dimensional vector (state of the dynamical system).","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"reinit!(integ, state) : to be used with standard integrator.\nreinit!(integ, Vector_of_states) : to be used with the parallel_integrator.\nreinit!(integ, state, Q0::AbstractMatrix) : to be used with the tangent_integrator. This three argument version of reinit! is exported from DynamicalSystemsBase.","category":"page"},{"location":"advanced/#Re-init-of-continuous-tangent-integrator-1","page":"Advanced Documentation","title":"Re-init of continuous tangent integrator","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"Here we compute the lyapunovs for many different initial conditions.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"ds = Systems.lorenz()\ntinteg = tangent_integrator(ds, 2)\nics = [rand(3) for i in 1:100]\nfor ic in ics\n  reinit!(tinteg, ic, orthonormal(3, 2))\n  λ = lyapunovs(tinteg, 1000, 0.1, 10.0)\n  # reminder: lyapunovs(tinteg, N, dt::Real, Ttr::Real = 0.0)\nend","category":"page"},{"location":"advanced/#Re-init-of-discrete-parallel-integrator-1","page":"Advanced Documentation","title":"Re-init of discrete parallel integrator","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"Here we compute the lyapunov for many different parameters.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"ds = Systems.henon()\nu0 = rand(SVector{2})\nps = 1.2:0.01:1.4\npinteg = parallel_integrator(ds, [u0, u0 + 1e-9rand(SVector{2})])\nfor p in ps\n  set_parameter!(ds, 1, p)\n  reinit!(pinteg, [u0, u0 + 1e-9rand(SVector{2})])\n  λ = lyapunov(pinteg, 1000, 10, 1, 1e-9, 1e-6, 1e-12)\n  # reminder: lyapunov(pinteg, T, Ttr, dt, d0, ut, lt)\nend","category":"page"},{"location":"advanced/#Using-callbacks-with-integrators-1","page":"Advanced Documentation","title":"Using callbacks with integrators","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"For the case of continuous systems you can add callbacks from the event handling of DifferentialEquations.jl. This is done simply as a keyword argument to the initializers.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"In this example we use a simple SavingCallback to save the distance between the two states of a parallel_integrator.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"using DynamicalSystems, DiffEqCallbacks\nusing LinearAlgebra: norm\n\nkwargs = (abstol=1e-14, reltol=1e-14, maxiters=1e9)\nds = Systems.lorenz()\nd0 = 1e-9\nT = 100.0\n\nsave_func(u, t, integrator) = norm(u[1] - u[2])\nsaved_values = SavedValues(eltype(ds.t0), eltype(get_state(ds)))\ncb = SavingCallback(save_func, saved_values)\n\nu0 = get_state(ds)\npinteg = parallel_integrator(ds, [u0, u0 + rand(SVector{3})*d0*√3];\nkwargs..., callback = cb)\nstep!(pinteg, T)\nt = saved_values.t\nn = saved_values.saveval","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"As expected you can see that the recorded distance between two states is increasing.","category":"page"},{"location":"advanced/#DynamicalSystem-implementation-1","page":"Advanced Documentation","title":"DynamicalSystem implementation","text":"","category":"section"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"abstract type DynamicalSystem{\n        IIP,     # is in place , for dispatch purposes and clarity\n        S,       # state type\n        D,       # dimension\n        F,       # equations of motion\n        P,       # parameters\n        JAC,     # jacobian\n        JM,      # jacobian matrix\n        IAD}     # is auto-differentiated\n    # one-liner: {IIP, S, D, F, P, JAC, JM, IAD}\n    # Subtypes of DynamicalSystem have fields:\n    # 1. f\n    # 2. u0\n    # 3. p\n    # 4. t0\n    # 5. jacobian (function)\n    # 6. J (matrix)\nend","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"The DynamicalSystem stores only the absolutely necessary information. Every other functionality of DynamicalSystems.jl initializes an integrator.","category":"page"},{"location":"advanced/#","page":"Advanced Documentation","title":"Advanced Documentation","text":"The final type-parameter IAD is useful when creating the tangent_integrator, so that the vector field is not computed twice!","category":"page"},{"location":"ds/general/#Dynamical-Systems-1","page":"Dynamical System Definition","title":"Dynamical Systems","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Currently a system in DynamicalSystems.jl can be either continuous","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"fracdvecudt = vecf(vecu p t)","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"or discrete","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"vecu_n+1 = vecf(vecu_n p n)","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"where p contains the parameters of the system. In addition to the above equations of motion, information about the Jacobian of the system is also part of a \"dynamical system\".","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Keep in mind that almost all functions of DynamicalSystems.jl assume that vecf is differentiable!","category":"page"},{"location":"ds/general/#Creating-a-Dynamical-System-1","page":"Dynamical System Definition","title":"Creating a Dynamical System","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"DynamicalSystem","category":"page"},{"location":"ds/general/#DynamicalSystemsBase.DynamicalSystem","page":"Dynamical System Definition","title":"DynamicalSystemsBase.DynamicalSystem","text":"DynamicalSystem\n\nThe central structure of DynamicalSystems.jl. All functions of the suite that can use known equations of motion expect an instance of this type.\n\nConstructing a DynamicalSystem\n\nDiscreteDynamicalSystem(eom, state, p [, jacobian [, J0]]; t0::Int = 0)\nContinuousDynamicalSystem(eom, state, p [, jacobian [, J0]]; t0 = 0.0)\n\nwith eom the equations of motion function (see below). p is a parameter container, which we highly suggest to use a mutable object like Array, LMArray or a dictionary. Pass nothing in the place of p if your system does not have parameters.\n\nt0, J0 allow you to choose the initial time and provide an initialized Jacobian matrix. See CDS_KWARGS for the default options used to evolve continuous systems (through OrdinaryDiffEq).\n\nEquations of motion\n\nThe are two \"versions\" for DynamicalSystem, depending on whether the equations of motion (eom) are in-place (iip) or out-of-place (oop). Here is how to define them:\n\noop : The eom must be in the form eom(x, p, t) -> SVector which means that given a state x::SVector and some parameter container p it returns an SVector (from the StaticArrays module) containing the next state.\niip : The eom must be in the form eom!(xnew, x, p, t) which means that given a state x::Vector and some parameter container p, it writes in-place the new state in xnew.\n\nt stands for time (integer for discrete systems). iip is suggested for big systems, whereas oop is suggested for small systems. The break-even point at around 100 dimensions, and for using functions that use the tangent space (like e.g. lyapunovs or gali), the break-even point is at around 10 dimensions.\n\nThe constructor deduces automatically whether eom is iip or oop. It is not possible however to deduce whether the system is continuous or discrete just from the equations of motion, hence the 2 constructors.\n\nJacobian\n\nThe optional argument jacobian for the constructors is a function and (if given) must also be of the same form as the eom, jacobian(x, p, n) -> SMatrix for the out-of-place version and jacobian!(Jnew, x, p, n) for the in-place version.\n\nIf jacobian is not given, it is constructed automatically using the module ForwardDiff. Even though ForwardDiff is very fast, depending on your exact system you might gain significant speed-up by providing a hand-coded Jacobian and so we recommend it.\n\nInterface to DifferentialEquations.jl\n\nContinuous systems are solved using DifferentialEquations.jl. The following two interfaces are provided:\n\nContinuousDynamicalSystem(prob::ODEProblem [, jacobian [, J0]])\nODEProblem(continuous_dynamical_system, tspan, args...)\n\nwhere in the second case args stands for the standard extra arguments of ODEProblem: callback, mass_matrix.\n\nIf you want to use callbacks with tangent_integrator or parallel_integrator, then invoke them with extra arguments as shown in the Advanced Documentation.\n\nRelevant Functions\n\ntrajectory, set_parameter!.\n\n\n\n\n\n","category":"type"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"","category":"page"},{"location":"ds/general/#Definition-Table-1","page":"Dynamical System Definition","title":"Definition Table","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Here is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"System Type equations of motion Jacobian\nin-place (big systems) eom!(du, u, p, t) jacobian!(J, u, p, t)\nout-of-place (small systems) eom(u, p, t) -> SVector jacobian(u, p, t) -> SMatrix","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"tip: Use mutable containers for the parameters\nIt is highly suggested to use a subtype of Array,  LMArray or a dictionary for the container of the model's parameters. Some functions offered by DynamicalSystems.jl, like e.g. orbitdiagram, assume that the parameters can be first accessed by p[x] with x some qualifier as well as that this value can be set by p[x] = newvalue.The Labelled Arrays package offers Array implementations that can be accessed both by index as well as by some name.","category":"page"},{"location":"ds/general/#General-Functions-1","page":"Dynamical System Definition","title":"General Functions","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"The following functions are defined for convenience for any dynamical system:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"dimension\njacobian\nset_parameter!","category":"page"},{"location":"ds/general/#DynamicalSystemsBase.dimension","page":"Dynamical System Definition","title":"DynamicalSystemsBase.dimension","text":"dimension(thing) -> D\n\nReturn the dimension of the thing, in the sense of state-space dimensionality.\n\n\n\n\n\n","category":"function"},{"location":"ds/general/#DynamicalSystemsBase.jacobian","page":"Dynamical System Definition","title":"DynamicalSystemsBase.jacobian","text":"jacobian(ds::DynamicalSystem, u = ds.u0, t = ds.t0)\n\nReturn the jacobian of the system at u, at t.\n\n\n\n\n\n","category":"function"},{"location":"ds/general/#DynamicalSystemsBase.set_parameter!","page":"Dynamical System Definition","title":"DynamicalSystemsBase.set_parameter!","text":"set_parameter!(ds::DynamicalSystem, index, value)\nset_parameter!(ds::DynamicalSystem, values)\n\nChange one or many parameters of the system by setting p[index] = value in the first case and p .= values in the second.\n\nThe same function also works for any integrator.\n\n\n\n\n\n","category":"function"},{"location":"ds/general/#Examples-1","page":"Dynamical System Definition","title":"Examples","text":"","category":"section"},{"location":"ds/general/#Continuous,-out-of-place-1","page":"Dynamical System Definition","title":"Continuous, out-of-place","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Let's see an example for a small system, which is a case where out-of-place equations of motion are preferred.","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"using DynamicalSystems # also exports relevant StaticArrays names\n# Lorenz system\n# Equations of motion:\n@inline @inbounds function loop(u, p, t)\n    σ = p[1]; ρ = p[2]; β = p[3]\n    du1 = σ*(u[2]-u[1])\n    du2 = u[1]*(ρ-u[3]) - u[2]\n    du3 = u[1]*u[2] - β*u[3]\n    return SVector{3}(du1, du2, du3)\nend\n# Jacobian:\n@inline @inbounds function loop_jac(u, p, t)\n    σ, ρ, β = p\n    J = @SMatrix [-σ  σ  0;\n    ρ - u[3]  (-1)  (-u[1]);\n    u[2]   u[1]  -β]\n    return J\nend\n\nds = ContinuousDynamicalSystem(loop, rand(3), [10.0, 28.0, 8/3], loop_jac)","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"3-dimensional continuous dynamical system\n state:     [0.068248, 0.828095, 0.0743729]\n e.o.m.:    loop\n in-place?  false\n jacobian:  loop_jac","category":"page"},{"location":"ds/general/#Discrete,-in-place-1","page":"Dynamical System Definition","title":"Discrete, in-place","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"The following example is only 2-dimensional, and thus once again it is \"correct\" to use out-of-place version with SVector. For the sake of example though, we use the in-place version.","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"# Henon map.\n# equations of motion:\nfunction hiip(dx, x, p, n)\n    dx[1] = 1.0 - p[1]*x[1]^2 + x[2]\n    dx[2] = p[2]*x[1]\n    return\nend\n# Jacobian:\nfunction hiip_jac(J, x, p, n)\n    J[1,1] = -2*p[1]*x[1]\n    J[1,2] = 1.0\n    J[2,1] = p[2]\n    J[2,2] = 0.0\n    return\nend\nds = DiscreteDynamicalSystem(hiip, zeros(2), [1.4, 0.3], hiip_jac)","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  hiip_jac","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Or, if you don't want to write a Jacobian and want to use the auto-differentiation capabilities of DynamicalSystems.jl, which use the module ForwardDiff:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"ds = DiscreteDynamicalSystem(hiip, zeros(2), [1.4, 0.3])","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  ForwardDiff","category":"page"},{"location":"ds/general/#Complex-Example-1","page":"Dynamical System Definition","title":"Complex Example","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"In this example we will go through the implementation of the coupled standard maps from our Predefined Dynamical Systems. It is the most complex implementation and takes full advantage of the flexibility of the constructors. The example will use a Functor as equations of motion, as well as a sparse matrix for the Jacobian.","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Coupled standard maps is a big mapping that can have arbitrary number of equations of motion, since you can couple N standard maps which are 2D maps, like:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"theta_i = theta_i + p_i \np_i = p_i + k_isin(theta_i) - Gamma leftsin(theta_i+1 - theta_i) + sin(theta_i-1 - theta_i) right","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"To model this, we will make a dedicated struct, which is parameterized on the number of coupled maps:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"struct CoupledStandardMaps{N}\n    idxs::SVector{N, Int}\n    idxsm1::SVector{N, Int}\n    idxsp1::SVector{N, Int}\nend","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"(what these fields are will become apparent later)","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"We initialize the struct with the amount of standard maps we want to couple, and we also define appropriate parameters:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"M = 5  # couple number\nu0 = 0.001rand(2M) #initial state\nks = 0.9ones(M) # nonlinearity parameters\nΓ = 1.0 # coupling strength\np = (ks, Γ) # parameter container\n\n# Create struct:\nSV = SVector{M, Int}\nidxs = SV(1:M...) # indexes of thetas\nidxsm1 = SV(circshift(idxs, +1)...)  #indexes of thetas - 1\nidxsp1 = SV(circshift(idxs, -1)...)  #indexes of thetas + 1\n# So that:\n# x[i] ≡ θᵢ\n# x[[idxsp1[i]]] ≡ θᵢ+₁\n# x[[idxsm1[i]]] ≡ θᵢ-₁\ncsm = CoupledStandardMaps{M}(idxs, idxsm1, idxsp1);","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"We will now use this struct to define a functor, a Type that also acts as a function.","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"function (f::CoupledStandardMaps{N})(xnew::AbstractVector, x, p, n) where {N}\n    ks, Γ = p\n    @inbounds for i in f.idxs\n\n        xnew[i+N] = mod2pi(\n            x[i+N] + ks[i]*sin(x[i]) -\n            Γ*(sin(x[f.idxsp1[i]] - x[i]) + sin(x[f.idxsm1[i]] - x[i]))\n        )\n\n        xnew[i] = mod2pi(x[i] + xnew[i+N])\n    end\n    return nothing\nend","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"We will use the same struct to create a function for the Jacobian:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"function (f::CoupledStandardMaps{M})(\n    J::AbstractMatrix, x, p, n) where {M}\n\n    ks, Γ = p\n    # x[i] ≡ θᵢ\n    # x[[idxsp1[i]]] ≡ θᵢ+₁\n    # x[[idxsm1[i]]] ≡ θᵢ-₁\n    @inbounds for i in f.idxs\n        cosθ = cos(x[i])\n        cosθp= cos(x[f.idxsp1[i]] - x[i])\n        cosθm= cos(x[f.idxsm1[i]] - x[i])\n        J[i+M, i] = ks[i]*cosθ + Γ*(cosθp + cosθm)\n        J[i+M, f.idxsm1[i]] = - Γ*cosθm\n        J[i+M, f.idxsp1[i]] = - Γ*cosθp\n        J[i, i] = 1 + J[i+M, i]\n        J[i, f.idxsm1[i]] = J[i+M, f.idxsm1[i]]\n        J[i, f.idxsp1[i]] = J[i+M, f.idxsp1[i]]\n    end\n    return nothing\nend","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"The only reason that this is possible, is because the eom always takes a AbstractVector as first argument, while the Jacobian always takes an AbstractMatrix. Therefore we can take advantage of multiple dispatch!","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Notice in addition, that the Jacobian function accesses only half the elements of the matrix. This is intentional, and takes advantage of the fact that the other half is constant. We can leverage this further, by making the Jacobian a sparse matrix. Because the DynamicalSystem constructors allow us to give in a pre-initialized Jacobian matrix, we take advantage of that and create:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"J = zeros(eltype(u0), 2M, 2M)\n# Set ∂/∂p entries (they are eye(M,M))\n# And they dont change they are constants\nfor i in idxs\n    J[i, i+M] = 1\n    J[i+M, i+M] = 1\nend\nsparseJ = sparse(J)\n\ncsm(sparseJ, u0, p, 0) # apply Jacobian to initial state","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"And finally, we are ready to create our dynamical system:","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"ds = DiscreteDynamicalSystem(csm, u0, p, csm, sparseJ)","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"10-dimensional discrete dynamical system\n state:       [0.000803001, 0.00092095, 0.000313022, …, 3.07769e-5, 0.000670152]\n e.o.m.:      CoupledStandardMaps\n in-place?    true\n jacobian:    CoupledStandardMaps\n parameters:  Tuple","category":"page"},{"location":"ds/general/#A-comment-on-using-automatic-Jacobians-1","page":"Dynamical System Definition","title":"A comment on using automatic Jacobians","text":"","category":"section"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"Notice that if you are using automatic differentiation for the Jacobian, you should take care to not define your equations of motion so that they explicitly use, or return, Float64 numbers. This is because ForwardDiff uses DualNumbers for differentiation. For example, if you did","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"function lorenz(u,p,t)\n    σ, ρ, β = p\n    dx = zeros(3)\n    du1 = σ*(u[2] - u[1]) +\n    du2 = u[1]*(ρ - u[3]) - u[2]\n    du3 = u[1]*u[2] - β*u[3]\n    return SVector{Float64, 3}(du1, du2, du3)\nend","category":"page"},{"location":"ds/general/#","page":"Dynamical System Definition","title":"Dynamical System Definition","text":"this function could not be used to autodifferentiate, as you would get an error when adding dual numbers to SVector{Float64}. Instead, leave the number type untyped, or use eltype(u) as the number type.","category":"page"},{"location":"embedding/reconstruction/#Delay-Coordinates-Embedding-1","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"","category":"section"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as delay coordinates embedding or delay coordinates reconstruction.","category":"page"},{"location":"embedding/reconstruction/#Reconstruct/Embed-1","page":"Delay Coordinates Embedding","title":"Reconstruct/Embed","text":"","category":"section"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"Delay embedding reconstructions are done through reconstruct or embed:","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"reconstruct\nembed","category":"page"},{"location":"embedding/reconstruction/#DelayEmbeddings.reconstruct","page":"Delay Coordinates Embedding","title":"DelayEmbeddings.reconstruct","text":"reconstruct(s, γ, τ [, w])\n\nReconstruct s using the delay coordinates embedding with γ temporal neighbors and delay τ and return the result as a Dataset.\n\nUse embed for the version that accepts the embedding dimension D = γ+1 instead.\n\nDescription\n\nSingle Timeseries\n\nIf τ is an integer, then the n-th entry of the embedded space is\n\n(s(n) s(n+tau) s(n+2tau) dots s(n+γtau))\n\nIf instead τ is a vector of integers, so that length(τ) == γ, then the n-th entry is\n\n(s(n) s(n+tau1) s(n+tau2) dots s(n+tauγ))\n\nThe reconstructed dataset can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper γ and τ. This is known as the Takens embedding theorem [1, 2]. The case of different delay times allows reconstructing systems with many time scales, see [3].\n\nNotice - The dimension of the returned dataset (i.e. embedding dimension) is γ+1!\n\nIf w (a \"weight\") is provided as an extra argument, then the entries of the embedded vector are further weighted with w^gamma, like so\n\n(s(n) w*s(n+tau) w^2*s(n+2tau) dotsw^gamma * s(n+γtau))\n\nMultiple Timeseries\n\nTo make a reconstruction out of a multiple timeseries (i.e. trajectory) the number of timeseries must be known by type, so s can be either:\n\ns::AbstractDataset{B}\ns::SizedAray{A, B}\n\nIf the trajectory is for example (x y) and τ is integer, then the n-th entry of the embedded space is\n\n(x(n) y(n) x(n+tau) y(n+tau) dots x(n+γtau) y(n+γtau))\n\nIf τ is an AbstractMatrix{Int}, so that size(τ) == (γ, B), then we have\n\n(x(n) y(n) x(n+tau1 1) y(n+tau1 2) dots x(n+tauγ 1) y(n+tauγ 2))\n\nNotice - The dimension of the returned dataset is (γ+1)*B!\n\nReferences\n\n[1] : F. Takens, Detecting Strange Attractors in Turbulence — Dynamical Systems and Turbulence, Lecture Notes in Mathematics 366, Springer (1981)\n\n[2] : T. Sauer et al., J. Stat. Phys. 65, pp 579 (1991)\n\n[3] : K. Judd & A. Mees, Physica D 120, pp 273 (1998)\n\n\n\n\n\n","category":"function"},{"location":"embedding/reconstruction/#DelayEmbeddings.embed","page":"Delay Coordinates Embedding","title":"DelayEmbeddings.embed","text":"embed(s, D, τ)\n\nPerform a delay coordinates embedding on signal s with embedding dimension D and delay time τ. The result is returned as a Dataset, which is a vector of static vectors.\n\nSee reconstruct for an advanced version that supports multiple delay times and can reconstruct multiple timeseries efficiently.\n\n\n\n\n\n","category":"function"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"Here are some examples of reconstructing a 3D continuous chaotic system:","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"using DynamicalSystems, PyPlot\n\nds = Systems.gissinger(ones(3))\ndata = trajectory(ds, 1000.0, dt = 0.05)\n\nxyz = columns(data)\n\nfigure(figsize = (12,10))\nk = 1\nfor i in 1:3\n    for τ in [5, 30, 100]\n        R = reconstruct(xyz[i], 1, τ)\n        ax = subplot(3,3,k)\n        plot(R[:, 1], R[:, 2], color = \"C$(k-1)\", lw = 0.8)\n        title(\"var = $i, τ = $τ\")\n        global k+=1\n    end\nend\n\ntight_layout()\nsuptitle(\"2D reconstructed space\")\nsubplots_adjust(top=0.9)\nsavefig(\"simple_reconstruction.png\"); nothing # hide","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"(Image: )","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"note: `τ` and `dt`\nKeep in mind that whether a value of τ is \"reasonable\" for continuous systems depends on dt. In the above example the value τ=30 is good, only for the case of using dt = 0.05. For shorter/longer dt one has to adjust properly τ so that their product τ*dt is the same.","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"You can also reconstruct multidimensional timeseries. For this to be possible, the number of timeseries must be known by Type:","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"using StaticArrays: Size\na = rand(1000, 3) # my trajectory\n\nA = Size(1000, 3)(a) # create array with the size as Type information\nR = reconstruct(A, 2, 2) #aaaall good","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"ds = Systems.towel(); tr = trajectory(ds, 10000)\nR = reconstruct(tr, 2, 2) # Dataset size is also known by Type!","category":"page"},{"location":"embedding/reconstruction/#Embedding-Functors-1","page":"Delay Coordinates Embedding","title":"Embedding Functors","text":"","category":"section"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"The high level functions embed, reconstruct utilize a low-level interface for creating embedded vectors on-the-fly. The high level interface simply loops over the low level interface. The low level interface is composed of the following two structures:","category":"page"},{"location":"embedding/reconstruction/#","page":"Delay Coordinates Embedding","title":"Delay Coordinates Embedding","text":"DelayEmbedding\nMTDelayEmbedding","category":"page"},{"location":"embedding/reconstruction/#DelayEmbeddings.DelayEmbedding","page":"Delay Coordinates Embedding","title":"DelayEmbeddings.DelayEmbedding","text":"DelayEmbedding(γ, τ) -> `embedding`\n\nReturn a delay coordinates embedding structure to be used as a functor, given a timeseries and some index. Calling\n\nembedding(s, n)\n\nwill create the n-th reconstructed vector of the embedded space, which has γ temporal neighbors with delay(s) τ. See reconstruct for more.\n\nBe very careful when choosing n, because @inbounds is used internally.\n\n\n\n\n\n","category":"type"},{"location":"embedding/reconstruction/#DelayEmbeddings.MTDelayEmbedding","page":"Delay Coordinates Embedding","title":"DelayEmbeddings.MTDelayEmbedding","text":"MTDelayEmbedding(γ, τ, B) -> `embedding`\n\nReturn a delay coordinates embedding structure to be used as a functor, given multiple timeseries (B in total), either as a Dataset or a SizedArray), and some index. Calling\n\nembedding(s, n)\n\nwill create the n-th reconstructed vector of the embedded space, which has γ temporal neighbors with delay(s) τ. See reconstruct for more.\n\nBe very careful when choosing n, because @inbounds is used internally.\n\n\n\n\n\n","category":"type"},{"location":"rqa/windowed/#Windowed-RQA-1","page":"Windowed RQA","title":"Windowed RQA","text":"","category":"section"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"In some cases, specially with very long time series, it may be suitable to perform the analysis at different points, considering only a limited window of data around each observation. The macro @windowed modifies the behaviour of the basic functions to calculate RQA parameters in that fashion. For instance, if rmat is a 10<sup>4</sup>&times;10<sup>4</sup> recurrence matrix, then","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"@windowed determinism(rmat, theiler=2, lmin=3) width=1000 step=100","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"will return a 91-element vector, such that each value is the determinism associated to a 1000-point fragment, starting at every 100 points (i.e. at 1, 101, &hellip; 9001).","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"The general syntax of that macro is:","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"@windowed expr w                 #1\n@windowed expr width=w step=s    #2","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"where:","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"expr is an expression used to calculate RQA parameters\nw is the width of the window for relevant data around each point.\ns is the step or distance between points where the calculations are done (starting in the first point).","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"To prevent syntax failures in the expansion of the macro, identify the RQA function (rqa, recurrencerate, determinism,...) directly by its name (avoid aliases), and use simple variable names (not complex expressions) for the arguments. On the other hand, the windowing options width and step can be given in any order. If step is ommitted, the calculations are done at every point, and the keyword width may be ommitted. (However, using step=1 may be computationally very expensive, and that will provide just overly redundant results around each point, so it is advisable to set step a relatively big fraction of the window width.)","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"The value returned by the macro will normally be a vector with the same type of numbers as expected by expr. In the case of @windowed rqa(...) ..., it will return a NamedTuple with a similar structure as in the default rqa function, but replacing scalar values by vectors.","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"The macro @windowed can also be applied to the functions that calculate recurrence matrices (RecurrenceMatrix, CrossRecurrenceMatrix, JointRecurrenceMatrix). That creates a sparse matrix with the same size as if the macro was not used, but only containing valid values for pairs of points that belong to the w first main diagonals (i.e. the separation in time from one point to the other is w or smaller). The &lsquo;step&rsquo; parameter s has no effect on those functions. Such &lsquo;windowed&rsquo; matrices can be used as the input arguments to calculate windowed RQA parameters, obtaining the same results as if the complete matrix was used (under certain conditions, see below). For instance, the following calculations are equivalent:","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"# Using complete matrix\nrmat = RecurrenceMatrix(x, 1.5)\nd = @windowed determinism(rmat) width=1000 step=250\n\n# Using windowed matrix\nrmatw = @windowed RecurrenceMatrix(x, 1.5) 1000\nd = @windowed determinism(rmatw) width=1000 step=250","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"The main difference between the two alternatives is that the second one will be faster and consume less memory. To ensure the equivalence between both approaches, the window width used to create the matrix must be greater than the one used to calculate the RQA parameters. Otherwise, the computation of RQA parameters might involve data points whose value is not well defined. Besides, the threshold to identify recurrences should be referred to a fixed scale. For instance:","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"rmat  =           RecurrenceMatrix(x, 0.1, scale=maximum)\nrmatw = @windowed RecurrenceMatrix(x, 0.1, scale=maximum) 1000\nrmat[1:1000,1:1000] == rmatw[1:1000,1:1000] # FALSE!!!","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"In this example, the 1000×1000 blocks of both matrices differ, because the threshold 0.1 is scaled with respect to the maximum distance between all points of x in rmat, but in the case of rmatw the scale changes between subsets of points. Something similar may happen if the recurrence matrix is calculated for a fixed recurrence rate (with the option fixedrate=true).","category":"page"},{"location":"rqa/windowed/#Docstring-1","page":"Windowed RQA","title":"Docstring","text":"","category":"section"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"@windowed","category":"page"},{"location":"rqa/windowed/#RecurrenceAnalysis.@windowed","page":"Windowed RQA","title":"RecurrenceAnalysis.@windowed","text":"@windowed(f(x,...), width)\n@windowed(f(x,...); width, step=1)\n\nCalculate windowed RQA parameters with a given window width.\n\nf(x,...) may be any call to RQA functions (e.g. recurrencerate, determinism, etc.), with x being a named variable that designates the recurrence matrix (do not use in-place calculations of the recurrence matrix). The results are returned in a vector with one value for each position of the window. By default the window moves at one-point intervals, but a longer step length may be specified, together with the window width, by declaring those options as keyword arguments.\n\nThis macro may be also used with recurrence matrix constructors (RecurrenceMatrix, CrossRecurrenceMatrix, JointRecurrenceMatrix), to create 'incomplete' matrices that are suitable for such windowed RQA. The values of the resulting matrix in the diagonals within the window width will be equal to those obtained without the @windowed macro, if the distances are not scaled (using the option scale=1, see RecurrenceMatrix). Outside the window width, the values of the recurrence matrix will be undefined (mostly zero).\n\n\n\n\n\n","category":"macro"},{"location":"rqa/windowed/#Alternative-syntax-for-@windowed-1","page":"Windowed RQA","title":"Alternative syntax for @windowed","text":"","category":"section"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"The following ways of using the macro @windowed are equivalent:","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"y = @windowed f(x,...) w\n@windowed y=f(x,...) w\ny = @windowed(f(x,...), w)\n@windowed(y=f(x,...), w)","category":"page"},{"location":"rqa/windowed/#","page":"Windowed RQA","title":"Windowed RQA","text":"In all four cases, the width parameter w might have been qualified with a keyword as width=w. If the step parameter is added, the keyword qualification is mandatory.","category":"page"},{"location":"chaos/lyapunovs/#Lyapunov-Exponents-1","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"","category":"section"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"Lyapunov exponents measure exponential rates of separation of nearby trajectories in the flow of a dynamical system. The Wikipedia and the Scholarpedia entries have a lot of valuable information about the history and usage of these quantities.","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"This page treats systems where the equations of motion are known. If instead you have numerical data, see numericallyapunov.","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"info: Performance depends on the solver\nNotice that the performance of functions that use ContinuousDynamicalSystems depend crucially on the chosen solver. Please see the documentation page on Choosing a solver for an in-depth discussion.","category":"page"},{"location":"chaos/lyapunovs/#Concept-of-the-Lyapunov-exponent-1","page":"Lyapunov Exponents","title":"Concept of the Lyapunov exponent","text":"","category":"section"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"Before providing the documentation of the offered functionality, it is good to demonstrate exactly what are the Lyapunov exponents.","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"For chaotic systems, nearby trajectories separate in time exponentially fast (while for stable systems they come close exponentially fast). This happens at least for small separations, and is demonstrated in the following sketch:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"(Image: ).","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"In this sketch lambda is the maximum Lyapunov exponent (and in general a system has as many exponents as its dimensionality).","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"Let's demonstrate these concepts using a real system, the Henon map:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"beginaligned\nx_n+1 = 1 - ax_n^2 + y_n \ny_n+1 = bx_n\nendaligned","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"Let's get a trajectory","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"using DynamicalSystems, PyPlot\nhenon = Systems.henon()\ntr1 = trajectory(henon, 100)\nsummary(tr1)","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"and create one more trajectory that starts very close to the first one","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"u2 = get_state(henon) + (1e-9 * ones(dimension(henon)))\ntr2 = trajectory(henon, 100, u2)\nsummary(tr2)","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"We now want to demonstrate how the distance between these two trajectories increases with time:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"using LinearAlgebra: norm\n\nfigure(figsize=(8,5))\n\n# Plot the x-coordinate of the two trajectories:\nax1 = subplot(2,1,1)\nplot(tr1[:, 1], alpha = 0.5)\nplot(tr2[:, 1], alpha = 0.5)\nylabel(\"x\")\n\n# Plot their distance in a semilog plot:\nax2 = subplot(2,1,2, sharex = ax1)\nd = [norm(tr1[i] - tr2[i]) for i in 1:length(tr2)]\nylabel(\"d\"); xlabel(\"n\"); semilogy(d);\ntight_layout() # hide\nsavefig(\"demonstration.png\"); nothing # hide","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"(Image: )","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"The initial slope of the d vs n plot (before the curve saturates) is approximately the maximum Lyapunov exponent!","category":"page"},{"location":"chaos/lyapunovs/#Lyapunov-Spectrum-1","page":"Lyapunov Exponents","title":"Lyapunov Spectrum","text":"","category":"section"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"The function lyapunovs calculates the entire spectrum of the Lyapunov exponents of a system:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"lyapunovs","category":"page"},{"location":"chaos/lyapunovs/#ChaosTools.lyapunovs","page":"Lyapunov Exponents","title":"ChaosTools.lyapunovs","text":"lyapunovs(ds::DynamicalSystem, N [, k::Int | Q0]; kwargs...) -> λs\n\nCalculate the spectrum of Lyapunov exponents [1] of ds by applying a QR-decomposition on the parallelepiped matrix N times. Return the spectrum sorted from maximum to minimum.\n\nThe third argument k is optional, and dictates how many lyapunov exponents to calculate (defaults to dimension(ds)). Instead of passing an integer k you can pass a pre-initialized matrix Q0 whose columns are initial deviation vectors (then k = size(Q0)[2]).\n\nKeyword Arguments\n\nu0 = get_state(ds) : State to start from.\nTtr = 0 : Extra \"transient\" time to evolve the system before application of the algorithm. Should be Int for discrete systems. Both the system and the deviation vectors are evolved for this time.\ndt = 1 : Time of individual evolutions between successive orthonormalization steps. For continuous systems this is approximate.\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems.\n\nDescription\n\nThe method we employ is \"H2\" of [2], originally stated in [3]. The deviation vectors defining a D-dimensional parallepiped in tangent space are evolved using the tangent dynamics of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over N successive steps, yielding the lyapunov exponent spectrum (at each step the parallepiped is re-normalized).\n\nPerformance Notes\n\nThis function uses a tangent_integrator. For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and reinit! it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is\n\nlyapunovs(tinteg, N, dt::Real, Ttr::Real)\n\nIf you want to obtain the convergence timeseries of the Lyapunov spectrum, use the method\n\nChaosTools.lyapunovs_convergence(tinteg, N, dt, Ttr)\n\n(not exported).\n\nReferences\n\n[1] : A. M. Lyapunov, The General Problem of the Stability of Motion, Taylor & Francis (1992)\n\n[2] : K. Geist et al., Progr. Theor. Phys. 83, pp 875 (1990)\n\n[3] : G. Benettin et al., Meccanica 15, pp 9-20 & 21-30 (1980)\n\n\n\n\n\n","category":"function"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"As you can see, the documentation string is detailed and self-contained. For example, the Lyapunov spectrum of the folded towel map is calculated as:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"using DynamicalSystems\n\nds = Systems.towel()\nλλ = lyapunovs(ds, 10000)","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"Similarly, for a continuous system, e.g. the Lorenz system, you would do:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"lor = Systems.lorenz(ρ = 32.0) #this is not the original parameter!\nλλ = lyapunovs(lor, 10000, dt = 0.1)","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"lyapunovs is also very fast:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"using BenchmarkTools\nds = Systems.towel()\n@btime lyapunovs($ds, 2000);","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"  237.226 μs (45 allocations: 4.27 KiB)","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"Here is an example of plotting the exponents of the Henon map for various parameters:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"using DynamicalSystems, PyPlot\n\nhe = Systems.henon()\nas = 0.8:0.005:1.225; λs = zeros(length(as), 2)\nfor (i, a) in enumerate(as)\n    set_parameter!(he, 1, a)\n    λs[i, :] .= lyapunovs(he, 10000; Ttr = 500)\nend\n\nfigure()\nplot(as, λs); xlabel(\"\\$a\\$\"); ylabel(\"\\$\\\\lambda\\$\")\ntight_layout() # hide\nsavefig(\"heλ.png\"); nothing # hide","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"(Image: )","category":"page"},{"location":"chaos/lyapunovs/#Maximum-Lyapunov-Exponent-1","page":"Lyapunov Exponents","title":"Maximum Lyapunov Exponent","text":"","category":"section"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"It is possible to get only the maximum Lyapunov exponent simply by giving 1 as the third argument of lyapunovs. However, there is a second algorithm that allows you to do the same thing, which is offered by the function lyapunov:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"lyapunov","category":"page"},{"location":"chaos/lyapunovs/#ChaosTools.lyapunov","page":"Lyapunov Exponents","title":"ChaosTools.lyapunov","text":"lyapunov(ds::DynamicalSystem, Τ; kwargs...) -> λ\n\nCalculate the maximum Lyapunov exponent λ using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one. T  denotes the total time of evolution (should be Int for discrete systems).\n\nKeyword Arguments\n\nTtr = 0 : Extra \"transient\" time to evolve the trajectories before starting to measure the expontent. Should be Int for discrete systems.\nd0 = 1e-9 : Initial & rescaling distance between the two neighboring trajectories.\nupper_threshold = 1e-6 : Upper distance threshold for rescaling.\nlower_threshold = 1e-12 : Lower distance threshold for rescaling (in order to  be able to detect negative exponents).\ndt = 1 : Time of evolution between each check of distance exceeding the thresholds. For continuous systems this is approximate.\ninittest = (u1, d0) -> u1 .+ d0/sqrt(D) : A function that given (u1, d0) initializes the test state with distance d0 from the given state u1 (D is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems.\n\nDescription\n\nTwo neighboring trajectories with initial distance d0 are evolved in time. At time t_i their distance d(t_i) either exceeds the upper_threshold, or is lower than lower_threshold, which initializes a rescaling of the test trajectory back to having distance d0 from the given one, while the rescaling keeps the difference vector along the maximal expansion/contraction direction: u_2 to u_1+(u_2u_1)(d(t_i)d_0).\n\nThe maximum Lyapunov exponent is the average of the time-local Lyapunov exponents\n\nlambda = frac1t_n - t_0sum_i=1^n\nlnleft( a_i right)quad a_i = fracd(t_i)d_0\n\nPerformance Notes\n\nThis function uses a parallel_integrator. For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and reinit! it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is\n\nlyapunov(pinteg, T, Ttr, dt, d0, ut, lt)\n\nReferences\n\n[1] : G. Benettin et al., Phys. Rev. A 14, pp 2338 (1976)\n\n\n\n\n\n","category":"function"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"For example:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"using DynamicalSystems, PyPlot\nhenon = Systems.henon()\nλ = lyapunov(henon, 10000, d0 = 1e-7, upper_threshold = 1e-4, Ttr = 100)","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"The same is done for continuous systems:","category":"page"},{"location":"chaos/lyapunovs/#","page":"Lyapunov Exponents","title":"Lyapunov Exponents","text":"lor = Systems.lorenz(ρ = 32)\nλ = lyapunov(lor, 10000.0, dt = 10.0, Ttr = 100.0)","category":"page"},{"location":"chaos/choosing/#Choosing-a-solver-1","page":"Choosing a solver","title":"Choosing a solver","text":"","category":"section"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"ContinuousDynamicalSystems are evolved using solvers from DifferentialEquations.jl. In this page we discuss the importance of which solver to choose.","category":"page"},{"location":"chaos/choosing/#Default-Solver-1","page":"Choosing a solver","title":"Default Solver","text":"","category":"section"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"The default solver is:","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"using DynamicalSystems\nDynamicalSystemsBase.DEFAULT_SOLVER","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"which is a Runge-Kutta-like solver. The number in the solver's name is the \"order\" of the solver.","category":"page"},{"location":"chaos/choosing/#Speed-of-a-solver-1","page":"Choosing a solver","title":"Speed of a solver","text":"","category":"section"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"Estimating a given solver's performance for a particular problem is not trivial. The following are general rules of thumb:","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"Higher order solvers call the equations of motion function more times per step.\nHigher order solvers can cover larger timespans per step.\nHigher order solvers do better at small tolerances.","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"This means that there is a delicate balance between how expensive is your function and how large of a step a solver can take while it is still efficient. In general you want to strike a point of taking large steps but also not calling the function exceedingly often.","category":"page"},{"location":"chaos/choosing/#How-do-I-pick?-1","page":"Choosing a solver","title":"How do I pick?","text":"","category":"section"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"The answer to this question is easy: benchmarks!","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"Here is a simple case: let's compute the Lyapunov spectrum of the Lorenz system using lyapunovs:","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"ds = Systems.lorenz()\ntols = (abstol = 1e-6, reltol = 1e-6)\nlyapunovs(ds, 2000; Ttr = 100.0, tols...)","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"The above uses the default solver. Let's now benchmark using two different solvers, SimpleATsit5 and Vern9. Since the SimpleATsit5 case is of lower order, naively one might think it is faster because it makes less function calls. This argument is not necessarily true though.","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"It is important to understand that when calling lyapunovs(ds, 2000) you want the system (and the tangent space) to be evolved so that it reaches a total time of 2000*dt, which by default is 2000.0 units of time. Even though SimpleATsit5 requires less function calls per step, Vern9 can cover larger timespans per step.","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"Here are the numbers:","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"using BenchmarkTools, OrdinaryDiffEq, SimpleDiffEq, Statistics\nb1 = @benchmark lyapunovs(ds, 2000; alg = SimpleATsit5(), Ttr = 100.0, tols...);\nb2 = @benchmark lyapunovs(ds, 2000; alg = Vern9(),        Ttr = 100.0, tols...);\nprintln(\"Timing for SimpleATsit5:\")\nprintln(mean(b1))\nprintln(\"Timing for Vern9:\")\nprintln(mean(b2))","category":"page"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"As you can see Vern9 is faster in doing the entire computation! Of course this does not have to be universally true. It is true for the Lorenz system, but for your specific system you should do dedicated benchmarks!","category":"page"},{"location":"chaos/choosing/#DifferentialEquations.jl-1","page":"Choosing a solver","title":"DifferentialEquations.jl","text":"","category":"section"},{"location":"chaos/choosing/#","page":"Choosing a solver","title":"Choosing a solver","text":"For more info about the possible solvers be sure to head over to the documentation of DifferentialEquations.jl!","category":"page"},{"location":"ds/evolve/#Time-Evolution-of-Systems-1","page":"Time Evolution","title":"Time Evolution of Systems","text":"","category":"section"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"info: Trajectory and Timeseries\nThe word \"timeseries\" can be confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in DynamicalSystems.jl we have the following convention: \"timeseries\" always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word \"trajectory\" is used to refer to a multi-dimensional timeseries, which is of course simply a group/set of one-dimensional timeseries.Note that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a Dataset, which is a Vector of SVectors, and each SVector represents a data-point (the values of the variables at a given time-point).","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"DynamicalSystems.jl provides a convenient function for getting a trajectory of a system at equally spaced time points:","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"trajectory","category":"page"},{"location":"ds/evolve/#DynamicalSystemsBase.trajectory","page":"Time Evolution","title":"DynamicalSystemsBase.trajectory","text":"trajectory(ds::DynamicalSystem, T [, u]; kwargs...) -> dataset\n\nReturn a dataset that will contain the trajectory of the system, after evolving it for total time T, optionally starting from state u. See Dataset for info on how to use this object.\n\nA W×D dataset is returned, with W = length(t0:dt:T) with t0:dt:T representing the time vector (not returned) and D the system dimension. For discrete systems both T and dt must be integers.\n\nKeyword Arguments\n\ndt :  Time step of value output during the solving of the continuous system. For discrete systems it must be an integer. Defaults to 0.01 for continuous and 1 for discrete.\nTtr : Transient time to evolve the initial state before starting saving states.\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. For example abstol = 1e-9.  Only valid for continuous systems. If you want to specify a solver, do so by using the name alg, e.g.: alg = Tsit5(), maxiters = 1000. This requires you to have been first using OrdinaryDiffEq to access the solvers. See DynamicalSystemsBase.CDS_KWARGS for default values. These keywords can also include callback for event handling. Using a SavingCallback with trajectory will lead to unexpected behavior!\n\n\n\n\n\n","category":"function"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"Notice that if you want to do repeated evolutions of different states of a continuous system, you should use the integrator interface instead.","category":"page"},{"location":"ds/evolve/#Example-1","page":"Time Evolution","title":"Example","text":"","category":"section"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"using DynamicalSystems\nds = Systems.towel()\ntr = trajectory(ds, 100)","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"To get every 3-rd point of the trajectory, do","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"tr = trajectory(ds, 100; dt = 3)","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"Identical syntax is used for continuous systems","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"ds = Systems.lorenz()\ntr = trajectory(ds, 10.0; dt = 0.01)","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"And a final example controlling the integrator accuracy:","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"ds = Systems.lorenz()\ntr = trajectory(ds, 10.0; dt = 0.1, atol = 1e-9, rtol = 1e-9)","category":"page"},{"location":"ds/evolve/#Solution-precision-for-continuous-systems-1","page":"Time Evolution","title":"Solution precision for continuous systems","text":"","category":"section"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"A numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"DifferentialEquations.jl offers a tool, called Uncertainty Quantification, which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of DynamicalSystems.jl, the Lorenz system is accurate up to time t = 50.0.","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"However, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the shadowing theorem (or shadowing lemma):","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"quote: Shadowing Theorem\nAlthough a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.","category":"page"},{"location":"ds/evolve/#","page":"Time Evolution","title":"Time Evolution","text":"This simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book Chaos in Dynamical Systems by E. Ott, or the scholarpedia entry.","category":"page"},{"location":"rqa/quantification/#Recurrence-Quantification-Analysis-1","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"A RecurrenceMatrix can be analyzed in several ways to yield information about the dynamics of the trajectory. All these various measures and functions are collectively called \"Recurrence Quantification Analysis\" (RQA).","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"To understand how each measure can be useful, we suggest to see the review articles listed in our documentation strings, namely:","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"N. Marwan et al., \"Recurrence plots for the analysis of complex systems\", Phys. Reports 438(5-6), 237-329 (2007).\nN. Marwan & C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. & N. Marwan (eds.), Recurrence Quantification Analysis. Theory and Best Practices, Springer, pp. 3-43 (2015).","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"You can also check the wikipedia page for Recurrence quantification analysis.","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"The functions described in this page all accept a recurrence matrix (x), see RecurrenceMatrix.","category":"page"},{"location":"rqa/quantification/#RQA-Measures-1","page":"Recurrence Quantification Analysis","title":"RQA Measures","text":"","category":"section"},{"location":"rqa/quantification/#All-in-one-Bundle-1","page":"Recurrence Quantification Analysis","title":"All-in-one Bundle","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"In case you need all of the RQA-related functions (see below) and you don't want to write 10 lines of code to compute them all (since they are so many) we provide an all-in-one function that computes all of them and returns a NamedTuple of the results!","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"rqa","category":"page"},{"location":"rqa/quantification/#RecurrenceAnalysis.rqa","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.rqa","text":"rqa(R; kwargs...)\n\nCalculate all RQA parameters of a recurrence matrix R. See the functions referred to below for the definition of the different parameters and the default values of the arguments. Using this function is much more efficient than calling all individual functions one by one.\n\nReturn\n\nThe returned value is a NamedTuple with the following entries:\n\nRR: recurrence rate (see recurrencerate)\nDET: determinsm (see determinism)\nL: average length of diagonal structures (see dl_average)\nLmax: maximum length of diagonal structures (see dl_max)\nDIV: divergence (see divergence)\nENTR: entropy of diagonal structures (see dl_entropy)\nTREND: trend of recurrences (see trend)\nLAM: laminarity (see laminarity)\nTT: trapping time (see trappingtime)\nVmax: maximum length of vertical structures (see vl_max)\nVENTR: entropy of vertical structures (see vl_entropy)\nMRT: mean recurrence time (see meanrecurrencetime)\nRTE recurrence time entropy (see rt_entropy)\nNMPRT: number of the most probable recurrence time (see nmprt)\n\nIn the case of empty histograms (e.g. no existing vertical lines less than the keyword lminvert) the average and maximum values (L, Lmax, TT, Vmax, MRT) are returned as 0.0 but their respective entropies (ENTR, VENTR, RTE) are returned as NaN.\n\nKeyword Arguments\n\nStandard keyword arguments are the ones accepted by the functions listed below, i.e. theiler, lmin, and border:\n\ntheiler is used to define a \"Theiler window\" around the central diagonal or \"line of identity\" (LOI): a region of points that are excluded in the calculation of RQA parameters, in order to rule out self-recurrences and apparent recurrences for smooth or high resolution data. The LOI is excluded by default for matrices of the types RecurrenceMatrix or JointRecurrenceMatrix, but it is included for matrices of the type CrossRecurrenceMatrix. theiler=0 means that the whole matrix is scanned for lines. theiler=1 means that the LOI is excluded. In general, theiler=n means that the n central diagonals are excluded (at both sides of the LOI, i.e. actually 2n-1 diagonals are excluded).\nlmin is used to define the minimum line length in the parameters that describe the distributions of diagonal or vertical lines (it is set as 2 by default).\nborder is used to avoid border effects in the calculation of TREND (cf. trend).\n\nIn addition theilerdiag, lmindiag may be used to declare specific values that override the values of theiler and lmin in the calculation of parameters related to diagonal structures. Likewise, theilervert and lminvert can be used for the calculation of parameters related to vertical structures.\n\nThe keyword argument onlydiagonal (false by default) can be set to true in order to restrict the analysis to the recurrence rate and the parameters related to diagonal structures (RR, DET, L, Lmax, DIV and ENTR), which makes this function slightly faster.\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"note: Return values for empty histograms\nIt may be the case that for a given recurrence matrix some structures do not exist at all. For example there are recurrence matrices that have no vertical lengths (or no vertical lengths with length less than lmin). In such cases the behavior of our RQA pipeline is the following:Quantities that represent maximum or average values are 0.0.\nQuantities that represent entropies are NaN.","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"See also the @windowed macro for a windowed version of rqa.","category":"page"},{"location":"rqa/quantification/#Classical-RQA-Measures-1","page":"Recurrence Quantification Analysis","title":"Classical RQA Measures","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"recurrencerate\ndeterminism\ndl_average\ndl_max\ndl_entropy\ndivergence\ntrend","category":"page"},{"location":"rqa/quantification/#RecurrenceAnalysis.recurrencerate","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.recurrencerate","text":"recurrencerate(R[; theiler])\n\nCalculate the recurrence rate of the recurrence matrix R.\n\nDescription\n\nThe recurrence rate is calculated as:\n\nRR = frac1S sum R\n\nwhere S is the size of R or the region of R with potential recurrent points. There is not a unique definition of that denominator, which is defined as the full size of the matrix in many sources (e.g. [1]), whereas in others it is adjusted to remove the points of the LOI when they are excluded from the count [2,3].\n\nFor matrices of type RecurrenceMatrix or JointRecurrenceMatrix, where the points around the central diagonal are usually excluded, the denominator is adjusted to the size of the matrix outside the Theiler window (by default equal to the LOI, and adjustable with the keyword argument theiler; see rqa for details). For matrices of type CrossRecurrenceMatrix, where normally all points are analyzed, the denominator is always the full size of the matrix, regardless of the Theiler window that might be defined (none by default).\n\nHint: to reproduce the calculations done following the formulas that use the full size of the matrix in the denominator, use CrossRecurrenceMatrix(s,s,ε) to define the recurrence matrix, instead of RecurrenceMatrix(s,ε), setting theiler=1 (or theiler=n in general) to explicitly exclude the LOI or other diagonals around it.\n\nReferences\n\n[1] : N. Marwan et al., \"Recurrence plots for the analysis of complex systems\", Phys. Reports 438(5-6), 237-329 (2007).\n\n[2] : C.L. Webber & J.P. Zbilut, \"Recurrence Quantification Analysis of Nonlinear Dynamical Systems\", in: Riley MA & Van Orden GC, Tutorials in Contemporary Nonlinear Methods for the Behavioral Sciences, 26-94 (2005). URL: https://www.nsf.gov/pubs/2005/nsf05057/nmbs/nmbs.pdf\n\n[3] : N. Marwan & C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. & N. Marwan (eds.), Recurrence Quantification Analysis. Theory and Best Practices, Springer, pp. 3-43 (2015).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.determinism","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.determinism","text":"determinism(R[; lmin=2, theiler])\n\nCalculate the determinism of the recurrence matrix R:\n\nDescription\n\nThe determinism is calculated as:\n\nDET = fracsum_l=lminl P(l)sum_l=1l P(l) =\nfracsum_l=lminl P(l)sum R\n\nwhere l stands for the lengths of diagonal lines in the matrix, and P(l) is the number of lines of length equal to l.\n\nlmin is set to 2 by default, and this calculation rules out all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.dl_average","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.dl_average","text":"dl_average(R[; lmin=2, theiler])\n\nCalculate the average of the diagonal lines contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.dl_max","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.dl_max","text":"dl_max(R[; lmin=2, theiler])\n\nCalculate the longest diagonal line contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.dl_entropy","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.dl_entropy","text":"dl_entropy(R[; lmin=2, theiler])\n\nCalculate the Shannon entropy of the diagonal lines contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.divergence","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.divergence","text":"divergence(R[; theiler])\n\nCalculate the divergence of the recurrence matrix R (actually the inverse of dl_max).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.trend","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.trend","text":"trend(R[; border=10, theiler])\n\nCalculate the trend of recurrences in the recurrence matrix R.\n\nDescription\n\nThe trend is the slope of the linear regression that relates the density of recurrent points in the diagonals parallel to the LOI and the distance between those diagonals and the LOI. It quantifies the degree of system stationarity, such that in recurrence plots where points \"fade away\" from the central diagonal, the trend will have a negative value.\n\nIt is calculated as:\n\nTREND = 10^3fracsum_d=tau^tildeNdeltadleft(RRd-langle RRdrangleright)sum_d=tau^tildeNdeltad^2\n\nwhere RRd is the local recurrence rate of the diagonal d, deltad is a balanced measure of the distance between that diagonal and the LOI, tau is the Theiler window (number of central diagonals that are excluded), and tildeN is the number of the outmost diagonal that is included.\n\nThis parameter is expressed in units of variation recurrence rate every 1000 data points, hence the factor 10^3 in the formula [1]. \n\nThe 10 outermost diagonals (counting from the corners of the matrix) are excluded by default to avoid \"border effects\". Use the keyword argument border to define a different number of excluded lines, and theiler to define the size of the Theiler window (see rqa for details).\n\nNote: In rectangular cross-recurrence plots (i.e. when the time series that originate them are not of the same length), the limits of the formula for TREND are not clearly defined. For the sake of consistency, this function limits the calculations to the biggest square matrix that contains the LOI.\n\nReferences\n\n[1] C.L. Webber & J.P. Zbilut, \"Recurrence Quantification Analysis of Nonlinear Dynamical Systems\", in: Riley MA & Van Orden GC, Tutorials in Contemporary Nonlinear Methods for the Behavioral Sciences, 2005, 26-94. https://www.nsf.gov/pubs/2005/nsf05057/nmbs/nmbs.pdf\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"","category":"page"},{"location":"rqa/quantification/#Extended-RQA-Measures-1","page":"Recurrence Quantification Analysis","title":"Extended RQA Measures","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"laminarity\ntrappingtime\nvl_average\nvl_max\nvl_entropy","category":"page"},{"location":"rqa/quantification/#RecurrenceAnalysis.laminarity","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.laminarity","text":"laminarity(R[; lmin=2, theiler])\n\nCalculate the laminarity of the recurrence matrix R.\n\nDescription\n\nThe laminarity is calculated as:\n\nLAM = fracsum_v=lminv P(l)sum_v=1v P(v) =\nfracsum_v=lminv P(l)sum R\n\nwhere v stands for the lengths of vertical lines in the matrix, and P(v) is the number of lines of length equal to v.\n\nlmin is set to 2 by default, and this calculation rules out all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.trappingtime","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.trappingtime","text":"trappingtime(R[; lmin=2, theiler])\n\nCalculate the trapping time of the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\nThe trapping time is the average of the vertical line structures and thus equal to vl_average.\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.vl_average","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.vl_average","text":"vl_average(R[; lmin=2, theiler])\n\nCalculate the average of the vertical lines contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.vl_max","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.vl_max","text":"vl_max(R[; lmin=2, theiler])\n\nCalculate the longest vertical line contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.vl_entropy","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.vl_entropy","text":"vl_entropy(R[; lmin=2, theiler])\n\nCalculate the Shannon entropy of the vertical lines contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"","category":"page"},{"location":"rqa/quantification/#Recurrence-Time-Measures-1","page":"Recurrence Quantification Analysis","title":"Recurrence Time Measures","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"meanrecurrencetime\nnmprt\nrt_entropy\nrt_average","category":"page"},{"location":"rqa/quantification/#RecurrenceAnalysis.meanrecurrencetime","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.meanrecurrencetime","text":"meanrecurrencetime(R[; lmin=2, theiler])\n\nCalculate the mean recurrence time of the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\nEquivalent to rt_average.\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.nmprt","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.nmprt","text":"nmprt(R[; lmin=2, theiler])\n\nCalculate the number of the most probable recurrence time (NMPRT), ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\nThis number indicates how many times the system has recurred using the recurrence time that appears most frequently, i.e it is the maximum value of the histogram of recurrence times [1].\n\nReferences\n\n[1] : E.J. Ngamga et al. \"Recurrence analysis of strange nonchaotic dynamics\", Physical Review E, 75(3), 036222(1-8), 2007, DOI:10.1103/physreve.75.036222\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.rt_entropy","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.rt_entropy","text":"rt_entropy(R[; lmin=2, theiler])\n\nCalculate the Shannon entropy of the recurrence times contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#RecurrenceAnalysis.rt_average","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.rt_average","text":"rt_average(R[; lmin=2, theiler])\n\nCalculate the average of the recurrence times contained in the recurrence matrix R, ruling out the lines shorter than lmin (2 by default) and all the points inside the Theiler window (see rqa for the default values and usage of the keyword argument theiler).\n\n\n\n\n\n","category":"function"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"","category":"page"},{"location":"rqa/quantification/#Keyword-table-1","page":"Recurrence Quantification Analysis","title":"Keyword table","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"Since most of the above functions can be fined tuned with keyword arguments, here is a table summarizing them that could be of use:","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"Argument Default Functions Description\ntheiler 0 for CrossRecurrenceMatrix, 1 otherwise. recurrencerate<br/>determinism<br/>*_average<br/>*_max<br/>*_entropy<br/>divergence<br/>trend<br/>laminarity<br/>trappingtime<br/> meanrecurrencetime<br/>nmprt Theiler window: number of diagonals around the LOI excluded from the analysis. The value 0 means that the LOI is included in the analysis. Use 1 to exclude the LOI.\nlmin 2 determinism<br/>*_average<br/>*_max<br/>*_entropy<br/>divergence<br/>laminarity<br/>trappingtime<br/> meanrecurrencetime<br/>nmprt Minimum length of the recurrent structures (diagonal or vertical) considered in the analysis.\nborder 10 trend Number of diagonals excluded from the analysis near the border of the matrix.","category":"page"},{"location":"rqa/quantification/#Recurrence-Structures-Histograms-1","page":"Recurrence Quantification Analysis","title":"Recurrence Structures Histograms","text":"","category":"section"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"The functions that we list in this page internally compute histograms of some recurrence structures, like e.g. the vertical lengths. You can access these values directly with the following function:","category":"page"},{"location":"rqa/quantification/#","page":"Recurrence Quantification Analysis","title":"Recurrence Quantification Analysis","text":"recurrencestructures","category":"page"},{"location":"rqa/quantification/#RecurrenceAnalysis.recurrencestructures","page":"Recurrence Quantification Analysis","title":"RecurrenceAnalysis.recurrencestructures","text":"recurrencestructures(x::AbstractRecurrenceMatrix;\n                         diagonal=true,\n                         vertical=true,\n                         recurrencetimes=true,\n                         kwargs...)\n\nReturn a dictionary with the histograms of the recurrence structures contained in the recurrence matrix x, with the keys \"diagonal\", \"vertical\" or \"recurrencetimes\", depending on what keyword arguments are given as true.\n\nDescription\n\nEach item of the dictionary is a vector of integers, such that the i-th element of the vector is the number of lines of length i contained in x.\n\n\"diagonal\" counts the diagonal lines, i.e. the recurrent trajectories.\n\"vertical\" counts the vertical lines, i.e. the laminar states.\n\"recurrencetimes\" counts the vertical distances between recurrent states,   i.e. the recurrence times.\n\nAll the points of the matrix are counted by default. The keyword argument theiler can be passed to rule out the lines around the main diagonal. See the arguments of the function rqa for further details.\n\n\"Empty\" histograms are represented always as [0].\n\nNotice: There is not a unique operational definition of \"recurrence times\". In the analysis of recurrence plots, usually the  \"second type\" of recurrence times as defined by Gao and Cai [1] are considered, i.e. the distance between consecutive (but separated) recurrent structures in the vertical direction of the matrix. But that distance is not uniquely defined when the vertical recurrent structures are longer than one point. The recurrence times calculated here are the distance between the midpoints of consecutive lines, which is a balanced estimator of the Poincaré recurrence times [2].\n\nReferences\n\n[1] J. Gao & H. Cai. \"On the structures and quantification of recurrence plots\". Physics Letters A, 270(1-2), 75–87 (2000).\n\n[2] N. Marwan & C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. & N. Marwan (eds.), Recurrence Quantification Analysis. Theory and Best Practices, Springer, pp. 3-43 (2015).\n\n\n\n\n\n","category":"function"},{"location":"rqa/rplots/#Recurrence-Plots-1","page":"Recurrence Plots","title":"Recurrence Plots","text":"","category":"section"},{"location":"rqa/rplots/#Recurrence-Matrices-1","page":"Recurrence Plots","title":"Recurrence Matrices","text":"","category":"section"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"A Recurrence plot (which refers to the plot of a matrix) is a way to quantify recurrences that occur in a trajectory. A recurrence happens when a trajectory visits the same neighborhood on the phase space that it was at some previous time.","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"The central structure used in these recurrences is the (cross-) recurrence matrix:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"Ri j = begincases\n1 quad textifquad d(xi yj) le varepsilon\n0 quad textelse\nendcases","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"where d(xi yj) stands for the distance between trajectory x at point i and trajectory y at point j. Both x y can be single timeseries, full trajectories or embedded timeseries (which are also trajectories).","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"If xequiv y then R is called recurrence matrix, otherwise it is called cross-recurrence matrix. There is also the joint-recurrence variant, see below. With RecurrenceAnalysis you can use the following functions to access these matrices","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"RecurrenceMatrix\nCrossRecurrenceMatrix\nJointRecurrenceMatrix","category":"page"},{"location":"rqa/rplots/#RecurrenceAnalysis.RecurrenceMatrix","page":"Recurrence Plots","title":"RecurrenceAnalysis.RecurrenceMatrix","text":"RecurrenceMatrix(x, ε; kwargs...)\n\nCreate a recurrence matrix from trajectory x. Objects of type <:AbstractRecurrenceMatrix are displayed as a recurrenceplot.\n\nDescription\n\nThe recurrence matrix is a numeric representation of a \"recurrence plot\" [^1, ^2], in the form of a sparse square matrix of Boolean values.\n\nx must be a Vector or a Dataset or a Matrix with data points in rows (possibly representing and embedded phase space; see embed). If d(x[i], x[j]) ≤ ε (with d the distance function), then the cell (i, j) of the matrix will have a true value. The criteria to evaluate distances between data points are defined by the following keyword arguments:\n\nscale=1 : a function of the distance matrix (see distancematrix), or a fixed number, used to scale the value of ε. Typical choices are maximum or mean, such that the threshold ε is defined as a ratio of the maximum or the mean distance between data points, respectively (using mean or maximum calls specialized versions that are faster than the naive approach).  Use 1 to keep the distances unscaled (default).\nfixedrate::Bool=false : a flag that indicates if ε should be taken as a target fixed recurrence rate (see recurrencerate). If fixedrate is set to true, ε must be a value between 0 and 1, and scale is ignored.\nmetric=\"euclidean\" : metric of the distances, either Metric or a string,  as in distancematrix.\nparallel=false : whether to parallelize the computation of the recurrence  matrix.  This will split the computation of the matrix across multiple threads.  This may not work on Julia versions before v1.3, so be warned!\n\nSee also: CrossRecurrenceMatrix, JointRecurrenceMatrix and use recurrenceplot to turn the result of these functions into a plottable format.\n\nReferences\n\n[1] : N. Marwan et al., \"Recurrence plots for the analysis of complex systems\", Phys. Reports 438(5-6), 237-329 (2007).\n\n[2] : N. Marwan & C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. & N. Marwan (eds.), Recurrence Quantification Analysis. Theory and Best Practices, Springer, pp. 3-43 (2015).\n\n\n\n\n\n","category":"type"},{"location":"rqa/rplots/#RecurrenceAnalysis.CrossRecurrenceMatrix","page":"Recurrence Plots","title":"RecurrenceAnalysis.CrossRecurrenceMatrix","text":"CrossRecurrenceMatrix(x, y, ε; kwargs...)\n\nCreate a cross recurrence matrix from trajectories x and y.\n\nThe cross recurrence matrix is a bivariate extension of the recurrence matrix. For the time series x, y, of length n and m, respectively, it is a sparse n×m matrix of Boolean values, such that if d(x[i], y[j]) ≤ ε, then the cell (i, j) of the matrix will have a true value.\n\nSee RecurrenceMatrix for details, references and keywords. See also: JointRecurrenceMatrix.\n\n\n\n\n\n","category":"type"},{"location":"rqa/rplots/#RecurrenceAnalysis.JointRecurrenceMatrix","page":"Recurrence Plots","title":"RecurrenceAnalysis.JointRecurrenceMatrix","text":"JointRecurrenceMatrix(x, y, ε; kwargs...)\n\nCreate a joint recurrence matrix from x and y.\n\nThe joint recurrence matrix considers the recurrences of the trajectories of x and y separately, and looks for points where both recur simultaneously. It is calculated by the element-wise multiplication of the recurrence matrices of x and y. If x and y are of different length, the recurrences are only calculated until the length of the shortest one.\n\nSee RecurrenceMatrix for details, references and keywords. See also: CrossRecurrenceMatrix.\n\n\n\n\n\n","category":"type"},{"location":"rqa/rplots/#Simple-Recurrence-Plots-1","page":"Recurrence Plots","title":"Simple Recurrence Plots","text":"","category":"section"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"The recurrence matrices are internally stored as sparse matrices with boolean values. Typically in the literature one does not \"see\" the matrices themselves but instead a plot of them (hence \"Recurrence Plots\"). By default, when a Recurrence Matrix is created we \"show\" a mini plot of it which is a text-based scatterplot.","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"Here is an example recurrence plot/matrix of a full trajectory of the Roessler system:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"using DynamicalSystems\nro = Systems.roessler(ones(3), a=0.15, b=0.20, c=10.0)\nN = 2000; dt = 0.05\ntr = trajectory(ro, N*dt; dt = dt, Ttr = 10.0)\n\nR = RecurrenceMatrix(tr, 5.0; metric = \"euclidean\")\nrecurrenceplot(R; ascii = true)","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"typeof(R)","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"summary(R)","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"The above simple plotting functionality is possible through the package UnicodePlots. The following function creates the plot:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"recurrenceplot","category":"page"},{"location":"rqa/rplots/#RecurrenceAnalysis.recurrenceplot","page":"Recurrence Plots","title":"RecurrenceAnalysis.recurrenceplot","text":"recurrenceplot([io,] R; minh = 25, maxh = 0.5, ascii, kwargs...) -> u\n\nCreate a text-based scatterplot representation of a recurrence matrix R to be displayed in io (by default stdout) using UnicodePlots. The matrix spans at minimum minh rows and at maximum maxh*displaysize(io)[1] (i.e. by default half the display). As we always try to plot in equal aspect ratio, if the width of the plot is even less, the minimum height is dictated by the width.\n\nThe keyword ascii::Bool can ensure that all elements of the plot are ASCII characters (true) or Unicode (false).\n\nThe rest of the kwargs are propagated into UnicodePlots.scatterplot.\n\nNotice that the accuracy of this function drops drastically for matrices whose size is significantly bigger than the width and height of the display (assuming each index of the matrix is one character).\n\n\n\n\n\n","category":"function"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"Here is the same plot but using Unicode Braille characters","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"recurrenceplot(R; ascii = false)","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"As you can see, the Unicode based plotting doesn't display nicely everywhere. It does display perfectly in e.g. Juno, which is where it is the default printing type. Here is how it looks like in a dark background:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"(Image: )","category":"page"},{"location":"rqa/rplots/#Advanced-Recurrence-Plots-1","page":"Recurrence Plots","title":"Advanced Recurrence Plots","text":"","category":"section"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"A text-based plot is cool, fast and simple. But often one needs the full resolution offered by the data of a recurrence matrix.","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"There are two more ways to plot a recurrence matrix using RecurrenceAnalysis:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"coordinates\ngrayscale","category":"page"},{"location":"rqa/rplots/#RecurrenceAnalysis.coordinates","page":"Recurrence Plots","title":"RecurrenceAnalysis.coordinates","text":"coordinates(R) -> xs, ys\n\nReturn the coordinates of the recurrence points of R (in indices).\n\n\n\n\n\n","category":"function"},{"location":"rqa/rplots/#RecurrenceAnalysis.grayscale","page":"Recurrence Plots","title":"RecurrenceAnalysis.grayscale","text":"grayscale(R [, bwcode]; width::Int, height::Int, exactsize=false)\n\nTransform the recurrence matrix R into a full matrix suitable for plotting as a grayscale image. By default it returns a matrix with the same size as R, but switched axes, containing \"black\" values in the cells that represent recurrent points, and \"white\" values in the empty cells and interpolating in-between for cases with both recurrent and empty cells, see below.\n\nThe numeric codes for black and white are given in a 2-element tuple as a second optional argument. Its default value is (0.0, 1.0), i.e. black is coded as 0.0 (no brightness) and white as 1.0 (full brightness). The type of the elements in the tuple defines the type of the returned matrix. This must be taken into account if, for instance, the image is coded as a matrix of integers corresponding to a grayscale; in such case the black and white codes must be given as numbers of the required integer type.\n\nThe keyword arguments width and height can be given to define a custom size of the image. If only one dimension is given, the other is automatically calculated. If both dimensions are given, by default they are adjusted to keep an aspect proportional to the original matrix, such that the returned matrix fits into a matrix of the given dimensions. This automatic adjustment can be disabled by passing the keyword argument exactsize=true.\n\nIf the image has different dimensions than R, the cells of R are distributed in a grid with the size of the image, and a gray level between white and black is calculated for each element of the grid, proportional to the number of recurrent points contained in it. The levels of gray are coded as numbers of the same type as the black and white codes.\n\nIt is advised to use width, height arguments for large matrices otherwise plots using functions like e.g. imshow could be misleading.\n\n\n\n\n\n","category":"function"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"For example, here is the representation of the above R from the Roessler system using both plotting approaches:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"using PyPlot\nfigure(figsize = (10,5))\n\nax = subplot(121)\nxs, ys = coordinates(R)\nscatter(xs, ys, color = \"k\", s = 1)\nxlim(1, size(R)[1]); ylim(1, size(R)[2]);\nax.set_aspect(\"equal\")\n\nsubplot(122)\nRg = grayscale(R)\nimshow(Rg, cmap = \"binary_r\", extent = (1, size(R)[1], 1, size(R)[2]))\nsavefig(\"different_rplots.png\"); nothing # hide","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"(Image: )","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"and here is exactly the same process, but using the embedded trajectory instead","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"using PyPlot # hide\ny = tr[:, 2]\nτ = estimate_delay(y, \"mi_min\")\nm = reconstruct(y, 2, τ)\nR = RecurrenceMatrix(m, 5.0; metric = \"euclidean\")\n\nfigure(figsize = (5,5))\n\nxs, ys = coordinates(R)\nscatter(xs, ys, color = \"k\", s = 1)\nxlim(1, size(R)[1]); ylim(1, size(R)[2]);\nsavefig(\"rmatrix2.png\"); nothing # hide","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"(Image: )","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"which justifies why recurrence plots are so fitting to be used in embedded timeseries.","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"warning: Careful when using Recurrence Plots\nIt is easy when using grayscale to not change the width/height parameters. These are however very important when the matrix size exceeds the display size! Most plotting libraries may resample arbitrarily or simply limit the displayed pixels, so one needs to be extra careful.Besides graphical problems there are also other potential pitfalls dealing with the conceptual understanding and use of recurrence plots. All of these are summarized in the following paper which we suggest users to take a look at:N. Marwan, How to avoid potential pitfalls in recurrence plot based data analysis, Int. J. of Bifurcations and Chaos (arXiv).","category":"page"},{"location":"rqa/rplots/#Example-1","page":"Recurrence Plots","title":"Example","text":"","category":"section"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"In the following we will plot recurrence plots of the Lorenz system for a periodic and chaotic regime (using scatter plot).","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"using PyPlot # hide\nlor = Systems.lorenz()\nfigure(figsize = (10,10))\n\nfor (i, ρ) in enumerate((69.75, 28.0))\n    set_parameter!(lor, 2, ρ)\n    t, dt = 20.0, 0.01\n    tr = trajectory(lor, t; dt = dt, Ttr = 2000.0)\n    tvec = 0:dt:t\n\n    subplot(2,2, i)\n    plot(tr[:, 1], tr[:, 3], color = \"C$(i+1)\", label = \"X vs Z\")\n    title(\"ρ = $ρ, \" * (i != 1 ? \"not periodic\" : \"periodic\")); legend()\n\n    ε = i == 1 ? 5.0 : 3.0\n    R = RecurrenceMatrix(tr, ε)\n\n    subplot(2,2,i+2)\n    x, y = coordinates(R)\n    scatter(tvec[x], tvec[y], s = 1, alpha = 0.2, color = \"C$(i+1)\")\n    xlim(0, t); ylim(0, t); gca().set_aspect(\"equal\")\n    xlabel(\"t\"); i == 1 && ylabel(\"t\");\nend\nPyPlot.tight_layout()\nsavefig(\"rplotexamples.png\"); nothing # hide","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"(Image: )","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"On the left we see long (infinite) diagonals repeated over and over for different times. This is the case for periodic systems as they visit exactly the same area on the phase space again and again. The distance between the offset diagonals also coincides with the periodicity of the system, which is around t ≈ 4.","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"On the right we see a structure typical of chaotic motion on a strange attractor such as the one of the Lorenz system: the orbit visits neighborhoods of previous points but then quickly diverges again. This results in many small diagonal lines.","category":"page"},{"location":"rqa/rplots/#Distances-1","page":"Recurrence Plots","title":"Distances","text":"","category":"section"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"The distance function used in RecurrenceMatrix and co. can be specified either as a string or as any Metric instance from Distances. In addition, the following function returns a matrix with the cross-distances across all points in one or two trajectories:","category":"page"},{"location":"rqa/rplots/#","page":"Recurrence Plots","title":"Recurrence Plots","text":"distancematrix","category":"page"},{"location":"rqa/rplots/#RecurrenceAnalysis.distancematrix","page":"Recurrence Plots","title":"RecurrenceAnalysis.distancematrix","text":"distancematrix(x [, y = x], metric = \"euclidean\")\n\nCreate a matrix with the distances between each pair of points of the time series x and y using metric.\n\nThe time series x and y can be Datasets or vectors or matrices with data points in rows. The data point dimensions (or number of columns) must be the same for x and y. The returned value is a n×m matrix, with n being the length (or number of rows) of x, and m the length of y.\n\nThe metric can be identified by a string, or any of the Metrics defined in the Distances package. The list of strings available to define the metric are:\n\n\"max\" or \"inf\" for the maximum or L∞ norm (Chebyshev() in the Distances package).\n\"euclidean\" for the L2 or Euclidean norm, used by default (Euclidean() in Distances).\n\"manhattan\", \"cityblock\", \"taxicab\" or \"min\" for the Manhattan or L1 norm (Cityblock() in Distances).\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#Detecting-and-Categorizing-Chaos-1","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"Being able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum lyapunov exponent and a bounded system indicate chaos.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"However, the convergence of the Lyapunov exponent can be slow, or even misleading, as the types of chaotic behavior vary with respect to their predictability. There are many alternatives, some more efficient and some more accurate in characterizing chaotic and regular motion. Some of these methods are included in DynamicalSystems.jl.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"info: Performance depends on the solver\nNotice that the performance of functions that use ContinuousDynamicalSystems depend crucially on the chosen solver. Please see the documentation page on Choosing a solver for an in-depth discussion.","category":"page"},{"location":"chaos/chaos_detection/#Generalized-Alignment-Index-1","page":"Detecting & Categorizing Chaos","title":"Generalized Alignment Index","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaotic and regular behavior, introduced first in 2007 by Skokos, Bountis & Antonopoulos.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"gali","category":"page"},{"location":"chaos/chaos_detection/#ChaosTools.gali","page":"Detecting & Categorizing Chaos","title":"ChaosTools.gali","text":"gali(ds::DynamicalSystem, tmax, k::Int | Q0; kwargs...) -> GALI_k, t\n\nCompute textGALI_k [1] for a given k up to time tmax. Return textGALI_k(t) and time vector t.\n\nThe third argument, which sets the order of gali, can be an integer k, or a matrix with its columns being the deviation vectors (then k = size(Q0)[2]). In the first case random orthonormal vectors are chosen.\n\nKeyword Arguments\n\nthreshold = 1e-12 : If GALI_k falls below the threshold iteration is terminated.\ndt = 1 : Time-step between deviation vector normalizations. For continuous systems this is approximate.\nu0 : Initial state for the system. Defaults to get_state(ds).\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems.\n\nDescription\n\nThe Generalized Alignment Index, textGALI_k, is an efficient (and very fast) indicator of chaotic or regular behavior type in D-dimensional Hamiltonian systems (D is number of variables). The asymptotic behavior of textGALI_k(t) depends critically on the type of orbit resulting from the initial condition. If it is a chaotic orbit, then\n\ntextGALI_k(t) sim\nexpleftsum_j=1^k (lambda_1 - lambda_j)t right\n\nwith lambda_j being the j-th Lyapunov exponent (see lyapunov, lyapunovs). If on the other hand the orbit is regular, corresponding to movement in d-dimensional torus with 1 le d le D2 then it holds\n\ntextGALI_k(t) sim\n    begincases\n      textconst  textif  2 le k le d    textand\n       d  1 \n      t^-(k - d)  textif   d  k le D - d \n      t^-(2k - D)  textif   D - d  k le D\n    endcases\n\nTraditionally, if textGALI_k(t) does not become less than the threshold until tmax the given orbit is said to be chaotic, otherwise it is regular.\n\nOur implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of A, a matrix that has as columns the deviation vectors.\n\nPerformance Notes\n\nThis function uses a tangent_integrator. For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and reinit! it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is\n\nChaosTools.gali(tinteg, tmax, dt, threshold)\n\nReferences\n\n[1] : Skokos, C. H. et al., Physica D 231, pp 30–54 (2007)\n\n[2] : Skokos, C. H. et al., Chaos Detection and Predictability - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics 915, Springer (2016)\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"","category":"page"},{"location":"chaos/chaos_detection/#Discrete-Example-1","page":"Detecting & Categorizing Chaos","title":"Discrete Example","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"We will use 3 coupled standard maps as an example for a discrete system:","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"using DynamicalSystems\nusing PyPlot\nM = 3; ks = 3ones(M); Γ = 0.1;\nstable = [π, π, π, 0.01, 0, 0] .+ 0.1\nchaotic = rand(2M)\n\nds = Systems.coupledstandardmaps(M, stable; ks=ks, Γ = Γ)","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"First, let's see the behavior of GALI for a stable orbit","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"figure(figsize = (8,4))\ntr = trajectory(ds, 100000)\n\nsubplot(1,2,1)\nplot(tr[:,1], tr[:,1+M], alpha = 0.5,\nlabel=\"stable\",marker=\"o\", ms=1, linewidth=0)\nlegend()\n\nsubplot(1,2,2)\nfor k in [4, 5, 6]\n    g, t = gali(ds, 1e5, k; threshold=1e-12)\n    lt = log10.(t); lg = log10.(g)\n    plot(lt, lg, label=\"GALI_$(k)\")\nend\nlt = 2:0.5:5.5\nplot(lt, -2(lt .- 3), label=\"slope -2\")\nplot(lt, -4(lt .- 3), label=\"slope -4\")\nplot(lt, -6(lt .- 3), label=\"slope -6\")\n\nxlim(2, 5.5)\nylim(-12, 2)\nlegend()\ntight_layout()\nsavefig(\"gali_discrete_stable.png\"); nothing # hide","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: gali_discrete_stable)","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"Now do the same for a chaotic orbit","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"figure(figsize = (8,4))\ntr = trajectory(ds, 100000, chaotic)\nsubplot(1,2,1)\nplot(tr[:,1], tr[:,1+M], alpha = 0.5,\nlabel=\"chaotic\",marker=\"o\", ms=1, linewidth=0)\nlegend()\n\nsubplot(1,2,2)\nls = lyapunovs(ds, 100000; u0 = chaotic)\nfor k in [2,3,6]\n    ex = sum(ls[1] - ls[j] for j in 2:k)\n    g, t = gali(ds, 1000, k; u0 = chaotic)\n    semilogy(t, exp.(-ex.*t), label=\"exp. k=$k\")\n    semilogy(t, g, label=\"GALI_$(k)\")\nend\nlegend()\nxlim(0,100)\nylim(1e-12, 1)\nsavefig(\"gali_discrete_chaos.png\"); nothing # hide","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: gali_discrete_chaos)","category":"page"},{"location":"chaos/chaos_detection/#Continuous-Example-1","page":"Detecting & Categorizing Chaos","title":"Continuous Example","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"As an example of a continuous system, let's see the henonheiles:","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"using DynamicalSystems\nusing PyPlot, OrdinaryDiffEq\nsp = [0, .295456, .407308431, 0] # stable periodic orbit: 1D torus\nqp = [0, .483000, .278980390, 0] # quasiperiodic orbit: 2D torus\nch = [0, -0.25, 0.42081, 0]      # chaotic orbit\nds = Systems.henonheiles(sp)","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"First, we see the behavior with a stable periodic orbit","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"figure(figsize = (8,4))\nsubplot(1,2,1)\ndt = 1.0\n\ndiffeq = (abstol=1e-9, reltol=1e-9, alg = Tsit5(), maxiters = typemax(Int))\ntr = trajectory(ds, 10000.0; dt=dt, diffeq...)\nplot(tr[:,1], tr[:,3], alpha = 0.5,\nlabel=\"sp\",marker=\"o\",markersize=2, linewidth=0)\nlegend()\n\nsubplot(1,2,2)\nfor k in [2,3,4]\n    g, t = gali(ds, 10000.0, k; dt = dt, diffeq...)\n    loglog(t, g, label=\"GALI_$(k)\")\n    if k < 4\n        loglog(t, 100 ./ t.^(k-1), label=\"slope -$(k-1)\")\n    else\n        loglog(t, 10000 ./ t.^(2k-4), label=\"slope -$(2k-4)\")\n    end\nend\nylim(1e-12, 2)\nlegend();\nsavefig(\"gali_cont_stable.png\"); nothing # hide","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: gali_cont_stable)","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"Next, let's see what happens with a quasi-periodic orbit. Don't forget to change the u0 arguments!","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"figure(figsize = (8,4))\nsubplot(1,2,1)\ntr = trajectory(ds, 10000.0, qp; dt=dt, diffeq...)\nplot(tr[:,1], tr[:,3], alpha = 0.5,\nlabel=\"qp\",marker=\"o\",markersize=2, linewidth=0)\nlegend()\n\nsubplot(1,2,2)\nfor k in [2,3,4]\n    g, t = gali(ds, 10000.0, k; u0 = qp, dt = dt, diffeq...)\n    loglog(t, g, label=\"GALI_$(k)\")\n    if k == 2\n        loglog(t, 1 ./ t.^(2k-4), label=\"slope -$(2k-4)\")\n    else\n        loglog(t, 100 ./ t.^(2k-4), label=\"slope -$(2k-4)\")\n    end\nend\nylim(1e-12, 2)\nlegend()\ntight_layout()\nsavefig(\"gali_cont_quasi.png\"); nothing # hide","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: gali_cont_quasi)","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"Finally, here is GALI of a continuous system with a chaotic orbit","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"figure(figsize = (8,4))\ntr = trajectory(ds, 10000.0, ch; dt=dt, diffeq...)\nsubplot(1,2,1)\nplot(tr[:,1], tr[:,3], alpha = 0.5,\nlabel=\"ch\",marker=\"o\",markersize=2, linewidth=0)\nlegend()\n\nsubplot(1,2,2)\nls = lyapunovs(ds, 5000.0; dt=dt, u0 = ch, diffeq...)\nfor k in [2,3,4]\n    ex = sum(ls[1] - ls[j] for j in 2:k)\n    g, t = gali(ds, 1000, k; u0 = ch, dt = dt, diffeq...)\n    semilogy(t, exp.(-ex.*t), label=\"exp. k=$k\")\n    semilogy(t, g, label=\"GALI_$(k)\")\nend\nlegend()\nylim(1e-16, 1)\ntight_layout()\nsavefig(\"gali_cont_chaos.png\"); nothing # hide","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: gali_cont_chaos)","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"As you can see, the results of both discrete and continuous systems match very well the theory described in gali.","category":"page"},{"location":"chaos/chaos_detection/#Using-GALI-1","page":"Detecting & Categorizing Chaos","title":"Using GALI","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"No-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just proofs that the method works as expected in all cases.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"The most common usage of textGALI_k is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether textGALI_k stays below it, for a (sufficiently) big k.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"The following is an example of advanced usage (see Advanced documentation):","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"using DynamicalSystems, PyPlot\n\nfunction main(k)\n# Measure of chaoticity: final time of gali_2\ndens = 201\nchaoticity = zeros(Int, dens, dens)\n\nθs = ps = range(0, stop = 2π, length = dens+1)\nds = Systems.standardmap(k = k)\n\ntinteg = tangent_integrator(ds, 2)\n\nfor (i, θ) ∈ enumerate(θs[1:dens])\n    println(\"i = $(i)\")\n    for (j, p) ∈ enumerate(ps[1:dens])\n\n        # new initial state is the system initial state\n        u0 = SVector{2}(θ, p)\n        reinit!(tinteg, u0, orthonormal(2,2))\n\n        # Low-level call signature of gali:\n        #  gali(tinteg, tmax, dt, threshold)\n        chaoticity[i, j] = gali(tinteg, 500, 1, 1e-12)[2][end]\n    end\nend\nfigure()\npcolormesh(θs .- (θs[2] - θs[1])/2, ps .- (ps[2] - ps[1])/2,\nchaoticity')\ncolorbar()\nxlabel(\"\\$\\\\theta\\$\")\nylabel(\"\\$p\\$\")\nreturn\nend\n\nmain(0.9);","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: )","category":"page"},{"location":"chaos/chaos_detection/#Regular-orbits-in-the-Henon-Heiles-system-1","page":"Detecting & Categorizing Chaos","title":"Regular orbits in the Henon-Heiles system","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"In this example we use the poincaresos function to produce surfaces of section of the Systems.henonheiles system at different energies. At each energy gali is used to color-code each initial condition according to how chaotic/regular it is, i.e. how much time does it need to exceed the threshold of gali.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"<video width=\"100%\" height=\"auto\" controls> <source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/chaos/galipsoshenonhelies.mp4?raw=true\" type=\"video/mp4\"> </video>","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"You can download the video using this link.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"You can find the script that produced this animation in DynamicalSystems/docs/coolanimations/gali_psos_henonhelies.jl.","category":"page"},{"location":"chaos/chaos_detection/#Predictability-of-a-chaotic-system-1","page":"Detecting & Categorizing Chaos","title":"Predictability of a chaotic system","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"Even if a system is \"formally\" chaotic, it can still be in phases where it is very predictable, because the correlation coefficient between nearby trajectories vanishes very slowly with time. Wernecke, Sándor & Gros have developed an algorithm that allows one to classify a dynamical system to one of three categories: strongly chaotic, partially predictable chaos or regular (called laminar in their paper).","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"We have implemented their algorithm in the function predictability. Note that we set up the implementation to always return regular behavior for negative Lyapunov exponent. You may want to override this for research purposes.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"predictability","category":"page"},{"location":"chaos/chaos_detection/#ChaosTools.predictability","page":"Detecting & Categorizing Chaos","title":"ChaosTools.predictability","text":"predictability(ds::DynamicalSystem; kwargs...) -> chaos_type, ν, C\n\nDetermine whether ds displays strongly chaotic, partially-predictable chaotic or regular behaviour, using the method by Wernecke et al. described in [1].\n\nReturn the type of the behavior, the cross-distance scaling coefficient ν and the correlation coefficient C. Typical values for ν, C and chaos_type are given in Table 2 of [1]:\n\nchaos_type ν C\n:SC 0 0\n:PPC 0 1\n:REG 1 1\n\nKeyword Arguments\n\nTtr = 200 : Extra \"transient\" time to evolve the system before sampling from  the trajectory. Should be Int for discrete systems.\nT_sample = 1e4 : Time to evolve the system for taking samples. Should be Int for discrete systems.\nn_samples = 500 : Number of samples to take for use in calculating statistics.\nλ_max = lyapunov(ds, 5000) : Value to use for largest Lyapunov exponent for finding the Lyapunov prediction time. If it is less than zero a regular result is returned immediatelly.\nd_tol = 1e-3 : tolerance distance to use for calculating Lyapunov prediction time.\nT_multiplier = 10 : Multiplier from the Lyapunov prediction time to the evaluation time.\nT_max = Inf : Maximum time at which to evaluate trajectory distance. If the internally  computed evaluation time is larger than T_max, stop at T_max instead.\nδ_range = 10.0 .^ (-9:-6) : Range of initial condition perturbation distances  to use to determine scaling ν.\ndiffeq... : Keyword arguments propagated into init of DifferentialEquations.jl. See trajectory for examples. Only valid for continuous systems.\n\nDescription\n\nSamples points from a trajectory of the system to be used as initial conditions. Each of these initial conditions is randomly perturbed by a distance δ, and the trajectories for both the original and perturbed initial conditions are computed to the 'evaluation time' T.\n\nThe average (over the samples) distance and cross-correlation coefficient of the state at time T is computed. This is repeated for a range of δ (defined by δ_range), and linear regression is used to determine how the distance and cross-correlation scale with δ, allowing for identification of chaos type.\n\nThe evaluation time T is calculated as T = T_multiplier*Tλ, where the Lyapunov prediction time Tλ = log(d_tol/δ)/λ_max. This may be very large if the λ_max is small, e.g. when the system is regular, so this internally computed time T can be overridden by a smaller T_max set by the user.\n\nPerformance Notes\n\nFor continuous systems, it is likely that the maxiters used by the integrators needs to be increased, e.g. to 1e9. This is part of the diffeq kwargs. In addition, be aware that this function does a lot of internal computations. It is operating in a different speed than e.g. lyapunov.\n\nReferences\n\n[1] : Wernecke, H., Sándor, B. & Gros, C.       How to test for partially predictable chaos. Scientific Reports 7, (2017).\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#Example-Hénon-Map-1","page":"Detecting & Categorizing Chaos","title":"Example Hénon Map","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"We will create something similar to figure 2 of the paper, but for the Hénon map.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"figure()\nhe = Systems.henon()\nas = 0.8:0.01:1.225\nod = orbitdiagram(he, 1, 1, as; n = 2000, Ttr = 2000)\ncolors = Dict(:REG => \"b\", :PPC => \"g\", :SC => \"r\")\nfor (i, a) in enumerate(as)\n    set_parameter!(he, 1, a)\n    chaos_type, ν, C = predictability(he; T_max = 400000, Ttr = 2000)\n    scatter(a .* ones(length(od[i])), od[i], c = colors[chaos_type], s = 2,\n    alpha = 0.05)\nend\nxlabel(\"\\$a\\$\"); ylabel(\"\\$x\\$\")\ntitle(\"predictability of Hénon map\"); tight_layout()\nsavefig(\"partial_henon.png\"); nothing # hide","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"(Image: partial_henon)","category":"page"},{"location":"chaos/chaos_detection/#The-0-1-test-for-chaos-1","page":"Detecting & Categorizing Chaos","title":"The 0-1 test for chaos","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"The methods mentioned in this page so far require a DynamicalSystem instance. But of course this is not always the case. The so-called \"0 to 1\" test for chaos, by Gottwald & Melbourne, takes as an input a timeseries and outputs a boolean true if the timeseries is chaotic or false if it is not.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"Notice that the method does have a lot of caveats, so you should read the review paper before using.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"testchaos01","category":"page"},{"location":"chaos/chaos_detection/#ChaosTools.testchaos01","page":"Detecting & Categorizing Chaos","title":"ChaosTools.testchaos01","text":"testchaos01(φ::Vector [, cs, N0]) -> chaotic?\n\nPerform the so called \"0-1\" test for chaos introduced by Gottwald and Melbourne [1] on the timeseries φ. Return true if φ is chaotic, false otherwise.\n\nDescription\n\nThis method tests if the given timeseries is chaotic or not by transforming it into a two-dimensional diffusive process. If the timeseries is chaotic, the mean square displacement of the process grows as sqrt(length(φ)), while it stays constant if the timeseries is regular. The implementation here computes K, the correlation coefficient (median of Kc for c ∈ cs), and simply checks if K > 0.5.\n\nIf you want to access the various Kc you should call the method testchaos01(φ, c::Real, N0) which returns Kc.\n\ncs defaults to 3π/5*rand(10) + π/4 and N0, the length of the two-dimensional process, is N0 = length(φ)/10.\n\nNotice that for data sampled from continous dynamical systems, some care must be taken regarding the values of cs, see [1].\n\nReferences\n\n[1] : Gottwald & Melbourne, “The 0-1 test for chaos: A review” Lect. Notes Phys., vol. 915, pp. 221–247, 2016.\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#Expansion-entropy-1","page":"Detecting & Categorizing Chaos","title":"Expansion entropy","text":"","category":"section"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"The expansion entropy is a quantity that is suggested by B. Hunt and E. Ott as a measure that can define chaos (so far no widely accepted definition of chaos exists). Positive expansion entropy means chaos.","category":"page"},{"location":"chaos/chaos_detection/#","page":"Detecting & Categorizing Chaos","title":"Detecting & Categorizing Chaos","text":"expansionentropy\nboxregion\nexpansionentropy_sample\nexpansionentropy_batch","category":"page"},{"location":"chaos/chaos_detection/#ChaosTools.expansionentropy","page":"Detecting & Categorizing Chaos","title":"ChaosTools.expansionentropy","text":"expansionentropy(ds::DynamicalSystem, sampler, restraining; kwargs...)\n\nCalculate the expansion entropy [1] of ds, in the restraining region S defined by restraining, by estimating the slope of the biggest linear region of the curve log E_t0+T t0(f S) versus T (using linear_region). This is an approximation of the expansion entropy H_0, according to [1].\n\nsampler is a 0-argument function that generates a random initial condition (a sample) of ds. restraining is a 1-argument function restraining(u) that given the state u it returns true if the state is inside the restraining region S.\n\nUse boxregion for an easy way to define sampler and restraining on a multidimension box.\n\nKeyword Arguments\n\nN = 1000 : Number of samples taken at each batch (same as N of [1]).\nsteps = 40 : The maximal steps for which the system will be run.\nTtr = 0 : Transient time to evolve each initial condition before starting to comute E. This is t0 of [1] and of the following notation.\nbatches = 100 : Number of batches to run the calculation, see below.\ndiffeq... : Other keywords are propagated to the solvers of DifferentialEquations.jl.\n\nDescription\n\nN samples are initialized and propagated forwards in time (along with their tangent space). At every time t in [t0+dt, t0+2dt, ... t0+steps*dt] we calculate H:\n\nHt = log E_t0+T t0(f S)\n\nwith\n\nE_t0+T t0(f S) = frac 1 N sum_i G(Df_t0+t t0(x_i))\n\n(using same notation as [1]). In principle E is the average largest possible growth ratio within the restraining region (sampled by the initial conditions). The summation is only over x_i that stay inside the region S defined by the boolean function restraining. This process is done by the expansionentropy_sample function.\n\nThen, this is repeated for batches amount of times, as recommended in [1]. From all these batches, the mean and std of H is computed at every time point. This is done by the expansionentropy_batch function. When plotted versus t, these create the curves and error bars of e.g. Figs 2, 3 of [1].\n\nThis function expansionentropy simply returns the slope of the biggest linear region of the curve H versus t, which approximates the expansion entropy H_0. It is therefore recommended to use expansionentropy_batch directly and evaluate the result yourself, as this step is known to be inaccurate for non-chaotic systems (where H fluctuates strongly around 0).\n\n[1] : B. Hunt & E. Ott, ‘Defining Chaos’, Chaos 25.9 (2015)\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#ChaosTools.boxregion","page":"Detecting & Categorizing Chaos","title":"ChaosTools.boxregion","text":"boxregion(as, bs) -> sampler, restraining\n\nDefine a box in mathbbR^d with edges the as and bs and then return two functions: sampler, which generates a random initial condition in that box and restraining that returns true if a given state is in the box.\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#ChaosTools.expansionentropy_sample","page":"Detecting & Categorizing Chaos","title":"ChaosTools.expansionentropy_sample","text":"expansionentropy_sample(ds, sampler, restraining; kwargs...)\n\nReturn times, H for one sample of ds (see expansionentropy). Accepts the same argumets as expansionentropy, besides batches.\n\n\n\n\n\n","category":"function"},{"location":"chaos/chaos_detection/#ChaosTools.expansionentropy_batch","page":"Detecting & Categorizing Chaos","title":"ChaosTools.expansionentropy_batch","text":"expansionentropy_batch(ds, sampler, restraining; kwargs...)\n\nRun expansionentropy_sample batch times, and return times, mean(H), std(H) for all resulting H, see expansionentropy.\n\nAccepts the same arguments as expansionentropy.\n\n\n\n\n\n","category":"function"},{"location":"embedding/dataset/#Numerical-Data-1","page":"Numerical Data","title":"Numerical Data","text":"","category":"section"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"Numerical data in DynamicalSystems.jl is most often represented by a structure called Dataset","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"Dataset","category":"page"},{"location":"embedding/dataset/#DelayEmbeddings.Dataset","page":"Numerical Data","title":"DelayEmbeddings.Dataset","text":"Dataset{D, T} <: AbstractDataset{D,T}\n\nA dedicated interface for datasets. It contains equally-sized datapoints of length D, represented by SVector{D, T}.\n\nWhen indexed with 1 index, a dataset is like a vector of datapoints.\n\nWhen indexed with 2 indices it behaves like a matrix that has each of the columns be the timeseries of each of the dynamic variables.\n\nDescription of indexing\n\nIn the following let i, j be integers,  typeof(data) <: AbstractDataset and v1, v2 be <: AbstractVector{Int} (v1, v2 could also be ranges).\n\ndata[i] gives the ith datapoint (returns an SVector)\ndata[v1] will return a vector of datapoints\ndata[v1, :] using a Colon as a second index will return a Dataset of these points\ndata[:, j] gives the jth variable timeseries, as Vector\ndata[v1, v2] returns a Dataset with the appropriate entries (first indices being \"time\"/point index, while second being dynamic variables)\ndata[i, j] value of the jth variable, at the ith timepoint\n\nUse Matrix(dataset) or Dataset(matrix) to convert. It is assumed that each column of the matrix is one dynamic variable. If you have various timeseries vectors x, y, z, ... pass them like Dataset(x, y, z, ...). You can use columns(dataset) to obtain the reverse, i.e. all columns of the dataset in a tuple.\n\n\n\n\n\n","category":"type"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"In essence a Dataset is simply a container for a Vector of SVectors. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the column direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"using DynamicalSystems\nhen = Systems.henon()\ndata = trajectory(hen, 10000) # this returns a dataset\nfor point in data\n# do stuff with each datapoint\n# (vector with as many elements as system dimension)\nend","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"Most functions from DynamicalSystems.jl that manipulate and use data are expecting an AbstractDataset subtype. This allows us to define efficient methods that coordinate well with each other, like e.g. neighborhood.","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"If given a matrix, we first convert to Dataset. This means that you should first convert your data to a Dataset if you want to call functions more than once, to avoid constantly converting.","category":"page"},{"location":"embedding/dataset/#Dataset-Functions-1","page":"Numerical Data","title":"Dataset Functions","text":"","category":"section"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"Functions that operate on datasets.","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"minima\nmaxima\nminmaxima\ncolumns","category":"page"},{"location":"embedding/dataset/#DelayEmbeddings.minima","page":"Numerical Data","title":"DelayEmbeddings.minima","text":"minima(dataset)\n\nReturn an SVector that contains the minimum elements of each timeseries of the dataset.\n\n\n\n\n\n","category":"function"},{"location":"embedding/dataset/#DelayEmbeddings.maxima","page":"Numerical Data","title":"DelayEmbeddings.maxima","text":"maxima(dataset)\n\nReturn an SVector that contains the maximum elements of each timeseries of the dataset.\n\n\n\n\n\n","category":"function"},{"location":"embedding/dataset/#DelayEmbeddings.minmaxima","page":"Numerical Data","title":"DelayEmbeddings.minmaxima","text":"minmaxima(dataset)\n\nReturn minima(dataset), maxima(dataset) without doing the computation twice.\n\n\n\n\n\n","category":"function"},{"location":"embedding/dataset/#DelayEmbeddings.columns","page":"Numerical Data","title":"DelayEmbeddings.columns","text":"columns(dataset) -> x, y, z, ...\n\nReturn the individual columns of the dataset.\n\n\n\n\n\n","category":"function"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"","category":"page"},{"location":"embedding/dataset/#Dataset-I/O-1","page":"Numerical Data","title":"Dataset I/O","text":"","category":"section"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"Input/output functionality for an AbstractDataset is already achieved using base Julia, specifically writedlm and readdlm.","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"The thing to note is that all data of an AbstractDataset is contained within its field data.","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"To write and read a dataset, simply do:","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"using DelimitedFiles\n\ndata = Dataset(rand(1000, 2))\n\n# I will write and read using delimiter ','\nwritedlm(\"data.txt\", data.data, ',')\n\n# Don't forget to convert the matrix to a Dataset when reading\ndata = Dataset(readdlm(\"data.txt\", ',', Float64))","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"","category":"page"},{"location":"embedding/dataset/#Neighborhoods-in-a-dataset-1","page":"Numerical Data","title":"Neighborhoods in a dataset","text":"","category":"section"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"Combining the excellent performance of NearestNeighbors.jl with the AbstractDataset allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of AbstractNeighborhood.","category":"page"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"neighborhood\nAbstractNeighborhood","category":"page"},{"location":"embedding/dataset/#DelayEmbeddings.neighborhood","page":"Numerical Data","title":"DelayEmbeddings.neighborhood","text":"neighborhood(point, tree, ntype)\nneighborhood(point, tree, ntype, n::Int, w::Int = 1)\n\nReturn a vector of indices which are the neighborhood of point in some data, where the tree was created using tree = KDTree(data [, metric]). The ntype is the type of neighborhood and can be any subtype of AbstractNeighborhood.\n\nUse the second method when the point belongs in the data, i.e. point = data[n]. Then w stands for the Theiler window (positive integer). Only points that have index abs(i - n) ≥ w are returned as a neighborhood, to exclude close temporal neighbors. The default w=1 is the case of excluding the point itself.\n\nReferences\n\nneighborhood simply interfaces the functions knn and inrange from NearestNeighbors.jl by using the argument ntype.\n\n\n\n\n\n","category":"function"},{"location":"embedding/dataset/#DelayEmbeddings.AbstractNeighborhood","page":"Numerical Data","title":"DelayEmbeddings.AbstractNeighborhood","text":"AbstractNeighborhood\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\nConcrete subtypes:\n\nFixedMassNeighborhood(K::Int) : The neighborhood of a point consists of the K nearest neighbors of the point.\nFixedSizeNeighborhood(ε::Real) : The neighborhood of a point consists of all neighbors that have distance < ε from the point.\n\nSee neighborhood for more.\n\n\n\n\n\n","category":"type"},{"location":"embedding/dataset/#","page":"Numerical Data","title":"Numerical Data","text":"","category":"page"},{"location":"chaos/entropies/#Entropies-and-Dimensions-1","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"section"},{"location":"chaos/entropies/#Generalized-Entropy-1","page":"Entropies and Dimensions","title":"Generalized Entropy","text":"","category":"section"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known thermodynamic ones, used in Statistical Physics. Rather, they are more like the to the entropies of information theory, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"One way of computing entropies in DynamicalSystems.jl is the \"generalized entropy\":","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"genentropy","category":"page"},{"location":"chaos/entropies/#ChaosTools.genentropy","page":"Entropies and Dimensions","title":"ChaosTools.genentropy","text":"genentropy(α, ε, dataset::AbstractDataset; base = e)\n\nCompute the α order generalized (Rényi) entropy [1] of a dataset, by first partitioning it into boxes of length ε using non0hist.\n\ngenentropy(α, p::AbstractArray; base = e)\n\nCompute the entropy of an array p directly, assuming that p is sum-normalized.\n\nOptionally use base for the logarithms.\n\nDescription\n\nLet p be an array of probabilities (summing to 1). Then the Rényi entropy is\n\nH_alpha(p) = frac11-alpha log left(sum_i pi^alpharight)\n\nand generalizes other known entropies, like e.g. the information entropy (alpha = 1, see [2]), the maximum entropy (alpha=0, also known as Hartley entropy), or the correlation entropy (alpha = 2, also known as collision entropy).\n\nReferences\n\n[1] : A. Rényi, Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability, pp 547 (1960)\n\n[2] : C. E. Shannon, Bell Systems Technical Journal 27, pp 379 (1948)\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"Basically, given a Dataset you can partition it into boxes to calculate an entropy. See below for a detailed example.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"tip: Worried about memory overflow? Don't be!\nPartitioning the dataset (i.e. doing a histogram) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size ε.However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"The function used internally by genentropy is non0hist:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"non0hist","category":"page"},{"location":"chaos/entropies/#ChaosTools.non0hist","page":"Entropies and Dimensions","title":"ChaosTools.non0hist","text":"non0hist(ε, dataset::AbstractDataset)\n\nPartition a dataset into tabulated intervals (boxes) of size ε and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements and bin edge information.\n\nPerformances Notes\n\nThis method has a linearithmic time complexity (n log(n) for n = length(data)) and a linear space complexity (l for l = dimension(data)). This allows computation of entropies of high-dimensional datasets and with small box sizes ε without memory overflow.\n\nUse e.g. fit(Histogram, ...) from StatsBase if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#Attractor-Dimension-Estimation-1","page":"Entropies and Dimensions","title":"Attractor Dimension Estimation","text":"","category":"section"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the Fractal dimension. This real number can offer a lot of information about the object that the dataset represents.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"Based on the definition of the generalized entropy, one can calculate an appropriate dimension, called generalized dimension:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"generalized_dim","category":"page"},{"location":"chaos/entropies/#ChaosTools.generalized_dim","page":"Entropies and Dimensions","title":"ChaosTools.generalized_dim","text":"generalized_dim(α, dataset [, sizes]) -> D_α\n\nReturn the α order generalized dimension of the dataset, by calculating the genentropy for each ε ∈ sizes.\n\nDescription\n\nThe returned dimension is approximated by the (inverse) power law exponent of the scaling of the genentropy versus the box size ε, where ε ∈ sizes.\n\nCalling this function performs a lot of automated steps:\n\nA vector of box sizes is decided by calling sizes = estimate_boxsizes(dataset), if sizes is not given.\nFor each element of sizes the appropriate entropy is calculated, through d = genentropy.(α, sizes, dataset). Let x = -log.(sizes).\nThe curve d(x) is decomposed into linear regions, using linear_regions(x, d).\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the function linear_region. This slope is the return value of generalized_dim.\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\nThe following aliases are provided:\n\nα = 0 : boxcounting_dim, capacity_dim\nα = 1 : information_dim\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"danger: Be wary when using `generalized_dim`\nAs stated clearly by the documentation string, calling generalized_dim performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"estimate_boxsizes\nlinear_regions\nlinear_region","category":"page"},{"location":"chaos/entropies/#ChaosTools.estimate_boxsizes","page":"Entropies and Dimensions","title":"ChaosTools.estimate_boxsizes","text":"estimate_boxsizes(dataset::AbstractDataset; k::Int = 12, z = -1, w = 1)\n\nReturn k exponentially spaced values: 10 .^ range(lower+w, upper+z, length = k).\n\nlower is the magnitude of the minimum pair-wise distance between datapoints while upper is the magnitude of the maximum difference between greatest and smallest number among each timeseries.\n\n\"Magnitude\" here stands for order of magnitude, i.e. round(log10(x)).\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#ChaosTools.linear_regions","page":"Entropies and Dimensions","title":"ChaosTools.linear_regions","text":"linear_regions(x, y; dxi::Int = 1, tol = 0.2) -> (lrs, tangents)\n\nIdentify regions where the curve y(x) is linear, by scanning the x-axis every dxi indices (e.g. at x[1] to x[5], x[5] to x[10], x[10] to x[15] and so on if dxi=5).\n\nIf the slope (calculated using LsqFit) of a region of width dxi is approximatelly equal to that of the previous region, within tolerance tol, then these two regions belong to the same linear region.\n\nReturn the indices of x that correspond to linear regions, lrs, and the approximated tangents at each region. lrs is a vector of Int. Notice that tangents is not accurate: it is not recomputed at every step, but only when its error exceeds the tolerance tol! Use linear_region to obtain a correct estimate for the slope of the largest linear region.\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#ChaosTools.linear_region","page":"Entropies and Dimensions","title":"ChaosTools.linear_region","text":"linear_region(x, y; dxi::Int = 1, tol = 0.2) -> ([ind1, ind2], slope)\n\nCall linear_regions, identify the largest linear region and approximate the slope of the entire region using linreg. Return the indices where the region starts and stops (x[ind1:ind2]) as well as the approximated slope.\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#Example-1","page":"Entropies and Dimensions","title":"Example","text":"","category":"section"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"For an example of using entropies to compute the dimension of an attractor let's use everyone's favorite system:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"using DynamicalSystems, PyPlot\nlor = Systems.lorenz()","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"Our goal is to compute entropies for many different partition sizes ε, so let's get down to it:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"tr = trajectory(lor, 100.0; Ttr = 10.0)\n\nες = ℯ .^ (-3.5:0.5:3.5) # semi-random guess\nHs = genentropy.(1, ες, Ref(tr))","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"xs = @. -log(ες)\nfigure()\nplot(xs, Hs)\nylabel(\"\\$H_1\\$\")\nxlabel(\"\\$-\\\\log (\\\\epsilon)\\$\");\nsavefig(\"genentropy1.png\"); nothing # hide","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"(Image: )","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"The slope of the linear scaling region of the above plot is the generalized dimension (of order α = 2) for the attractor of the Lorenz system.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"Given that we see the plot, we can estimate where the linear scaling region starts and ends. However, we can use the function linear_region to get an estimate of the result as well. First let's visualize what it does:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"lrs, slopes = linear_regions(xs, Hs, tol = 0.25)\n\nfigure()\nfor i in 1:length(lrs)-1\n    plot(xs[lrs[i]:lrs[i+1]], Hs[lrs[i]:lrs[i+1]], marker = \"o\")\nend\nylabel(\"\\$H_1\\$\")\nxlabel(\"\\$-\\\\log (\\\\epsilon)\\$\");\nsavefig(\"genentropy2.png\"); nothing # hide","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"(Image: )","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"The linear_region function  computes the slope of the largest region:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"linear_region(xs, Hs)[2]","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"This result is an approximation of the information dimension (because we used α = 1) of the Lorenz attractor.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"The above pipeline is bundled in generalized_dim. For example, the dimension of the strange attractor of the Systems.henon map, following the above approach but taking automated steps, is:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"using DynamicalSystems\nhen = Systems.henon()\nts = trajectory(hen, 200000)\nD_hen = generalized_dim(1, ts)","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D 56, pp 185-187 (1992)).","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#Permutation-Entropy-1","page":"Entropies and Dimensions","title":"Permutation Entropy","text":"","category":"section"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"The permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"permentropy","category":"page"},{"location":"chaos/entropies/#ChaosTools.permentropy","page":"Entropies and Dimensions","title":"ChaosTools.permentropy","text":"permentropy(x::AbstractVector, order [, interval=1]; base = e)\n\nCompute the permutation entropy [1] of given order from the x timeseries.\n\nOptionally, interval can be specified to use x[t0:interval:t1] when calculating permutation of the sliding windows between t0 and t1 = t0 + interval * (order - 1).\n\nOptionally use base for the logarithms.\n\nReferences\n\n[1] : C. Bandt, & B. Pompe, Phys. Rev. Lett. 88 (17), pp 174102 (2002)\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"For example, we will compute and compare the lyapunov exponent of the logistic map with the order-6 permutation entropy, like in the original paper.","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"using DynamicalSystems, PyPlot\nds = Systems.logistic()\nrs = 3.5:0.001:4\nls = Float64[]; hs = Float64[]\nfor r in rs\n    ds.p[1] = r\n    push!(ls, lyapunov(ds, 100000))\n    # For 1D systems `trajectory` returns a vector\n    push!(hs, permentropy(trajectory(ds, 10000), 6))\nend\n\nf = figure(figsize = (10,6))\na1 = subplot(211)\nplot(rs, ls); ylim(-2, log(2)); ylabel(\"\\$\\\\lambda\\$\")\na1.axes.get_xaxis().set_ticklabels([])\nxlim(rs[1], rs[end]);\n\na2 = subplot(212)\nplot(rs, hs; color = \"C1\"); ylabel(\"\\$h_6\\$\")\nxlim(rs[1], rs[end]); xlabel(\"\\$r\\$\")\ntight_layout()\nsavefig(\"permentropy.png\"); nothing # hide","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"(Image: )","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"info: Permutation Entropy performance\nEven though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue ChaosTools.jl#22 keeps track of this, and contains information on how to improve performance.","category":"page"},{"location":"chaos/entropies/#Kaplan-Yorke-Dimension-1","page":"Entropies and Dimensions","title":"Kaplan-Yorke Dimension","text":"","category":"section"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"kaplanyorke_dim","category":"page"},{"location":"chaos/entropies/#ChaosTools.kaplanyorke_dim","page":"Entropies and Dimensions","title":"ChaosTools.kaplanyorke_dim","text":"kaplanyorke_dim(lyapunovs::AbstractVector)\n\nCalculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].\n\nDescription\n\nThe Kaplan-Yorke dimension is simply the point where cumsum(lyapunovs) becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.\n\nUseful in combination with lyapunovs.\n\nReferences\n\n[1] :  J. Kaplan & J. Yorke, Chaotic behavior of multidimensional difference equations, Lecture Notes in Mathematics vol. 730, Springer (1979)\n\n\n\n\n\n","category":"function"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:","category":"page"},{"location":"chaos/entropies/#","page":"Entropies and Dimensions","title":"Entropies and Dimensions","text":"using DynamicalSystems\nhen = Systems.henon()\nD_kp = kaplanyorke_dim(lyapunovs(hen, 100000))","category":"page"},{"location":"chaos/nlts/#Nonlinear-Timeseries-Analysis-1","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"","category":"section"},{"location":"chaos/nlts/#Numerical-Lyapunov-Exponent-1","page":"Nonlinear Timeseries Analysis","title":"Numerical Lyapunov Exponent","text":"","category":"section"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"Given any timeseries, one can first reconstruct it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"numericallyapunov","category":"page"},{"location":"chaos/nlts/#ChaosTools.numericallyapunov","page":"Nonlinear Timeseries Analysis","title":"ChaosTools.numericallyapunov","text":"numericallyapunov(R::Dataset, ks;  refstates, w, distance, ntype)\n\nReturn E = [E(k) for k ∈ ks], where E(k) is the average logarithmic distance between states of a neighborhood that are evolved in time for k steps (k must be integer).\n\nKeyword Arguments\n\nrefstates = 1:(length(R) - ks[end]) : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in refstates.\nw::Int = 1 : The Theiler window, which determines whether points are separated enough in time to be considered separate trajectories (see [1] and neighborhood).\nntype::AbstractNeighborhood = FixedMassNeighborhood(1) : The method to be used when evaluating the neighborhood of each reference state. See AbstractNeighborhood or neighborhood for more info.\ndistance::Metric = Cityblock() : The distance function used in the logarithmic distance of nearby states. The allowed distances are Cityblock() and Euclidean(). See below for more info.\n\nDescription\n\nIf the dataset/reconstruction exhibits exponential divergence of nearby states, then it should clearly hold\n\nE(k) approx lambdaDelta t k + E(0)\n\nfor a well defined region in the k axis, where lambda is the approximated maximum Lyapunov exponent. Delta t is the time between samples in the original timeseries. You can use linear_region with arguments (ks .* Δt, E) to identify the slope (= lambda) immediatelly, assuming you have choosen sufficiently good ks such that the linear scaling region is bigger than the saturated region. The algorithm used in this function is due to Parlitz [Skokos2016], which itself expands upon Kantz [Kantz1994]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index k increases. The average of the above over all neighborhood states over all reference states is the returned result. If the Metric is Euclidean() then use the Euclidean distance of the full D-dimensional points (distance d_E in ref. [Skokos2016]). If however the Metric is Cityblock(), calculate the absolute distance of only the first elements of the m+k and n+k points of the reconstruction R (distance d_F in ref. [Skokos2016]).\n\nReferences\n\n[Skokos2016]: Skokos, C. H. et al., Chaos Detection and Predictability - Chapter 1\n\n(section 1.3.2), Lecture Notes in Physics 915, Springer (2016)\n\n[Kantz1994]: Kantz, H., Phys. Lett. A 185, pp 77–87 (1994)\n\n\n\n\n\n","category":"function"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"The function numericallyapunov has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.","category":"page"},{"location":"chaos/nlts/#Example-of-Numerical-Lyapunov-computation-1","page":"Nonlinear Timeseries Analysis","title":"Example of Numerical Lyapunov computation","text":"","category":"section"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"using DynamicalSystems, PyPlot\n\nds = Systems.henon()\ndata = trajectory(ds, 100000)\nx = data[:, 1] #fake measurements for the win!\n\nks = 1:20\nℜ = 1:10000\nfig = figure(figsize=(10,6))\n\nfor (i, di) in enumerate([Euclidean(), Cityblock()])\n    subplot(1, 2, i)\n    ntype = FixedMassNeighborhood(2)\n    title(\"Distance: $(di)\", size = 18)\n    for D in [1, 3, 6]\n        R = reconstruct(x, D, 1)\n        E = numericallyapunov(R, ks;\n        refstates = ℜ, distance = di, ntype = ntype)\n        Δt = 1\n        λ = linear_region(ks.*Δt, E)[2]\n        # gives the linear slope, i.e. the Lyapunov exponent\n        plot(ks .- 1, E .- E[1], label = \"D=$D, λ=$(round(λ, digits = 3))\")\n        legend()\n        tight_layout()\n    end\nend\nsavefig(\"numerlyap.png\"); nothing # hide","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"(Image: )","category":"page"},{"location":"chaos/nlts/#Bad-Time-axis-(ks)-length-1","page":"Nonlinear Timeseries Analysis","title":"Bad Time-axis (ks) length","text":"","category":"section"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"danger: Large `ks`\nThis simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"Let's revisit the example of the previous section:","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"ds = Systems.henon()\ndata = trajectory(ds, 100000)\nx = data[:, 1]\nlength(x)","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"The timeseries of such length could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"ks = 1:100\nR = reconstruct(x, 1, 1)\nE = numericallyapunov(R, ks, ntype = FixedMassNeighborhood(2))\nfigure()\nplot(ks .- 1, E .- E[1])\ntitle(\"Lyappunov: $(linear_region(ks, E)[2])\")\nsavefig(\"badlyap.png\"); nothing # hide","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"(Image: )","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function linear_region would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)","category":"page"},{"location":"chaos/nlts/#Case-of-a-Continuous-system-1","page":"Nonlinear Timeseries Analysis","title":"Case of a Continuous system","text":"","category":"section"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"The process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example helps the users get familiar with the process:","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"using DynamicalSystems, PyPlot\n\nntype = FixedMassNeighborhood(5) #5 nearest neighbors of each state\n\nds = Systems.lorenz()\n# create a timeseries of 1 dimension\ndt = 0.05\nx = trajectory(ds, 1000.0; dt = dt)[:, 1]","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"We know that we have to use much bigger ks than 1:20, because this is a continuous case! (See reference given in numericallyapunovs)","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"ks1 = 0:200","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"and in fact it is even better to not increment the ks one by one but instead do","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"ks2 = 0:4:200","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"Now we plot some example computations","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"figure()\nfor D in [3, 7], τ in [7, 15]\n    r = reconstruct(x, D, τ)\n\n    # E1 = numericallyapunov(r, ks1; ntype = ntype)\n    # λ1 = linear_region(ks1 .* dt, E1)[2]\n    E2 = numericallyapunov(r, ks2; ntype = ntype)\n    λ2 = linear_region(ks2 .* dt, E2)[2]\n\n    # plot(ks1,E1.-E1[1], label = \"dense, D=$(D), τ=$(τ), λ=$(round(λ1, 3))\")\n    plot(ks2,E2.-E2[1], label = \"D=$(D), τ=$(τ), λ=$(round(λ2, digits = 3))\")\nend\n\nlegend()\nxlabel(\"k (0.05×t)\")\nylabel(\"E - E(0)\")\ntitle(\"Continuous Reconstruction Lyapunov\")\ntight_layout()\nsavefig(\"continuousnumlyap.png\"); nothing # hide","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"(Image: )","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"As you can see, using τ = 15 is not a great choice! The estimates with τ = 7 though are very good (the actual value is around λ ≈ 0.89...).","category":"page"},{"location":"chaos/nlts/#Broomhead-King-Coordinates-1","page":"Nonlinear Timeseries Analysis","title":"Broomhead-King Coordinates","text":"","category":"section"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"broomhead_king","category":"page"},{"location":"chaos/nlts/#ChaosTools.broomhead_king","page":"Nonlinear Timeseries Analysis","title":"ChaosTools.broomhead_king","text":"broomhead_king(s::AbstractVector, d::Int) -> U, S, Vtr\n\nReturn the Broomhead-King coordinates of a timeseries s by performing svd on the so-called trajectory matrix with dimension d.\n\nDescription\n\nBroomhead and King coordinates is an approach proposed in [1] that applies the Karhunen–Loève theorem to delay coordinates embedding with smallest possible delay.\n\nThe function performs singular value decomposition on the d-dimensional trajectory matrix X of s,\n\nX = frac1sqrtNleft(\nbeginarraycccc\nx_1  x_2  ldots  x_d \nx_2  x_3  ldots  x_d+1\nvdots  vdots  vdots  vdots \nx_N-d+1  x_N-d+2 ldots  x_N\nendarray\nright) = Ucdot S cdot V^tr\n\nwhere x = s - bars. The columns of U can then be used as a new coordinate system, and by considering the values of the singular values S you can decide how many columns of U are \"important\". See the documentation page for example application.\n\nReferences\n\n[1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A 20, 9, pp L563 (1987)\n\n\n\n\n\n","category":"function"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"This alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"Take the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"using DynamicalSystems, PyPlot\n\nds = Systems.gissinger()\ndata = trajectory(ds, 1000.0, dt = 0.05)\nx = data[:, 1]\n\nL = length(x)\ns = x .+ 0.5rand(L) #add noise\n\nU, S = broomhead_king(s, 40)\nsummary(U)","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"Now let's simply compare the above result with the one you get from doing a \"standard\" call to reconstruct:","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"figure(figsize= (10,6))\nsubplot(1,2,1)\nplot(U[:, 1], U[:, 2])\ntitle(\"Broomhead-King of s\")\n\nsubplot(1,2,2)\nR = reconstruct(s, 1, 30)\nplot(columns(R)...; color = \"C3\")\ntitle(\"2D reconstruction of s\")\ntight_layout()\nsavefig(\"broomhead_king.png\"); nothing # hide","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"(Image: )","category":"page"},{"location":"chaos/nlts/#","page":"Nonlinear Timeseries Analysis","title":"Nonlinear Timeseries Analysis","text":"we have used the same system as in the Delay Coordinates Embedding example, and picked the optimal delay time of τ = 30 (for same dt = 0.05). Regardless, the vanilla delay coordinates is much worse than the Broomhead-King coordinates.","category":"page"},{"location":"chaos/visualization/#","page":"-","title":"-","text":"DynamicalSystems.jl offers some basic methods for visualizing chaotic systems in the form of the functions described in this documentation page.","category":"page"},{"location":"chaos/visualization/#","page":"-","title":"-","text":"All plotting is done through the PyPlot.jl package. However, this is not a dependency of DynamicalSystems.jl. Instead, all functions described here are brought into scope as soon as the user executes using PyPlot, which works regardless if PyPlot module was loaded before or after DynamicalSystems. This is possible through the Requires.jl package.","category":"page"},{"location":"chaos/visualization/#","page":"-","title":"-","text":"Use the help mode (press ? and then the function name) to access the documentation strings for e.g. using keyword arguments.","category":"page"},{"location":"chaos/visualization/#Visualization-Library-1","page":"-","title":"Visualization Library","text":"","category":"section"},{"location":"chaos/visualization/#","page":"-","title":"-","text":"phasespace : Plots the phasespace of a 2D DiscreteDynamicalSystem.\nplot_linear_regions : Plots the results of lnear_regions.\nplot_dataset : Plots each column of a dataset.\nplot_trajectory : Produces a trajectory and plots each column.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"(Image: DynamicalSystems.jl logo: The Double Pendulum)","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"DynamicalSystems.jl is an award-winning Julia software library for the exploration of chaos and nonlinear dynamics. It is part of JuliaDynamics, an organization dedicated to creating high quality scientific software.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"tip: Latest news\nExpansion entropy from Ott and Hunt implemented as expansionentropy!","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"The documentation you are reading now was built with the following stable versions:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"using Pkg.API: installed\nins = installed()\nfunction f()\nfor pkg in [\"DelayEmbeddings\", \"RecurrenceAnalysis\", \"DynamicalSystemsBase\", \"ChaosTools\"]\n  println(rpad(\" * $(pkg) \", 30, \".\"), \" $(ins[pkg])\")\nend\nend","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"f() # hide","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"info: Introductory textbooks\nOur library assumes some basic knowledge of nonlinear dynamics and complex systems.If you are new to the field but want to learn more, we can suggest the following textbooks as introductions:Nonlinear Dynamics And Chaos - S. Strogatz\nAn Exploration of Dynamical Systems and Chaos - J. Argyris et al.\nChaos in Dynamical Systems - E. Ott\nNonlinear Time series Analysis - H. Kantz & T. Schreiber\nChaos and Integrability in Nonlinear Dynamics - M. Tabor","category":"page"},{"location":"#Installation-1","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Simply use ]add DynamicalSystems to install everything. Alternatively you can also do using Pkg; Pkg.add(\"DynamicalSystems\").","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"For more advanced users, you can choose which packages to install and use at a high level. The package DynamicalSystems serves two purposes: it re-exports everything under a single module DynamicalSystems and it also builds the documentation.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"All packages depend on DelayEmbeddings which defines core numeric data structures and methods. For example RecurrenceAnalysis and TimeseriesPrediction depend only on DelayEmbeddings. Packages that require equations of motion also depend on DynamicalSystemsBase, like for example ChaosTools.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"If you only need functionality of a specific package you can install only that one, e.g. ]add RecurrenceAnalysis and only the minimum amount of requirements will be installed.","category":"page"},{"location":"#Tutorials-1","page":"Introduction","title":"Tutorials","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Tutorials for DynamicalSystems.jl exist in the form of Jupyter notebooks.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"In addition, a full 2-hours YouTube tutorial is available below:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/A8g9rdEfdNg\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"#Our-Goals-1","page":"Introduction","title":"Our Goals","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"The ultimate goal for DynamicalSystems.jl is to be a useful software library for students and scientists working on chaos, nonlinear dynamics and in general dynamical systems. The word \"library\" is intended in the literal sense: a place where people go to learn things.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"With DynamicalSystems.jl we try to","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"Be concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the Lorenz attractor, or a high dimensional discrete map like coupled standard maps.\nBe accurate, reliable and performant.\nBe transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.","category":"page"},{"location":"#Citing-1","page":"Introduction","title":"Citing","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"There is a (very small) paper associated with DynamicalSystems.jl. If we have helped you in research that led to a publication, please be kind enough to cite it, using the DOI 10.21105/joss.00598 or the following BiBTeX entry:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"@article{Datseris2018,\n  doi = {10.21105/joss.00598},\n  url = {https://doi.org/10.21105/joss.00598},\n  year  = {2018},\n  month = {mar},\n  volume = {3},\n  number = {23},\n  pages = {598},\n  author = {George Datseris},\n  title = {DynamicalSystems.jl: A Julia software library for chaos and nonlinear dynamics},\n  journal = {Journal of Open Source Software}\n}","category":"page"},{"location":"#Issues-with-Bounties-1","page":"Introduction","title":"Issues with Bounties","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Money that DynamicalSystems.jl obtains from awards, sponsors or donators are converted into bounties for GitHub issues. The full list of issues that have a bounty is available here.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"By solving these issues you not only contribute to open source, but you also get some pocket money to boot :)","category":"page"},{"location":"#Contacting-1","page":"Introduction","title":"Contacting","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"You can join our chatroom for discussions and/or questions about the packages of the JuliaDynamics organization! If you are using the Julia Slack workplace, please join the channel #dynamics-bridged.","category":"page"},{"location":"#Contributing-and-Donating-1","page":"Introduction","title":"Contributing & Donating","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Be sure to visit the Contributor Guide page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on GitHub! This gives us an accurate lower bound of users that this package has already helped!","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"Finally, you can donate for the development of DynamicalSystems.jl. You can do that by adding bounties to existing issues on the GitHub repositories (you can open new issues as well). Every issue has an automatic way to create a bounty using Bountysource, see the first comment of each issue.","category":"page"},{"location":"#Contributor-list-1","page":"Introduction","title":"Contributor list","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"The GitHub \"contributor list\" for DynamicalSystems.jl is misleading. For a true list of contributors you should visit the GitHub's contributor list for the sub-packages of DynamicalSystems.jl, e.g. ChaosTools.jl.","category":"page"}]
}
