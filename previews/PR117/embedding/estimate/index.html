<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimal DCE Parameters · DynamicalSystems.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DynamicalSystems.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DynamicalSystems.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../contents/">Contents</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Dynamical systems</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../ds/general/">Dynamical System Definition</a></li><li><a class="tocitem" href="../../ds/predefined/">Predefined Dynamical Systems</a></li><li><a class="tocitem" href="../dataset/">Numerical Data</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox" checked/><label class="tocitem" for="menuitem-4"><span class="docs-label">DelayEmbeddings</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../reconstruction/">Delay Coordinates Embedding</a></li><li class="is-active"><a class="tocitem" href>Optimal DCE Parameters</a><ul class="internal"><li><a class="tocitem" href="#Independent-delay-time-1"><span>Independent delay time</span></a></li><li><a class="tocitem" href="#Independent-embedding-dimension-1"><span>Independent embedding dimension</span></a></li><li><a class="tocitem" href="#Unified-approach-1"><span>Unified approach</span></a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">ChaosTools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../chaos/orbitdiagram/">Orbit Diagrams &amp; PSOS</a></li><li><a class="tocitem" href="../../chaos/lyapunovs/">Lyapunov Exponents</a></li><li><a class="tocitem" href="../../chaos/chaos_detection/">Detecting &amp; Categorizing Chaos</a></li><li><a class="tocitem" href="../../chaos/entropies/">Entropies and Dimensions</a></li><li><a class="tocitem" href="../../chaos/nlts/">Nonlinear Timeseries Analysis</a></li><li><a class="tocitem" href="../../chaos/periodicity/">Periodicity &amp; Ergodicity</a></li><li><a class="tocitem" href="../../chaos/choosing/">Choosing a solver</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">RecurrenceAnalysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../rqa/rplots/">Recurrence Plots</a></li><li><a class="tocitem" href="../../rqa/quantification/">Recurrence Quantification Analysis</a></li><li><a class="tocitem" href="../../rqa/windowed/">Windowed RQA</a></li></ul></li><li><a class="tocitem" href="../../advanced/">Advanced Documentation</a></li><li><a class="tocitem" href="../../contributors_guide/">Contributor Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">DelayEmbeddings</a></li><li class="is-active"><a href>Optimal DCE Parameters</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimal DCE Parameters</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/DynamicalSystems.jl/blob/master/docs/src/embedding/estimate.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimal-DCE-Parameters-1"><a class="docs-heading-anchor" href="#Optimal-DCE-Parameters-1">Optimal DCE Parameters</a><a class="docs-heading-anchor-permalink" href="#Optimal-DCE-Parameters-1" title="Permalink"></a></h1><p>This page discusses and provides algorithms for estimating optimal parameters to do Delay Coordinates Embedding (DCE) with.</p><p>The approaches can be grouped into two schools:</p><ol><li><strong>Independent</strong> (also called <strong>traditional</strong>), where one tries to independently find the best value for a delay time <code>τ</code> and an embedding dimension <code>d</code>.</li><li><strong>Unified</strong>, where at the same time an optimal combination of <code>τ, d</code> is found.</li></ol><p>The independent approach is something &quot;old school&quot;, while recent scientific research has shifted almost exclusively to unified approaches.</p><p>In addition, the unified approaches are the only ones that can accommodate multi-variate inputs. This means that if you have multiple measured input timeseries, you should be able to take advantage of all of them for the best possible embedding of the dynamical system&#39;s set.</p><h2 id="Independent-delay-time-1"><a class="docs-heading-anchor" href="#Independent-delay-time-1">Independent delay time</a><a class="docs-heading-anchor-permalink" href="#Independent-delay-time-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.estimate_delay" href="#DelayEmbeddings.estimate_delay"><code>DelayEmbeddings.estimate_delay</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">estimate_delay(s, method::String [, τs = 1:100]; kwargs...) -&gt; τ</code></pre><p>Estimate an optimal delay to be used in <a href="embedding/@ref"><code>reconstruct</code></a> or <a href="../reconstruction/#DelayEmbeddings.embed"><code>embed</code></a>. The <code>method</code> can be one of the following:</p><ul><li><code>&quot;ac_zero&quot;</code> : first delay at which the auto-correlation function becomes &lt;0.</li><li><code>&quot;ac_min&quot;</code> : delay of first minimum of the auto-correlation function.</li><li><code>&quot;mi_min&quot;</code> : delay of first minimum of mutual information of <code>s</code> with itself (shifted for various <code>τs</code>). Keywords <code>nbins, binwidth</code> are propagated into <a href="#DelayEmbeddings.mutualinformation"><code>mutualinformation</code></a>.</li><li><code>&quot;exp_decay&quot;</code> : <a href="#DelayEmbeddings.exponential_decay_fit"><code>exponential_decay_fit</code></a> of the correlation function rounded  to an integer (uses least squares on <code>c(t) = exp(-t/τ)</code> to find <code>τ</code>).</li><li><code>&quot;exp_extrema&quot;</code> : same as above but the exponential fit is done to the absolute value of the local extrema of the correlation function.</li></ul><p>Both the mutual information and correlation function (<code>autocor</code>) are computed <em>only</em> for delays <code>τs</code>. This means that the <code>min</code> methods can never return the first value of <code>τs</code>!</p><p>The method <code>mi_min</code> is significantly more accurate than the others and also returns good results for most timeseries. It is however the slowest method (but still quite fast!).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.exponential_decay_fit" href="#DelayEmbeddings.exponential_decay_fit"><code>DelayEmbeddings.exponential_decay_fit</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">exponential_decay_fit(x, y, weight = :equal) -&gt; τ</code></pre><p>Perform a least square fit of the form <code>y = exp(-x/τ)</code> and return <code>τ</code>. Taken from:  http://mathworld.wolfram.com/LeastSquaresFittingExponential.html. Assumes equal lengths of <code>x, y</code> and that <code>y ≥ 0</code>.</p><p>To use the method that gives more weight to small values of <code>y</code>, use <code>weight = :small</code>.</p></div></section></article><h3 id="Mutual-Information-1"><a class="docs-heading-anchor" href="#Mutual-Information-1">Mutual Information</a><a class="docs-heading-anchor-permalink" href="#Mutual-Information-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.mutualinformation" href="#DelayEmbeddings.mutualinformation"><code>DelayEmbeddings.mutualinformation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mutualinformation(s, τs[; nbins, binwidth])</code></pre><p>Calculate the mutual information between the time series <code>s</code> and its images delayed by <code>τ</code> points for <code>τ</code> ∈ <code>τs</code>, using an <em>improvement</em> of the method outlined by Fraser &amp; Swinney in<sup class="footnote-reference"><a id="citeref-Fraser1986" href="#footnote-Fraser1986">[Fraser1986]</a></sup>.</p><p><strong>Description</strong></p><p>The joint space of <code>s</code> and its <code>τ</code>-delayed image (<code>sτ</code>) is partitioned as a rectangular grid, and the mutual information is computed from the joint and marginal frequencies of <code>s</code> and <code>sτ</code> in the grid as defined in [1]. The mutual information values are returned in a vector of the same length as <code>τs</code>.</p><p>If any of the optional keyword parameters is given, the grid will be a homogeneous partition of the space where <code>s</code> and <code>sτ</code> are defined. The margins of that partition will be divided in a number of bins equal to <code>nbins</code>, such that the width of each bin will be <code>binwidth</code>, and the range of nonzero values of <code>s</code> will be in the centre. If only of those two parameters is given, the other will be automatically calculated to adjust the size of the grid to the area where <code>s</code> and <code>sτ</code> are nonzero.</p><p>If no parameter is given, the space will be partitioned by a recursive bisection algorithm based on the method given in [1].</p><p>Notice that the recursive method of [1] evaluates the joint frequencies of <code>s</code> and <code>sτ</code> in each cell resulting from a partition, and stops when the data points are uniformly distributed across the sub-partitions of the following levels. For performance and stability reasons, the automatic partition method implemented in this function is only used to divide the axes of the grid, using the marginal frequencies of <code>s</code>.</p></div></section></article><h2 id="Independent-embedding-dimension-1"><a class="docs-heading-anchor" href="#Independent-embedding-dimension-1">Independent embedding dimension</a><a class="docs-heading-anchor-permalink" href="#Independent-embedding-dimension-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.optimal_traditional_de" href="#DelayEmbeddings.optimal_traditional_de"><code>DelayEmbeddings.optimal_traditional_de</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">optimal_traditional_de(s, method = &quot;afnn&quot;, dmethod = &quot;mi_min&quot;; kwargs...) → 𝒟, τ, E</code></pre><p>Produce an optimal delay embedding <code>𝒟</code> of the given timeseries <code>s</code> by using the traditional approach of first finding an optimal (and constant) delay time using <a href="#DelayEmbeddings.estimate_delay"><code>estimate_delay</code></a> with the given <code>dmethod</code>, and then an optimal embedding dimension, by calculating an appropriate statistic for each dimension <code>d ∈ 1:dmax</code>. Return the embedding <code>𝒟</code>, the optimal delay time <code>τ</code> (the optimal embedding dimension <code>d</code> is just <code>size(𝒟, 2)</code>) and the actual statistic <code>E</code> used to estimate optimal <code>d</code>.</p><p>Notice that <code>E</code> is a function of the embedding dimension, which ranges from 1 to <code>dmax</code>.</p><p>For calculating <code>E</code> to estimate the dimension we use the given <code>method</code> which can be:</p><ul><li><code>&quot;afnn&quot;</code> (default) is Cao&#39;s &quot;Averaged False Nearest Neighbors&quot; method<sup class="footnote-reference"><a id="citeref-Cao1997" href="#footnote-Cao1997">[Cao1997]</a></sup>,   which gives a ratio of distances between nearest neighbors.</li><li><code>&quot;ifnn&quot;</code> is the &quot;Improved False Nearest Neighbors&quot; from Hegger &amp; Kantz<sup class="footnote-reference"><a id="citeref-Hegger1999" href="#footnote-Hegger1999">[Hegger1999]</a></sup>,   which gives the fraction of false nearest neighbors.</li><li><code>&quot;fnn&quot;</code> is Kennel&#39;s &quot;False Nearest Neighbors&quot; method<sup class="footnote-reference"><a id="citeref-Kennel1992" href="#footnote-Kennel1992">[Kennel1992]</a></sup>, which gives   the number of points that cease to be &quot;nearest neighbors&quot; when the dimension   increases.</li><li><code>&quot;f1nn&quot;</code> is Krakovská&#39;s &quot;False First Nearest Neighbors&quot; method<sup class="footnote-reference"><a id="citeref-Krakovská2015" href="#footnote-Krakovská2015">[Krakovská2015]</a></sup>,   which gives the ratio of pairs of points that cease to be &quot;nearest neighbors&quot;   when the dimension increases.</li></ul><p>For more details, see individual methods: <a href="#DelayEmbeddings.delay_afnn"><code>delay_afnn</code></a>, <a href="#DelayEmbeddings.delay_ifnn"><code>delay_ifnn</code></a>, <a href="#DelayEmbeddings.delay_fnn"><code>delay_fnn</code></a>, <a href="#DelayEmbeddings.delay_f1nn"><code>delay_f1nn</code></a>. The special keywords `` denote for which possible embedding dimensions should the statistics be computed for.</p><div class="admonition is-category-warn"><header class="admonition-header">Careful in automated methods</header><div class="admonition-body"><p>While this method is automated if you want to be <strong>really sure</strong> of the results, you should directly calculate the statistic and plot its values versus the dimensions.</p></div></div><p><strong>Keywords</strong></p><p>The keywords</p><pre><code class="language-none">τs = 1:100, dmax = 10</code></pre><p>denote which delay times and embedding dimensions <code>ds ∈ 1:dmax</code> to consider when calculating optimal embedding. All remaining keywords are propagated to the low level functions:</p><pre><code class="language-none">fnn_thres::Real = 0.05, slope_thres::Real= 0.2, w::Int=1,
rtol=10.0, atol=2.0, τs = 1:100, metric = Euclidean(), r::Real=2.0</code></pre><p><strong>Description</strong></p><p>We estimate the optimal embedding dimension based on the given delay time gained from <code>dmethod</code> as follows: For Cao&#39;s method the optimal dimension is reached, when the slope of the <code>E₁</code>-statistic (output from <code>&quot;afnn&quot;</code>) falls below the threshold <code>slope_thres</code> (Default is .05) and the according stochastic test turns out to be false, i.e. when the <code>E₂</code>-statistic is not &quot;equal&quot; to 1 for all en- countered dimensions. We treat <code>E₂</code>-values as equal to 1, when <code>1-E₂ ≤ fnn_thres</code>. For all the other methods we return the optimal embedding dimension when the corresponding FNN-statistic (output from <code>&quot;ifnn&quot;</code>, <code>&quot;fnn&quot;</code> or <code>&quot;f1nn&quot;</code>) falls below the fnn-threshold <code>fnn_thres</code> (Default is .05) AND the slope of the statistic falls below the threshold <code>slope_thres</code>. Note that with noise contaminated time series, one might need to adjust <code>fnn_thres</code> according to the noise level.</p><p>See also the file <code>test/compare_different_dimension_estimations.jl</code> for a comparison.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.delay_afnn" href="#DelayEmbeddings.delay_afnn"><code>DelayEmbeddings.delay_afnn</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">delay_afnn(s::AbstractVector, τ:Int, ds = 2:6, metric=Euclidean()) → E₁</code></pre><p>Compute the parameter E₁ of Cao&#39;s &quot;averaged false nearest neighbors&quot; method for determining the minimum embedding dimension of the time series <code>s</code>, with a sequence of <code>τ</code>-delayed temporal neighbors.</p><p><strong>Description</strong></p><p>Given the scalar timeseries <code>s</code> and the embedding delay <code>τ</code> compute the values of <code>E₁</code> for each embedding dimension <code>d ∈ ds</code>, according to Cao&#39;s Method (eq. 3 of<sup class="footnote-reference"><a id="citeref-Cao1997" href="#footnote-Cao1997">[Cao1997]</a></sup>).</p><p>This quantity is a ratio of the averaged distances between the nearest neighbors of the reconstructed time series, which quantifies the increment of those distances when the embedding dimension changes from <code>d</code> to <code>d+1</code>.</p><p>Return the vector of all computed <code>E₁</code>s. To estimate a good value for <code>d</code> from this, find <code>d</code> for which the value <code>E₁</code> saturates at some value around 1.</p><p><em>Note: This method does not work for datasets with perfectly periodic signals.</em></p><p>See also: <a href="#DelayEmbeddings.optimal_traditional_de"><code>optimal_traditional_de</code></a> and <a href="embedding/@ref"><code>stochastic_indicator</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.delay_ifnn" href="#DelayEmbeddings.delay_ifnn"><code>DelayEmbeddings.delay_ifnn</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">delay_ifnn(s::Vector, τ::Int, ds = 1:10; kwargs...) → `FNNs`</code></pre><p>Compute and return the <code>FNNs</code>-statistic for the time series <code>s</code> and a uniform time delay <code>τ</code> and embedding dimensions <code>ds</code> after <sup class="footnote-reference"><a id="citeref-Hegger1999" href="#footnote-Hegger1999">[Hegger1999]</a></sup>. In this notation <code>γ ∈ γs = d-1</code>, if <code>d</code> is the embedding dimension. This fraction tends to 0 when the optimal embedding dimension with an appropriate lag is reached.</p><p><strong>Keywords</strong></p><p>*<code>r = 2</code>: Obligatory threshold, which determines the maximum tolerable spreading     of trajectories in the reconstruction space. *<code>metric = Euclidean</code>: The norm used for distance computations. *<code>w = 1</code> = The Theiler window, which excludes temporally correlated points from     the nearest neighbor search.</p><p>See also: <a href="#DelayEmbeddings.optimal_traditional_de"><code>optimal_traditional_de</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.delay_fnn" href="#DelayEmbeddings.delay_fnn"><code>DelayEmbeddings.delay_fnn</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">delay_fnn(s::AbstractVector, τ:Int, ds = 2:6; rtol=10.0, atol=2.0) → FNNs</code></pre><p>Calculate the number of &quot;false nearest neighbors&quot; (FNNs) of the datasets created from <code>s</code> with <code>embed(s, d, τ) for d ∈ ds</code>.</p><p><strong>Description</strong></p><p>Given a dataset made by <code>embed(s, d, τ)</code> the &quot;false nearest neighbors&quot; (FNN) are the pairs of points that are nearest to each other at dimension <code>d</code>, but are separated at dimension <code>d+1</code>. Kennel&#39;s criteria for detecting FNN are based on a threshold for the relative increment of the distance between the nearest neighbors (<code>rtol</code>, eq. 4 in<sup class="footnote-reference"><a id="citeref-Kennel1992" href="#footnote-Kennel1992">[Kennel1992]</a></sup>), and another threshold for the ratio between the increased distance and the &quot;size of the attractor&quot; (<code>atol</code>, eq. 5 in<sup class="footnote-reference"><a id="citeref-Kennel1992" href="#footnote-Kennel1992">[Kennel1992]</a></sup>). These thresholds are given as keyword arguments.</p><p>The returned value is a vector with the number of FNN for each <code>γ ∈ γs</code>. The optimal value for <code>γ</code> is found at the point where the number of FNN approaches zero.</p><p>See also: <a href="#DelayEmbeddings.optimal_traditional_de"><code>optimal_traditional_de</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.delay_f1nn" href="#DelayEmbeddings.delay_f1nn"><code>DelayEmbeddings.delay_f1nn</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">delay_f1nn(s::AbstractVector, τ::Int, ds = 2:6, metric = Euclidean())</code></pre><p>Calculate the ratio of &quot;false first nearest neighbors&quot; (FFNN) of the datasets created from <code>s</code> with <code>embed(s, d, τ) for d ∈ ds</code>.</p><p><strong>Description</strong></p><p>Given a dataset made by <code>embed(s, d, τ)</code> the &quot;false first nearest neighbors&quot; (FFNN) are the pairs of points that are nearest to each other at dimension <code>d</code> that cease to be nearest neighbors at dimension <code>d+1</code>.</p><p>The returned value is a vector with the ratio between the number of FFNN and the number of points in the dataset for each <code>d ∈ ds</code>. The optimal value for <code>d</code> is found at the point where this ratio approaches zero.</p><p>See also: <a href="#DelayEmbeddings.optimal_traditional_de"><code>optimal_traditional_de</code></a>.</p></div></section></article><h3 id="Example-1"><a class="docs-heading-anchor" href="#Example-1">Example</a><a class="docs-heading-anchor-permalink" href="#Example-1" title="Permalink"></a></h3><pre><code class="language-julia">using DynamicalSystems, PyPlot

ds = Systems.roessler()
# This trajectory is a chaotic attractor with fractal dim ≈ 2
# therefore the set needs at least embedding dimension of 3
tr = trajectory(ds, 1000.0; dt = 0.05)
x = tr[:, 1]

dmax = 7
fig = figure()
for (i, method) in enumerate([&quot;afnn&quot;, &quot;fnn&quot;, &quot;f1nn&quot;, &quot;ifnn&quot;])
    # Plot statistic used to estimate optimal embedding
    # as well as the automated output embedding
    𝒟, τ, E = optimal_traditional_de(x, method; dmax)
    plot(1:dmax, E; label = method, marker = &quot;o&quot;, ms = 5, color = &quot;C$(i-1)&quot;)
    optimal_d = size(𝒟, 2)
    scatter(optimal_d, E[optimal_d]; marker = &quot;s&quot;, s = 100, color = &quot;C$(i-1)&quot;)
end
legend(); xlabel(&quot;embedding dimension&quot;)
ylabel(&quot;estimator&quot;)
tight_layout()</code></pre><pre><code class="language-none">Algorithm stopped due to convergence of E₁-statistic. Valid embedding achieved ✓.
Algorithm stopped due to sufficiently small FNNs. Valid embedding achieved ✓.
Sufficiently small FNNs NOT reached. Valid embedding NOT achieved ⨉.
Algorithm stopped due to sufficiently small FNNs. Valid embedding achieved ✓.</code></pre><p><img src="../estimateD.png" alt/></p><hr/><h2 id="Unified-approach-1"><a class="docs-heading-anchor" href="#Unified-approach-1">Unified approach</a><a class="docs-heading-anchor-permalink" href="#Unified-approach-1" title="Permalink"></a></h2><p>Several algorithms have been created to implement a unified approach to delay coordinates embedding. You can find some implementations below:</p><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.pecora" href="#DelayEmbeddings.pecora"><code>DelayEmbeddings.pecora</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pecora(s, τs, js; kwargs...) → ⟨ε★⟩, ⟨Γ⟩</code></pre><p>Compute the (average) continuity statistic <code>⟨ε★⟩</code> and undersampling statistic <code>⟨Γ⟩</code> according to Pecora et al.<sup class="footnote-reference"><a id="citeref-Pecoral2007" href="#footnote-Pecoral2007">[Pecoral2007]</a></sup> (A unified approach to attractor reconstruction), for a given input <code>s</code> (timeseries or <code>Dataset</code>) and input generalized embedding defined by <code>(τs, js)</code>, according to <a href="../reconstruction/#DelayEmbeddings.genembed"><code>genembed</code></a>. The continuity statistic represents functional independence between the components of the existing embedding and one additional timeseries. The returned results are <em>matrices</em> with size <code>T</code>x<code>J</code>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>delays = 0:50</code>: Possible time delay values <code>delays</code> (in sampling time units). For each of the <code>τ</code>&#39;s in <code>delays</code> the continuity-statistic <code>⟨ε★⟩</code> gets computed. If <code>undersampling = true</code> (see further down), also the undersampling statistic <code>⟨Γ⟩</code> gets returned for all considered delay values.</li><li><code>J = 1:dimension(s)</code>: calculate for all timeseries indices in <code>J</code>. If input <code>s</code> is a timeseries, this is always just 1.</li><li><code>samplesize::Real = 0.1</code>: determine the fraction of all phase space points (=<code>length(s)</code>) to be considered (fiducial points v) to average ε★ to produce <code>⟨ε★⟩, ⟨Γ⟩</code></li><li><code>K::Int = 13</code>: the amount of nearest neighbors in the δ-ball (read algorithm description). Must be at least 8 (in order to gurantee a valid statistic). <code>⟨ε★⟩</code> is computed taking the minimum result over all <code>k ∈ K</code>.</li><li><code>metric = Chebyshev()</code>: metrix with which to find nearest neigbhors in the input embedding (ℝᵈ space, <code>d = length(τs)</code>).</li><li><code>w = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>undersampling = false</code> : whether to calculate the undersampling statistic or not (if not, zeros are returned for <code>⟨Γ⟩</code>). Calculating <code>⟨Γ⟩</code> is thousands of times slower than <code>⟨ε★⟩</code>.</li><li><code>db::Int = 100</code>: Amount of bins used into calculating the histograms of each timeseries (for the undersampling statistic).</li><li><code>α::Real = 0.05</code>: The significance level for obtaining the continuity statistic</li><li><code>p::Real = 0.5</code>: The p-parameter for the binomial distribution used for the computation of the continuity statistic.</li></ul><p><strong>Description</strong></p><p>Notice that the full algorithm is too large to discuss here, and is written in detail (several pages!) in the source code of <code>pecora</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.uzal_cost" href="#DelayEmbeddings.uzal_cost"><code>DelayEmbeddings.uzal_cost</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">uzal_cost(Y::Dataset; kwargs...) → L</code></pre><p>Compute the L-statistic <code>L</code> for input dataset <code>Y</code> according to Uzal et al.<sup class="footnote-reference"><a id="citeref-Uzal2011" href="#footnote-Uzal2011">[Uzal2011]</a></sup>, based on theoretical arguments on noise amplification, the complexity of the reconstructed attractor and a direct measure of local stretch which constitutes an irrelevance measure. It serves as a cost function of a state space trajectory/embedding and therefore allows to estimate a &quot;goodness of a embedding&quot; and also to choose proper embedding parameters, while minimizing <code>L</code> over the parameter space. For receiving the local cost function <code>L_local</code> (for each point in state space - not averaged), use <code>uzal_cost_local(...)</code>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>samplesize = 0.5</code>: Number of considered fiducial points v as a fraction of input state space trajectory <code>Y</code>&#39;s length, in order to average the conditional variances and neighborhood sizes (read algorithm description) to produce <code>L</code>.</li><li><code>K = 3</code>: the amount of nearest neighbors considered, in order to compute σ_k^2 (read algorithm description). If given a vector, minimum result over all <code>k ∈ K</code> is returned.</li><li><code>metric = Euclidean()</code>: metric used for finding nearest neigbhors in the input state space trajectory `Y.</li><li><code>w = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>Tw = 40</code>: The time horizon (in sampling units) up to which E_k^2 gets computed and averaged over (read algorithm description).</li></ul><p><strong>Description</strong></p><p>The <code>L</code>-statistic is based on theoretical arguments on noise amplification, the complexity of the reconstructed attractor and a direct measure of local stretch which constitutes an irrelevance measure. Technically, it is the logarithm of the product of <code>σ</code>-statistic and a normalization statistic <code>α</code>:</p><p>L = log10(σ*α)</p><p>The <code>σ</code>-statistic is computed as follows. <code>σ = √σ² = √(E²/ϵ²)</code>. <code>E²</code> approximates the conditional variance at each point in state space and for a time horizon <code>T ∈ Tw</code>, using <code>K</code> nearest neighbors. For each reference point of the state space trajectory, the neighborhood consists of the reference point itself and its <code>K+1</code> nearest neighbors. <code>E²</code> measures how strong a neighborhood expands during <code>T</code> time steps. <code>E²</code> is averaged over many time horizons <code>T = 1:Tw</code>. Consequently, <code>ϵ²</code> is the size of the neighborhood at the reference point itself and is defined as the mean pairwise distance of the neighborhood. Finally, <code>σ²</code> gets averaged over a range of reference points on the attractor, which is controlled by <code>samplesize</code>. This is just for performance reasons and the most accurate result will obviously be gained when setting <code>samplesize=1.0</code></p><p>The <code>α</code>-statistic is a normalization factor, such that <code>σ</code>&#39;s from different embeddings can be compared. <code>α²</code> is defined as the inverse of the sum of the inverse of all <code>ϵ²</code>&#39;s for all considered reference points.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.garcia_almeida_embedding" href="#DelayEmbeddings.garcia_almeida_embedding"><code>DelayEmbeddings.garcia_almeida_embedding</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">garcia_almeida_embedding(s; kwargs...) → Y, τ_vals, ts_vals, FNNs ,NS</code></pre><p>A unified approach to properly embed a time series (<code>Vector</code> type) or a set of time series (<code>Dataset</code> type) based on the papers of Garcia &amp; Almeida <sup class="footnote-reference"><a id="citeref-Garcia2005a" href="#footnote-Garcia2005a">[Garcia2005a]</a></sup>,<sup class="footnote-reference"><a id="citeref-Garcia2005b" href="#footnote-Garcia2005b">[Garcia2005b]</a></sup>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>τs= 0:50</code>: Possible delay values <code>τs</code> (in sampling time units). For each of the <code>τs</code>&#39;s the N-statistic gets computed.</li><li><code>w::Int = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>r1 = 10</code>: The threshold, which defines the factor of tolerable stretching for the d<em>E1-statistic (see algorithm description in [`garcia</em>embedding_cycle`](@ref)).</li><li><code>r2 = 2</code>: The threshold for the tolerable relative increase of the distance between the nearest neighbors, when increasing the embedding dimension.</li><li><code>fnn_thres= 0.05</code>: A threshold value defining a sufficiently small fraction of false nearest neighbors, in order to the let algorithm terminate and stop the embedding procedure (`0 ≤ fnn_thres &lt; 1).</li><li><code>T::Int = 1</code>: The forward time step (in sampling units) in order to compute the <code>d_E2</code>-statistic (see algorithm description). Note that in the paper this is not a free parameter and always set to <code>T=1</code>.</li><li><code>metric = Euclidean()</code>: metric used for finding nearest neigbhors in the input phase space trajectory <code>Y</code>.</li><li><code>max_num_of_cycles = 50</code>: The algorithm will stop after that many cycles no matter what.</li></ul><p><strong>Description</strong></p><p>The method works iteratively and gradually builds the final embedding vectors <code>Y</code>. Based on the <code>N</code>-statistic <a href="embedding/@ref"><code>garcia_embedding_cycle</code></a> the algorithm picks an optimal delay value <code>τ</code> for each embedding cycle as the first local minimum of <code>N</code>. In case of multivariate embedding, i.e. when embedding a set of time series (<code>s::Dataset</code>), the optimal delay value <code>τ</code> is chosen as the first minimum from all minimum&#39;s of all considered <code>N</code>-statistics for each embedding cycle. The range of considered delay values is determined in <code>τs</code> and for the nearest neighbor search we respect the Theiler window <code>w</code>. After each embedding cycle the FNN-statistic <code>FNNs</code> <sup class="footnote-reference"><a id="citeref-Hegger1999" href="#footnote-Hegger1999">[Hegger1999]</a></sup><sup class="footnote-reference"><a id="citeref-Kennel1992" href="#footnote-Kennel1992">[Kennel1992]</a></sup> is being checked and as soon as this statistic drops below the threshold <code>fnn_thres</code>, the algorithm breaks. In order to increase the  practability of the method the algorithm also breaks, when the FNN-statistic <code>FNNs</code> increases . The final embedding vector is stored in <code>Y</code> (<code>Dataset</code>). The chosen delay values for each embedding cycle are stored in the <code>τ_vals</code> and the according time series number chosen for the according delay value in <code>τ_vals</code> is stored in <code>ts_vals</code>. For univariate embedding (<code>s::Vector</code>) <code>ts_vals</code> is a vector of ones of length <code>τ_vals</code>, because there is simply just one time series to choose from. The function also returns the <code>N</code>-statistic <code>NS</code> for each embedding cycle as an <code>Array</code> of <code>Vector</code>s.</p><p>Notice that we were <em>not</em> able to reproduce the figures from the papers with our implementation (which nevertheless we believe is the correct one).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.mdop_embedding" href="#DelayEmbeddings.mdop_embedding"><code>DelayEmbeddings.mdop_embedding</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mdop_embedding(s::Vector; kwargs...) → Y, τ_vals, ts_vals, FNNs, βS</code></pre><p>MDOP (for &quot;maximizing derivatives on projection&quot;) is a unified approach to properly embed a timeseries or a set of timeseries (<code>Dataset</code>) based on the paper of Chetan Nichkawde <sup class="footnote-reference"><a id="citeref-Nichkawde2013" href="#footnote-Nichkawde2013">[Nichkawde2013]</a></sup>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>τs= 0:50</code>: Possible delay values <code>τs</code>. For each of the <code>τs</code>&#39;s the β-statistic gets computed.</li><li><code>w::Int = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>fnn_thres::Real= 0.05</code>: A threshold value defining a sufficiently small fraction of false nearest neighbors, in order to the let algorithm terminate and stop the embedding procedure (`0 ≤ fnn_thres &lt; 1).</li><li><code>r::Real = 2</code>: The threshold for the tolerable relative increase of the distance between the nearest neighbors, when increasing the embedding dimension.</li><li><code>max_num_of_cycles = 50</code>: The algorithm will stop after that many cycles no matter what.</li></ul><p><strong>Description</strong></p><p>The method works iteratively and gradually builds the final embedding <code>Y</code>. Based on the <a href="#DelayEmbeddings.beta_statistic"><code>beta_statistic</code></a> the algorithm picks an optimal delay value <code>τ</code> for each embedding cycle as the global maximum of <code>β</code>. In case of multivariate embedding, i.e. when embedding a set of time series (<code>s::Dataset</code>), the optimal delay value <code>τ</code> is chosen as the maximum from all maxima&#39;s of all considered <code>β</code>-statistics for each possible timeseries. The range of considered delay values is determined in <code>τs</code> and for the nearest neighbor search we respect the Theiler window <code>w</code>.</p><p>After each embedding cycle the FNN-statistic <code>FNNs</code> <sup class="footnote-reference"><a id="citeref-Hegger1999" href="#footnote-Hegger1999">[Hegger1999]</a></sup><sup class="footnote-reference"><a id="citeref-Kennel1992" href="#footnote-Kennel1992">[Kennel1992]</a></sup> is being checked and as soon as this statistic drops below the threshold <code>fnn_thres</code>, the algorithm terminates. In order to increase the practability of the method the algorithm also terminates when the FNN-statistic <code>FNNs</code> increases.</p><p>The final embedding is returned as <code>Y</code>. The chosen delay values for each embedding cycle are stored in the <code>τ_vals</code> and the according timeseries index chosen for the the respective according delay value in <code>τ_vals</code> is stored in <code>ts_vals</code>. <code>βS, FNNs</code> are returned for clarity and double-checking, since they are computed anyway. In case of multivariate embedding, <code>βS</code> will store all <code>β</code>-statistics for all available time series in each embedding cycle. To double-check the actual used <code>β</code>-statistics in an embedding cycle &#39;k&#39;, simply <code>βS[k][:,ts_vals[k+1]]</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.pecuzal_embedding" href="#DelayEmbeddings.pecuzal_embedding"><code>DelayEmbeddings.pecuzal_embedding</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pecuzal_embedding(s; kwargs...) → 𝒟, τ_vals, ts_vals, Ls, ⟨ε★⟩</code></pre><p>A unified approach to properly embed a time series or a set of time series (<code>Dataset</code>) based on the ideas of Pecora et al. <sup class="footnote-reference"><a id="citeref-Pecoral2007" href="#footnote-Pecoral2007">[Pecoral2007]</a></sup> and Uzal et al. <sup class="footnote-reference"><a id="citeref-Uzal2011" href="#footnote-Uzal2011">[Uzal2011]</a></sup>. For a detailled description of the algorithm see Kraemer et al. <sup class="footnote-reference"><a id="citeref-Kraemer2020" href="#footnote-Kraemer2020">[Kraemer2020]</a></sup>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>τs = 0:50</code>: Possible delay values <code>τs</code> (in sampling time units). For each of the <code>τs</code>&#39;s the continuity statistic ⟨ε★⟩ gets computed and further processed in order to find optimal delays <code>τᵢ</code> for each embedding cycle <code>i</code> (read algorithm description).</li><li><code>w::Int = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>samplesize::Real = 1</code>: determine the fraction of all phase space points (=<code>length(s)</code>) to be considered (fiducial points v) to average ε★, in order to produce <code>⟨ε★⟩</code>.</li><li><code>K::Int = 13</code>: the amount of nearest neighbors in the δ-ball (read algorithm description). Must be at least 8 (in order to gurantee a valid statistic). <code>⟨ε★⟩</code> is computed taking the minimum result over all <code>k ∈ K</code>.</li><li><code>KNN::Int = 3</code>: the amount of nearest neighbors considered, in order to compute σ<em>k^2 (read algorithm description [`uzal</em>cost<code>]@ref). If given a vector, the minimum result over all</code>knn ∈ KNN` is returned.</li><li><code>Tw::Int = 4*w</code>: the maximal considered time horizon for obtaining σ<em>k^2 (read  algorithm description [`uzal</em>cost`]@ref).</li><li><code>α::Real = 0.05</code>: The significance level for obtaining the continuity statistic</li><li><code>p::Real = 0.5</code>: The p-parameter for the binomial distribution used for the computation of the continuity statistic ⟨ε★⟩.</li><li><code>max_cycles = 50</code>: The algorithm will stop after that many cycles no matter what.</li></ul><p><strong>Description</strong></p><p>The method works iteratively and gradually builds the final embedding vectors <code>𝒟</code>. Based on the <code>⟨ε★⟩</code>-statistic <a href="#DelayEmbeddings.pecora"><code>pecora</code></a> the algorithm picks an optimal delay value <code>τᵢ</code> for each embedding cycle i. For achieving that, we take the inpute time series <code>s</code> and compute the continuity statistic <code>⟨ε★⟩</code>. 1. Each local maxima in <code>⟨ε★⟩</code> is used for constructing a candidate embedding trajectory <code>𝒟_trial</code> with a delay corresponding to that specific peak in <code>⟨ε★⟩</code>. 2. We then compute the <code>L</code>-statistic <a href="#DelayEmbeddings.uzal_cost"><code>uzal_cost</code></a> for <code>𝒟_trial</code>. 3. We pick the peak/<code>τ</code>-value, for which <code>L</code> is minimal and construct the actual embedding trajectory <code>𝒟_actual</code> (steps 1.-3. correspond to an embedding cycle). 4. We repeat steps 1.-3. with <code>𝒟_actual</code> as input and stop the algorithm when <code>L</code> can not be reduced anymore. <code>𝒟_actual</code> -&gt; <code>𝒟</code>.</p><p>In case of multivariate embedding, i.e. when embedding a set of M time series (<code>s::Dataset</code>), in each embedding cycle the continuity statistic <code>⟨ε★⟩</code> gets computed for all M time series available. The optimal delay value <code>τ</code> in each embedding cycle is chosen as the peak/<code>τ</code>-value for which <code>L</code> is minimal under all available peaks and under all M <code>⟨ε★⟩</code>&#39;s. In the first embedding cycle there will be M^2 different <code>⟨ε★⟩</code>&#39;s to consider, since it is not clear a priori which time series of the input should consitute the first component of the embedding vector and form <code>𝒟_actual</code>.</p><p>The range of considered delay values is determined in <code>τs</code> and for the nearest neighbor search we respect the Theiler window <code>w</code>. The final embedding vector is stored in <code>𝒟</code> (<code>Dataset</code>). The chosen delay values for each embedding cycle are stored in <code>τ_vals</code> and the according time series numbers chosen for each delay value in <code>τ_vals</code> are stored in <code>ts_vals</code>. For univariate embedding (<code>s::Vector</code>) <code>ts_vals</code> is a vector of ones of length <code>τ_vals</code>, because there is simply just one time series to choose from. The function also returns the <code>L</code>-statistic <code>Ls</code> for each embedding cycle and the continuity statistic <code>⟨ε★⟩</code> as an <code>Array</code> of <code>Vector</code>s.</p><p>For distance computations the Euclidean norm is used.</p></div></section></article><h3 id="Example-2"><a class="docs-heading-anchor" href="#Example-2">Example</a><a class="docs-heading-anchor-permalink" href="#Example-2" title="Permalink"></a></h3><p>In following we illustrate the functionality of the PECUZAL method on three examples. We start with a univariate case, i.e. we only feed in one time series, here the <em>x</em>-component of the Lorenz system.  </p><pre><code class="language-julia">using DelayEmbeddings

lo = Systems.lorenz([1.0, 1.0, 50.0])
tr = trajectory(lo, 100; dt = 0.01, Ttr = 10)

s = vec(tr[:, 1]) # input timeseries = x component of lorenz
theiler = estimate_delay(s, &quot;mi_min&quot;) # estimate a Theiler window
Tmax = 100 # maximum possible delay

Y, τ_vals, ts_vals, Ls , εs = pecuzal_embedding(s; τs = 0:Tmax , w = theiler)

println(τ_vals)
println(ts_vals)
println(Ls)</code></pre><pre><code class="language-none">Algorithm stopped due to minimum L-value reached. VALID embedding achieved ✓.
[0, 18, 9]
[1, 1, 1]
[-2.8725894723648135, -2.9978353120801096, -2.9458665448810084]</code></pre><p>The output reveals that PECUZAL suggests a 3-dimensional embedding out of the un-lagged time series as the 1st component of the reconstruction, the time series lagged by 18 samples as the 2nd component and the time series lagged by 9 samples as the 3rd component. The minimum obtained <em>L</em>-value in the 3rd embedding cycle has been ~-2.63, after which the algorithm breaks.</p><pre><code class="language-julia">using PyPlot

figure(figsize=(14., 8.))
subplot(1,2,1, projection=&quot;3d&quot;)
plot3D(Y[:,1], Y[:,2], Y[:,3],&quot;gray&quot;)
title(&quot;PECUZAL reconstructed x-component of Lorenz System&quot;)
xlabel(&quot;x(t+$(τ_vals[1]))&quot;)
ylabel(&quot;x(t+$(τ_vals[2]))&quot;)
zlabel(&quot;x(t+$(τ_vals[3]))&quot;)
grid()

subplot(1,2,2, projection=&quot;3d&quot;)
plot3D(tr[:,1], tr[:,2], tr[:,3],&quot;gray&quot;)
title(&quot;Original Lorenz System&quot;)
xlabel(&quot;x(t)&quot;)
ylabel(&quot;y(t)&quot;)
zlabel(&quot;z(t)&quot;)
grid()

tight_layout()</code></pre><p><img src="../pecuzal_uni.png" alt/></p><p>We can also look at the output of the low-level function leading to the results, here the <em>continuity statistic</em>.</p><pre><code class="language-julia">using PyPlot

figure(figsize=(8., 5.))
plot(εs[:,1], label=&quot;1st embedding cycle&quot;)
scatter([τ_vals[2]], [εs[τ_vals[2],1]])
plot(εs[:,2], label=&quot;2nd embedding cycle&quot;)
scatter([τ_vals[3]], [εs[τ_vals[3],2]])
plot(εs[:,3], label=&quot;3rd embedding cycle&quot;)
title(&quot;Continuity statistics for PECUZAL embedding of Lorenz x-component&quot;)
xlabel(&quot;delay τ&quot;)
ylabel(&quot;⟨ε⋆⟩&quot;)
legend(loc=&quot;upper left&quot;)
grid()</code></pre><p><img src="../continuity_uni.png" alt/></p><p>Similar to the approach in the preceding example, we now highlight the capability of the PECUZAL embedding method for a multivariate input. The idea is now to feed in all three time series to the algorithm, even though this is a very far-from-reality example. We already have an adequate representation of the system we want to reconstruct, namely the three time series from the numerical integration. But let us see what PECUZAL suggests for a reconstruction.</p><pre><code class="language-julia"># compute Theiler window
w1 = estimate_delay(tr[:,1], &quot;mi_min&quot;)
w2 = estimate_delay(tr[:,2], &quot;mi_min&quot;)
w3 = estimate_delay(tr[:,3], &quot;mi_min&quot;)
w = maximum(hcat(w1,w2,w3))
Y_m, τ_vals_m, ts_vals_m, Ls_m , εs_m = pecuzal_embedding(tr; τs = 0:Tmax , w = theiler)

println(τ_vals_m)
println(ts_vals_m)
println(Ls_m)</code></pre><pre><code class="language-none">Algorithm stopped due to minimum L-value reached. VALID embedding achieved ✓.
[0, 12, 0]
[3, 1, 1]
[-2.5231456900201734, -2.8548327001280525, -2.813549538642902]</code></pre><p>PECUZAL offers a 3-dimensional embedding using the un-lagged <em>z</em>- and <em>x</em>-component as 1st and 3rd component of the reconstruction vectors, as well as the <em>x</em>-component lagged by 12 samples.</p><pre><code class="language-julia">ts_str = [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;]

figure(figsize=(14., 8.))
subplot(1,2,1, projection=&quot;3d&quot;)
plot3D(Y_m[:,1], Y_m[:,2], Y_m[:,3],&quot;gray&quot;)
title(&quot;PECUZAL reconstructed Lorenz System&quot;)
xlabel(&quot;$(ts_str[ts_vals_m[1]])(t+$(τ_vals_m[1]))&quot;)
ylabel(&quot;$(ts_str[ts_vals_m[2]])(t+$(τ_vals_m[2]))&quot;)
zlabel(&quot;$(ts_str[ts_vals_m[3]])(t+$(τ_vals_m[3]))&quot;)
grid()

subplot(1,2,2, projection=&quot;3d&quot;)
plot3D(tr[:,1], tr[:,2], tr[:,3],&quot;gray&quot;)
title(&quot;Original Lorenz System&quot;)
xlabel(&quot;x(t)&quot;)
ylabel(&quot;y(t)&quot;)
zlabel(&quot;z(t)&quot;)
grid()

tight_layout()</code></pre><p><img src="../pecuzal_multi.png" alt/></p><p>Finally we show what PECUZAL does with a non-deterministic source:</p><pre><code class="language-julia">using Random

# Dummy input
d1 = randn(1000)
d2 = rand(1000)
Tmax = 100
dummy_set = Dataset(hcat(d1,d2))

w1 = estimate_delay(d1, &quot;mi_min&quot;)
w2 = estimate_delay(d2, &quot;mi_min&quot;)
theiler = minimum(hcat(w1,w2))

Y_d, τ_vals_d, ts_vals_d, Ls_d , ε★_d = pecuzal_embedding(dummy_set; τs = 0:Tmax , w = theiler)</code></pre><pre><code class="language-none">([0.3189101791674429, 0.4013755894206177, 0.5532908027371273, 0.3915861016061508, 0.7523748422351944, 0.9833357258668438, 0.16832672271389826, 0.9173651520928998, 0.9995209382743728, 0.15371842702663474  …  0.46061377353160915, 0.10409664036936239, 0.9932220008802439, 0.3179640876413188, 0.7572609857578172, 0.28051963644308664, 0.7472559486944665, 0.19384767657813584, 0.9993309657974672, 0.44815134358606024], [0], [2], [-1.4426335383425364], [[1.2844032869781017 0.01118718594778279; 1.2929562394473293 1.4349525591149497; … ; 1.324860879528224 1.4196745896144887; 1.2979855188444795 1.410137136907791]])</code></pre><h3 id="Low-level-functions-of-unified-approach-1"><a class="docs-heading-anchor" href="#Low-level-functions-of-unified-approach-1">Low-level functions of unified approach</a><a class="docs-heading-anchor-permalink" href="#Low-level-functions-of-unified-approach-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.n_statistic" href="#DelayEmbeddings.n_statistic"><code>DelayEmbeddings.n_statistic</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">n_statistic(Y, s; kwargs...) → N, d_E1</code></pre><p>Perform one embedding cycle according to the method proposed in <sup class="footnote-reference"><a id="citeref-Garcia2005a" href="#footnote-Garcia2005a">[Garcia2005a]</a></sup> for a given phase space trajectory <code>Y</code> (of type <code>Dataset</code>) and a time series <code>s (of type</code>Vector<code>). Return the proposed N-Statistic</code>N<code>and all nearest neighbor distances</code>d_E1<code>for each point of the input phase space trajectory</code>Y<code>. Note that</code>Y` is a single time series in case of the first embedding cycle.</p><p><strong>Keyword arguments</strong></p><ul><li><code>τs= 0:50</code>: Considered delay values <code>τs</code> (in sampling time units). For each of the <code>τs</code>&#39;s the N-statistic gets computed.</li><li><code>r = 10</code>: The threshold, which defines the factor of tolerable stretching for the d_E1-statistic (see algorithm description).</li><li><code>T::Int = 1</code>: The forward time step (in sampling units) in order to compute the <code>d_E2</code>-statistic (see algorithm description). Note that in the paper this is not a free parameter and always set to <code>T=1</code>.</li><li><code>w::Int = 0</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors. Note that in the paper this is not a free parameter and always <code>w=0</code>.</li><li><code>metric = Euclidean()</code>: metric used for finding nearest neigbhors in the input phase space trajectory <code>Y</code>.</li></ul><p><strong>Description</strong></p><p>For a range of possible delay values <code>τs</code> one constructs a temporary embedding matrix. That is, one concatenates the input phase space trajectory <code>Y</code> with the <code>τ</code>-lagged input time series <code>s</code>. For each point on the temporary trajectory one computes its nearest neighbor, which is denoted as the <code>d_E1</code>-statistic for a specific <code>τ</code>. Now one considers the distance between the reference point and its nearest neighbor <code>T</code> sampling units ahead and calls this statistic <code>d_E2</code>. <sup class="footnote-reference"><a id="citeref-Garcia2005a" href="#footnote-Garcia2005a">[Garcia2005a]</a></sup> strictly use <code>T=1</code>, so they forward each reference point and its corresponding nearest neighbor just by one (!) sampling unit. Here it is a free parameter.</p><p>The <code>N</code>-statistic is then the fraction of <code>d_E2</code>/<code>d_E1</code>-pairs which exceed a threshold <code>r</code>.</p><p>Plotted vs. the considered <code>τs</code>-values it is proposed to pick the <code>τ</code>-value for this embedding cycle as the value, where <code>N</code> has its first local minimum.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.beta_statistic" href="#DelayEmbeddings.beta_statistic"><code>DelayEmbeddings.beta_statistic</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">beta_statistic(Y::Dataset, s::Vector) [, τs, w]) → β</code></pre><p>Compute the β-statistic <code>β</code> for input state space trajectory <code>Y</code> and a timeseries <code>s</code> according to Nichkawde <sup class="footnote-reference"><a id="citeref-Nichkawde2013" href="#footnote-Nichkawde2013">[Nichkawde2013]</a></sup>, based on estimating derivatives on a projected manifold. For a range of delay values <code>τs</code>, <code>β</code> gets computed and its maximum over all considered <code>τs</code> serves as the optimal delay considered in this embedding cycle.</p><p>Arguments <code>τs, w</code> as in <a href="#DelayEmbeddings.mdop_embedding"><code>mdop_embedding</code></a>.</p><p><strong>Description</strong></p><p>The <code>β</code>-statistic is based on the geometrical idea of maximal unfolding of the reconstructed attractor and is tightly related to the False Nearest Neighbor method (<sup class="footnote-reference"><a id="citeref-Kennel1992" href="#footnote-Kennel1992">[Kennel1992]</a></sup>). In fact the method eliminates the maximum amount of false nearest neighbors in each embedding cycle. The idea is to estimate the absolute value of the directional derivative with respect to a possible new dimension in the reconstruction process, and with respect to the nearest neighbor, for all points of the state space trajectory:</p><p>ϕ&#39;(τ) = Δϕ<em>d(τ) / Δx</em>d</p><p>Δx<em>d is simply the Euclidean nearest neighbor distance for a reference point with respect to the given Theiler window <code>w</code>. Δϕ</em>d(τ) is the distance of the reference point to its nearest neighbor in the one dimensional time series <code>s</code>, for the specific τ. Δϕ_d(τ) = |s(i+τ)-s(j+τ)|, with i being the index of the considered reference point and j the index of its nearest neighbor.</p><p>Finally,</p><p><code>β</code> = log β(τ) = ⟨log₁₀ ϕ&#39;(τ)⟩ ,</p><p>with ⟨.⟩ being the mean over all reference points. When one chooses the maximum of <code>β</code> over all considered τ&#39;s, one obtains the optimal delay value for this embedding cycle. Note that in the first embedding cycle, the input state space trajectory <code>Y</code> can also be just a univariate time series.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DelayEmbeddings.mdop_maximum_delay" href="#DelayEmbeddings.mdop_maximum_delay"><code>DelayEmbeddings.mdop_maximum_delay</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mdop_maximum_delay(s, tw = 1:50, samplesize = 1.0)) -&gt; τ_max, L</code></pre><p>Compute an upper bound for the search of optimal delays, when using <code>mdop_embedding</code> <a href="#DelayEmbeddings.mdop_embedding"><code>mdop_embedding</code></a> or <code>beta_statistic</code> <a href="#DelayEmbeddings.beta_statistic"><code>beta_statistic</code></a>.</p><p><strong>Description</strong></p><p>The input time series <code>s</code> gets embedded with unit lag and increasing dimension, for dimensions (or time windows) <code>tw</code> (<code>RangeObject</code>). For each of such a time window the <code>L</code>-statistic from Uzal et al. <sup class="footnote-reference"><a id="citeref-Uzal2011" href="#footnote-Uzal2011">[Uzal2011]</a></sup> will be computed. <code>samplesize</code> determines the fraction of points to be considered in the computation of <code>L</code> (see <a href="#DelayEmbeddings.uzal_cost"><code>uzal_cost</code></a>). When this statistic reaches its global minimum the maximum delay value <code>τ_max</code> gets returned. When <code>s</code> is a multivariate <code>Dataset</code>, <code>τ_max</code> will becomputed for all timeseries of that Dataset and the maximum value will be returned. The returned <code>L</code>-statistic has size <code>(length(tw), size(s,2))</code>.</p></div></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Fraser1986"><a class="tag is-link" href="#citeref-Fraser1986">Fraser1986</a>Fraser A.M. &amp; Swinney H.L. &quot;Independent coordinates for strange attractors from mutual information&quot; <em>Phys. Rev. A 33</em>(2), 1986, 1134:1140.</li><li class="footnote" id="footnote-Cao1997"><a class="tag is-link" href="#citeref-Cao1997">Cao1997</a>Liangyue Cao, <a href="https://www.sciencedirect.com/science/article/pii/S0167278997001188?via%3Dihub">Physica D, pp. 43-50 (1997)</a></li><li class="footnote" id="footnote-Kennel1992"><a class="tag is-link" href="#citeref-Kennel1992">Kennel1992</a>M. Kennel <em>et al.</em>, <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.45.3403">Phys. Review A <strong>45</strong>(6), (1992)</a>.</li><li class="footnote" id="footnote-Krakovská2015"><a class="tag is-link" href="#citeref-Krakovská2015">Krakovská2015</a>Anna Krakovská <em>et al.</em>, <a href="https://doi.org/10.1155/2015/932750">J. Complex Sys. 932750 (2015)</a></li><li class="footnote" id="footnote-Hegger1999"><a class="tag is-link" href="#citeref-Hegger1999">Hegger1999</a>Hegger &amp; Kantz, <a href="https://doi.org/10.1103/PhysRevE.60.4970">Improved false nearest neighbor method to detect determinism in time series data. Physical Review E 60, 4970</a>.</li><li class="footnote" id="footnote-Pecora2007"><a class="tag is-link" href="#citeref-Pecora2007">Pecora2007</a>Pecora, L. M., Moniz, L., Nichols, J., &amp; Carroll, T. L. (2007). <a href="https://doi.org/10.1063/1.2430294">A unified approach to attractor reconstruction. Chaos 17(1)</a>.</li><li class="footnote" id="footnote-Uzal2011"><a class="tag is-link" href="#citeref-Uzal2011">Uzal2011</a>Uzal, L. C., Grinblat, G. L., Verdes, P. F. (2011). <a href="https://doi.org/10.1103/PhysRevE.84.016223">Optimal reconstruction of dynamical systems: A noise amplification approach. Physical Review E 84, 016223</a>.</li><li class="footnote" id="footnote-Garcia2005a"><a class="tag is-link" href="#citeref-Garcia2005a">Garcia2005a</a>Garcia, S. P., Almeida, J. S. (2005). <a href="https://doi.org/10.1103/PhysRevE.71.037204">Nearest neighbor embedding with different time delays. Physical Review E 71, 037204</a>.</li><li class="footnote" id="footnote-Garcia2005b"><a class="tag is-link" href="#citeref-Garcia2005b">Garcia2005b</a>Garcia, S. P., Almeida, J. S. (2005). <a href="https://doi.org/10.1103/PhysRevE.72.027205">Multivariate phase space reconstruction by nearest neighbor embedding with different time delays. Physical Review E 72, 027205</a>.</li><li class="footnote" id="footnote-Nichkawde2013"><a class="tag is-link" href="#citeref-Nichkawde2013">Nichkawde2013</a>Nichkawde, Chetan (2013). <a href="https://doi.org/10.1103/PhysRevE.87.022905">Optimal state-space reconstruction using derivatives on projected manifold. Physical Review E 87, 022905</a>.</li><li class="footnote" id="footnote-Hegger1999"><a class="tag is-link" href="#citeref-Hegger1999">Hegger1999</a>Hegger, Rainer and Kantz, Holger (1999). <a href="https://doi.org/10.1103/PhysRevE.60.4970">Improved false nearest neighbor method to detect determinism in time series data. Physical Review E 60, 4970</a>.</li><li class="footnote" id="footnote-Kennel1992"><a class="tag is-link" href="#citeref-Kennel1992">Kennel1992</a>Kennel, M. B., Brown, R., Abarbanel, H. D. I. (1992). <a href="https://doi.org/10.1103/PhysRevA.45.3403">Determining embedding dimension for state-space reconstruction using a geometrical construction. Phys. Rev. A 45, 3403</a>.</li><li class="footnote" id="footnote-Pecora2007"><a class="tag is-link" href="#citeref-Pecora2007">Pecora2007</a>Pecora, L. M., Moniz, L., Nichols, J., &amp; Carroll, T. L. (2007). <a href="https://doi.org/10.1063/1.2430294">A unified approach to attractor reconstruction. Chaos 17(1)</a>.</li><li class="footnote" id="footnote-Uzal2011"><a class="tag is-link" href="#citeref-Uzal2011">Uzal2011</a>Uzal, L. C., Grinblat, G. L., Verdes, P. F. (2011). <a href="https://doi.org/10.1103/PhysRevE.84.016223">Optimal reconstruction of dynamical systems: A noise amplification approach. Physical Review E 84, 016223</a>.</li><li class="footnote" id="footnote-Kraemer2020"><a class="tag is-link" href="#citeref-Kraemer2020">Kraemer2020</a>Kraemer, K.H., Datseris, G., Kurths, J., Kiss, I.Z., Ocampo-Espindola, Marwan, N. (2020). <a href="https://arxiv.org/abs/2011.07040">A unified and automated approach to attractor reconstruction. arXiv:2011.07040</a>.</li><li class="footnote" id="footnote-Garcia2005a"><a class="tag is-link" href="#citeref-Garcia2005a">Garcia2005a</a>Garcia, S. P., Almeida, J. S. (2005). <a href="https://doi.org/10.1103/PhysRevE.71.037204">Nearest neighbor embedding with different time delays. Physical Review E 71, 037204</a>.</li><li class="footnote" id="footnote-Nichkawde2013"><a class="tag is-link" href="#citeref-Nichkawde2013">Nichkawde2013</a>Nichkawde, Chetan (2013). <a href="https://doi.org/10.1103/PhysRevE.87.022905">Optimal state-space reconstruction using derivatives on projected manifold. Physical Review E 87, 022905</a>.</li><li class="footnote" id="footnote-Kennel1992"><a class="tag is-link" href="#citeref-Kennel1992">Kennel1992</a>Kennel, M. B., Brown, R., Abarbanel, H. D. I. (1992). <a href="https://doi.org/10.1103/PhysRevA.45.3403">Determining embedding dimension for state-space reconstruction using a geometrical construction. Phys. Rev. A 45, 3403</a>.</li><li class="footnote" id="footnote-Nichkawde2013"><a class="tag is-link" href="#citeref-Nichkawde2013">Nichkawde2013</a>Nichkawde, Chetan (2013). <a href="https://doi.org/10.1103/PhysRevE.87.022905">Optimal state-space reconstruction using derivatives on projected manifold. Physical Review E 87, 022905</a>.</li><li class="footnote" id="footnote-Uzal2011"><a class="tag is-link" href="#citeref-Uzal2011">Uzal2011</a>Uzal, L. C., Grinblat, G. L., Verdes, P. F. (2011). <a href="https://doi.org/10.1103/PhysRevE.84.016223">Optimal reconstruction of dynamical systems: A noise amplification approach. Physical Review E 84, 016223</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../reconstruction/">« Delay Coordinates Embedding</a><a class="docs-footer-nextpage" href="../../chaos/orbitdiagram/">Orbit Diagrams &amp; PSOS »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 19 November 2020 22:37">Thursday 19 November 2020</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
