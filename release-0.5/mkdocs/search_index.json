{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nDynamicalSystems.jl\n is a Julia package for the exploration of continuous and discrete dynamical systems. It aims to be a useful and powerful companion for students and scientists treading on the fields of Chaos, nonlinear dynamics and dynamical systems in general.\n\n\nOne of a major goals of this package is to be completely transparent as to what is going on \"under the hood\". In scientific research, you never want to use \nblack boxes\n, e.g. functions that give a result without telling you how it was calculated. \nDynamicalSystems.jl\n battles this in 3 ways: Firstly, it is written entirely in Julia, making the source code clear and easy to understand for even novice users. Secondly, almost every documentation string gives \ndirect references to the original papers\n where the algorithm is taken from, in case some users don't understand (or simply don't want to read) the source code. For example, the documentation string of \nlyapunovs\n will cite relevant publications for the definition and computation of the lyapunov spectrum. Thirdly, all documentation strings for all exported names have very detailed descriptions of the algorithms (whenever it is possible).\n\n\nYou can \njoin our chatroom\n for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!\n\n\nBe sure to visit the \nContributor Guide\n page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on \nGitHub\n! This gives us an accurate lower bound of users that this package has already helped!\n\n\n\n\nInstallation\n\n\nThis package is registered. Simply use \nPkg.add(\"DynamicalSystems\")\n to install it.\n\n\nBug-fixes and upgrades are constantly fed to the master branch, which accessed with \nPkg.checkout(\"DynamicalSystems\")\n after installing. On the other hand the master branch may also have breaking changes and therefore caution is advised!\n\n\nThe \nstable\n documentation refers to the version of the package installed with \nPkg.add()\n. The \nlatest\n documentation refers to the version under development, obtained with \nPkg.checkout(\"DynamicalSystems\")\n.\n\n\nTo ensure that your installation works perfectly, you can use \nPkg.test(\"DynamicalSystems\")\n.\n\n\n\n\nContents\n\n\n\n\nSystem Definition\n\n\n\n\n\n\nIntuitive, consistent APIs for the definition of general dynamical systems. The currently supported system types are:\n\n\n\n\nDiscrete Maps\n\n\nContinuous Flows\n\n\nNumerical Data\n\n\n\n\n\n\n\n\nAutomatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\n\n\n\n\nInterface for \nDifferentialEquations.jl\n for flexible integration of continuous system.\n\n\nWell-defined functions for (numerically) evolving dynamical systems.\n\n\nDedicated interface (\nDataset\n) for handling sets of data, in a way that feels familiar to scientists but is also fast.\n\n\nLibrary of predefined well-known dynamical systems that have been used extensively in scientific research.\n\n\n\n\n\n\nLyapunov Exponents\n\n\nThe following treat systems where the equations of motion are known:\n\n\n\n\nMaximum Lyapunov exponent for both discrete and continuous systems: \nlyapunov\n.\n\n\n\n\nLyapunov \nspectrum\n for both discrete and continuous systems: \nlyapunovs\n.\n\n\n\n\nIt is also possible to obtain the convergence timeseries of the above algorithms, in order to e.g. estimate better parameters for faster convergence.\n\n\n\n\n\n\n\n\n\n\nEntropies and Dimensions\n\n\n\n\n\n\nGeneralized (Renyi) entropy and all related entropies: \ngenentropy\n.\n\n\n\n\nUltra-fast and cheap method for computing entropies of large datasets without ever having to worry about memory overflow.\n\n\n\n\n\n\n\n\nGeneralized dimensions (e.g. capacity dimension, information dimension, etc.): \ngeneralized_dim\n.\n\n\n\n\nKaplan-Yorke dimension: \nkaplanyorke_dim\n.\n\n\nAutomated detection of best algorithmic parameters for calculating attractor dimensions.\n\n\n\n\nAnd, in order to automatically deduce dimensions, we also offer methods for:\n\n\n\n\nPartitioning a function \n\\(y(x)\\)\n vs. \n\\(x\\)\n into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See \nlinear_regions\n.\n\n\nDetection of largest linear region of a function \n\\(y(x)\\)\n vs. \n\\(x\\)\n and extraction of the slope of this region.\n\n\n\n\n\n\nNonlinear Timeseries Analysis\n\n\n\n\nFlexible and abstracted \nReconstruction\n interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.\n\n\nMethods for estimating good \nReconstruction\n parameters (delay and dimension).\n\n\n\n\nFour\n different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries: \nnumericallyapunov\n.\n\n\n\n\nFast computation of the above algorithms made possible by the interaction of \nNearestNeighbors.jl\n, multiple dispatch and smart indexing (through the \nReconstruction\n abstraction).\n\n\n\n\n\n\n\n\n\n\nPeriodicity\n\n\n\n\n\n\nNumerical method to find unstable and stable fixed points of \nany order\n \n\\(n\\)\n of a discrete map (of any dimensionality): \nperiodicorbits\n.\n\n\n\n\nConvenience functions for defining and realizing all possible combinations of \n\\(\\mathbf{\\Lambda}_k\\)\n matrices required in the above method.\n\n\n\n\n\n\n\n\n\n\nWanted Features\n\n\nThe \nwanted features GitHub page\n lists features that are wanted by the \nDynamicalSystems\n, and are open to contributors.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "DynamicalSystems.jl  is a Julia package for the exploration of continuous and discrete dynamical systems. It aims to be a useful and powerful companion for students and scientists treading on the fields of Chaos, nonlinear dynamics and dynamical systems in general.  One of a major goals of this package is to be completely transparent as to what is going on \"under the hood\". In scientific research, you never want to use  black boxes , e.g. functions that give a result without telling you how it was calculated.  DynamicalSystems.jl  battles this in 3 ways: Firstly, it is written entirely in Julia, making the source code clear and easy to understand for even novice users. Secondly, almost every documentation string gives  direct references to the original papers  where the algorithm is taken from, in case some users don't understand (or simply don't want to read) the source code. For example, the documentation string of  lyapunovs  will cite relevant publications for the definition and computation of the lyapunov spectrum. Thirdly, all documentation strings for all exported names have very detailed descriptions of the algorithms (whenever it is possible).  You can  join our chatroom  for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!  Be sure to visit the  Contributor Guide  page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on  GitHub ! This gives us an accurate lower bound of users that this package has already helped!", 
            "title": "Introduction"
        }, 
        {
            "location": "/#installation", 
            "text": "This package is registered. Simply use  Pkg.add(\"DynamicalSystems\")  to install it.  Bug-fixes and upgrades are constantly fed to the master branch, which accessed with  Pkg.checkout(\"DynamicalSystems\")  after installing. On the other hand the master branch may also have breaking changes and therefore caution is advised!  The  stable  documentation refers to the version of the package installed with  Pkg.add() . The  latest  documentation refers to the version under development, obtained with  Pkg.checkout(\"DynamicalSystems\") .  To ensure that your installation works perfectly, you can use  Pkg.test(\"DynamicalSystems\") .", 
            "title": "Installation"
        }, 
        {
            "location": "/#contents", 
            "text": "", 
            "title": "Contents"
        }, 
        {
            "location": "/#system-definition", 
            "text": "Intuitive, consistent APIs for the definition of general dynamical systems. The currently supported system types are:   Discrete Maps  Continuous Flows  Numerical Data     Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.   Interface for  DifferentialEquations.jl  for flexible integration of continuous system.  Well-defined functions for (numerically) evolving dynamical systems.  Dedicated interface ( Dataset ) for handling sets of data, in a way that feels familiar to scientists but is also fast.  Library of predefined well-known dynamical systems that have been used extensively in scientific research.", 
            "title": "System Definition"
        }, 
        {
            "location": "/#lyapunov-exponents", 
            "text": "The following treat systems where the equations of motion are known:   Maximum Lyapunov exponent for both discrete and continuous systems:  lyapunov .   Lyapunov  spectrum  for both discrete and continuous systems:  lyapunovs .   It is also possible to obtain the convergence timeseries of the above algorithms, in order to e.g. estimate better parameters for faster convergence.", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/#entropies-and-dimensions", 
            "text": "Generalized (Renyi) entropy and all related entropies:  genentropy .   Ultra-fast and cheap method for computing entropies of large datasets without ever having to worry about memory overflow.     Generalized dimensions (e.g. capacity dimension, information dimension, etc.):  generalized_dim .   Kaplan-Yorke dimension:  kaplanyorke_dim .  Automated detection of best algorithmic parameters for calculating attractor dimensions.   And, in order to automatically deduce dimensions, we also offer methods for:   Partitioning a function  \\(y(x)\\)  vs.  \\(x\\)  into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See  linear_regions .  Detection of largest linear region of a function  \\(y(x)\\)  vs.  \\(x\\)  and extraction of the slope of this region.", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/#nonlinear-timeseries-analysis", 
            "text": "Flexible and abstracted  Reconstruction  interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.  Methods for estimating good  Reconstruction  parameters (delay and dimension).   Four  different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries:  numericallyapunov .   Fast computation of the above algorithms made possible by the interaction of  NearestNeighbors.jl , multiple dispatch and smart indexing (through the  Reconstruction  abstraction).", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/#periodicity", 
            "text": "Numerical method to find unstable and stable fixed points of  any order   \\(n\\)  of a discrete map (of any dimensionality):  periodicorbits .   Convenience functions for defining and realizing all possible combinations of  \\(\\mathbf{\\Lambda}_k\\)  matrices required in the above method.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/#wanted-features", 
            "text": "The  wanted features GitHub page  lists features that are wanted by the  DynamicalSystems , and are open to contributors.", 
            "title": "Wanted Features"
        }, 
        {
            "location": "/system_definition/", 
            "text": "System Definition\n\n\nFor \nDynamicalSystems.jl\n a system is simple a structure that contains the system's state, the equations of motion and the Jacobian. The last two are \nfunctions\n that take as an input a state.\n\n\nThis of course stands for systems where one already \nknows the equations of motion\n. if instead, your \"system\" is in the form of \nnumerical data\n, then see the appropriate section.\n\n\n\n\nNon-autonomous systems\n\n\nThis package does \nnot\n accept non-autonomous systems. To use such systems with this package increase the dimensionality of your system by 1, by introducing an additional variable \n\u03c4\n such that \nd\u03c4dt = 1\n (or \n\u03c4_next = \u03c4_prev + 1\n). This additional variable will serve as the \"time\" in your equations of motion.\n\n\n\n\n\n\nTrajectory and Timeseries\n\n\nThe word \"timeseries\" can be very confusing, because it can mean a one-dimensional timeseries or a multi-dimensional timeseries. To resolve this confusion, in \nDynamicalSystems.jl\n we have the following convention: \n\"timeseries\"\n always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word \n\"trajectory\"\n is used to refer to a \nmulti-dimensional\n timeseries, which is of course simply a group/set of one-dimensional timeseries.\n\n\nNote that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a \nDataset\n, which is a \nVector\n of \nSVector\ns, and each \nSVector\n represents a data-point (the values of the variables at a given time-point).\n\n\n\n\n\n\nDiscrete Systems\n\n\nDiscrete systems are of the form:\n\n\n\\[\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\\]\nThe Type representing such systems is called \nDiscreteDS\n:\n\n\n#\n\n\nDynamicalSystems.DiscreteDS\n \n \nType\n.\n\n\nDiscreteDS(state, eom [, jacob]) \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional discrete dynamical system (used for \nD \u2264 10\n).\n\n\nFields:\n\n\n\n\nstate::SVector{D}\n : Current state-vector of the system, stored in the data format of \nStaticArray\n's \nSVector\n.\n\n\neom\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom(u) -\n SVector\n which means that given a state-vector \nu\n it returns an \nSVector\n containing the next state.\n\n\njacob::J\n (function) : A function that calculates the system's jacobian matrix, based on the format: \njacob(u) -\n SMatrix\n which means that given a state-vector \nu\n it returns an \nSMatrix\n containing the Jacobian at that state.\n\n\n\n\nIf the \njacob\n is not provided by the user, it is created efficiently using the module \nForwardDiff\n.\n\n\nsource\n\n\n\n\nThe documentation string of the constructor is perfectly self-contained, but for the sake of clarity we will go through all the steps in the following.\n\n\nstate\n is simply the state the system starts (a.k.a. initial conditions) and \neom\n is a \nfunction\n that takes a \nstate\n as an input and returns the next state as an output. The \njacob\n is also a \nfunction\n that takes a \nstate\n as an input and returns the Jacobian matrix of the system (at this state). This however is optional and if not provided by the user, will be calculated automatically using the package \nForwardDiff.jl\n.\n\n\n\n\nReturn form of the \neom\n function\n\n\nIt is \nheavily\n advised that the equations of motion \neom\n function returns an \nSVector\n from the julia package \nStaticArrays.jl\n and similarly the \njacob\n function returns an \nSMatrix\n. \nNumerous benchmarks\n have been made in order to deduce the most efficient possible way to define a system, and this way was proved to be the best when the system's dimension is small.\n\n\n\n\nFor example, let's create one of the \nPredefined Systems\n offered by this package, the H\u00e9non map:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nStaticArrays\n \n#only necessary when defining a system\n\n\n\neom_henon\n(\nx\n)\n \n=\n \nSVector\n{\n2\n}(\n1.0\n \n-\n \na\n*\nx\n[\n1\n]\n^\n2\n \n+\n \nx\n[\n2\n],\n \nb\n*\nx\n[\n1\n])\n\n\njacob_henon\n(\nx\n)\n \n=\n \n@SMatrix\n \n[\n-\n2\n*\na\n*\nx\n[\n1\n]\n \n1.0\n;\n \nb\n \n0.0\n]\n\n\n\nhen\n \n=\n \nDiscreteDS\n(\nrand\n(\n2\n),\n \neom_henon\n,\n \njacob_henon\n)\n\n\n\n\n\n\nIf we did not want to write a Jacobian, we could do\n\n\nhen_nojac\n \n=\n \nDiscreteDS\n(\nrand\n(\n2\n),\n \neom_henon\n)\n\n\n\n\n\n\nand the Jacobian function would be created automatically.\n\n\n\n\n1-dimensional Discrete Systems\n\n\nIn the case of maps, there a special structure for one-dimensional systems, since they are commonly used in scientific research. The syntax is \nDiscreteDS1D(state, eom [, deriv])\n. In this one-dimensional case, you don't need to worry about \nStaticArrays.jl\n because everything is in plain numbers. For example:\n\n\nusing\n \nDynamicalSystems\n\n\n\n@inline\n \neom_logistic\n(\nr\n)\n \n=\n \n(\nx\n)\n \n-\n \nr\n*\nx\n*\n(\n1\n-\nx\n)\n  \n# this is a closure\n\n\n@inline\n \nderiv_logistic\n(\nr\n)\n \n=\n \n(\nx\n)\n \n-\n \nr\n*\n(\n1\n-\n2\nx\n)\n \n# this is a closure\n\n\nr\n \n=\n \n3.7\n\n\nlogistic\n \n=\n \nDiscreteDS1D\n(\nrand\n(),\n \neom_logistic\n(\nr\n),\n \nderiv_logistic\n(\nr\n))\n\n\n\n\n\n\nOnce again, if you skip the derivative functions it will be calculated automatically using \nForwardDiff.jl\n.\n\n\n\n\nContinuous Systems\n\n\nContinuous systems of the form\n\n\n\\[\n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}),\n\\]\nare defined in a similar manner with the discrete systems:\n\n\n#\n\n\nDynamicalSystems.ContinuousDS\n \n \nType\n.\n\n\nContinuousDS(state, eom! [, jacob]) \n: ContinuousDynamicalSystem\nContinuous dynamical system with dimension D = length(state)\n\n\n\n\n\nFields:\n\n\n\n\nstate::Vector{T}\n : Current state-vector of the system\n\n\neom!\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom!(du, u)\n which means that it is \nin-place\n, with the Julian syntax (the mutated argument \ndu\n is the first).\n\n\njacob\n (function) : The function that represents the Jacobian of the system, given in the format: \njacob(u) =\n J\n (i.e. returns a matrix). If the matrix is an \nSMatrix\n from \nStaticArrays.jl\n there are major performance gains.\n\n\n\n\nBecause the \njacob\n function is only necessary for a small subset of algorithms, you do not have to provide it necessarily to the constructor (but then you can't use these functions).\n\n\nsource\n\n\n\n\nThere are two major differences compared to the discrete case:\n\n\n\n\nThe second field \neom!\n ends with an \n!\n to remind users that it is an in-place function. This is necessary because the integration of continuous systems using \nDifferentialEquations.jl\n is much better this way.\n\n\nAutomated Jacobian function evaluation is not yet supported due to the dissonance of the interfaces of \nDifferentialEquations.jl\n and \nForwardDiff.jl\n\n\n\n\nNotice that providing a Jacobian is not necessary, since currently it is only used by the function \nlyapunovs\n. If you do provide a Jacobian, it is best if it returns an \nSMatrix\n, just like with the discrete systems case.\n\n\nAs an example, the continuous R\u00f6ssler system can be defined as:\n\n\n@inline\n \n@inbounds\n \nfunction\n \neom_roessler!\n(\ndu\n,\n \nu\n)\n\n    \na\n \n=\n \n0.2\n;\n \nb\n \n=\n \n0.2\n;\n \nc\n \n=\n \n5.7\n\n    \ndu\n[\n1\n]\n \n=\n \n-\nu\n[\n2\n]\n-\nu\n[\n3\n]\n\n    \ndu\n[\n2\n]\n \n=\n \nu\n[\n1\n]\n \n+\n \na\n*\nu\n[\n2\n]\n\n    \ndu\n[\n3\n]\n \n=\n \nb\n \n+\n \nu\n[\n3\n]\n*\n(\nu\n[\n1\n]\n \n-\n \nc\n)\n\n\nend\n\n\n@inline\n \n@inbounds\n \nfunction\n \njacob_roessler\n(\nu\n)\n\n    \ni\n \n=\n \none\n(\neltype\n(\nu\n))\n\n    \no\n \n=\n \nzero\n(\neltype\n(\nu\n))\n\n    \n@SMatrix\n \n[\no\n     \n-\ni\n      \n-\ni\n;\n\n              \ni\n      \na\n       \no\n;\n\n              \nu\n[\n3\n]\n   \no\n       \nu\n[\n1\n]\n \n-\n \nc\n]\n\n\nend\n\n\n\nros\n \n=\n \nContinuousDS\n(\nrand\n(\n3\n),\n \neom_roessler!\n,\n \njacob_roessler\n)\n\n\n\n\n\n\n\n\nSystem evolution\n\n\nDynamicalSystems.jl\n provides convenient interfaces for the evolution of systems. Especially in the continuous case, an interface is provided to the module \nDifferentialEquations.jl\n, with an approach that fits more the structuring of the present package (e.g. time is never passed to the equations of motion).\n\n\nNotice that if you want to do repeated evolutions of a system, use the \nevolve!(::ODEProblem)\n interface, which does not create a new \nODEProblem\n every time.\n\n\nThese are the functions related to system-evolution:\n\n\n#\n\n\nDynamicalSystems.evolve\n \n \nFunction\n.\n\n\nevolve\n(\nds\n::\nDynamicalSystem\n,\n \nT\n=\n1\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n \n-\n \nfinal_state\n\n\n\n\n\n\nEvolve a \nds\n for total \"time\" \nT\n and return the \nfinal_state\n (does not change \nds.state\n). For discrete systems \nT\n corresponds to steps and thus it must be integer. See \ntrajectory\n for using \ndiff_eq_kwargs\n.\n\n\nThis function \ndoes not store\n any information about intermediate steps. Use \ntrajectory\n if you want to produce a trajectory of the system. If you want to perform step-by-step evolution of a continuous system, use \nODEIntegrator(ds, t_final)\n and the \nstep!(integrator)\n function provided by \nDifferentialEquations\n.\n\n\nSee also \nevolve!\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.evolve!\n \n \nFunction\n.\n\n\nevolve\n!(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n \n-\n \nds\n\n\n\n\n\n\nEvolve (in-place) a dynamical system for total \"time\" \nT\n, setting the final state as the system's state. For discrete systems \nT\n corresponds to steps and thus it must be integer. See \ntrajectory\n for using \ndiff_eq_kwargs\n.\n\n\nThis function \ndoes not store\n any information about intermediate steps. Use \ntrajectory\n if you want to produce a trajectory of the system. If you want to perform step-by-step evolution of a continuous system, use \nODEIntegrator(ds, t_final)\n and the \nstep!(integrator)\n function provided by \nDifferentialEquations\n.\n\n\nSee also \nevolve\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.trajectory\n \n \nFunction\n.\n\n\ntrajectory\n(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \nkwargs\n...\n)\n \n-\n \ndataset\n\n\n\n\n\n\nReturn a dataset what will contain the trajectory of the sytem, after evolving it for time \nT\n. See \nDataset\n for info on how to manipulate this object.\n\n\nFor the discrete case, \nT\n is an integer and a \nT\u00d7D\n dataset is returned (\nD\n is the system dimensionality). For the continuous case, a \nW\u00d7D\n dataset is returned, with \nW = length(0:dt:T)\n with \n0:dt:T\n representing the time vector (\nnot\n returned).\n\n\nKeywords:\n\n\n\n\ndt = 0.05\n : (only for continuous) Time step of value output during the solving of the continuous system.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) A dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \nsolve\n of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :maxiters =\n 1e9)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\n\n\nsource\n\n\n\n\nIn addition, interfaces are provided for usage directly with \nDifferentialEquations.jl\n, by giving additional constructors:\n\n\n#\n\n\nDiffEqBase.ODEProblem\n \n \nType\n.\n\n\nODEProblem\n(\nds\n::\nContinuousDS\n,\n \nt\n)\n\n\n\n\n\n\nReturn an \nODEProblem\n with the given system information (t0 is zero). This can be passed directly into \nsolve\n from \nDifferentialEquations.jl\n.\n\n\nsource\n\n\n#\n\n\nOrdinaryDiffEq.ODEIntegrator\n \n \nType\n.\n\n\nODEIntegrator\n(\nds\n::\nContinuousDS\n,\n \nt\n;\n \ndiff_eq_kwargs\n)\n\n\n\n\n\n\nReturn an \nODEIntegrator\n, by first creating an \nODEProblem(ds, t)\n. This can be used directly with the interfaces of \nDifferentialEquations.jl\n.\n\n\ndiff_eq_kwargs = Dict()\n is a dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \ninit\n of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :tstops =\n 0:0.01:t)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\nsource\n\n\n\n\n\n\nNumerical Data\n\n\nNumerical data in \nDynamicalSystems.jl\n is represented by a structure called \nDataset\n:\n\n\n#\n\n\nDynamicalSystems.Dataset\n \n \nType\n.\n\n\nDataset{D, T} \n: AbstractDataset{D}\n\n\n\n\n\nA dedicated interface for datasets, i.e. vectors of vectors. It contains \nequally-sized datapoints\n of length \nD\n, represented by \nSVector{D, T}\n, containing numbers of type \nT\n.\n\n\nDataset\n has methods for iterating, \nconvert\n, \npush!\n, \nappend!\n and other basic functions.\n\n\nThe internal data representation is more efficient than having a \nMatrix\n and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables. \ntrajectory\n always returns a \nDataset\n.\n\n\nFor example,\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100.0\n)\n \n#this gives a dataset that behaves like a matrix\n\n\ndata\n[\n:\n,\n \n2\n]\n \n# this is the second variable timeseries\n\n\ndata\n[\n1\n]\n \n==\n \ndata\n[\n1\n,\n \n:\n]\n \n# this is the first datapoint of the dataset (D-dimensional)\n\n\ndata\n[\n5\n,\n \n3\n]\n \n# this is the value of the third variable, at the 5th timepoint\n\n\n\n\n\n\nUse \nconvert(Matrix, dataset)\n to create a \nMatrix\n, and \nconvert(Dataset, matrix)\n to create a \nDataset\n from a matrix. \nNotice:\n  \nconvert(Dataset, matrix)\n assumes that each column of the matrix represents one dynamic variable. If instead each column of the matrix represents a datapoint, use \nreinterpret(Dataset, matrix)\n.\n\n\nIf you have various timeseries vectors \nx, y, z, ...\n pass them like \nDataset(x, y, z, ...)\n.\n\n\nsource\n\n\n\n\nIn essence a \nDataset\n is simply a container for a \nVector\n of \nVector\ns, but only for cases where the all inner vectors are of equal size. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the \ncolumn\n direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:\n\n\ndata\n \n=\n \ntrajectory\n(\nhen\n,\n \n10000\n)\n\n\nfor\n \npoint\n \nin\n \ndata\n\n\n# do stuff with each datapoint (vector with as many elements as system dimension)\n\n\nend\n\n\n\n\n\n\nAll functions of our package that manipulate and use data are expecting a \nDataset\n instance. If given a matrix, they will first convert to \nDataset\n. This means that you should first convert your data to a \nDataset\n if you want to call functions more than once, to avoid constantly converting.\n\n\n\n\nPredefined Systems\n\n\nPredefined systems exist in the \nSystems\n submodule exported by \nDynamicalSystems\n, in the form of functions that return a \nDynamicalSystem\n. They are accessed like:\n\n\nusing\n \nDynamicalSystems\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n\n\nts\n \n=\n \ntrajectory\n(\nds\n,\n \n10.0\n)\n\n\n\n\n\n\nAll of these functions have very similar documentation strings:\n\n\n\n\nCall signature (parameters of the system are always passed as keyword arguments).\n\n\nEquations of the system in \n\\(\\LaTeX\\)\n (how cool is that!).\n\n\nIntroductory text about what this system is and who introduced it first.\n\n\nCouple of sentences that contain cool science info about the system.\n\n\nReference to the original papers.\n\n\n\n\nSo far, the predefined systems that exist in the \nSystems\n sub-module are:\n\n\n#\n\n\nDynamicalSystems.Systems.double_pendulum\n \n \nFunction\n.\n\n\ndouble_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)\n\n\n\n\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\n\nThe variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].\n\n\nJacobian is not created! So no \nlyapunovs\n for you!\n\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.henon\n \n \nFunction\n.\n\n\nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\nx_{n+1} \n= 1 - ax^2_n+y_n \\\\\ny_{n+1} \n = bx_n\n\\end{align*}\n\\]\nThe H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : M. H\u00e9non, Commun.Math. Phys. \n50\n, pp 69 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.logistic\n \n \nFunction\n.\n\n\nlogistic\n(\nx0\n \n=\n \nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n\n\n\n\n\n\\[\nx_{n+1} = rx_n(1-x_n)\n\\]\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].\n\n\n[1] : R. M. May, Nature \n261\n, pp 459 (1976)\n\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. \n19\n, pp 25 (1978)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.lorenz\n \n \nFunction\n.\n\n\nlorenz\n(\nu0\n=\n[\n0.0\n,\n \n10.0\n,\n \n0.0\n];\n \n\u03c3\n \n=\n \n10.0\n,\n \n\u03c1\n \n=\n \n28.0\n,\n \n\u03b2\n \n=\n \n8\n/\n3\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\dot{X} \n= \\sigma(Y-X) \\\\\n\\dot{Y} \n= -XZ + \\rho X -Y \\\\\n\\dot{Z} \n= XY - \\beta Z\n\\end{align*}\n\\]\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\n\n[1] : E. N. Lorenz, J. atmos. Sci. \n20\n, pp 130 (1963)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.roessler\n \n \nFunction\n.\n\n\nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\dot{x} \n= -y-z \\\\\n\\dot{y} \n= x+ay \\\\\n\\dot{z} \n= -b + z(x-c)\n\\end{align*}\n\\]\nThis three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the \nlorenz\n system and displays a (fractal) strange attractor.\n\n\nHowever, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n57A\n, pp 397 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.standardmap\n \n \nFunction\n.\n\n\nstandardmap\n(\nu0\n=\n0.001\nrand\n(\n2\n);\n \nk\n \n=\n \n0.971635\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\theta_{n+1} \n= \\theta_n + p_{n+1} \\\\\np_{n+1} \n= p_n + k\\sin(\\theta_n)\n\\end{align*}\n\\]\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\n\nThe map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter \nk\n transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\n\nThe default parameter \nk\n is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable \n\u03b8\n to be the first, and the angular momentum \np\n to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).\n\n\n[1] : B. V. Chirikov, Preprint N. \n267\n, Institute of Nuclear Physics, Novosibirsk (1969)\n\n\n[2] : J. M. Greene, J. Math. Phys. \n20\n, pp 1183 (1979)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.towel\n \n \nFunction\n.\n\n\ntowel\n(\nu0\n \n=\n \n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n])\n\n\n\n\n\n\n\\[\n\\begin{align*}\nx_{n+1} \n= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} \n= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} \n= 3.78 z_n (1-z_n) + b y_n\n\\end{align*}\n\\]\nThe folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative lyapunov exponent.\n\n\nThe name comes from the fact that when plotted looks like a folded towel, in every projection.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n71A\n, pp 155 (1979)\n\n\nsource", 
            "title": "System Definition"
        }, 
        {
            "location": "/system_definition/#system-definition", 
            "text": "For  DynamicalSystems.jl  a system is simple a structure that contains the system's state, the equations of motion and the Jacobian. The last two are  functions  that take as an input a state.  This of course stands for systems where one already  knows the equations of motion . if instead, your \"system\" is in the form of  numerical data , then see the appropriate section.   Non-autonomous systems  This package does  not  accept non-autonomous systems. To use such systems with this package increase the dimensionality of your system by 1, by introducing an additional variable  \u03c4  such that  d\u03c4dt = 1  (or  \u03c4_next = \u03c4_prev + 1 ). This additional variable will serve as the \"time\" in your equations of motion.    Trajectory and Timeseries  The word \"timeseries\" can be very confusing, because it can mean a one-dimensional timeseries or a multi-dimensional timeseries. To resolve this confusion, in  DynamicalSystems.jl  we have the following convention:  \"timeseries\"  always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word  \"trajectory\"  is used to refer to a  multi-dimensional  timeseries, which is of course simply a group/set of one-dimensional timeseries.  Note that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a  Dataset , which is a  Vector  of  SVector s, and each  SVector  represents a data-point (the values of the variables at a given time-point).", 
            "title": "System Definition"
        }, 
        {
            "location": "/system_definition/#discrete-systems", 
            "text": "Discrete systems are of the form:  \\[\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\\] The Type representing such systems is called  DiscreteDS :  #  DynamicalSystems.DiscreteDS     Type .  DiscreteDS(state, eom [, jacob])  : DynamicalSystem  D -dimensional discrete dynamical system (used for  D \u2264 10 ).  Fields:   state::SVector{D}  : Current state-vector of the system, stored in the data format of  StaticArray 's  SVector .  eom  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom(u) -  SVector  which means that given a state-vector  u  it returns an  SVector  containing the next state.  jacob::J  (function) : A function that calculates the system's jacobian matrix, based on the format:  jacob(u) -  SMatrix  which means that given a state-vector  u  it returns an  SMatrix  containing the Jacobian at that state.   If the  jacob  is not provided by the user, it is created efficiently using the module  ForwardDiff .  source   The documentation string of the constructor is perfectly self-contained, but for the sake of clarity we will go through all the steps in the following.  state  is simply the state the system starts (a.k.a. initial conditions) and  eom  is a  function  that takes a  state  as an input and returns the next state as an output. The  jacob  is also a  function  that takes a  state  as an input and returns the Jacobian matrix of the system (at this state). This however is optional and if not provided by the user, will be calculated automatically using the package  ForwardDiff.jl .   Return form of the  eom  function  It is  heavily  advised that the equations of motion  eom  function returns an  SVector  from the julia package  StaticArrays.jl  and similarly the  jacob  function returns an  SMatrix .  Numerous benchmarks  have been made in order to deduce the most efficient possible way to define a system, and this way was proved to be the best when the system's dimension is small.   For example, let's create one of the  Predefined Systems  offered by this package, the H\u00e9non map:  using   DynamicalSystems  using   StaticArrays   #only necessary when defining a system  eom_henon ( x )   =   SVector { 2 }( 1.0   -   a * x [ 1 ] ^ 2   +   x [ 2 ],   b * x [ 1 ])  jacob_henon ( x )   =   @SMatrix   [ - 2 * a * x [ 1 ]   1.0 ;   b   0.0 ]  hen   =   DiscreteDS ( rand ( 2 ),   eom_henon ,   jacob_henon )   If we did not want to write a Jacobian, we could do  hen_nojac   =   DiscreteDS ( rand ( 2 ),   eom_henon )   and the Jacobian function would be created automatically.", 
            "title": "Discrete Systems"
        }, 
        {
            "location": "/system_definition/#1-dimensional-discrete-systems", 
            "text": "In the case of maps, there a special structure for one-dimensional systems, since they are commonly used in scientific research. The syntax is  DiscreteDS1D(state, eom [, deriv]) . In this one-dimensional case, you don't need to worry about  StaticArrays.jl  because everything is in plain numbers. For example:  using   DynamicalSystems  @inline   eom_logistic ( r )   =   ( x )   -   r * x * ( 1 - x )    # this is a closure  @inline   deriv_logistic ( r )   =   ( x )   -   r * ( 1 - 2 x )   # this is a closure  r   =   3.7  logistic   =   DiscreteDS1D ( rand (),   eom_logistic ( r ),   deriv_logistic ( r ))   Once again, if you skip the derivative functions it will be calculated automatically using  ForwardDiff.jl .", 
            "title": "1-dimensional Discrete Systems"
        }, 
        {
            "location": "/system_definition/#continuous-systems", 
            "text": "Continuous systems of the form  \\[\n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}),\n\\] are defined in a similar manner with the discrete systems:  #  DynamicalSystems.ContinuousDS     Type .  ContinuousDS(state, eom! [, jacob])  : ContinuousDynamicalSystem\nContinuous dynamical system with dimension D = length(state)  Fields:   state::Vector{T}  : Current state-vector of the system  eom!  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom!(du, u)  which means that it is  in-place , with the Julian syntax (the mutated argument  du  is the first).  jacob  (function) : The function that represents the Jacobian of the system, given in the format:  jacob(u) =  J  (i.e. returns a matrix). If the matrix is an  SMatrix  from  StaticArrays.jl  there are major performance gains.   Because the  jacob  function is only necessary for a small subset of algorithms, you do not have to provide it necessarily to the constructor (but then you can't use these functions).  source   There are two major differences compared to the discrete case:   The second field  eom!  ends with an  !  to remind users that it is an in-place function. This is necessary because the integration of continuous systems using  DifferentialEquations.jl  is much better this way.  Automated Jacobian function evaluation is not yet supported due to the dissonance of the interfaces of  DifferentialEquations.jl  and  ForwardDiff.jl   Notice that providing a Jacobian is not necessary, since currently it is only used by the function  lyapunovs . If you do provide a Jacobian, it is best if it returns an  SMatrix , just like with the discrete systems case.  As an example, the continuous R\u00f6ssler system can be defined as:  @inline   @inbounds   function   eom_roessler! ( du ,   u ) \n     a   =   0.2 ;   b   =   0.2 ;   c   =   5.7 \n     du [ 1 ]   =   - u [ 2 ] - u [ 3 ] \n     du [ 2 ]   =   u [ 1 ]   +   a * u [ 2 ] \n     du [ 3 ]   =   b   +   u [ 3 ] * ( u [ 1 ]   -   c )  end  @inline   @inbounds   function   jacob_roessler ( u ) \n     i   =   one ( eltype ( u )) \n     o   =   zero ( eltype ( u )) \n     @SMatrix   [ o       - i        - i ; \n               i        a         o ; \n               u [ 3 ]     o         u [ 1 ]   -   c ]  end  ros   =   ContinuousDS ( rand ( 3 ),   eom_roessler! ,   jacob_roessler )", 
            "title": "Continuous Systems"
        }, 
        {
            "location": "/system_definition/#system-evolution", 
            "text": "DynamicalSystems.jl  provides convenient interfaces for the evolution of systems. Especially in the continuous case, an interface is provided to the module  DifferentialEquations.jl , with an approach that fits more the structuring of the present package (e.g. time is never passed to the equations of motion).  Notice that if you want to do repeated evolutions of a system, use the  evolve!(::ODEProblem)  interface, which does not create a new  ODEProblem  every time.  These are the functions related to system-evolution:  #  DynamicalSystems.evolve     Function .  evolve ( ds :: DynamicalSystem ,   T = 1 ;   diff_eq_kwargs   =   Dict ())   -   final_state   Evolve a  ds  for total \"time\"  T  and return the  final_state  (does not change  ds.state ). For discrete systems  T  corresponds to steps and thus it must be integer. See  trajectory  for using  diff_eq_kwargs .  This function  does not store  any information about intermediate steps. Use  trajectory  if you want to produce a trajectory of the system. If you want to perform step-by-step evolution of a continuous system, use  ODEIntegrator(ds, t_final)  and the  step!(integrator)  function provided by  DifferentialEquations .  See also  evolve! .  source  #  DynamicalSystems.evolve!     Function .  evolve !( ds :: DynamicalSystem ,   T ;   diff_eq_kwargs   =   Dict ())   -   ds   Evolve (in-place) a dynamical system for total \"time\"  T , setting the final state as the system's state. For discrete systems  T  corresponds to steps and thus it must be integer. See  trajectory  for using  diff_eq_kwargs .  This function  does not store  any information about intermediate steps. Use  trajectory  if you want to produce a trajectory of the system. If you want to perform step-by-step evolution of a continuous system, use  ODEIntegrator(ds, t_final)  and the  step!(integrator)  function provided by  DifferentialEquations .  See also  evolve .  source  #  DynamicalSystems.trajectory     Function .  trajectory ( ds :: DynamicalSystem ,   T ;   kwargs ... )   -   dataset   Return a dataset what will contain the trajectory of the sytem, after evolving it for time  T . See  Dataset  for info on how to manipulate this object.  For the discrete case,  T  is an integer and a  T\u00d7D  dataset is returned ( D  is the system dimensionality). For the continuous case, a  W\u00d7D  dataset is returned, with  W = length(0:dt:T)  with  0:dt:T  representing the time vector ( not  returned).  Keywords:   dt = 0.05  : (only for continuous) Time step of value output during the solving of the continuous system.  diff_eq_kwargs = Dict()  : (only for continuous) A dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  solve  of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :maxiters =  1e9) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.   source   In addition, interfaces are provided for usage directly with  DifferentialEquations.jl , by giving additional constructors:  #  DiffEqBase.ODEProblem     Type .  ODEProblem ( ds :: ContinuousDS ,   t )   Return an  ODEProblem  with the given system information (t0 is zero). This can be passed directly into  solve  from  DifferentialEquations.jl .  source  #  OrdinaryDiffEq.ODEIntegrator     Type .  ODEIntegrator ( ds :: ContinuousDS ,   t ;   diff_eq_kwargs )   Return an  ODEIntegrator , by first creating an  ODEProblem(ds, t) . This can be used directly with the interfaces of  DifferentialEquations.jl .  diff_eq_kwargs = Dict()  is a dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  init  of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :tstops =  0:0.01:t) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.  source", 
            "title": "System evolution"
        }, 
        {
            "location": "/system_definition/#numerical-data", 
            "text": "Numerical data in  DynamicalSystems.jl  is represented by a structure called  Dataset :  #  DynamicalSystems.Dataset     Type .  Dataset{D, T}  : AbstractDataset{D}  A dedicated interface for datasets, i.e. vectors of vectors. It contains  equally-sized datapoints  of length  D , represented by  SVector{D, T} , containing numbers of type  T .  Dataset  has methods for iterating,  convert ,  push! ,  append!  and other basic functions.  The internal data representation is more efficient than having a  Matrix  and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables.  trajectory  always returns a  Dataset .  For example,  data   =   trajectory ( ds ,   100.0 )   #this gives a dataset that behaves like a matrix  data [ : ,   2 ]   # this is the second variable timeseries  data [ 1 ]   ==   data [ 1 ,   : ]   # this is the first datapoint of the dataset (D-dimensional)  data [ 5 ,   3 ]   # this is the value of the third variable, at the 5th timepoint   Use  convert(Matrix, dataset)  to create a  Matrix , and  convert(Dataset, matrix)  to create a  Dataset  from a matrix.  Notice:    convert(Dataset, matrix)  assumes that each column of the matrix represents one dynamic variable. If instead each column of the matrix represents a datapoint, use  reinterpret(Dataset, matrix) .  If you have various timeseries vectors  x, y, z, ...  pass them like  Dataset(x, y, z, ...) .  source   In essence a  Dataset  is simply a container for a  Vector  of  Vector s, but only for cases where the all inner vectors are of equal size. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the  column  direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:  data   =   trajectory ( hen ,   10000 )  for   point   in   data  # do stuff with each datapoint (vector with as many elements as system dimension)  end   All functions of our package that manipulate and use data are expecting a  Dataset  instance. If given a matrix, they will first convert to  Dataset . This means that you should first convert your data to a  Dataset  if you want to call functions more than once, to avoid constantly converting.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/system_definition/#predefined-systems", 
            "text": "Predefined systems exist in the  Systems  submodule exported by  DynamicalSystems , in the form of functions that return a  DynamicalSystem . They are accessed like:  using   DynamicalSystems  ds   =   Systems . lorenz ( \u03c1   =   32.0 )  ts   =   trajectory ( ds ,   10.0 )   All of these functions have very similar documentation strings:   Call signature (parameters of the system are always passed as keyword arguments).  Equations of the system in  \\(\\LaTeX\\)  (how cool is that!).  Introductory text about what this system is and who introduced it first.  Couple of sentences that contain cool science info about the system.  Reference to the original papers.   So far, the predefined systems that exist in the  Systems  sub-module are:  #  DynamicalSystems.Systems.double_pendulum     Function .  double_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)  Famous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).  The variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].  Jacobian is not created! So no  lyapunovs  for you!  (please contribute the Jacobian and the e.o.m. in LaTeX :smile:)  source  #  DynamicalSystems.Systems.henon     Function .  henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 )   \\[\n\\begin{align*}\nx_{n+1}  = 1 - ax^2_n+y_n \\\\\ny_{n+1}   = bx_n\n\\end{align*}\n\\] The H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.  According to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible.  Default values are the ones used in the original paper.  [1] : M. H\u00e9non, Commun.Math. Phys.  50 , pp 69 (1976)  source  #  DynamicalSystems.Systems.logistic     Function .  logistic ( x0   =   rand ();   r   =   4.0 )   \\[\nx_{n+1} = rx_n(1-x_n)\n\\] The logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.  Originally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].  [1] : R. M. May, Nature  261 , pp 459 (1976)  [2] : M. J. Feigenbaum, J. Stat. Phys.  19 , pp 25 (1978)  source  #  DynamicalSystems.Systems.lorenz     Function .  lorenz ( u0 = [ 0.0 ,   10.0 ,   0.0 ];   \u03c3   =   10.0 ,   \u03c1   =   28.0 ,   \u03b2   =   8 / 3 )   \\[\n\\begin{align*}\n\\dot{X}  = \\sigma(Y-X) \\\\\n\\dot{Y}  = -XZ + \\rho X -Y \\\\\n\\dot{Z}  = XY - \\beta Z\n\\end{align*}\n\\] The famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.  Currently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.  [1] : E. N. Lorenz, J. atmos. Sci.  20 , pp 130 (1963)  source  #  DynamicalSystems.Systems.roessler     Function .  roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 )   \\[\n\\begin{align*}\n\\dot{x}  = -y-z \\\\\n\\dot{y}  = x+ay \\\\\n\\dot{z}  = -b + z(x-c)\n\\end{align*}\n\\] This three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the  lorenz  system and displays a (fractal) strange attractor.  However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  57A , pp 397 (1976)  source  #  DynamicalSystems.Systems.standardmap     Function .  standardmap ( u0 = 0.001 rand ( 2 );   k   =   0.971635 )   \\[\n\\begin{align*}\n\\theta_{n+1}  = \\theta_n + p_{n+1} \\\\\np_{n+1}  = p_n + k\\sin(\\theta_n)\n\\end{align*}\n\\] The standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.  The map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter  k  transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.  The default parameter  k  is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable  \u03b8  to be the first, and the angular momentum  p  to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).  [1] : B. V. Chirikov, Preprint N.  267 , Institute of Nuclear Physics, Novosibirsk (1969)  [2] : J. M. Greene, J. Math. Phys.  20 , pp 1183 (1979)  source  #  DynamicalSystems.Systems.towel     Function .  towel ( u0   =   [ 0.085 ,   - 0.121 ,   0.075 ])   \\[\n\\begin{align*}\nx_{n+1}  = a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1}  = 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1}  = 3.78 z_n (1-z_n) + b y_n\n\\end{align*}\n\\] The folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative lyapunov exponent.  The name comes from the fact that when plotted looks like a folded towel, in every projection.  Default values are the ones used in the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  71A , pp 155 (1979)  source", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/lyapunovs/", 
            "text": "Lyapunov Exponents\n\n\nLyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The \nWikipedia\n and the \nScholarpedia\n entries have a lot of valuable information about the history and usage of these quantities.\n\n\nThe naming comes after Aleksandr M. Lyapunov, a Russian mathematician/physicist that had major impact on the analysis of the stability of systems.\n\n\nThis page treats systems where the equations of motion are known. If instead you have numerical data, see the \nnonlinear timeseries analysis page\n.\n\n\n\n\nLyapunov Spectrum\n\n\nThe function \nlyapunovs\n calculates the entire spectrum of the Lyapunov exponents of a system:\n\n\n#\n\n\nDynamicalSystems.lyapunovs\n \n \nFunction\n.\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n;\n \nkwargs\n...\n)\n \n-\n \n[\n\u03bb1\n,\n \n\u03bb2\n,\n \n...\n,\n \n\u03bbD\n]\n\n\n\n\n\n\nCalculate the spectrum of Lyapunov exponents [1] of \nds\n by applying the QR-decomposition method \nN\n times (see method \"H2\" of [2], or directly the original paper(s) [3]). Returns a vector with the \nfinal\n values of the lyapunov exponents in descending order.\n\n\nKeyword Arguments:\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\ndt = 1.0\n : (only for continuous) Time of individual evolutions between sucessive orthonormalization steps.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\n\n\n[1] : A. M. Lyapunov, \nThe General Problem of the Stability of Motion\n, Taylor \n Francis (1992)\n\n\n[2] : K. Geist \net al.\n, Progr. Theor. Phys. \n83\n, pp 875 (1990)\n\n\n[3] : G. Benettin \net al.\n, Meccanica \n15\n, pp 9-20 \n 21-30 (1980)\n\n\nsource\n\n\n\n\nAs you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the \nfolded towel map\n is calculated as:\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nds\n,\n \n10000\n)\n\n\n# result:\n\n\n[\n0.432253\n,\n \n0.371617\n,\n \n-\n3.29632\n]\n\n\n\n\n\n\nSimilarly, for a continuous system, e.g. the Lorenz system, you would do:\n\n\nusing\n \nDynamicalSystems\n\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n \n#this is not the original parameter!\n\n\nissubtype\n(\ntypeof\n(\nds\n),\n \nDynamicalSystems\n.\nContinuousDynamicalSystem\n)\n \n# true\n\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nlor\n,\n \n10000\n,\n\n\ndt\n \n=\n \n0.1\n,\n \ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nabstol\n \n=\n \n1e-9\n,\n \n:\nreltol\n \n=\n \n1e-9\n))\n\n\n# result:\n\n\n[\n0.999176\n,\n \n0.000774754\n,\n \n-\n14.6666\n]\n\n\n\n\n\n\n\n\nMaximum Lyapunov Exponent\n\n\nThe function \nlyapunov\n calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of \nlyapunovs\n:\n\n\n#\n\n\nDynamicalSystems.lyapunov\n \n \nFunction\n.\n\n\nlyapunov\n(\nds\n::\nDynamicalSystem\n,\n \n\u03a4\n,\n \nret_conv\n \n=\n \nVal\n{\nfalse\n};\n \nkwargs\n...\n)\n\n\n\n\n\n\nCalculate the maximum Lyapunov exponent \n\u03bb\n using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one. \nT\n  denotes the total time of evolution (should be \nInt\n for discrete systems). The Lyapunov exponent is the average of the time-local Lyapunov exponents, meaning\n\n\n\\[\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}\n\\]\nwith \n\\(d(t_i)\\)\n the distance between test and given trajectory at time \n\\(t_i\\)\n, which is also the time of the \n\\(i\\)\n-th rescaling.\n\n\nIf \nret_conv\n is \nVal{true}\n return the convergence timeseries of the Lyapunov exponent \n\u03bbts\n as well as the corresponding time vector \nts\n. If \nret_conv\n is \nVal{false}\n (default) return the converged Lyapunov value \n\u03bbts[end]\n instead.\n\n\nKeyword Arguments:\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\nd0 = 1e-9\n : Initial \n rescaling distance between two neighboring trajectories.\n\n\nthreshold = 1e-5\n : Whenever the distance between given and test trajectory exceeds \nthreshold\n, the test trajectory is rescaled back to having distance \nd0\n from the given trajectory.\n\n\ndiff_eq_kwargs = Dict(:abstol=\nd0, :reltol=\nd0)\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\ndt = 0.1\n : (only for continuous) Time of evolution between each check of distance exceeding the \nthreshold\n.\n\n\ninittest = (st1, d0) -\n st1 .+ d0/sqrt(D)\n : A function that given \n(st1, d0)\n initializes the test state with distance \nd0\n from the given state \nst1\n (\nD\n is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.\n\n\n\n\nFor the continuous case, the algorithm becomes faster with increasing \ndt\n, since integration is interrupted less frequenty. For the fastest performance you want to fine-tune \ndt, d0, threshold\n such that you have the minimum amount of rescalings but you want to still be well within the linearized dynamics region.\n\n\n[1] : G. Benettin \net al.\n, Phys. Rev. A \n14\n, pp 2338 (1976)\n\n\nsource\n\n\n\n\nFor example:\n\n\nusing\n \nDynamicalSystems\n\n\n\nhenon\n \n=\n \nSystems\n.\nhenon\n()\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nhenon\n,\n \n10000\n,\n \nd0\n \n=\n \n1e-7\n,\n \nthreshold\n \n=\n \n1e-4\n,\n \nTtr\n \n=\n \n100\n)\n\n\n# result:\n\n\n0.420\n...\n\n\n\n\n\n\nThe same is done for continuous systems:\n\n\nusing\n \nDynamicalSystems\n,\n \nOrdinaryDiffEq\n\n\n\nross\n \n=\n \nSystems\n.\nroessler\n(\na\n \n=\n \n0.1\n,\n \nb\n \n=\n \n0.1\n,\n \nc\n \n=\n \n14.0\n)\n \n#not original parameters\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nross\n,\n \n100000\n,\n \ndt\n \n=\n \n10.0\n,\n \ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nsolver\n \n=\n \nVern8\n(),\n \n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n),\n \nTtr\n \n=\n \n100.0\n)\n\n\n# result:\n\n\n0.0711\n...\n\n\n\n\n\n\n\n\nConvergence Timeseries\n\n\nAs was explained in the documentation of the functions, one can choose to get the convergence timeseries of the lyapunov exponents, instead of simply the converged values. This can be very helpful if one will e.g. prepare to run a lot of simulations and would like to have some adjusted parameters for optimal convergence.\n\n\nFor example\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n()\n \n#works for continuous\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n  \n#works for discrete as well\n\n\n\n# use `Val{true}` as the third argument to get convergence info\n\n\nls\n,\n \nts\n \n=\n \nlyapunov\n(\nhen\n,\n \n1000000\n,\n \nVal\n{\ntrue\n},\n \nd0\n \n=\n \n1e-12\n)\n\n\nls2\n,\n \nts2\n \n=\n \nlyapunov\n(\nhen\n,\n \n100000\n,\n \nVal\n{\ntrue\n},\n \nd0\n \n=\n \n1e-6\n,\n \nthreshold\n \n=\n \n1e-4\n)\n\n\n\nusing\n \nPyPlot\n\n\nplot\n(\nts\n,\n \nls\n,\n \nlabel\n \n=\n \n1: \u03bb = \n$\n(\nls\n[\nend\n])\n,\n \nlinestyle\n=\ndashed\n)\n\n\nplot\n(\nts2\n,\n \nls2\n,\n \nlabel\n \n=\n \n2: \u03bb = \n$\n(\nls2\n[\nend\n])\n)\n\n\nlegend\n()\n\n\nxlabel\n(\nn\n)\n\n\nylabel\n(\n\u03bb\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\nwhich plots:", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/lyapunovs/#lyapunov-exponents", 
            "text": "Lyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The  Wikipedia  and the  Scholarpedia  entries have a lot of valuable information about the history and usage of these quantities.  The naming comes after Aleksandr M. Lyapunov, a Russian mathematician/physicist that had major impact on the analysis of the stability of systems.  This page treats systems where the equations of motion are known. If instead you have numerical data, see the  nonlinear timeseries analysis page .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/lyapunovs/#lyapunov-spectrum", 
            "text": "The function  lyapunovs  calculates the entire spectrum of the Lyapunov exponents of a system:  #  DynamicalSystems.lyapunovs     Function .  lyapunovs ( ds :: DynamicalSystem ,   N ;   kwargs ... )   -   [ \u03bb1 ,   \u03bb2 ,   ... ,   \u03bbD ]   Calculate the spectrum of Lyapunov exponents [1] of  ds  by applying the QR-decomposition method  N  times (see method \"H2\" of [2], or directly the original paper(s) [3]). Returns a vector with the  final  values of the lyapunov exponents in descending order.  Keyword Arguments:   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  dt = 1.0  : (only for continuous) Time of individual evolutions between sucessive orthonormalization steps.  diff_eq_kwargs = Dict()  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).   [1] : A. M. Lyapunov,  The General Problem of the Stability of Motion , Taylor   Francis (1992)  [2] : K. Geist  et al. , Progr. Theor. Phys.  83 , pp 875 (1990)  [3] : G. Benettin  et al. , Meccanica  15 , pp 9-20   21-30 (1980)  source   As you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the  folded towel map  is calculated as:  using   DynamicalSystems  ds   =   Systems . towel ()  \u03bb\u03bb   =   lyapunovs ( ds ,   10000 )  # result:  [ 0.432253 ,   0.371617 ,   - 3.29632 ]   Similarly, for a continuous system, e.g. the Lorenz system, you would do:  using   DynamicalSystems  lor   =   Systems . lorenz ( \u03c1   =   32.0 )   #this is not the original parameter!  issubtype ( typeof ( ds ),   DynamicalSystems . ContinuousDynamicalSystem )   # true  \u03bb\u03bb   =   lyapunovs ( lor ,   10000 ,  dt   =   0.1 ,   diff_eq_kwargs   =   Dict ( : abstol   =   1e-9 ,   : reltol   =   1e-9 ))  # result:  [ 0.999176 ,   0.000774754 ,   - 14.6666 ]", 
            "title": "Lyapunov Spectrum"
        }, 
        {
            "location": "/lyapunovs/#maximum-lyapunov-exponent", 
            "text": "The function  lyapunov  calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of  lyapunovs :  #  DynamicalSystems.lyapunov     Function .  lyapunov ( ds :: DynamicalSystem ,   \u03a4 ,   ret_conv   =   Val { false };   kwargs ... )   Calculate the maximum Lyapunov exponent  \u03bb  using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one.  T   denotes the total time of evolution (should be  Int  for discrete systems). The Lyapunov exponent is the average of the time-local Lyapunov exponents, meaning  \\[\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}\n\\] with  \\(d(t_i)\\)  the distance between test and given trajectory at time  \\(t_i\\) , which is also the time of the  \\(i\\) -th rescaling.  If  ret_conv  is  Val{true}  return the convergence timeseries of the Lyapunov exponent  \u03bbts  as well as the corresponding time vector  ts . If  ret_conv  is  Val{false}  (default) return the converged Lyapunov value  \u03bbts[end]  instead.  Keyword Arguments:   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  d0 = 1e-9  : Initial   rescaling distance between two neighboring trajectories.  threshold = 1e-5  : Whenever the distance between given and test trajectory exceeds  threshold , the test trajectory is rescaled back to having distance  d0  from the given trajectory.  diff_eq_kwargs = Dict(:abstol= d0, :reltol= d0)  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).  dt = 0.1  : (only for continuous) Time of evolution between each check of distance exceeding the  threshold .  inittest = (st1, d0) -  st1 .+ d0/sqrt(D)  : A function that given  (st1, d0)  initializes the test state with distance  d0  from the given state  st1  ( D  is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.   For the continuous case, the algorithm becomes faster with increasing  dt , since integration is interrupted less frequenty. For the fastest performance you want to fine-tune  dt, d0, threshold  such that you have the minimum amount of rescalings but you want to still be well within the linearized dynamics region.  [1] : G. Benettin  et al. , Phys. Rev. A  14 , pp 2338 (1976)  source   For example:  using   DynamicalSystems  henon   =   Systems . henon ()  \u03bb   =   lyapunov ( henon ,   10000 ,   d0   =   1e-7 ,   threshold   =   1e-4 ,   Ttr   =   100 )  # result:  0.420 ...   The same is done for continuous systems:  using   DynamicalSystems ,   OrdinaryDiffEq  ross   =   Systems . roessler ( a   =   0.1 ,   b   =   0.1 ,   c   =   14.0 )   #not original parameters  \u03bb   =   lyapunov ( ross ,   100000 ,   dt   =   10.0 ,   diff_eq_kwargs   =   Dict ( : solver   =   Vern8 (),   : abstol = 1e-9 ,   : reltol = 1e-9 ),   Ttr   =   100.0 )  # result:  0.0711 ...", 
            "title": "Maximum Lyapunov Exponent"
        }, 
        {
            "location": "/lyapunovs/#convergence-timeseries", 
            "text": "As was explained in the documentation of the functions, one can choose to get the convergence timeseries of the lyapunov exponents, instead of simply the converged values. This can be very helpful if one will e.g. prepare to run a lot of simulations and would like to have some adjusted parameters for optimal convergence.  For example  lor   =   Systems . lorenz ()   #works for continuous  hen   =   Systems . henon ()    #works for discrete as well  # use `Val{true}` as the third argument to get convergence info  ls ,   ts   =   lyapunov ( hen ,   1000000 ,   Val { true },   d0   =   1e-12 )  ls2 ,   ts2   =   lyapunov ( hen ,   100000 ,   Val { true },   d0   =   1e-6 ,   threshold   =   1e-4 )  using   PyPlot  plot ( ts ,   ls ,   label   =   1: \u03bb =  $ ( ls [ end ]) ,   linestyle = dashed )  plot ( ts2 ,   ls2 ,   label   =   2: \u03bb =  $ ( ls2 [ end ]) )  legend ()  xlabel ( n )  ylabel ( \u03bb )  tight_layout ()   which plots:", 
            "title": "Convergence Timeseries"
        }, 
        {
            "location": "/entropies/", 
            "text": "Entropies and Dimensions\n\n\n\n\nEntropies\n\n\nIn the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known \nthermodynamic ones\n, used in Statistical Physics. Rather, they are more like the to the entropies of \ninformation theory\n, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.\n\n\nDynamicalSystems.jl\n defines a lot entropies, summarized in the following sections.\n\n\n\n\nGeneralized Entropy \n Co.\n\n\nThe generalized entropy is a concept mainly attributed to R\u00e9nyi (see below).\n\n\n#\n\n\nDynamicalSystems.genentropy\n \n \nFunction\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \n\u03b5\n,\n \ndataset\n)\n\n\n\n\n\n\nCompute the \n\u03b1\n order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length \n\u03b5\n using \nnon0hist\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \np\n::\nAbstractArray\n)\n\n\n\n\n\n\nCompute the entropy of an Array \np\n directly, assuming that \np\n is sum-normalized. \nlog base-e is used in both cases, i.e. units of \"nat\".\n\n\nThe R\u00e9nyi entropy\n\n\n\\[\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p_i^\\alpha\n\\]\ngeneralizes other known entropies, like e.g. the information entropy (\n\\(\\alpha = 1\\)\n, see [2]), the maximum entropy (\n\\(\\alpha=0\\)\n, also known as Hartley entropy), or the correlation entropy (\n\\(\\alpha = 2\\)\n, also known as collision entropy).\n\n\nThe following aliases are provided:\n\n\n\n\nrenyi = genentropy\n\n\nshannon(args...) = genentropy(1, args...)\n\n\nhartley(args...) = genentropy(0, args...)\n\n\n\n\n[1] : A. R\u00e9nyi, \nProceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability\n, pp 547 (1960)\n\n\n[2] : C. E. Shannon, Bell Systems Technical Journal \n27\n, pp 379 (1948)\n\n\nsource\n\n\n\n\nBasically, given a \ndataset\n you can partition it into boxes to calculate an entropy.\n\n\n\n\nWorried about memory overflow? Don't be!\n\n\nPartitioning the dataset (i.e. doing a \nhistogram\n) is in general a costly operation that depends exponentially on the number of dimensions of the system. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time! You can compare \nnon0hist\n with \nfit(Histogram, ...)\n of \nStatsBase\n for specific numbers on your machine.\n\n\n\n\nThe function used internally by \ngenentropy\n is \nnon0hist\n:\n\n\n#\n\n\nDynamicalSystems.non0hist\n \n \nFunction\n.\n\n\nnon0hist\n(\n\u03b5\n,\n \ndataset\n)\n\n\n\n\n\n\nPartition a dataset into tabulated intervals (boxes) of size \n\u03b5\n and return the \nsum-normalized\n histogram in an \nunordered 1D form\n, \ndiscarding all zero\n elements. This method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins.\n\n\nUse e.g. \nfit(Histogram, ...)\n from \nStatsBase\n if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\nsource\n\n\n\n\nFor example, the Shannon entropy of a coin-flip process should be one bit, \nby definition\n. Let's see...\n\n\nusing\n \nDynamicalSystems\n\n\ny\n \n=\n \nFloat64\n.\n(\nrand\n(\nBool\n,\n \n1000000\n))\n \n# just some coin tosses\n\n\nsh\n \n=\n \nshannon\n(\n0.1\n,\n \ny\n)\n  \n# \u2261 genentropy(1, 0.0, y)\n\n\nisapprox\n(\nsh\n,\n \nlog\n(\n2\n),\n  \nrtol\n \n=\n \n1e-6\n)\n \n# true!\n\n\n\n\n\n\nBecause all entropies are calculated on base-\n\\(e\\)\n, the unit of measurement is \"nat\" and one bit is \n\\(\\log(2)\\times\\)\nnat.\n\n\n\n\nAttractor Dimension Estimation\n\n\nThere are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the \nFractal dimension\n. This real number can offer a lot of information about the object that the dataset represents.\n\n\n\n\nGeneralized Dimensions \n Co.\n\n\nBased on the definition of the \ngeneralized entropy\n, one can calculate an appropriate dimension, called \ngeneralized dimension\n:\n\n\n#\n\n\nDynamicalSystems.generalized_dim\n \n \nFunction\n.\n\n\ngeneralized_dim(\u03b1, dataset) -\n D_\u03b1\n\n\n\n\n\nReturn the \n\\(\\alpha\\)\n order generalized dimension that corresponds to the given dataset. The dimension is approximated by the power law exponent of the scaling of the \ngenentropy\n versus the box size \n\u03b5\n.\n\n\nWARNING\n - This call performs a lot of automated steps:\n\n\n\n\nA vector of box sizes is decided by calling \nes = estimate_boxsizes(dataset)\n.\n\n\nFor each element of \nes\n the appropriate entropy is calculated, through \nd[i] = genentropy(\u03b1, es[i], dataset)\n. Let \nx = -log.(es)\n.\n\n\nThe curve d(x) is decomposed into linear regions, using \nlinear_regions\n(x, d)\n.\n\n\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the function \nlinear_region\n.\n\n\nThis fitted slope is returned.\n\n\n\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\n\nThe following aliases are provided:\n\n\n\n\n\u03b1 = 0 : \nboxcounting_dim\n, \ncapacity_dim\n\n\n\u03b1 = 1 : \ninformation_dim\n\n\n\u03b1 = 2 : \ncorrelation_dim\n, \ncollision_dim\n\n\n\n\nsource\n\n\n\n\nAs stated clearly, this call performs a lot of automated steps by calling the following functions with default arguments:\n\n\n#\n\n\nDynamicalSystems.estimate_boxsizes\n \n \nFunction\n.\n\n\nestimate_boxsizes(dataset; k::Int = 12, z = 0, w = 2)\n\n\n\n\n\nReturn a \nk\n-element \nlogspace\n from the magnitude + \nz\n of the biggest absolute value of the dataset, to the magnitude + \nw\n of the minimum pair-wise distance between datapoints.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.linear_regions\n \n \nFunction\n.\n\n\nlinear_regions(x, y; dxi::Int = 1, tol = 0.2) -\n (lrs, tangents)\n\n\n\n\n\nIdentify regions where the curve \ny(x)\n is linear, by scanning the \nx\n-axis every \ndxi\n indices (e.g. at \nx[1] to x[5], x[5] to x[10], x[10] to x[15]\n and so on if \ndxi=5\n).\n\n\nIf the slope (calculated using \nLsqFit\n) of a region of width \ndxi\n is approximatelly equal to that of the previous region, within tolerance \ntol\n, then these two regions belong to the same linear region.\n\n\nReturn the indices of \nx\n that correspond to linear regions, \nlrs\n, and the approximated \ntangents\n at each region. \nlrs\n is a vector of \nInt\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.linear_region\n \n \nFunction\n.\n\n\nlinear_region(x, y; dxi::Int = 1, tol = 0.2) -\n ([ind1, ind2], slope)\n\n\n\n\n\nCall \nlinear_regions\n, identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops (\nx[ind1:ind2]\n) as well as the approximated slope.\n\n\nsource\n\n\n\n\n\n\nExample\n\n\nOne is better off (if possible) performing the automated steps one by one to attain maximum control.\n\n\nFor example, we will calculate the dimensions of the strange attractors of the \nH\u00e9non map\n and the \nLorenz system\n:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n(\n-\nrand\n(\n2\n))\n\n\nts\n \n=\n \ntrajectory\n(\nhen\n,\n \n1000000\n)\n\n\nD_hen\n \n=\n \ninformation_dim\n(\nts\n)\n\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\nrand\n(\n3\n))\n\n\nts\n \n=\n \ntrajectory\n(\nlor\n,\n \n5000\n,\n \ndt\n \n=\n \n0.05\n)\n\n\nD_lor\n \n=\n \ncapacity_dim\n(\nts\n)\n\n\n\n\n\n\nYou will find that \nD_hen\n is around \n1.2\n and \nD_lor\n is around \n1.9\n. As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D \n56\n, pp 185-187 (1992)).\n\n\n\n\nKaplan-Yorke Dimension\n\n\nAlso known as Lyapunov Dimension:\n\n\n#\n\n\nDynamicalSystems.kaplanyorke_dim\n \n \nFunction\n.\n\n\nkaplanyorke_dim(lyapunovs::AbstractVector)\n\n\n\n\n\nCalculate the Kaplan-Yorke dimension \n1\n. This simply is the point where \ncumsum(lyapunovs)\n becomes zero (interpolated). Returns the length of the vector if the sum of the exponents never becomes negative.\n\n\nUseful in combination with \nlyapunovs\n.\n\n\n[1] :  J. Kaplan \n J. Yorke, \nChaotic behavior of multidimensional difference equations\n, Lecture Notes in Mathematics vol. \n730\n, Springer (1979)\n\n\nsource\n\n\n\n\nNotice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nD_kp\n \n=\n \nkaplanyorke_dim\n(\nlyapunovs\n(\nhen\n,\n \n1000000\n))", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/entropies/#entropies-and-dimensions", 
            "text": "", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/entropies/#entropies", 
            "text": "In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known  thermodynamic ones , used in Statistical Physics. Rather, they are more like the to the entropies of  information theory , which represents information contained within a dataset, or information about the dimensional scaling of a dataset.  DynamicalSystems.jl  defines a lot entropies, summarized in the following sections.", 
            "title": "Entropies"
        }, 
        {
            "location": "/entropies/#generalized-entropy-co", 
            "text": "The generalized entropy is a concept mainly attributed to R\u00e9nyi (see below).  #  DynamicalSystems.genentropy     Function .  genentropy ( \u03b1 ,   \u03b5 ,   dataset )   Compute the  \u03b1  order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length  \u03b5  using  non0hist .  genentropy ( \u03b1 ,   p :: AbstractArray )   Compute the entropy of an Array  p  directly, assuming that  p  is sum-normalized.  log base-e is used in both cases, i.e. units of \"nat\".  The R\u00e9nyi entropy  \\[\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p_i^\\alpha\n\\] generalizes other known entropies, like e.g. the information entropy ( \\(\\alpha = 1\\) , see [2]), the maximum entropy ( \\(\\alpha=0\\) , also known as Hartley entropy), or the correlation entropy ( \\(\\alpha = 2\\) , also known as collision entropy).  The following aliases are provided:   renyi = genentropy  shannon(args...) = genentropy(1, args...)  hartley(args...) = genentropy(0, args...)   [1] : A. R\u00e9nyi,  Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability , pp 547 (1960)  [2] : C. E. Shannon, Bell Systems Technical Journal  27 , pp 379 (1948)  source   Basically, given a  dataset  you can partition it into boxes to calculate an entropy.   Worried about memory overflow? Don't be!  Partitioning the dataset (i.e. doing a  histogram ) is in general a costly operation that depends exponentially on the number of dimensions of the system. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time! You can compare  non0hist  with  fit(Histogram, ...)  of  StatsBase  for specific numbers on your machine.   The function used internally by  genentropy  is  non0hist :  #  DynamicalSystems.non0hist     Function .  non0hist ( \u03b5 ,   dataset )   Partition a dataset into tabulated intervals (boxes) of size  \u03b5  and return the  sum-normalized  histogram in an  unordered 1D form ,  discarding all zero  elements. This method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins.  Use e.g.  fit(Histogram, ...)  from  StatsBase  if you wish to keep information about the edges of the binning as well as the zero elements.  source   For example, the Shannon entropy of a coin-flip process should be one bit,  by definition . Let's see...  using   DynamicalSystems  y   =   Float64 . ( rand ( Bool ,   1000000 ))   # just some coin tosses  sh   =   shannon ( 0.1 ,   y )    # \u2261 genentropy(1, 0.0, y)  isapprox ( sh ,   log ( 2 ),    rtol   =   1e-6 )   # true!   Because all entropies are calculated on base- \\(e\\) , the unit of measurement is \"nat\" and one bit is  \\(\\log(2)\\times\\) nat.", 
            "title": "Generalized Entropy &amp; Co."
        }, 
        {
            "location": "/entropies/#attractor-dimension-estimation", 
            "text": "There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the  Fractal dimension . This real number can offer a lot of information about the object that the dataset represents.", 
            "title": "Attractor Dimension Estimation"
        }, 
        {
            "location": "/entropies/#generalized-dimensions-co", 
            "text": "Based on the definition of the  generalized entropy , one can calculate an appropriate dimension, called  generalized dimension :  #  DynamicalSystems.generalized_dim     Function .  generalized_dim(\u03b1, dataset) -  D_\u03b1  Return the  \\(\\alpha\\)  order generalized dimension that corresponds to the given dataset. The dimension is approximated by the power law exponent of the scaling of the  genentropy  versus the box size  \u03b5 .  WARNING  - This call performs a lot of automated steps:   A vector of box sizes is decided by calling  es = estimate_boxsizes(dataset) .  For each element of  es  the appropriate entropy is calculated, through  d[i] = genentropy(\u03b1, es[i], dataset) . Let  x = -log.(es) .  The curve d(x) is decomposed into linear regions, using  linear_regions (x, d) .  The biggest linear region is chosen, and a fit for the slope of that region is performed using the function  linear_region .  This fitted slope is returned.   By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.  The following aliases are provided:   \u03b1 = 0 :  boxcounting_dim ,  capacity_dim  \u03b1 = 1 :  information_dim  \u03b1 = 2 :  correlation_dim ,  collision_dim   source   As stated clearly, this call performs a lot of automated steps by calling the following functions with default arguments:  #  DynamicalSystems.estimate_boxsizes     Function .  estimate_boxsizes(dataset; k::Int = 12, z = 0, w = 2)  Return a  k -element  logspace  from the magnitude +  z  of the biggest absolute value of the dataset, to the magnitude +  w  of the minimum pair-wise distance between datapoints.  source  #  DynamicalSystems.linear_regions     Function .  linear_regions(x, y; dxi::Int = 1, tol = 0.2) -  (lrs, tangents)  Identify regions where the curve  y(x)  is linear, by scanning the  x -axis every  dxi  indices (e.g. at  x[1] to x[5], x[5] to x[10], x[10] to x[15]  and so on if  dxi=5 ).  If the slope (calculated using  LsqFit ) of a region of width  dxi  is approximatelly equal to that of the previous region, within tolerance  tol , then these two regions belong to the same linear region.  Return the indices of  x  that correspond to linear regions,  lrs , and the approximated  tangents  at each region.  lrs  is a vector of  Int .  source  #  DynamicalSystems.linear_region     Function .  linear_region(x, y; dxi::Int = 1, tol = 0.2) -  ([ind1, ind2], slope)  Call  linear_regions , identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops ( x[ind1:ind2] ) as well as the approximated slope.  source", 
            "title": "Generalized Dimensions &amp; Co."
        }, 
        {
            "location": "/entropies/#example", 
            "text": "One is better off (if possible) performing the automated steps one by one to attain maximum control.  For example, we will calculate the dimensions of the strange attractors of the  H\u00e9non map  and the  Lorenz system :  using   DynamicalSystems  hen   =   Systems . henon ( - rand ( 2 ))  ts   =   trajectory ( hen ,   1000000 )  D_hen   =   information_dim ( ts )  lor   =   Systems . lorenz ( rand ( 3 ))  ts   =   trajectory ( lor ,   5000 ,   dt   =   0.05 )  D_lor   =   capacity_dim ( ts )   You will find that  D_hen  is around  1.2  and  D_lor  is around  1.9 . As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D  56 , pp 185-187 (1992)).", 
            "title": "Example"
        }, 
        {
            "location": "/entropies/#kaplan-yorke-dimension", 
            "text": "Also known as Lyapunov Dimension:  #  DynamicalSystems.kaplanyorke_dim     Function .  kaplanyorke_dim(lyapunovs::AbstractVector)  Calculate the Kaplan-Yorke dimension  1 . This simply is the point where  cumsum(lyapunovs)  becomes zero (interpolated). Returns the length of the vector if the sum of the exponents never becomes negative.  Useful in combination with  lyapunovs .  [1] :  J. Kaplan   J. Yorke,  Chaotic behavior of multidimensional difference equations , Lecture Notes in Mathematics vol.  730 , Springer (1979)  source   Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:  hen   =   Systems . henon ()  D_kp   =   kaplanyorke_dim ( lyapunovs ( hen ,   1000000 ))", 
            "title": "Kaplan-Yorke Dimension"
        }, 
        {
            "location": "/nlts/", 
            "text": "Nonlinear Timeseries Analysis\n\n\n\n\nDelay Coordinates Reconstruction\n\n\nA timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as \ndelay coordinates embedding\n.\n\n\nIn \nDynamicalSystems.jl\n this is done through the \nreconstruct\n interface:\n\n\n#\n\n\nDynamicalSystems.Reconstruction\n \n \nType\n.\n\n\nReconstruction{V, T, D, \u03c4} \n: AbstractDataset{D}\n\n\n\n\n\nD\n-dimensional reconstruction object with delay \n\u03c4\n, created from a vector \ns::V\n. \ns\n is the only field of \nReconstruction\n.\n\n\nThe \nn\nth row of this object is formally the \nD\n-dimensional vector:\n\n\n\\[\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\\]\nwhich is created only on demand. (\n\\(s\\)\n = \nR.s\n with \nR\n the \nReconstruction\n object)\n\n\nSee \nreconstruct\n for usage.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.reconstruct\n \n \nFunction\n.\n\n\nreconstruct(s::AbstractVector, D::Int, \u03c4::Int) -\n R::Reconstruction\n\n\n\n\n\nCreate and return an efficient \nReconstruction\n data structure that serves as the delay coordinates embedding [1, 2] reconstruction of the signal \ns\n. The reconstuction has dimension \nD\n and delay \n\u03c4\n (measured in indices). This object can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper \nD\n and \n\u03c4\n [1, 2].\n\n\nR\n interfaces \ns\n and can be accessed similarly to a \nDataset\n:\n\n\nR\n \n=\n \nreconstruct\n(\ns\n,\n \n4\n,\n \n1\n)\n \n# delay coords. reconstruction of dimension 4 and delay 1\n\n\nR\n[\n3\n]\n \n# third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])\n\n\nR\n[\n1\n,\n \n2\n]\n \n# Second element of first point of reconstruction, \u2261 s[2]\n\n\n\n\n\n\n(this is only smart indexing, no Vectors or SVectors are created during the construction of \nR\n)\n\n\nR\n can also be given to all functions that accept a \nDataset\n, but it is first converted to a \nDataset\n at each call. This means that you should first convert it yourself, using \nDataset(R)\n if you call functions like \ngeneralized_dim\n multiple times.\n\n\nThe functions \ndimension(R)\n and \ndelay(R)\n return \nD\n and \n\u03c4\n respectively. Notice that \nlength(R) = length(s) - (D-1)*\u03c4\n (i.e. the amount of D-dimensional points \"contained\" in \nR\n) but \nsize(R) = (length(R), D)\n.\n\n\n[1] : F. Takens, \nDetecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence\n, Lecture Notes in Mathematics \n366\n, Springer (1981)\n\n\n[2] : T. Sauer \net al.\n, J. Stat. Phys. \n65\n, pp 579 (1991)\n\n\nsource\n\n\n\n\nAs an example, let's pass a \nReconstruction\n into e.g. a method that calculates the attractor dimension:\n\n\nusing\n \nDynamicalSystems\n\n\nhe\n \n=\n \nSystems\n.\nhenon\n()\n\n\nts\n \n=\n \ntrajectory\n(\nhe\n,\n \n100000\n)\n\n\nD1\n \n=\n \ninformation_dim\n(\nts\n)\n \n# around 1.20\n\n\nx\n \n=\n \nts\n[\n:\n,\n \n1\n]\n \n# some \nrecorded\n timeseries\n\n\nR\n \n=\n \nreconstruct\n(\nx\n,\n \n2\n,\n \n1\n)\n \n# delay coords. reconstruction of dimension 2 and delay 1\n\n\nR\n[\n1\n]\n \n# first point of reconstruction, \u2261 (x[1], x[2])\n\n\nR\n[\n:\n,\n \n2\n]\n \n# Second COLUMN of the reconstruction, \u2261 x[2:end] since \u03c4=1\n\n\nD2\n \n=\n \ninformation_dim\n(\nR\n)\n \n#around 1.20\n\n\nprintln\n(\nD2 - D1 = \n$\n(\nabs\n(\nD2\n-\n \nD1\n))\n)\n\n\n# Prints something like 0.0032000971757613073\n\n\n\n\n\n\nThe 2 numbers \nD1\n and \nD2\n are \nvery close\n, but of course I knew before-hand good parameter values for \nD\n and \n\u03c4\n (I cheated, huhu!).\n\n\n\n\nEstimating Reconstruction Parameters\n\n\nThe following functions are provided estimate good values that can be used in \nreconstruct\n:\n\n\n#\n\n\nDynamicalSystems.estimate_delay\n \n \nFunction\n.\n\n\nestimate_delay(s) -\n \u03c4\n\n\n\n\n\nEstimate an optimal delay to be used in \nreconstruct\n, by performing an exponential fit to the \nabs.(c)\n with \nc\n the auto-correlation function of \ns\n. Return the exponential decay time \n\u03c4\n rounded to an integer.\n\n\nsource\n\n\n\n\nNumerical Lyapunov Estimation\n\n\nGiven any timeseries, one can first \nreconstruct\n it, and then calculate a maximum lyapunov exponent for it, provided that the system the timeseries was recorded from actually exhibits exponential separation of nearby trajectories. This is done with\n\n\n#\n\n\nDynamicalSystems.numericallyapunov\n \n \nFunction\n.\n\n\nnumericallyapunov\n(\nR\n::\nReconstruction\n,\n \nks\n;\n  \nrefstates\n,\n \ndistance\n,\n \nmethod\n)\n\n\n\n\n\n\nReturn \nE = [E(k) for k \u2208 ks]\n, where \nE(k)\n is the average logarithmic distance for nearby states that are evolved in time for \nk\n steps (\nk\n must be integer). If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold:\n\n\n\\[\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\\]\nfor a \nwell defined region\n in the \nk\n axis, where \n\\(\\lambda\\)\n is the approximated maximum Lyapunov exponent. \n\u0394t\n is the time between samples in the original timeseries. You can use \nlinear_region\n with arguments \n(ks, E)\n to identify the slope (= \n\\(\\lambda\\)\n) immediatelly, assuming you have choosen sufficiently good \nks\n such that the linear scaling region is bigger than the saturated region.\n\n\nThe algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index \nk\n increases. The average of the above over all neighborhood states over all reference states is the returned result.\n\n\nThe following keywords tune the algorithm behavior:\n\n\n\n\nrefstates::AbstractVector{Int} = 1:(length(R) - ks[end])\n : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in \nrefstates\n.\n\n\ndistance::Metric = Cityblock()\n : The distance function used in the logarithmic distance of nearby states. The allowed distances are \nCityblock()\n and \nEuclidean()\n. See below for more info on this choice which has fundamental impact on the algorithm.\n\n\nmethod::AbstractNeighborhood = FixedMassNeighborhood(1)\n : The method to be used when evaluating the neighborhood of each reference state. See \nAbstractNeighborhood\n for more info on this choice.\n\n\n\n\nIf the \nMetric\n is \nEuclidean()\n then calculate the Euclidean distance of the full \nD\n-dimensional points (distance \n\\(d_E\\)\n in ref. [1]). If however the \nMetric\n is \nCityblock()\n, calculate the absolute distance of \nonly the first elements\n of the \nm+k\n and \nn+k\n points of the reconstruction \nR\n, which are the \nm+k\n and \nn+k\n elements of vector \nR.s\n (distance \n\\(d_F\\)\n in ref. [1]). Notice that the distances used are defined in the package \nDistances.jl\n, but are re-exported in \nDynamicalSystems.jl\n for ease-of-use (the distances are used for dispatch purposes \nonly\n).\n\n\nThis function assumes that the Theiler window (see [1]) is the same as the delay time: \n\\(w  = \\tau\\)\n.\n\n\n[1] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 1 (section 1.3.2), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n[2] : Kantz, H., Phys. Lett. A \n185\n, pp 77\u201387 (1994)\n\n\nsource\n\n\n\n\n\n\nNeighborhoods\n\n\nThe function \nnumericallyapunov\n has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.\n\n\nThe methods for the neighborhoods are subtypes of \nAbstractNeighborhood\n, and offer a convenient way to find neighboring points to a given point in a dataset.\n\n\n#\n\n\nDynamicalSystems.AbstractNeighborhood\n \n \nType\n.\n\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\n\nConcrete subtypes:\n\n\n\n\nFixedMassNeighborhood(K::Int)\n  : The neighborhood of a point consists of the \nK\n nearest neighbors of the point.\n\n\nFixedSizeNeighborhood(\u03f5::Real)\n : The neighborhood of a point consists of all neighbors that have distance \n \n\u03f5\n from the point.\n\n\n\n\nNotice that these distances are always computed using the \nEuclidean()\n distance in \nD\n-dimensional space, irrespectively of the \ndistance\n used in the function \nnumericallyapunov\n.\n\n\nSee also \nneighborhood\n or \nnumericallyapunov\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.neighborhood\n \n \nFunction\n.\n\n\nneighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)\n\n\n\n\n\nReturn a vector of indices which are the neighborhood of \npoint\n, whose index in the original data is \nn\n. Both \npoint\n and \nn\n must be provided because the \ntree\n has indices in different sorting. The \nmethod\n can be a subtype of \nAbstractNeighborhood\n.\n\n\nFor example:\n\n\nR\n \n=\n \nsome_dataset\n\n\ntree\n \n=\n \nKDTree\n(\nR\n)\n\n\nneigh\n \n=\n \nneighborhood\n(\nn\n,\n \nR\n[\nn\n],\n \ntree\n,\n \nmethod\n)\n\n\n\n\n\n\nwhere \nR\n can be \neither\n a \nDataset\n or a \nReconstruction\n.\n\n\nNotice that the distances in the trees are always computed using the \nEuclidean()\n distance in \nD\n-dimensional space, irrespectively of the \ndistance\n used in the \nnumericallyapunov\n function.\n\n\nneighborhood\n \nsimply interfaces\n the functions \nknn\n and \ninrange\n from \nNearestNeighbors.jl\n by using the last argument, \nmethod\n.\n\n\nsource\n\n\n\n\nAs you can see, the function \nneighborhood\n is generally applicable!\n\n\n\n\nExample of Numerical Lyapunov computation\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\nks\n \n=\n \n1\n:\n20\n\n\n\u211c\n \n=\n \n1\n:\n10000\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n6\n))\n\n\ni\n \n=\n \n1\n\n\n\nfor\n \n(\ni\n,\n \ndi\n)\n \nin\n \nenumerate\n([\nEuclidean\n(),\n \nCityblock\n()])\n\n  \nsubplot\n(\n1\n,\n \n2\n,\n \ni\n)\n\n  \ni\n+=\n1\n\n  \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n)\n\n\n  \ntitle\n(\nDistance: \n$\n(\ndi\n)\n,\n \nsize\n \n=\n \n18\n)\n\n  \nfor\n \nD\n \nin\n \n[\n2\n,\n \n4\n,\n \n7\n]\n\n    \nR\n \n=\n \nreconstruct\n(\nx\n,\n \nD\n,\n \n1\n)\n\n    \nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n;\n\n    \nrefstates\n \n=\n \n\u211c\n,\n \ndistance\n \n=\n \ndi\n,\n \nmethod\n \n=\n \nmethod\n)\n\n    \n# The following operation:\n\n    \n\u0394t\n \n=\n \n1\n\n    \n\u03bb\n \n=\n \nlinear_region\n(\nks\n.*\n\u0394t\n,\n \nE\n)[\n2\n]\n\n    \n# gives the linear slope, i.e. the Lyapunov exponent\n\n    \nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$D\n, \u03bb=\n$\n(\nround\n(\n\u03bb\n,\n \n3\n))\n)\n\n    \nlegend\n()\n\n    \ntight_layout\n()\n\n  \nend\n\n\n\n\nend\n\n\n\n\n\n\nwhich gives the result \n\n\n\n\nBad Time-axis (\nks\n) length\n\n\n\n\nLarge \nks\n\n\nThis simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!\n\n\n\n\nLet's revisit the example of the previous section:\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\n\n\n\nThe timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following\n\n\nks\n \n=\n \n1\n:\n100\n\n\nR\n \n=\n \nreconstruct\n(\nx\n,\n \n2\n,\n \n1\n)\n\n\nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n,\n \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n))\n\n\nfigure\n()\n\n\nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n])\n\n\nprintln\n(\nLyappunov: \n,\n \nlinear_region\n(\nks\n,\n \nE\n)[\n2\n])\n\n\n\n\n\n\ngives this plot: \n and prints \"Lyapunov: 0.4161...\".\n\n\nNotice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function \nlinear_region\n would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)\n\n\n\n\nCase of a Continuous system\n\n\nThe process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n \n# Max lyapunov is around 0.90\n\n\n# create a timeseries of 1 dimension\n\n\ndt\n \n=\n \n0.05\n\n\nx\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n;\n \ndt\n \n=\n \ndt\n)[\n:\n,\n \n1\n]\n\n\n\n\u03c41\n \n=\n \nestimate_delay\n(\nx\n)\n \n#gives 7\n\n\n\n# Reconstruct it\n\n\nfigure\n()\n\n\nfor\n \nD\n \nin\n \n[\n4\n,\n \n8\n],\n \n\u03c4\n \nin\n \n[\n\u03c41\n,\n \n15\n]\n\n    \nR\n \n=\n \nreconstruct\n(\nx\n,\n \nD\n,\n \n\u03c4\n)\n\n\n    \n# I now know that I have to use much bigger ks than 1:20, because this is a\n\n    \n# continuous case! (See reference given in `numericallyapunovs`)\n\n    \nks1\n \n=\n \n0\n:\n200\n\n    \n# I also know that I do not need that dense computations, since 1 increment\n\n    \n# in k means increment of 0.05 real time\n\n    \nks2\n \n=\n \n0\n:\n4\n:\n200\n\n\n    \n# Calculate lyapunovs:\n\n    \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n5\n)\n \n#5 nearest neighbors of each state\n\n\n    \n# E1 = numericallyapunov(R, ks1; method = method)\n\n    \n# \u03bb1 = linear_region(ks1 .* dt, E1)[2]\n\n    \nE2\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks2\n;\n \nmethod\n \n=\n \nmethod\n)\n\n    \n\u03bb2\n \n=\n \nlinear_region\n(\nks2\n \n.*\n \ndt\n,\n \nE2\n)[\n2\n]\n\n\n\n    \n# plot(ks1,E1.-E1[1], label = \ndense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3))\n)\n\n    \nplot\n(\nks2\n,\nE2\n.-\nE2\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$\n(\nD\n)\n, \u03c4=\n$\n(\n\u03c4\n)\n, \u03bb=\n$\n(\nround\n(\n\u03bb2\n,\n \n3\n))\n)\n\n\nend\n\n\n\nlegend\n()\n\n\nxlabel\n(\nk (0.05\u00d7t)\n)\n\n\nylabel\n(\nE - E(0)\n)\n\n\ntitle\n(\nContinuous Reconstruction Lyapunov\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\nwhich produces: \n As you can see, using \n\\(\\tau = 15\\)\n makes almost no sense! The estimates with \n\u03c4 = 7\n though are very good (the actual value is around \n\u03bb \u2248 0.89...\n).", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/nlts/#nonlinear-timeseries-analysis", 
            "text": "", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/nlts/#delay-coordinates-reconstruction", 
            "text": "A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as  delay coordinates embedding .  In  DynamicalSystems.jl  this is done through the  reconstruct  interface:  #  DynamicalSystems.Reconstruction     Type .  Reconstruction{V, T, D, \u03c4}  : AbstractDataset{D}  D -dimensional reconstruction object with delay  \u03c4 , created from a vector  s::V .  s  is the only field of  Reconstruction .  The  n th row of this object is formally the  D -dimensional vector:  \\[\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\\] which is created only on demand. ( \\(s\\)  =  R.s  with  R  the  Reconstruction  object)  See  reconstruct  for usage.  source  #  DynamicalSystems.reconstruct     Function .  reconstruct(s::AbstractVector, D::Int, \u03c4::Int) -  R::Reconstruction  Create and return an efficient  Reconstruction  data structure that serves as the delay coordinates embedding [1, 2] reconstruction of the signal  s . The reconstuction has dimension  D  and delay  \u03c4  (measured in indices). This object can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper  D  and  \u03c4  [1, 2].  R  interfaces  s  and can be accessed similarly to a  Dataset :  R   =   reconstruct ( s ,   4 ,   1 )   # delay coords. reconstruction of dimension 4 and delay 1  R [ 3 ]   # third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])  R [ 1 ,   2 ]   # Second element of first point of reconstruction, \u2261 s[2]   (this is only smart indexing, no Vectors or SVectors are created during the construction of  R )  R  can also be given to all functions that accept a  Dataset , but it is first converted to a  Dataset  at each call. This means that you should first convert it yourself, using  Dataset(R)  if you call functions like  generalized_dim  multiple times.  The functions  dimension(R)  and  delay(R)  return  D  and  \u03c4  respectively. Notice that  length(R) = length(s) - (D-1)*\u03c4  (i.e. the amount of D-dimensional points \"contained\" in  R ) but  size(R) = (length(R), D) .  [1] : F. Takens,  Detecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence , Lecture Notes in Mathematics  366 , Springer (1981)  [2] : T. Sauer  et al. , J. Stat. Phys.  65 , pp 579 (1991)  source   As an example, let's pass a  Reconstruction  into e.g. a method that calculates the attractor dimension:  using   DynamicalSystems  he   =   Systems . henon ()  ts   =   trajectory ( he ,   100000 )  D1   =   information_dim ( ts )   # around 1.20  x   =   ts [ : ,   1 ]   # some  recorded  timeseries  R   =   reconstruct ( x ,   2 ,   1 )   # delay coords. reconstruction of dimension 2 and delay 1  R [ 1 ]   # first point of reconstruction, \u2261 (x[1], x[2])  R [ : ,   2 ]   # Second COLUMN of the reconstruction, \u2261 x[2:end] since \u03c4=1  D2   =   information_dim ( R )   #around 1.20  println ( D2 - D1 =  $ ( abs ( D2 -   D1 )) )  # Prints something like 0.0032000971757613073   The 2 numbers  D1  and  D2  are  very close , but of course I knew before-hand good parameter values for  D  and  \u03c4  (I cheated, huhu!).", 
            "title": "Delay Coordinates Reconstruction"
        }, 
        {
            "location": "/nlts/#estimating-reconstruction-parameters", 
            "text": "The following functions are provided estimate good values that can be used in  reconstruct :  #  DynamicalSystems.estimate_delay     Function .  estimate_delay(s) -  \u03c4  Estimate an optimal delay to be used in  reconstruct , by performing an exponential fit to the  abs.(c)  with  c  the auto-correlation function of  s . Return the exponential decay time  \u03c4  rounded to an integer.  source", 
            "title": "Estimating Reconstruction Parameters"
        }, 
        {
            "location": "/nlts/#numerical-lyapunov-estimation", 
            "text": "Given any timeseries, one can first  reconstruct  it, and then calculate a maximum lyapunov exponent for it, provided that the system the timeseries was recorded from actually exhibits exponential separation of nearby trajectories. This is done with  #  DynamicalSystems.numericallyapunov     Function .  numericallyapunov ( R :: Reconstruction ,   ks ;    refstates ,   distance ,   method )   Return  E = [E(k) for k \u2208 ks] , where  E(k)  is the average logarithmic distance for nearby states that are evolved in time for  k  steps ( k  must be integer). If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold:  \\[\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\\] for a  well defined region  in the  k  axis, where  \\(\\lambda\\)  is the approximated maximum Lyapunov exponent.  \u0394t  is the time between samples in the original timeseries. You can use  linear_region  with arguments  (ks, E)  to identify the slope (=  \\(\\lambda\\) ) immediatelly, assuming you have choosen sufficiently good  ks  such that the linear scaling region is bigger than the saturated region.  The algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index  k  increases. The average of the above over all neighborhood states over all reference states is the returned result.  The following keywords tune the algorithm behavior:   refstates::AbstractVector{Int} = 1:(length(R) - ks[end])  : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in  refstates .  distance::Metric = Cityblock()  : The distance function used in the logarithmic distance of nearby states. The allowed distances are  Cityblock()  and  Euclidean() . See below for more info on this choice which has fundamental impact on the algorithm.  method::AbstractNeighborhood = FixedMassNeighborhood(1)  : The method to be used when evaluating the neighborhood of each reference state. See  AbstractNeighborhood  for more info on this choice.   If the  Metric  is  Euclidean()  then calculate the Euclidean distance of the full  D -dimensional points (distance  \\(d_E\\)  in ref. [1]). If however the  Metric  is  Cityblock() , calculate the absolute distance of  only the first elements  of the  m+k  and  n+k  points of the reconstruction  R , which are the  m+k  and  n+k  elements of vector  R.s  (distance  \\(d_F\\)  in ref. [1]). Notice that the distances used are defined in the package  Distances.jl , but are re-exported in  DynamicalSystems.jl  for ease-of-use (the distances are used for dispatch purposes  only ).  This function assumes that the Theiler window (see [1]) is the same as the delay time:  \\(w  = \\tau\\) .  [1] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 1 (section 1.3.2), Lecture Notes in Physics  915 , Springer (2016)  [2] : Kantz, H., Phys. Lett. A  185 , pp 77\u201387 (1994)  source", 
            "title": "Numerical Lyapunov Estimation"
        }, 
        {
            "location": "/nlts/#neighborhoods", 
            "text": "The function  numericallyapunov  has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.  The methods for the neighborhoods are subtypes of  AbstractNeighborhood , and offer a convenient way to find neighboring points to a given point in a dataset.  #  DynamicalSystems.AbstractNeighborhood     Type .  Supertype of methods for deciding the neighborhood of points for a given point.  Concrete subtypes:   FixedMassNeighborhood(K::Int)   : The neighborhood of a point consists of the  K  nearest neighbors of the point.  FixedSizeNeighborhood(\u03f5::Real)  : The neighborhood of a point consists of all neighbors that have distance    \u03f5  from the point.   Notice that these distances are always computed using the  Euclidean()  distance in  D -dimensional space, irrespectively of the  distance  used in the function  numericallyapunov .  See also  neighborhood  or  numericallyapunov .  source  #  DynamicalSystems.neighborhood     Function .  neighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)  Return a vector of indices which are the neighborhood of  point , whose index in the original data is  n . Both  point  and  n  must be provided because the  tree  has indices in different sorting. The  method  can be a subtype of  AbstractNeighborhood .  For example:  R   =   some_dataset  tree   =   KDTree ( R )  neigh   =   neighborhood ( n ,   R [ n ],   tree ,   method )   where  R  can be  either  a  Dataset  or a  Reconstruction .  Notice that the distances in the trees are always computed using the  Euclidean()  distance in  D -dimensional space, irrespectively of the  distance  used in the  numericallyapunov  function.  neighborhood   simply interfaces  the functions  knn  and  inrange  from  NearestNeighbors.jl  by using the last argument,  method .  source   As you can see, the function  neighborhood  is generally applicable!", 
            "title": "Neighborhoods"
        }, 
        {
            "location": "/nlts/#example-of-numerical-lyapunov-computation", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]  ks   =   1 : 20  \u211c   =   1 : 10000  fig   =   figure ( figsize = ( 10 , 6 ))  i   =   1  for   ( i ,   di )   in   enumerate ([ Euclidean (),   Cityblock ()]) \n   subplot ( 1 ,   2 ,   i ) \n   i += 1 \n   method   =   FixedMassNeighborhood ( 2 ) \n\n   title ( Distance:  $ ( di ) ,   size   =   18 ) \n   for   D   in   [ 2 ,   4 ,   7 ] \n     R   =   reconstruct ( x ,   D ,   1 ) \n     E   =   numericallyapunov ( R ,   ks ; \n     refstates   =   \u211c ,   distance   =   di ,   method   =   method ) \n     # The following operation: \n     \u0394t   =   1 \n     \u03bb   =   linear_region ( ks .* \u0394t ,   E )[ 2 ] \n     # gives the linear slope, i.e. the Lyapunov exponent \n     plot ( ks - 1 ,   E - E [ 1 ],   label   =   D= $D , \u03bb= $ ( round ( \u03bb ,   3 )) ) \n     legend () \n     tight_layout () \n   end  end   which gives the result", 
            "title": "Example of Numerical Lyapunov computation"
        }, 
        {
            "location": "/nlts/#bad-time-axis-ks-length", 
            "text": "Large  ks  This simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!   Let's revisit the example of the previous section:  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   The timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following  ks   =   1 : 100  R   =   reconstruct ( x ,   2 ,   1 )  E   =   numericallyapunov ( R ,   ks ,   method   =   FixedMassNeighborhood ( 2 ))  figure ()  plot ( ks - 1 ,   E - E [ 1 ])  println ( Lyappunov:  ,   linear_region ( ks ,   E )[ 2 ])   gives this plot:   and prints \"Lyapunov: 0.4161...\".  Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function  linear_region  would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)", 
            "title": "Bad Time-axis (ks) length"
        }, 
        {
            "location": "/nlts/#case-of-a-continuous-system", 
            "text": "The process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . lorenz ()   # Max lyapunov is around 0.90  # create a timeseries of 1 dimension  dt   =   0.05  x   =   trajectory ( ds ,   1000.0 ;   dt   =   dt )[ : ,   1 ]  \u03c41   =   estimate_delay ( x )   #gives 7  # Reconstruct it  figure ()  for   D   in   [ 4 ,   8 ],   \u03c4   in   [ \u03c41 ,   15 ] \n     R   =   reconstruct ( x ,   D ,   \u03c4 ) \n\n     # I now know that I have to use much bigger ks than 1:20, because this is a \n     # continuous case! (See reference given in `numericallyapunovs`) \n     ks1   =   0 : 200 \n     # I also know that I do not need that dense computations, since 1 increment \n     # in k means increment of 0.05 real time \n     ks2   =   0 : 4 : 200 \n\n     # Calculate lyapunovs: \n     method   =   FixedMassNeighborhood ( 5 )   #5 nearest neighbors of each state \n\n     # E1 = numericallyapunov(R, ks1; method = method) \n     # \u03bb1 = linear_region(ks1 .* dt, E1)[2] \n     E2   =   numericallyapunov ( R ,   ks2 ;   method   =   method ) \n     \u03bb2   =   linear_region ( ks2   .*   dt ,   E2 )[ 2 ] \n\n\n     # plot(ks1,E1.-E1[1], label =  dense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3)) ) \n     plot ( ks2 , E2 .- E2 [ 1 ],   label   =   D= $ ( D ) , \u03c4= $ ( \u03c4 ) , \u03bb= $ ( round ( \u03bb2 ,   3 )) )  end  legend ()  xlabel ( k (0.05\u00d7t) )  ylabel ( E - E(0) )  title ( Continuous Reconstruction Lyapunov )  tight_layout ()   which produces:   As you can see, using  \\(\\tau = 15\\)  makes almost no sense! The estimates with  \u03c4 = 7  though are very good (the actual value is around  \u03bb \u2248 0.89... ).", 
            "title": "Case of a Continuous system"
        }, 
        {
            "location": "/periodicity/", 
            "text": "Detecting Stable and Unstable Periodic Orbits of Maps\n\n\nChaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the \nunstable periodic orbits\n existing in the chaotic sea.\n\n\nFinding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes \nimpossible\n for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher \n Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at \nunstable\n ones.\n\n\nThe functions \nperiodicorbits\n and \nlambdamatrix\n implement the algorithm:\n\n\n#\n\n\nDynamicalSystems.periodicorbits\n \n \nFunction\n.\n\n\nperiodicorbits\n(\nds\n::\nDiscreteDS\n,\n \no\n,\n \nics\n \n[\n,\n \n\u03bb\ns\n,\n \nindss\n,\n \nsingss\n]\n \n;\n \nkwargs\n...)\n \n-\n \nFP\n\n\n\n\n\n\nFind stable and unstable fixed points \nFP\n the system \nds\n of order \no\n using the algorithm due to Schmelcher \n Diakonos [1], which turns unstable fixed points of the original map to dissipatively stable through the transformation:\n\n\n\\[\n\\mathbf{x}_{n+1} = S_k(\\mathbf{x}_n) = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(\\mathbf{f}^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\\]\nwith \n\\(\\mathbf{f}\\)\n = \nds.eom\n. \nics\n is a collection of initial conditions (container of \nSVector\ns) to be evolved.\n\n\nThe optional arguments \n\u03bbs, indss, singss\n \nmust be containers\n of appropriate values, besides \n\u03bbs\n which can also be a number. The elements of those lists are passed to: \nlambdamatrix(\u03bb, inds, sings)\n, which creates the appropriate \n\\(\\mathbf{\\Lambda}_k\\)\n matrix (see \nlambdamatrix\n for more). If these arguments are not given, a random permutation will be chosen for them, with \n\u03bb=0.001\n.\n\n\nAll initial conditions are evolved for all\n \n\\(\\mathbf{\\Lambda}_k\\)\n which can very quickly lead to long computation times, so be wise on your choice of \n\u03bbs, indss, singss\n!\n\n\nThe following \nkeyword\n arguments fine-tune the algorithm convergence and output (i.c. stands for initial condition):\n\n\n\n\nmaxiters::Int = 100000\n : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\n\n\ndisttol = 1e-10\n : Distance tolerance. If the 2-norm of a previous state with  the next one is \n\u2264 disttol\n then it has converged to a fixed point.\n\n\ninftol = 10.0\n : If a state reaches \nnorm(state) \u2265 inftol\n it is assumed that  it has escaped to infinity (and is thus abandoned).\n\n\nroundtol::Int = 4\n : The found fixed points are rounded  to \nroundtol\n digits before pushed into the list of returned fixed points \nFP\n,  \nif\n they are not already contained in \nFP\n.  This is done so that \nFP\n doesn't contain duplicate fixed points (notice  that this has nothing to do with \ndisttol\n). Turn this to \n16\n to get the full  precision of the algorithm.\n\n\n\n\n[1] : P. Schmelcher \n F. K. Diakonos, Phys. Rev. Lett. \n78\n, pp 4733 (1997)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.lambdamatrix\n \n \nFunction\n.\n\n\nlambdamatrix(\u03bb, inds::Vector{Int}, sings) -\n \u039bk\n\n\n\n\n\nReturn the matrix \n\\(\\mathbf{\\Lambda}_k\\)\n used to create a new dynamical system with some unstable fixed points turned to stable (see \nperiodicorbits\n).\n\n\nArguments:\n\n\n\n\n\u03bb\n:Real\n : the multiplier of the \n\\(C_k\\)\n matrix, with \n0\n\u03bb\n1\n.\n\n\ninds::Vector{Int}\n : The \ni\nth entry of this vector gives the \nrow\n of the nonzero element of the \ni\nth column of \n\\(C_k\\)\n. Each element of \ninds\n \nmust be unique\n such that the resulting matrix is orthogonal \nand\n represents the group of special reflections and permutations.\n\n\nsings::Vector{\n:Real}\n : The element of the \ni\nth column of \n\\(C_k\\)\n is +1 if \nsigns[i] \n 0\n and -1 otherwise (\nsings\n can also be \nBool\n vector).\n\n\n\n\nDeciding the appropriate values for \n\u03bb, inds, sings\n is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for \n\u03bb\n, one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.\n\n\nlambdamatrix(\u03bb, D::Integer)\n\n\n\n\n\nCreate a random \n\\(\\mathbf{\\Lambda}_k\\)\n by randomly generating an \ninds\n and a \nsigns\n from all possible combinations. The \ncollections\n of all these combinations can be obtained by:\n\n\nindperms\n,\n \nsignperms\n \n=\n \nlambdaperms\n(\nD\n)\n\n\n\n\n\n\n[2] : D. Pingel \net al.\n, Phys. Rev. E \n62\n, pp 2119 (2000)\n\n\n[3] : F. K. Diakonos \net al.\n, Phys. Rev. Lett. \n81\n, pp 4349 (1998)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.lambdaperms\n \n \nFunction\n.\n\n\nlambdaperms(D) -\n indperms, singperms\n\n\n\n\n\nReturn two collections that each contain all possible combinations of indices (total of \n\\(D!\\)\n) and signs (total of \n\\(2^D\\)\n) for dimension \nD\n (see \nlambdamatrix\n).\n\n\nsource\n\n\n\n\n\n\nStandard Map example\n\n\nFor example, let's find the fixed points of the \nStandard Map\n of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the \nsigns\n but only one for the \ninds\n. We will also only use one \n\u03bb\n value, and a 21\u00d721 density of initial conditions:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\nxs\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \n21\n);\n \nys\n \n=\n \ncopy\n(\nxs\n)\n\n\nics\n \n=\n \n[\nSVector\n{\n2\n}(\nx\n,\ny\n)\n \nfor\n \nx\n \nin\n \nxs\n \nfor\n \ny\n \nin\n \nys\n]\n\n\n\n# All permutations of [\u00b11, \u00b11]:\n\n\nsingss\n \n=\n \nlambdaperms\n(\n2\n)[\n2\n]\n \n# second entry are the signs\n\n\n\n# I know from personal research I only need this `inds`:\n\n\nindss\n \n=\n \n[[\n1\n,\n2\n]]\n \n# \n- must be container of vectors!!!\n\n\n\n\u03bbs\n \n=\n \n0.005\n \n# \n- only this allowed to not be vector (could also be vector)\n\n\n\norders\n \n=\n \n[\n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n,\n \n8\n]\n\n\nALLFP\n \n=\n \nVector\n{\nSVector\n{\n2\n,\n \nFloat64\n}}[]\n\n\n\nttt\n \n=\n \ntime\n()\n\n\nfor\n \no\n \nin\n \norders\n\n    \nFP\n \n=\n \nperiodicorbits\n(\nds\n,\n \no\n,\n \nics\n,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n)\n\n    \npush!\n(\nALLFP\n,\n \nFP\n)\n\n\nend\n\n\nprintln\n(\nTotal time: \n$\n((\ntime\n()\n \n-\n \nttt\n)\n/\n60\n)\n mins.\n)\n\n\n# It takes a good 3-5 minutes to do all computations!\n\n\n\n\n# Create phase-space plot:\n\n\niters\n \n=\n \n1000\n\n\ndataset\n \n=\n \ntrajectory\n(\nds\n,\n \niters\n)\n\n\nfor\n \nx\n \nin\n \nxs\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\nx\n,\n \ny\n)\n\n        \nappend!\n(\ndataset\n,\n \ntrajectory\n(\nds\n,\n \niters\n))\n\n    \nend\n\n\nend\n\n\nm\n \n=\n \nMatrix\n(\ndataset\n)\n\n\nPyPlot\n.\nscatter\n(\nview\n(\nm\n,\n \n:\n,\n \n1\n),\n \nview\n(\nm\n,\n \n:\n,\n \n2\n),\n \ns\n=\n \n1\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nPyPlot\n.\nxlim\n(\nxs\n[\n1\n],\n \nxs\n[\nend\n])\n\n\nPyPlot\n.\nylim\n(\nys\n[\n1\n],\n \nys\n[\nend\n])\n\n\n\n# Plot fixed points:\n\n\nmarkers\n \n=\n \n[\nD\n,\n \n^\n,\n \ns\n,\n \np\n,\n \nh\n,\n \n8\n]\n\n\ncolors\n \n=\n \n[\nb\n,\n \ng\n,\n \nr\n,\n \nc\n,\n \nm\n,\n \ngrey\n]\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n6\n\n    \nFP\n \n=\n \nALLFP\n[\ni\n]\n\n    \no\n \n=\n \norders\n[\ni\n]\n\n    \nPyPlot\n.\nplot\n([\ns\n[\n1\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n \n[\ns\n[\n2\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n\n    \nmarker\n=\nmarkers\n[\ni\n],\n \ncolor\n \n=\n \ncolors\n[\ni\n],\n \nmarkersize\n=\n10.0\n \n+\n \n(\n8\n-\no\n),\n \nlinewidth\n=\n0.0\n,\n\n    \nlabel\n \n=\n \norder \n$o\n,\n \nmarkeredgecolor\n \n=\n \nyellow\n,\n \nmarkeredgewidth\n \n=\n \n0.5\n)\n\n\nend\n\n\nlegend\n(\nloc\n=\nupper right\n,\n \nframealpha\n=\n0.9\n)\n\n\nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n\nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\nAfter 3 to 5 minutes, you will get this plot: \n\n\nYou can confirm for yourself that this is correct, for many reasons:\n\n\n\n\nIt is the same \nfig. 12 of this publication\n.\n\n\nFixed points of order \n\\(n\\)\n are also fixed points of order \n\\(2n, 3n, 4n, ...\\)\n\n\nBesides fixed points of previous orders, \noriginal\n fixed points of order \n\\(n\\)\n come in \n\\(2n\\)\n-sized pairs (see e.g. order 5). This is correct because in a conservative map the fixed points must be pairs of elliptic-hyperbolic.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/periodicity/#detecting-stable-and-unstable-periodic-orbits-of-maps", 
            "text": "Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the  unstable periodic orbits  existing in the chaotic sea.  Finding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes  impossible  for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher   Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at  unstable  ones.  The functions  periodicorbits  and  lambdamatrix  implement the algorithm:  #  DynamicalSystems.periodicorbits     Function .  periodicorbits ( ds :: DiscreteDS ,   o ,   ics   [ ,   \u03bb s ,   indss ,   singss ]   ;   kwargs ...)   -   FP   Find stable and unstable fixed points  FP  the system  ds  of order  o  using the algorithm due to Schmelcher   Diakonos [1], which turns unstable fixed points of the original map to dissipatively stable through the transformation:  \\[\n\\mathbf{x}_{n+1} = S_k(\\mathbf{x}_n) = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(\\mathbf{f}^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\\] with  \\(\\mathbf{f}\\)  =  ds.eom .  ics  is a collection of initial conditions (container of  SVector s) to be evolved.  The optional arguments  \u03bbs, indss, singss   must be containers  of appropriate values, besides  \u03bbs  which can also be a number. The elements of those lists are passed to:  lambdamatrix(\u03bb, inds, sings) , which creates the appropriate  \\(\\mathbf{\\Lambda}_k\\)  matrix (see  lambdamatrix  for more). If these arguments are not given, a random permutation will be chosen for them, with  \u03bb=0.001 .  All initial conditions are evolved for all   \\(\\mathbf{\\Lambda}_k\\)  which can very quickly lead to long computation times, so be wise on your choice of  \u03bbs, indss, singss !  The following  keyword  arguments fine-tune the algorithm convergence and output (i.c. stands for initial condition):   maxiters::Int = 100000  : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.  disttol = 1e-10  : Distance tolerance. If the 2-norm of a previous state with  the next one is  \u2264 disttol  then it has converged to a fixed point.  inftol = 10.0  : If a state reaches  norm(state) \u2265 inftol  it is assumed that  it has escaped to infinity (and is thus abandoned).  roundtol::Int = 4  : The found fixed points are rounded  to  roundtol  digits before pushed into the list of returned fixed points  FP ,   if  they are not already contained in  FP .  This is done so that  FP  doesn't contain duplicate fixed points (notice  that this has nothing to do with  disttol ). Turn this to  16  to get the full  precision of the algorithm.   [1] : P. Schmelcher   F. K. Diakonos, Phys. Rev. Lett.  78 , pp 4733 (1997)  source  #  DynamicalSystems.lambdamatrix     Function .  lambdamatrix(\u03bb, inds::Vector{Int}, sings) -  \u039bk  Return the matrix  \\(\\mathbf{\\Lambda}_k\\)  used to create a new dynamical system with some unstable fixed points turned to stable (see  periodicorbits ).  Arguments:   \u03bb :Real  : the multiplier of the  \\(C_k\\)  matrix, with  0 \u03bb 1 .  inds::Vector{Int}  : The  i th entry of this vector gives the  row  of the nonzero element of the  i th column of  \\(C_k\\) . Each element of  inds   must be unique  such that the resulting matrix is orthogonal  and  represents the group of special reflections and permutations.  sings::Vector{ :Real}  : The element of the  i th column of  \\(C_k\\)  is +1 if  signs[i]   0  and -1 otherwise ( sings  can also be  Bool  vector).   Deciding the appropriate values for  \u03bb, inds, sings  is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for  \u03bb , one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.  lambdamatrix(\u03bb, D::Integer)  Create a random  \\(\\mathbf{\\Lambda}_k\\)  by randomly generating an  inds  and a  signs  from all possible combinations. The  collections  of all these combinations can be obtained by:  indperms ,   signperms   =   lambdaperms ( D )   [2] : D. Pingel  et al. , Phys. Rev. E  62 , pp 2119 (2000)  [3] : F. K. Diakonos  et al. , Phys. Rev. Lett.  81 , pp 4349 (1998)  source  #  DynamicalSystems.lambdaperms     Function .  lambdaperms(D) -  indperms, singperms  Return two collections that each contain all possible combinations of indices (total of  \\(D!\\) ) and signs (total of  \\(2^D\\) ) for dimension  D  (see  lambdamatrix ).  source", 
            "title": "Detecting Stable and Unstable Periodic Orbits of Maps"
        }, 
        {
            "location": "/periodicity/#standard-map-example", 
            "text": "For example, let's find the fixed points of the  Standard Map  of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the  signs  but only one for the  inds . We will also only use one  \u03bb  value, and a 21\u00d721 density of initial conditions:  using   DynamicalSystems ,   PyPlot ,   StaticArrays  ds   =   Systems . standardmap ()  xs   =   linspace ( 0 ,   2 \u03c0 ,   21 );   ys   =   copy ( xs )  ics   =   [ SVector { 2 }( x , y )   for   x   in   xs   for   y   in   ys ]  # All permutations of [\u00b11, \u00b11]:  singss   =   lambdaperms ( 2 )[ 2 ]   # second entry are the signs  # I know from personal research I only need this `inds`:  indss   =   [[ 1 , 2 ]]   #  - must be container of vectors!!!  \u03bbs   =   0.005   #  - only this allowed to not be vector (could also be vector)  orders   =   [ 2 ,   3 ,   4 ,   5 ,   6 ,   8 ]  ALLFP   =   Vector { SVector { 2 ,   Float64 }}[]  ttt   =   time ()  for   o   in   orders \n     FP   =   periodicorbits ( ds ,   o ,   ics ,   \u03bbs ,   indss ,   singss ) \n     push! ( ALLFP ,   FP )  end  println ( Total time:  $ (( time ()   -   ttt ) / 60 )  mins. )  # It takes a good 3-5 minutes to do all computations!  # Create phase-space plot:  iters   =   1000  dataset   =   trajectory ( ds ,   iters )  for   x   in   xs \n     for   y   in   ys \n         ds . state   =   SVector { 2 }( x ,   y ) \n         append! ( dataset ,   trajectory ( ds ,   iters )) \n     end  end  m   =   Matrix ( dataset )  PyPlot . scatter ( view ( m ,   : ,   1 ),   view ( m ,   : ,   2 ),   s =   1 ,   color   =   black )  PyPlot . xlim ( xs [ 1 ],   xs [ end ])  PyPlot . ylim ( ys [ 1 ],   ys [ end ])  # Plot fixed points:  markers   =   [ D ,   ^ ,   s ,   p ,   h ,   8 ]  colors   =   [ b ,   g ,   r ,   c ,   m ,   grey ]  for   i   in   1 : 6 \n     FP   =   ALLFP [ i ] \n     o   =   orders [ i ] \n     PyPlot . plot ([ s [ 1 ]   for   s   in   FP ],   [ s [ 2 ]   for   s   in   FP ], \n     marker = markers [ i ],   color   =   colors [ i ],   markersize = 10.0   +   ( 8 - o ),   linewidth = 0.0 , \n     label   =   order  $o ,   markeredgecolor   =   yellow ,   markeredgewidth   =   0.5 )  end  legend ( loc = upper right ,   framealpha = 0.9 )  xlabel ( \\$\\\\ theta \\$ )  ylabel ( \\$ p \\$ )   After 3 to 5 minutes, you will get this plot:   You can confirm for yourself that this is correct, for many reasons:   It is the same  fig. 12 of this publication .  Fixed points of order  \\(n\\)  are also fixed points of order  \\(2n, 3n, 4n, ...\\)  Besides fixed points of previous orders,  original  fixed points of order  \\(n\\)  come in  \\(2n\\) -sized pairs (see e.g. order 5). This is correct because in a conservative map the fixed points must be pairs of elliptic-hyperbolic.", 
            "title": "Standard Map example"
        }, 
        {
            "location": "/contributors_guide/", 
            "text": "Contributor Guide\n\n\nYou can contribute to this package even if you are not familiar with Julia or coding.\n\n\nThe ultimate goal for \nDynamicalSystems.jl\n is to be a useful tool for scientists working on chaos \n nonlinear dynamics and in general dynamical systems.\n\n\nFor such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!\n\n\nFor a something to be implemented in this package, the following steps have to happen:\n\n\n\n\nA suggestion that a method should be included\n has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.\n\n\nAn algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.\n\n\nThe source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the \nreliability of the implementation\n.\n\n\n\n\nIt is clear that one can contribute to \nDynamicalSystems.jl\n by contributing in steps (1) and (2). Neither of those require any knowledge of coding with Julia.\n\n\nFor step (1), you can open a new issue at the \nDynamicalSystems.jl Issues\n page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features \nhere\n and see for yourself if you can contribute to some of them!\n\n\nOf course, you can always contribute in the enhancement of the existing package by solving the some of the existing issues.\n\n\nIf you have any idea about how to improve this package please do not hesitate to \njoin our chatroom\n and share your ideas!\n\n\nDon't forget; you always help this package simply by \nusing it\n and reporting any unexpected behavior! So far we had very few testers and tested on a small subset of dynamical systems! Thus any extra testing is welcomed!\n\n\n\n\nExamples of new things you could contribute\n\n\n\n\nAny method that calculates a quantity that has been used in at least one scientific (and peer-reviewed) journal.\n\n\nAny kind of new \nType\n of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of \nDynamicalSystem\n. I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.\n\n\nAny kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the \nfamous_systems.jl\n file).\n\n\n\n\nNotice that the above are not conclusive, but only examples!\n\n\n\n\nHow you should contribute \ncode\n\n\n\n\nFor new methods and systems please always have very clear and self-contained documentation strings.\n\n\nHave enough comments in your code so that somebody that knows the method, can also understand the code immediately.\n\n\nAlways have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.\n\n\nIf you are adding a new system type accompanied by new methods and quantities, please introduce a new file in the \n/src\n folder, or even better create your own subfolder, instead of adding code to the existing files.\n\n\n\n\nWhen enhancing already existing code, make sure to:\n\n\n\n\nHave enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributor-guide", 
            "text": "You can contribute to this package even if you are not familiar with Julia or coding.  The ultimate goal for  DynamicalSystems.jl  is to be a useful tool for scientists working on chaos   nonlinear dynamics and in general dynamical systems.  For such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!  For a something to be implemented in this package, the following steps have to happen:   A suggestion that a method should be included  has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.  An algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.  The source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the  reliability of the implementation .   It is clear that one can contribute to  DynamicalSystems.jl  by contributing in steps (1) and (2). Neither of those require any knowledge of coding with Julia.  For step (1), you can open a new issue at the  DynamicalSystems.jl Issues  page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features  here  and see for yourself if you can contribute to some of them!  Of course, you can always contribute in the enhancement of the existing package by solving the some of the existing issues.  If you have any idea about how to improve this package please do not hesitate to  join our chatroom  and share your ideas!  Don't forget; you always help this package simply by  using it  and reporting any unexpected behavior! So far we had very few testers and tested on a small subset of dynamical systems! Thus any extra testing is welcomed!", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#examples-of-new-things-you-could-contribute", 
            "text": "Any method that calculates a quantity that has been used in at least one scientific (and peer-reviewed) journal.  Any kind of new  Type  of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of  DynamicalSystem . I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.  Any kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the  famous_systems.jl  file).   Notice that the above are not conclusive, but only examples!", 
            "title": "Examples of new things you could contribute"
        }, 
        {
            "location": "/contributors_guide/#how-you-should-contribute-code", 
            "text": "For new methods and systems please always have very clear and self-contained documentation strings.  Have enough comments in your code so that somebody that knows the method, can also understand the code immediately.  Always have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.  If you are adding a new system type accompanied by new methods and quantities, please introduce a new file in the  /src  folder, or even better create your own subfolder, instead of adding code to the existing files.   When enhancing already existing code, make sure to:   Have enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "How you should contribute code"
        }
    ]
}