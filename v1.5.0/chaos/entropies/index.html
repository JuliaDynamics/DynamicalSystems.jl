<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Entropies and Dimensions · DynamicalSystems.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DynamicalSystems.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DynamicalSystems.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../contents/">Contents</a></li><li><a class="tocitem" href="../../ds/general/">Dynamical System Definition</a></li><li><a class="tocitem" href="../../ds/predefined/">Predefined Dynamical Systems</a></li><li><a class="tocitem" href="../../embedding/dataset/">Numerical Data</a></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">DelayEmbeddings</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../embedding/reconstruction/">Delay Coordinates Embedding</a></li><li><a class="tocitem" href="../../embedding/estimate/">Optimal DCE Parameters</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox" checked/><label class="tocitem" for="menuitem-7"><span class="docs-label">ChaosTools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../orbitdiagram/">Orbit Diagrams &amp; PSOS</a></li><li><a class="tocitem" href="../lyapunovs/">Lyapunov Exponents</a></li><li><a class="tocitem" href="../chaos_detection/">Detecting &amp; Categorizing Chaos</a></li><li class="is-active"><a class="tocitem" href>Entropies and Dimensions</a><ul class="internal"><li><a class="tocitem" href="#Generalized-Entropy-1"><span>Generalized Entropy</span></a></li><li><a class="tocitem" href="#Generalized-Dimension-Estimation-1"><span>Generalized Dimension Estimation</span></a></li><li><a class="tocitem" href="#Correlation-sum-(Grassberger-Proccacia)-1"><span>Correlation sum (Grassberger-Proccacia)</span></a></li><li><a class="tocitem" href="#Permutation-Entropy-1"><span>Permutation Entropy</span></a></li><li><a class="tocitem" href="#Kaplan-Yorke-Dimension-1"><span>Kaplan-Yorke Dimension</span></a></li></ul></li><li><a class="tocitem" href="../nlts/">Nonlinear Timeseries Analysis</a></li><li><a class="tocitem" href="../periodicity/">Periodicity &amp; Ergodicity</a></li><li><a class="tocitem" href="../choosing/">Choosing a solver</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">RecurrenceAnalysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../rqa/rplots/">Recurrence Plots</a></li><li><a class="tocitem" href="../../rqa/quantification/">Recurrence Quantification Analysis</a></li><li><a class="tocitem" href="../../rqa/windowed/">Windowed RQA</a></li></ul></li><li><a class="tocitem" href="../../advanced/">Advanced Documentation</a></li><li><a class="tocitem" href="../../contributors_guide/">Contributor Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">ChaosTools</a></li><li class="is-active"><a href>Entropies and Dimensions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Entropies and Dimensions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/DynamicalSystems.jl/blob/master/docs/src/chaos/entropies.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Entropies-and-Dimensions-1"><a class="docs-heading-anchor" href="#Entropies-and-Dimensions-1">Entropies and Dimensions</a><a class="docs-heading-anchor-permalink" href="#Entropies-and-Dimensions-1" title="Permalink"></a></h1><h2 id="Generalized-Entropy-1"><a class="docs-heading-anchor" href="#Generalized-Entropy-1">Generalized Entropy</a><a class="docs-heading-anchor-permalink" href="#Generalized-Entropy-1" title="Permalink"></a></h2><p>In the study of dynamical systems there are many quantities that identify as &quot;entropy&quot;. Notice that these quantities are not the more commonly known <a href="https://en.wikipedia.org/wiki/Entropy">thermodynamic ones</a>, used in Statistical Physics. Rather, they are more like the to the entropies of <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">information theory</a>, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.</p><hr/><p>One way of computing entropies in <strong>DynamicalSystems.jl</strong> is the &quot;generalized entropy&quot;:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.genentropy" href="#ChaosTools.genentropy"><code>ChaosTools.genentropy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">genentropy(α, ε::Real, dataset::AbstractDataset; base = Base.MathConstants.e)</code></pre><p>Compute the <code>α</code> order generalized (Rényi) entropy<sup class="footnote-reference"><a id="citeref-Rényi1960" href="#footnote-Rényi1960">[Rényi1960]</a></sup> of a dataset, by first partitioning it into boxes of length <code>ε</code> using <a href="#ChaosTools.non0hist"><code>non0hist</code></a>.</p><pre><code class="language-none">genentropy(α, εs::AbstractVector, dataset::AbstractDataset; base = Base.MathConstants.e)</code></pre><p>Same as <code>[genentropy(α, ε, dataset) for ε in εs]</code>.</p><pre><code class="language-none">genentropy(α, p::AbstractArray; base = Base.MathConstants.e)</code></pre><p>Compute the entropy of an array of probabilities <code>p</code>, assuming that <code>p</code> is sum-normalized.</p><p>Optionally use <code>base</code> for the logarithms.</p><p><strong>Description</strong></p><p>Let <span>$p$</span> be an array of probabilities (summing to 1). Then the Rényi entropy is</p><div>\[H_\alpha(p) = \frac{1}{1-\alpha} \log \left(\sum_i p[i]^\alpha\right)\]</div><p>and generalizes other known entropies, like e.g. the information entropy (<span>$\alpha = 1$</span>, see <sup class="footnote-reference"><a id="citeref-Shannon1948" href="#footnote-Shannon1948">[Shannon1948]</a></sup>), the maximum entropy (<span>$\alpha=0$</span>, also known as Hartley entropy), or the correlation entropy (<span>$\alpha = 2$</span>, also known as collision entropy).</p></div></section></article><hr/><p>Basically, given a <a href="../../embedding/dataset/#DelayEmbeddings.Dataset"><code>Dataset</code></a> you can partition it into boxes to calculate an entropy. See below for a detailed example.</p><div class="admonition is-success"><header class="admonition-header">Worried about memory overflow? Don&#39;t be!</header><div class="admonition-body"><p>Partitioning the dataset (i.e. doing a <em>histogram</em>) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size <code>ε</code>.</p><p>However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!</p></div></div><p>The function used internally by <code>genentropy</code> is <code>non0hist</code>:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.non0hist" href="#ChaosTools.non0hist"><code>ChaosTools.non0hist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">non0hist(ε, dataset::AbstractDataset) → p</code></pre><p>Partition a dataset into tabulated intervals (boxes) of size <code>ε</code> and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements and bin edge information.</p><p><strong>Performances Notes</strong></p><p>This method has a linearithmic time complexity (<code>n log(n)</code> for <code>n = length(data)</code>) and a linear space complexity (<code>l</code> for <code>l = dimension(data)</code>). This allows computation of histograms of high-dimensional datasets and with small box sizes <code>ε</code> without memory overflow and with maximum performance.</p><p>Use <a href="#ChaosTools.binhist"><code>binhist</code></a> to retain bin edge information.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.binhist" href="#ChaosTools.binhist"><code>ChaosTools.binhist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">binhist(ε, data) → p, bins</code></pre><p>Do the same as <a href="#ChaosTools.non0hist"><code>non0hist</code></a> but also return the bin edge information.</p></div></section></article><hr/><h2 id="Generalized-Dimension-Estimation-1"><a class="docs-heading-anchor" href="#Generalized-Dimension-Estimation-1">Generalized Dimension Estimation</a><a class="docs-heading-anchor-permalink" href="#Generalized-Dimension-Estimation-1" title="Permalink"></a></h2><p>There are numerous methods that one can use to calculate a so-called &quot;dimension&quot; of a dataset, like for example the <a href="https://en.wikipedia.org/wiki/Fractal_dimension">Fractal dimension</a>. This real number can offer a lot of information about the object that the dataset represents.</p><p>Based on the definition of the <a href="#ChaosTools.genentropy">generalized entropy</a>, one can calculate an appropriate dimension, called <em>generalized dimension</em>:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.generalized_dim" href="#ChaosTools.generalized_dim"><code>ChaosTools.generalized_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">generalized_dim(α, dataset [, sizes]) -&gt; D_α</code></pre><p>Return the <code>α</code> order generalized dimension of the <code>dataset</code>, by calculating the <a href="#ChaosTools.genentropy"><code>genentropy</code></a> for each <code>ε ∈ sizes</code>.</p><p><strong>Description</strong></p><p>The returned dimension is approximated by the (inverse) power law exponent of the scaling of the <a href="#ChaosTools.genentropy"><code>genentropy</code></a> versus the box size <code>ε</code>, where <code>ε ∈ sizes</code>.</p><p>Calling this function performs a lot of automated steps:</p><ol><li>A vector of box sizes is decided by calling <code>sizes = estimate_boxsizes(dataset)</code>, if <code>sizes</code> is not given.</li><li>For each element of <code>sizes</code> the appropriate entropy is calculated, through <code>d = genentropy.(α, sizes, dataset)</code>. Let <code>x = -log.(sizes)</code>.</li><li>The curve <code>d(x)</code> is decomposed into linear regions, using <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a><code>(x, d)</code>.</li><li>The biggest linear region is chosen, and a fit for the slope of that region is performed using the function <a href="#ChaosTools.linear_region"><code>linear_region</code></a>. This slope is the return value of <code>generalized_dim</code>.</li></ol><p>By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.</p><p>The following aliases are provided:</p><ul><li>α = 0 : <code>boxcounting_dim</code>, <code>capacity_dim</code></li><li>α = 1 : <code>information_dim</code></li></ul></div></section></article><hr/><div class="admonition is-danger"><header class="admonition-header">Be wary when using `generalized_dim`</header><div class="admonition-body"><p>As stated clearly by the documentation string, calling <code>generalized_dim</code> performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.</p></div></div><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.estimate_boxsizes" href="#ChaosTools.estimate_boxsizes"><code>ChaosTools.estimate_boxsizes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">estimate_boxsizes(data::AbstractDataset; k::Int = 12, z = -1, w = 1)</code></pre><p>Return <code>k</code> exponentially spaced values: <code>10 .^ range(lower+w, upper+z, length = k)</code>.</p><p><code>lower</code> is the magnitude of the minimum pair-wise distance between datapoints while <code>upper</code> is the magnitude of the maximum difference between greatest and smallest number among each timeseries.</p><p>&quot;Magnitude&quot; here stands for order of magnitude, i.e. <code>round(log10(x))</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linear_regions" href="#ChaosTools.linear_regions"><code>ChaosTools.linear_regions</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">linear_regions(x, y; dxi::Int = 1, tol = 0.2) -&gt; (lrs, tangents)</code></pre><p>Identify regions where the curve <code>y(x)</code> is linear, by scanning the <code>x</code>-axis every <code>dxi</code> indices (e.g. at <code>x[1] to x[5], x[5] to x[10], x[10] to x[15]</code> and so on if <code>dxi=5</code>).</p><p>If the slope (calculated via linear regression) of a region of width <code>dxi</code> is approximatelly equal to that of the previous region, within tolerance <code>tol</code>, then these two regions belong to the same linear region.</p><p>Return the indices of <code>x</code> that correspond to linear regions, <code>lrs</code>, and the approximated <code>tangents</code> at each region. <code>lrs</code> is a vector of <code>Int</code>. Notice that <code>tangents</code> is <em>not</em> accurate: it is not recomputed at every step, but only when its error exceeds the tolerance <code>tol</code>! Use <a href="#ChaosTools.linear_region"><code>linear_region</code></a> to obtain a correct estimate for the slope of the largest linear region.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linear_region" href="#ChaosTools.linear_region"><code>ChaosTools.linear_region</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">linear_region(x, y; dxi::Int = 1, tol = 0.2) -&gt; ([ind1, ind2], slope)</code></pre><p>Call <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a>, identify the largest linear region and approximate the slope of the entire region using <code>linreg</code>. Return the indices where the region starts and stops (<code>x[ind1:ind2]</code>) as well as the approximated slope.</p></div></section></article><hr/><h3 id="Example-1"><a class="docs-heading-anchor" href="#Example-1">Example</a><a class="docs-heading-anchor-permalink" href="#Example-1" title="Permalink"></a></h3><p>For an example of using entropies to compute the dimension of an attractor let&#39;s use everyone&#39;s favorite system:</p><pre><code class="language-julia">using DynamicalSystems, PyPlot
lor = Systems.lorenz()</code></pre><pre><code class="language-none">3-dimensional continuous dynamical system
 state:       [0.0, 10.0, 0.0]
 e.o.m.:      loop
 in-place?    false
 jacobian:    loop_jac
 parameters:  [10.0, 28.0, 2.6666666666666665]</code></pre><p>Our goal is to compute entropies for many different partition sizes <code>ε</code>, so let&#39;s get down to it:</p><pre><code class="language-julia">tr = trajectory(lor, 100.0; Ttr = 10.0)

ες = ℯ .^ (-3.5:0.5:3.5) # semi-random guess
Hs = genentropy.(1, ες, Ref(tr))</code></pre><pre><code class="language-none">15-element Array{Float64,1}:
 9.210440366976329
 9.208499748932574
 9.195140334192946
 9.136445496766951
 8.998905310194775
 8.705004397152349
 8.1305312663553
 7.331853533923082
 6.408657913235563
 5.453352354803625
 4.485476740802795
 3.5260626238745894
 2.6067548710932336
 1.8789633825490644
 0.5375831514462662</code></pre><pre><code class="language-julia">xs = @. -log(ες)
figure()
plot(xs, Hs)
ylabel(&quot;\$H_1\$&quot;)
xlabel(&quot;\$-\\log (\\epsilon)\$&quot;);</code></pre><p><img src="../genentropy1.png" alt/></p><p>The slope of the linear scaling region of the above plot is the generalized dimension (of order α = 2) for the attractor of the Lorenz system.</p><p>Given that we <em>see</em> the plot, we can estimate where the linear scaling region starts and ends. However, we can use the function <a href="#ChaosTools.linear_region"><code>linear_region</code></a> to get an estimate of the result as well. First let&#39;s visualize what it does:</p><pre><code class="language-julia">lrs, slopes = linear_regions(xs, Hs, tol = 0.25)

figure()
for i in 1:length(lrs)-1
    plot(xs[lrs[i]:lrs[i+1]], Hs[lrs[i]:lrs[i+1]], marker = &quot;o&quot;)
end
ylabel(&quot;\$H_1\$&quot;)
xlabel(&quot;\$-\\log (\\epsilon)\$&quot;);</code></pre><p><img src="../genentropy2.png" alt/></p><p>The <a href="#ChaosTools.linear_region"><code>linear_region</code></a> function  computes the slope of the largest region:</p><pre><code class="language-julia">linear_region(xs, Hs)[2]</code></pre><pre><code class="language-none">1.833384047211349</code></pre><p>This result is an approximation of the information dimension (because we used <code>α = 1</code>) of the Lorenz attractor.</p><hr/><p>The above pipeline is bundled in <a href="#ChaosTools.generalized_dim"><code>generalized_dim</code></a>. For example, the dimension of the strange attractor of the <a href="../../ds/predefined/#DynamicalSystemsBase.Systems.henon"><code>Systems.henon</code></a> map, following the above approach but taking automated steps, is:</p><pre><code class="language-julia">using DynamicalSystems
hen = Systems.henon()
ts = trajectory(hen, 200000)
D_hen = generalized_dim(1, ts)</code></pre><pre><code class="language-none">1.215884931528749</code></pre><p>As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D <strong>56</strong>, pp 185-187 (1992)).</p><hr/><h2 id="Correlation-sum-(Grassberger-Proccacia)-1"><a class="docs-heading-anchor" href="#Correlation-sum-(Grassberger-Proccacia)-1">Correlation sum (Grassberger-Proccacia)</a><a class="docs-heading-anchor-permalink" href="#Correlation-sum-(Grassberger-Proccacia)-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.kernelprob" href="#ChaosTools.kernelprob"><code>ChaosTools.kernelprob</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kernelprob(X, ε, norm = Euclidean()) → p</code></pre><p>Associate each point in <code>X</code> (<code>Dataset</code> or timesries) with a probability <code>p</code> using the &quot;kernel estimation&quot; (also called &quot;nearest neighbor kernel estimation&quot; and other names):</p><div>\[p_j = \frac{1}{N}\sum_{i=1}^N I(||X_i - X_j|| &lt; \epsilon)\]</div><p>where <span>$N$</span> is its length and <span>$I$</span> gives 1 if the argument is <code>true</code>. Because <span>$p$</span> is further normalized, it can be used as an alternative for the <a href="#ChaosTools.genentropy"><code>genentropy</code></a> function (using the second method).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.correlationsum" href="#ChaosTools.correlationsum"><code>ChaosTools.correlationsum</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">correlationsum(X, ε::Real; w = 1, norm = Euclidean()) → C(ε)</code></pre><p>Calculate the correlation sum of <code>X</code> (<code>Dataset</code> or timeseries) for a given radius <code>ε</code> and <code>norm</code>, using the formula:</p><div>\[C(\epsilon) = \frac{2}{(N-w)(N-w-1)}\sum_{i=1}^{N}\sum_{j=1+w+i}^{N} I(||X_i - X_j|| &lt; \epsilon)\]</div><p>where <span>$N$</span> is its length and <span>$I$</span> gives 1 if the argument is <code>true</code>. <code>w</code> is the Theiler window, a correction to the correlation sum that skips points that are temporally close with each other, with the aim of removing spurious correlations.</p><p>See the book &quot;Nonlinear Time Series Analysis&quot;, Ch. 6, for a discussion around <code>w</code> and choosing best values.</p><p>See <a href="#ChaosTools.grassberger"><code>grassberger</code></a> for more. See also <a href="#ChaosTools.takens_best_estimate"><code>takens_best_estimate</code></a>.</p></div></section><section><div><pre><code class="language-none">correlationsum(X, εs::AbstractVector; kwargs...) → Cs</code></pre><p>Calculate the correlation sum for every <code>ε ∈ εs</code> using an optimized version.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.grassberger" href="#ChaosTools.grassberger"><code>ChaosTools.grassberger</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">grassberger(data, εs = estimate_boxsizes(data); kwargs...) → D_C</code></pre><p>Use the method of Grassberger and Proccacia<sup class="footnote-reference"><a id="citeref-Grassberger1983" href="#footnote-Grassberger1983">[Grassberger1983]</a></sup>, and the correction by Theiler<sup class="footnote-reference"><a id="citeref-Theiler1986" href="#footnote-Theiler1986">[Theiler1986]</a></sup>, to estimate the correlation dimension <code>D_C</code> of the given <code>data</code>.</p><p>This function does something extrely simple:</p><pre><code class="language-julia">cm = correlationsum(data, εs; kwargs...)
return linear_region(log.(sizes), log(cm))[2]</code></pre><p>i.e. it calculates <a href="#ChaosTools.correlationsum"><code>correlationsum</code></a> for various radii and then tries to find a linear region in the plot of the log of the correlation sum versus log(ε). See <a href="#ChaosTools.generalized_dim"><code>generalized_dim</code></a> for a more thorough explanation.</p><p>See also <a href="#ChaosTools.takens_best_estimate"><code>takens_best_estimate</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.takens_best_estimate" href="#ChaosTools.takens_best_estimate"><code>ChaosTools.takens_best_estimate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">takens_best_estimate(X, εmax, metric = Chebyshev(),εmin = 0) → D_C, D_C_95u, D_C_95l</code></pre><p>Use the so-called &quot;Takens&#39; best estimate&quot; <sup class="footnote-reference"><a id="citeref-Takens1985" href="#footnote-Takens1985">[Takens1985]</a></sup><sup class="footnote-reference"><a id="citeref-Theiler1988" href="#footnote-Theiler1988">[Theiler1988]</a></sup> method for estimating the correlation dimension <code>D_C</code> and the upper (<code>D_C_95u</code>) and lower (<code>D_C_95l</code>) confidence limit for the given dataset <code>X</code>.</p><p>The original formula is</p><div>\[D_C \approx \frac{C(\epsilon_\text{max})}{\int_0^{\epsilon_\text{max}}(C(\epsilon) / \epsilon) \, d\epsilon}\]</div><p>where <span>$C$</span> is the <a href="#ChaosTools.correlationsum"><code>correlationsum</code></a> and <span>$\epsilon_\text{max}$</span> is an upper cutoff. Here we use the later expression</p><div>\[D_C \approx - \frac{1}{\eta},\quad \eta = \frac{1}{(N-1)^*}\sum_{[i, j]^*}\log(||X_i - X_j|| / \epsilon_\text{max})\]</div><p>where the sum happens for all <span>$i, j$</span> so that <span>$i &lt; j$</span> and <span>$||X_i - X_j|| &lt; \epsilon_\text{max}$</span>. In the above expression, the bias in the original paper has already been corrected, as suggested in <sup class="footnote-reference"><a id="citeref-Borovkova1999" href="#footnote-Borovkova1999">[Borovkova1999]</a></sup>.</p><p>The confidence limits are estimated from the log-likelihood function by finding the values of <code>D_C</code> where the function has fallen by 2 from its maximum, see e.g. <sup class="footnote-reference"><a id="citeref-Barlow" href="#footnote-Barlow">[Barlow]</a></sup> chapter 5.3 Because the CLT does not apply (no independent measurements), the limits are not neccesarily symmetric.</p><p>According to <sup class="footnote-reference"><a id="citeref-Borovkova1999" href="#footnote-Borovkova1999">[Borovkova1999]</a></sup>, introducing a lower cutoff <code>εmin</code> can make the algorithm more stable (no divergence), this option is given but defaults to zero.</p><p>If <code>X</code> comes from a delay coordinates embedding of a timseries <code>x</code>, a recommended value for <span>$\epsilon_\text{max}$</span> is <code>std(x)/4</code>.</p></div></section></article><h2 id="Permutation-Entropy-1"><a class="docs-heading-anchor" href="#Permutation-Entropy-1">Permutation Entropy</a><a class="docs-heading-anchor-permalink" href="#Permutation-Entropy-1" title="Permalink"></a></h2><p>The permutation entropy is introduced by C. Bandt and B. Pompe as a &quot;A Natural Complexity Measure for Timeseries&quot;, which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.permentropy" href="#ChaosTools.permentropy"><code>ChaosTools.permentropy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">permentropy(x::AbstractVector, order [, interval=1]; base = Base.MathConstants.e)</code></pre><p>Compute the permutation entropy<sup class="footnote-reference"><a id="citeref-Brandt2002" href="#footnote-Brandt2002">[Brandt2002]</a></sup> of given <code>order</code> from the <code>x</code> timeseries.</p><p>Optionally, <code>interval</code> can be specified to use <code>x[t0:interval:t1]</code> when calculating permutation of the sliding windows between <code>t0</code> and <code>t1 = t0 + interval * (order - 1)</code>.</p><p>Optionally use <code>base</code> for the logarithms.</p></div></section></article><hr/><p>For example, we will compute and compare the <a href="../lyapunovs/#ChaosTools.lyapunov"><code>lyapunov</code></a> exponent of the logistic map with the order-6 permutation entropy, like in the original paper.</p><pre><code class="language-julia">using DynamicalSystems, PyPlot
ds = Systems.logistic()
rs = 3.5:0.001:4
ls = Float64[]; hs = Float64[]
for r in rs
    ds.p[1] = r
    push!(ls, lyapunov(ds, 100000))
    # For 1D systems `trajectory` returns a vector
    push!(hs, permentropy(trajectory(ds, 10000), 6))
end

f = figure(figsize = (10,6))
a1 = subplot(211)
plot(rs, ls); ylim(-2, log(2)); ylabel(&quot;\$\\lambda\$&quot;)
a1.axes.get_xaxis().set_ticklabels([])
xlim(rs[1], rs[end]);

a2 = subplot(212)
plot(rs, hs; color = &quot;C1&quot;); ylabel(&quot;\$h_6\$&quot;)
xlim(rs[1], rs[end]); xlabel(&quot;\$r\$&quot;)
tight_layout()</code></pre><p><img src="../permentropy.png" alt/></p><div class="admonition is-info"><header class="admonition-header">Permutation Entropy performance</header><div class="admonition-body"><p>Even though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue <a href="https://github.com/JuliaDynamics/ChaosTools.jl/issues/22">ChaosTools.jl#22</a> keeps track of this, and contains information on how to improve performance.</p></div></div><h2 id="Kaplan-Yorke-Dimension-1"><a class="docs-heading-anchor" href="#Kaplan-Yorke-Dimension-1">Kaplan-Yorke Dimension</a><a class="docs-heading-anchor-permalink" href="#Kaplan-Yorke-Dimension-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.kaplanyorke_dim" href="#ChaosTools.kaplanyorke_dim"><code>ChaosTools.kaplanyorke_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kaplanyorke_dim(λs::AbstractVector)</code></pre><p>Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension<sup class="footnote-reference"><a id="citeref-Kaplan1970" href="#footnote-Kaplan1970">[Kaplan1970]</a></sup>.</p><p><strong>Description</strong></p><p>The Kaplan-Yorke dimension is simply the point where <code>cumsum(λs)</code> becomes zero (interpolated):</p><div>\[ D_{KY} = k + \frac{\sum_{i=1}^k \lambda_i}{|\lambda_{k+1}|},\quad k = \max_j \left[ \sum_{i=1}^j \lambda_i &gt; 0 \right].\]</div><p>If the sum of the exponents never becomes negative the function will return the length of the input vector.</p><p>Useful in combination with <a href="../lyapunovs/#ChaosTools.lyapunovs"><code>lyapunovs</code></a>.</p></div></section></article><hr/><p>Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:</p><pre><code class="language-julia">using DynamicalSystems
hen = Systems.henon()
D_kp = kaplanyorke_dim(lyapunovs(hen, 100000))</code></pre><pre><code class="language-none">1.258705504865863</code></pre><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Rényi1960"><a class="tag is-link" href="#citeref-Rényi1960">Rényi1960</a>A. Rényi, <em>Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability</em>, pp 547 (1960)</li><li class="footnote" id="footnote-Shannon1948"><a class="tag is-link" href="#citeref-Shannon1948">Shannon1948</a>C. E. Shannon, Bell Systems Technical Journal <strong>27</strong>, pp 379 (1948)</li><li class="footnote" id="footnote-Grassberger1983"><a class="tag is-link" href="#citeref-Grassberger1983">Grassberger1983</a>Grassberger and Proccacia, <a href="https://journals-aps-org.e-bis.mpimet.mpg.de/prl/abstract/10.1103/PhysRevLett.50.346">Characterization of strange attractors, PRL 50 (1983)</a></li><li class="footnote" id="footnote-Theiler1986"><a class="tag is-link" href="#citeref-Theiler1986">Theiler1986</a>Theiler, <a href="https://doi.org/10.1103/PhysRevA.34.2427">Spurious dimension from correlation algorithms applied to limited time-series data. Physical Review A, 34</a></li><li class="footnote" id="footnote-Takens1985"><a class="tag is-link" href="#citeref-Takens1985">Takens1985</a>Takens, On the numerical determination of the dimension of an attractor, in: B.H.W. Braaksma, B.L.J.F. Takens (Eds.), Dynamical Systems and Bifurcations, in: Lecture Notes in Mathematics, Springer, Berlin, 1985, pp. 99–106.</li><li class="footnote" id="footnote-Theiler1988"><a class="tag is-link" href="#citeref-Theiler1988">Theiler1988</a>Theiler, <a href="https://doi.org/10.1016/0375-9601(88)91016-X">Lacunarity in a best estimator of fractal dimension. Physics Letters A, 133(4–5)</a></li><li class="footnote" id="footnote-Borovkova1999"><a class="tag is-link" href="#citeref-Borovkova1999">Borovkova1999</a>Borovkova et al., <a href="https://doi.org/10.1214/aoap/1029962747">Consistency of the Takens estimator for the correlation dimension. The Annals of Applied Probability, 9, 05 1999.</a></li><li class="footnote" id="footnote-Barlow"><a class="tag is-link" href="#citeref-Barlow">Barlow</a>Barlow, R., Statistics - A Guide to the Use of Statistical Methods in the Physical Sciences. Vol 29. John Wiley &amp; Sons, 1993</li><li class="footnote" id="footnote-Bandt2002"><a class="tag is-link" href="#citeref-Bandt2002">Bandt2002</a>C. Bandt, &amp; B. Pompe, <a href="http://doi.org/10.1103/PhysRevLett.88.174102">Phys. Rev. Lett. <strong>88</strong> (17), pp 174102 (2002)</a></li><li class="footnote" id="footnote-Kaplan1970"><a class="tag is-link" href="#citeref-Kaplan1970">Kaplan1970</a>J. Kaplan &amp; J. Yorke, <em>Chaotic behavior of multidimensional difference equations</em>, Lecture Notes in Mathematics vol. <strong>730</strong>, Springer (1979)</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../chaos_detection/">« Detecting &amp; Categorizing Chaos</a><a class="docs-footer-nextpage" href="../nlts/">Nonlinear Timeseries Analysis »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 25 September 2020 15:54">Friday 25 September 2020</span>. Using Julia version 1.5.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
