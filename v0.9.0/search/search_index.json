{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nDynamicalSystems.jl\n is a Julia suite for the exploration of chaos and nonlinear dynamics.\n\n\nYou can \njoin our chatroom\n for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!\n\n\nBe sure to visit the \nContributor Guide\n page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on \nGitHub\n! This gives us an accurate lower bound of users that this package has already helped!\n\n\n\n\nUse latest documentation\n\n\nWe highly suggest our users to read the  \nlatest\n documentation   and not the \nstable\n one.\n\n\n\n\nThe current documentation was built with the following versions\n\n\n - DynamicalSystemsBase          0.3.1\n - ChaosTools                    0.4.0\n\n\n\n\n\n\n\nOur Goals\n\n\nOur aim is for the \nDynamicalSystems.jl\n ecosystem to be a useful and powerful companion for students and scientists working on chaos and nonlinear dynamics.\n\n\nOur goals with this ecosystem can be summarized in the following three:\n\n\n\n\nBe concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the \nLorenz attractor\n, or a high dimensional discrete map like \ncoupled standard maps\n.\n\n\nBe accurate, reliable and performant.\n\n\nBe transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.\n\n\n\n\nFor example, provided you have first defined a \nDynamicalSystem\n (which simply reduces to writing a function for the equations of motion), you should be able to e.g. calculate the Lyapunov spectrum for it in a single line:\n\n\nlyapunovs\n(\nsystem\n,\n \ntimes_to_do_QR\n;\n \nkeywords\n...\n)\n\n\n\n\n\n\nThe same function call works with any system, no discriminations here!\n\n\n\n\nInstallation\n\n\nSimply use \nPkg.add(\"DynamicalSystems\")\n to install \neverything\n.\n\n\n\n\nLow Dependency usage\n\n\nBy running \nPkg.add(\"DynamicalSystems\")\n you install all packages of the ecosystem. That is not necessary however, since \nDynamicalSystems.jl\n is a bridging package that exports everything and hosts the documentation.\n\n\nFor example, if you only need the features of \nChaosTools.jl\n then you can get away by doing only \nPkg.add(\"ChaosTools\")\n and all other dependencies will be resolved accordingly.\n\n\n\n\nContents\n\n\n\n\nDynamicalSystemsBase.jl\n\n\n\n\nIntuitive, consistent APIs for the definition of general dynamical systems.\n\n\nDiscrete Maps\n\n\nContinuous Flows\n\n\nDedicated interface for \nNumerical Data\n\n\nAutomatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\n\n\nWell-defined functions for (numerically) evolving dynamical systems.\n\n\nLibrary of \npredefined well-known dynamical systems\n that have been used extensively in scientific research.\n\n\n\n\n\n\nChaosTools.jl\n\n\nPlease see the \noverview section\n for a full list of features.\n\n\nQuick summary:\n\n\n\n\nPoincare S.O.S. and orbit diagrams\n\n\nLyapunov Exponents\n\n\nEntropies and Dimensions\n\n\nDelay Coordinates Embedding\n\n\nNeighborhood estimation\n\n\nLyapunov exponent of a timeseries\n\n\nFinding Fixed Points of any Map of any order\n\n\nDetecting Chaos\n\n\n\n\n\n\nWanted Features\n\n\nThe following lists state features that are wanted by the \nDynamicalSystems.jl\n ecosystem and are open to contributors. These are structured in the form of GitHub Issues, with the label \nwanted_feature\n:\n\n\n\n\nDynamicalSystemsBase.jl wanted features\n\n\nChaosTools.jl wanted features", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "DynamicalSystems.jl  is a Julia suite for the exploration of chaos and nonlinear dynamics.  You can  join our chatroom  for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!  Be sure to visit the  Contributor Guide  page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on  GitHub ! This gives us an accurate lower bound of users that this package has already helped!   Use latest documentation  We highly suggest our users to read the   latest  documentation   and not the  stable  one.   The current documentation was built with the following versions   - DynamicalSystemsBase          0.3.1\n - ChaosTools                    0.4.0", 
            "title": "Introduction"
        }, 
        {
            "location": "/#our-goals", 
            "text": "Our aim is for the  DynamicalSystems.jl  ecosystem to be a useful and powerful companion for students and scientists working on chaos and nonlinear dynamics.  Our goals with this ecosystem can be summarized in the following three:   Be concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the  Lorenz attractor , or a high dimensional discrete map like  coupled standard maps .  Be accurate, reliable and performant.  Be transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.   For example, provided you have first defined a  DynamicalSystem  (which simply reduces to writing a function for the equations of motion), you should be able to e.g. calculate the Lyapunov spectrum for it in a single line:  lyapunovs ( system ,   times_to_do_QR ;   keywords ... )   The same function call works with any system, no discriminations here!", 
            "title": "Our Goals"
        }, 
        {
            "location": "/#installation", 
            "text": "Simply use  Pkg.add(\"DynamicalSystems\")  to install  everything .", 
            "title": "Installation"
        }, 
        {
            "location": "/#low-dependency-usage", 
            "text": "By running  Pkg.add(\"DynamicalSystems\")  you install all packages of the ecosystem. That is not necessary however, since  DynamicalSystems.jl  is a bridging package that exports everything and hosts the documentation.  For example, if you only need the features of  ChaosTools.jl  then you can get away by doing only  Pkg.add(\"ChaosTools\")  and all other dependencies will be resolved accordingly.", 
            "title": "Low Dependency usage"
        }, 
        {
            "location": "/#contents", 
            "text": "", 
            "title": "Contents"
        }, 
        {
            "location": "/#dynamicalsystemsbasejl", 
            "text": "Intuitive, consistent APIs for the definition of general dynamical systems.  Discrete Maps  Continuous Flows  Dedicated interface for  Numerical Data  Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.  Well-defined functions for (numerically) evolving dynamical systems.  Library of  predefined well-known dynamical systems  that have been used extensively in scientific research.", 
            "title": "DynamicalSystemsBase.jl"
        }, 
        {
            "location": "/#chaostoolsjl", 
            "text": "Please see the  overview section  for a full list of features.  Quick summary:   Poincare S.O.S. and orbit diagrams  Lyapunov Exponents  Entropies and Dimensions  Delay Coordinates Embedding  Neighborhood estimation  Lyapunov exponent of a timeseries  Finding Fixed Points of any Map of any order  Detecting Chaos", 
            "title": "ChaosTools.jl"
        }, 
        {
            "location": "/#wanted-features", 
            "text": "The following lists state features that are wanted by the  DynamicalSystems.jl  ecosystem and are open to contributors. These are structured in the form of GitHub Issues, with the label  wanted_feature :   DynamicalSystemsBase.jl wanted features  ChaosTools.jl wanted features", 
            "title": "Wanted Features"
        }, 
        {
            "location": "/definition/general/", 
            "text": "For \nDynamicalSystems.jl\n a \"system\" is simple a structure that contains the system's state, the equations of motion and the Jacobian. The last two are \nfunctions\n that take as an input a state. It is highly advised to create a \nDynamicalSystem\n using Functors (see below).\n\n\nThe above of course stand for systems where one already \nknows\n the equations of motion. if instead, your \"system\" is in the form of \nnumerical data\n, then see the appropriate section.\n\n\nAll core definitions in \nDynamicalSystems.jl\n are contained in the \nDynamicalSystemsBase.jl\n Julia package and are necessarily required in every other package of this ecosystem. All system \nsturct\ns are also a subtype of the abstract type \nDynamicalSystem\n.\n\n\n\n\nTrajectory and Timeseries\n\n\nThe word \"timeseries\" can be very confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in \nDynamicalSystems.jl\n we have the following convention: \n\"timeseries\"\n always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word \n\"trajectory\"\n is used to refer to a \nmulti-dimensional\n timeseries, which is of course simply a group/set of one-dimensional timeseries.\n\n\nNote that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a \nDataset\n, which is a \nVector\n of \nSVector\ns, and each \nSVector\n represents a data-point (the values of the variables at a given time-point).\n\n\n\n\n\n\n\n\nGeneral Functions\n\n\nThe following functions are defined for convenience for any dynamical system:\n\n\n#\n\n\nDynamicalSystemsBase.dimension\n \n \nFunction\n.\n\n\ndimension(ds::DynamicalSystem) -\n D\n\n\n\n\n\nReturn the dimension of the system\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.state\n \n \nFunction\n.\n\n\nstate(ds::DynamicalSystem) -\n u\n\n\n\n\n\nReturn the state of the system.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.jacobian\n \n \nFunction\n.\n\n\njacobian(ds::DynamicalSystem) -\n J\n\n\n\n\n\nReturn the Jacobian matrix of the equations of motion at the system's state.\n\n\nsource", 
            "title": "General Remarks"
        }, 
        {
            "location": "/definition/general/#general-functions", 
            "text": "The following functions are defined for convenience for any dynamical system:  #  DynamicalSystemsBase.dimension     Function .  dimension(ds::DynamicalSystem) -  D  Return the dimension of the system  source  #  DynamicalSystemsBase.state     Function .  state(ds::DynamicalSystem) -  u  Return the state of the system.  source  #  DynamicalSystemsBase.jacobian     Function .  jacobian(ds::DynamicalSystem) -  J  Return the Jacobian matrix of the equations of motion at the system's state.  source", 
            "title": "General Functions"
        }, 
        {
            "location": "/definition/continuous/", 
            "text": "Continuous Systems\n\n\nContinuous systems of the form\n\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),\n\n\n\n\n\nare defined using the \nContinuousDS\n structure:\n\n\n#\n\n\nDynamicalSystemsBase.ContinuousDS\n \n \nType\n.\n\n\nContinuousDS \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional continuous dynamical system.\n\n\nFields\n\n\n\n\nprob::ODEProblem\n : The fundamental structure used to describe a continuous dynamical system and also used in the \nDifferentialEquations.jl\n ecosystem. Contains the system's state, the equations of motion and optionally other information like e.g. \ncallbacks\n.\n\n\njacob!\n (function) : The function that represents the Jacobian of the system, given in the format: \njacob!(t, u, J)\n which means it is in-place, with the mutated argument being the last.\n\n\nJ::Matrix{T}\n : Jacobian matrix.\n\n\n\n\nYou can use \nds.prob.u0 .= newstate\n to set a new state to the system.\n\n\nCreating a \nContinuousDS\n\n\nThe equations of motion \nmust be\n in the form \neom!(t, u, du)\n, which means that they are \nin-place\n with the mutated argument \ndu\n the last one. Both \nu, du\n \nmust be\n \nVector\ns.\n\n\nIf you have this function, and optionally a function for the Jacobian, you can use the constructor\n\n\nContinuousDS\n(\nstate\n,\n \neom!\n \n[,\n \njacob!\n \n[,\n \nJ\n]];\n \ntspan\n \n=\n \n(\n0.0\n,\n \n100.0\n))\n\n\n\n\n\n\nwith \nstate\n the initial condition of the system.\n\n\nIf instead you already have an \nODEProblem\n because you also want to take advantage of the callback functionality of DifferentialEquations.jl, you may use the constructor\n\n\nContinuousDS\n(\nodeproblem\n \n[,\n \njacob!\n \n[,\n \nJ\n]])\n\n\n\n\n\n\nIf the \njacob!\n is not provided by the user, it is created automatically using the module \nForwardDiff\n (which always passes \nt=0\n at the \neom!\n) in both cases.\n\n\nAs mentioned in our \nofficial documentation\n, it is preferred to use Functors for both the equations of motion and the Jacobian.\n\n\nTo interfece \ntowards\n DifferentialEquations.jl use \nODEIntegrator(ds, stuff...)\n. Notice that you can have performance gains for stiff methods by explicitly adding a Jacobian caller for DifferentialEquations.jl by defining \neom!(::Type{Val{:jac}}, t, u, J) = jacob!(t, u, J)\n.\n\n\nsource\n\n\n\n\nYou can use any function that complies with the requirements stated by the documentation string. However, it is highly advised to use \nFunctors\n for dynamical systems where the equations of motion contain parameters.\n\n\nIn the following examples we will demonstrate how one can use both constructors.\n\n\n\n\nDefining a \nDynamicalSystem\n using Functors\n\n\nA Functor is a shorthand for saying \nFunction-like objects\n, i.e. \nstruct\ns that are also callable (see the linked documentation page). Using such objects one can create both the equations of motion and a parameter container under a single \nstruct\n definition.\n\n\nHere we will use the constructor\n\n\nContinuousDS\n(\nstate\n,\n\u00a0\neom!\n\u00a0\n[,\n\u00a0\njacob!\n\u00a0\n[,\n\u00a0\nJ\n]];\n\u00a0\ntspan\n\u00a0\n=\n\u00a0\n(\n0.0\n,\n\u00a0\n100.0\n))\n\n\n\n\n\n\nand create the continuous R\u00f6ssler system, from our \nPredefined Systems\n:\n\n\nusing\n \nDynamicalSystems\n\n\nmutable\n \nstruct\n \nR\u00f6ssler\n\n    \na\n::\nFloat64\n\n    \nb\n::\nFloat64\n\n    \nc\n::\nFloat64\n\n\nend\n\n\n@inline\n \n@inbounds\n \nfunction\n \n(\ns\n::\nR\u00f6ssler\n)(\nt\n,\n \nu\n::\nAbstractVector\n,\n \ndu\n::\nAbstractVector\n)\n\n    \ndu\n[\n1\n]\n \n=\n \n-\nu\n[\n2\n]\n-\nu\n[\n3\n]\n\n    \ndu\n[\n2\n]\n \n=\n \nu\n[\n1\n]\n \n+\n \ns\n.\na\n*\nu\n[\n2\n]\n\n    \ndu\n[\n3\n]\n \n=\n \ns\n.\nb\n \n+\n \nu\n[\n3\n]\n*\n(\nu\n[\n1\n]\n \n-\n \ns\n.\nc\n)\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n@inline\n \n@inbounds\n \nfunction\n \n(\ns\n::\nR\u00f6ssler\n)(\nt\n,\n \nu\n::\nAbstractVector\n,\n \nJ\n::\nAbstractMatrix\n)\n\n    \nJ\n[\n2\n,\n2\n]\n \n=\n \ns\n.\na\n\n    \nJ\n[\n3\n,\n1\n]\n \n=\n \nu\n[\n3\n];\n \nJ\n[\n3\n,\n3\n]\n \n=\n \nu\n[\n1\n]\n \n-\n \ns\n.\nc\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nThe first code-block defines a \nstruct\n that is simply a container for the parameters of the R\u00f6ssler system. The second code-block defines the equations of motion of the system, by taking advantage of the fact that you can \ncall\n this \nstruct\n as if it was a function:\n\n\ns\n \n=\n \nR\u00f6ssler\n(\n1\n,\n2\n,\n3\n)\n\n\nu\n \n=\n \nrand\n(\n3\n);\n \ndu\n \n=\n \ncopy\n(\nu\n)\n\n\ns\n(\n0\n,\n \nu\n,\n \ndu\n)\n\n\n\n\n\n\nThe third code-block then defines the Jacobian function using multiple dispatch. This allows us to use the \nsame\n instance of \nR\u00f6ssler\n for \nboth\n the equations of motion \nand\n the Jacobian function!\n\n\n\n\nUse \nAbstractVector\n and \nAbstractMatrix\n\n\nYou must define your equations of motion / Jacobian functions using \nAbstract\n Types, and \nnot\n types like \nVector\n or \nMatrix\n, otherwise functions like \nlyapunovs\n won't work properly.\n\n\n\n\nThe possibility of providing an initialized Jacobian to the \nContinuousDS\n constructor allows us to \"cheat\". Notice that the Jacobian function only accesses fields that depend on the parameters and/or the state variables, because the other fields are constants and will be initialized properly later.\n\n\nNext, we define a \"set-up\" function, that returns a \nContinuousDS\n:\n\n\nfunction\n \nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n    \ni\n \n=\n \none\n(\neltype\n(\nu0\n))\n\n    \no\n \n=\n \nzero\n(\neltype\n(\nu0\n))\n\n    \nJ\n \n=\n \nzeros\n(\neltype\n(\nu0\n),\n \n3\n,\n \n3\n)\n\n    \nJ\n[\n1\n,\n:\n]\n \n.=\n \n[\no\n,\n \n-\ni\n,\n      \n-\ni\n]\n\n    \nJ\n[\n2\n,\n:\n]\n \n.=\n \n[\ni\n,\n  \na\n,\n       \no\n]\n\n    \nJ\n[\n3\n,\n:\n]\n \n.=\n \n[\nu0\n[\n3\n],\n \no\n,\n \nu0\n[\n1\n]\n \n-\n \nc\n]\n\n\n    \ns\n \n=\n \nR\u00f6ssler\n(\na\n,\n \nb\n,\n \nc\n)\n\n    \nreturn\n \nContinuousDS\n(\nu0\n,\n \ns\n,\n \ns\n,\n \nJ\n)\n\n\nend\n\n\n\nds\n \n=\n \nroessler\n()\n\n\n# Equivalent with our predefined system:\n\n\nds\n \n=\n \nSystems\n.\nroessler\n()\n\n\n\n\n\n\n3-dimensional continuous dynamical system:\nstate: [0.021655, 0.530449, 0.0227049]\ne.o.m.: DynamicalSystemsBase.Systems.R\u00f6ssler(0.2, 0.2, 5.7)\n\n\n\n\n\nThen, it is trivial to change a parameter of the system by e.g. doing \nds.prob.f.c = 2.2\n. The equations of motion for a continuous system are stored in the \nODEProblem\n struct, the field \nf\n.\n\n\nNotice that this parameter change will affect both the equations of motion as well as the Jacobian function, making everything concise and easy-to-use!\n\n\n\n\nUsing \nODEProblem\n to define a \nContinuousDS\n\n\nHere we will show how one can take advantage of the callback capabilities of \nDifferentialEquations.jl\n to define a system.\n\n\n\n\nCallbacks do not propagate in variation vector methods!\n\n\nMethods that evolve variation vectors in time (currenlty \ngali\n and \nlyapunovs\n) do not inherit callbacks present in the definition of a \nContinuousDS\n. The issue that keeps track of this is \nhere\n.\n\n\n\n\nWe will make a H\u00e9non\u2013Heiles that also satisfies energy conservation. We first write the equations of motion and the Jacobian functions in the instructed form:\n\n\nfunction\n \nhheom!\n(\nt\n,\n \nu\n::\nAbstractVector\n,\n \ndu\n::\nAbstractVector\n)\n\n    \ndu\n[\n1\n]\n \n=\n \nu\n[\n3\n]\n\n    \ndu\n[\n2\n]\n \n=\n \nu\n[\n4\n]\n\n    \ndu\n[\n3\n]\n \n=\n \n-\nu\n[\n1\n]\n \n-\n \n2\nu\n[\n1\n]\n*\nu\n[\n2\n]\n\n    \ndu\n[\n4\n]\n \n=\n \n-\nu\n[\n2\n]\n \n-\n \n(\nu\n[\n1\n]\n^\n2\n \n-\n \nu\n[\n2\n]\n^\n2\n)\n\n    \nreturn\n \nnothing\n\n\nend\n\n\nfunction\n \nhhjacob!\n(\nt\n,\n \nu\n::\nAbstractVector\n,\n \nJ\n::\nAbstractMatrix\n)\n\n    \nJ\n[\n3\n,\n1\n]\n \n=\n \n-\n1\n \n-\n \n2\nu\n[\n2\n];\n \nJ\n[\n3\n,\n2\n]\n \n=\n \n-\n2\nu\n[\n1\n]\n\n    \nJ\n[\n4\n,\n1\n]\n \n=\n \n-\n2\nu\n[\n1\n];\n \nJ\n[\n4\n,\n2\n]\n \n=\n  \n-\n1\n \n+\n \n2\nu\n[\n2\n]\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nThe Jacobian matrix will be initialized properly later. Now, we are going to use a \nCallback\n to conserve energy. First, define the energy functions\n\n\n@inline\n \nV\n(\nq1\n,\n \nq2\n)\n \n=\n \n1\n//\n2\n \n*\n \n(\nq1\n^\n2\n \n+\n \nq2\n^\n2\n \n+\n \n2\nq1\n^\n2\n \n*\n \nq2\n \n-\n \n2\n//\n3\n \n*\n \nq2\n^\n3\n)\n\n\n@inline\n \nT\n(\np1\n,\n \np2\n)\n \n=\n \n1\n//\n2\n \n*\n \n(\np1\n^\n2\n \n+\n \np2\n^\n2\n)\n\n\n@inline\n \nH\n(\nq1\n,\n \nq2\n,\n \np1\n,\n \np2\n)\n \n=\n \nT\n(\np1\n,\n \np2\n)\n \n+\n \nV\n(\nq1\n,\n \nq2\n)\n\n\n@inline\n \nH\n(\nu\n::\nAbstractVector\n)\n \n=\n \nH\n(\nu\n...\n)\n\n\n\n\n\n\nThen, create a \"residual\" function, used in the \nManifoldProjection\n callback:\n\n\nu0\n \n=\n \n[\n0.1\n,\n \n0\n,\n \n0\n,\n \n0.5\n]\n\n\nconst\n \nE\n \n=\n \nH\n(\nu0\n[\n1\n],\nu0\n[\n2\n],\nu0\n[\n3\n],\nu0\n[\n4\n])\n\n\n\nfunction\n \ng\n(\nu\n,\n \nresid\n)\n\n    \nresid\n[\n1\n]\n \n=\n \nH\n(\nu\n[\n1\n],\nu\n[\n2\n],\nu\n[\n3\n],\nu\n[\n4\n])\n \n-\n \nE\n\n    \nresid\n[\n2\n:\n4\n]\n \n.=\n \n0\n\n\nend\n\n\n\n\n\n\nNext we create the \nCallback\n, the \nODEProblem\n and then dynamical system structure, \nContinuousDS\n:\n\n\n# Pkg.add(\nDiffEqCallbacks\n)\n\n\nusing\n \nDiffEqCallbacks\n,\n \nOrdinaryDiffEq\n\n\n\ncb\n \n=\n \nManifoldProjection\n(\ng\n,\n \nnlopts\n=\nDict\n(\n:\nftol\n=\n1e-13\n),\n \nsave\n \n=\n \nfalse\n)\n\n\nprob\n \n=\n \nODEProblem\n(\nhheom!\n,\n \nu0\n,\n \n(\n0.\n,\n \n100.0\n),\n  \ncallback\n=\ncb\n)\n\n\n\n# Initialize Jacobian\n\n\no\n \n=\n \n0.0\n;\n \ni\n \n=\n \n1.0\n;\n \nJ\n \n=\n \nzeros\n(\n4\n,\n4\n)\n\n\nJ\n[\n1\n,\n:\n]\n \n=\n \n[\no\n,\n    \no\n,\n     \ni\n,\n    \no\n]\n\n\nJ\n[\n2\n,\n:\n]\n \n=\n \n[\no\n,\n    \no\n,\n     \no\n,\n    \ni\n]\n\n\nJ\n[\n3\n,\n:\n]\n \n=\n \n[\n \n-\ni\n \n-\n \n2\nu0\n[\n2\n],\n   \n-\n2\nu0\n[\n1\n],\n   \no\n,\n   \no\n]\n\n\nJ\n[\n4\n,\n:\n]\n \n=\n \n[\n-\n2\nu0\n[\n1\n],\n  \n-\n1\n \n+\n \n2\nu0\n[\n2\n],\n  \no\n,\n   \no\n]\n\n\n\nds\n \n=\n \nContinuousDS\n(\nprob\n,\n \nhhjacob!\n,\n \nJ\n)\n\n\n\n\n\n\nNotice that using the argument \nsave = false\n in the \nManifoldProjection\n is crucial, because otherwise any data taken from the system, using e.g. \ntrajectory\n will necessarily have saved points at every callback realization (which you \ndo not\n want if you want timeseries of equi-sampled points).\n\n\nLet's see now if our system does indeed conserve energy!\n\n\na1\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n)\n\n\na2\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n,\n \ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nsolver\n \n=\n \nVern9\n(),\n\n\n:\nabstol\n \n=\n \n1e-9\n,\n \n:\nreltol\n \n=\n \n1e-9\n))\n\n\n\nenergies1\n \n=\n \n[\nH\n(\np\n)\n \nfor\n \np\n \nin\n \na1\n]\n\n\nenergies2\n \n=\n \n[\nH\n(\np\n)\n \nfor\n \np\n \nin\n \na2\n]\n\n\n\nprintln\n(\nDefault solver: \u0394E = \n,\n \nstd\n(\nenergies1\n))\n\n\nprintln\n(\nHigh-Accuracy solver: \u0394\u0395 = \n,\n \nstd\n(\nenergies2\n))\n\n\n\n\n\n\nDefault solver: \u0394E = 2.7868013699842223e-5\nHigh-Accuracy solver: \u0394\u0395 = 1.2345950190344736e-12\n\n\n\n\n\nBy combining a high-accuracy solver with a callback one can get an incredibly low energy error.", 
            "title": "Continuous Systems"
        }, 
        {
            "location": "/definition/continuous/#continuous-systems", 
            "text": "Continuous systems of the form   \n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),  \n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),   are defined using the  ContinuousDS  structure:  #  DynamicalSystemsBase.ContinuousDS     Type .  ContinuousDS  : DynamicalSystem  D -dimensional continuous dynamical system.  Fields   prob::ODEProblem  : The fundamental structure used to describe a continuous dynamical system and also used in the  DifferentialEquations.jl  ecosystem. Contains the system's state, the equations of motion and optionally other information like e.g.  callbacks .  jacob!  (function) : The function that represents the Jacobian of the system, given in the format:  jacob!(t, u, J)  which means it is in-place, with the mutated argument being the last.  J::Matrix{T}  : Jacobian matrix.   You can use  ds.prob.u0 .= newstate  to set a new state to the system.  Creating a  ContinuousDS  The equations of motion  must be  in the form  eom!(t, u, du) , which means that they are  in-place  with the mutated argument  du  the last one. Both  u, du   must be   Vector s.  If you have this function, and optionally a function for the Jacobian, you can use the constructor  ContinuousDS ( state ,   eom!   [,   jacob!   [,   J ]];   tspan   =   ( 0.0 ,   100.0 ))   with  state  the initial condition of the system.  If instead you already have an  ODEProblem  because you also want to take advantage of the callback functionality of DifferentialEquations.jl, you may use the constructor  ContinuousDS ( odeproblem   [,   jacob!   [,   J ]])   If the  jacob!  is not provided by the user, it is created automatically using the module  ForwardDiff  (which always passes  t=0  at the  eom! ) in both cases.  As mentioned in our  official documentation , it is preferred to use Functors for both the equations of motion and the Jacobian.  To interfece  towards  DifferentialEquations.jl use  ODEIntegrator(ds, stuff...) . Notice that you can have performance gains for stiff methods by explicitly adding a Jacobian caller for DifferentialEquations.jl by defining  eom!(::Type{Val{:jac}}, t, u, J) = jacob!(t, u, J) .  source   You can use any function that complies with the requirements stated by the documentation string. However, it is highly advised to use  Functors  for dynamical systems where the equations of motion contain parameters.  In the following examples we will demonstrate how one can use both constructors.", 
            "title": "Continuous Systems"
        }, 
        {
            "location": "/definition/continuous/#defining-a-dynamicalsystem-using-functors", 
            "text": "A Functor is a shorthand for saying  Function-like objects , i.e.  struct s that are also callable (see the linked documentation page). Using such objects one can create both the equations of motion and a parameter container under a single  struct  definition.  Here we will use the constructor  ContinuousDS ( state , \u00a0 eom! \u00a0 [, \u00a0 jacob! \u00a0 [, \u00a0 J ]]; \u00a0 tspan \u00a0 = \u00a0 ( 0.0 , \u00a0 100.0 ))   and create the continuous R\u00f6ssler system, from our  Predefined Systems :  using   DynamicalSystems  mutable   struct   R\u00f6ssler \n     a :: Float64 \n     b :: Float64 \n     c :: Float64  end  @inline   @inbounds   function   ( s :: R\u00f6ssler )( t ,   u :: AbstractVector ,   du :: AbstractVector ) \n     du [ 1 ]   =   - u [ 2 ] - u [ 3 ] \n     du [ 2 ]   =   u [ 1 ]   +   s . a * u [ 2 ] \n     du [ 3 ]   =   s . b   +   u [ 3 ] * ( u [ 1 ]   -   s . c ) \n     return   nothing  end  @inline   @inbounds   function   ( s :: R\u00f6ssler )( t ,   u :: AbstractVector ,   J :: AbstractMatrix ) \n     J [ 2 , 2 ]   =   s . a \n     J [ 3 , 1 ]   =   u [ 3 ];   J [ 3 , 3 ]   =   u [ 1 ]   -   s . c \n     return   nothing  end   The first code-block defines a  struct  that is simply a container for the parameters of the R\u00f6ssler system. The second code-block defines the equations of motion of the system, by taking advantage of the fact that you can  call  this  struct  as if it was a function:  s   =   R\u00f6ssler ( 1 , 2 , 3 )  u   =   rand ( 3 );   du   =   copy ( u )  s ( 0 ,   u ,   du )   The third code-block then defines the Jacobian function using multiple dispatch. This allows us to use the  same  instance of  R\u00f6ssler  for  both  the equations of motion  and  the Jacobian function!   Use  AbstractVector  and  AbstractMatrix  You must define your equations of motion / Jacobian functions using  Abstract  Types, and  not  types like  Vector  or  Matrix , otherwise functions like  lyapunovs  won't work properly.   The possibility of providing an initialized Jacobian to the  ContinuousDS  constructor allows us to \"cheat\". Notice that the Jacobian function only accesses fields that depend on the parameters and/or the state variables, because the other fields are constants and will be initialized properly later.  Next, we define a \"set-up\" function, that returns a  ContinuousDS :  function   roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 ) \n     i   =   one ( eltype ( u0 )) \n     o   =   zero ( eltype ( u0 )) \n     J   =   zeros ( eltype ( u0 ),   3 ,   3 ) \n     J [ 1 , : ]   .=   [ o ,   - i ,        - i ] \n     J [ 2 , : ]   .=   [ i ,    a ,         o ] \n     J [ 3 , : ]   .=   [ u0 [ 3 ],   o ,   u0 [ 1 ]   -   c ] \n\n     s   =   R\u00f6ssler ( a ,   b ,   c ) \n     return   ContinuousDS ( u0 ,   s ,   s ,   J )  end  ds   =   roessler ()  # Equivalent with our predefined system:  ds   =   Systems . roessler ()   3-dimensional continuous dynamical system:\nstate: [0.021655, 0.530449, 0.0227049]\ne.o.m.: DynamicalSystemsBase.Systems.R\u00f6ssler(0.2, 0.2, 5.7)  Then, it is trivial to change a parameter of the system by e.g. doing  ds.prob.f.c = 2.2 . The equations of motion for a continuous system are stored in the  ODEProblem  struct, the field  f .  Notice that this parameter change will affect both the equations of motion as well as the Jacobian function, making everything concise and easy-to-use!", 
            "title": "Defining a DynamicalSystem using Functors"
        }, 
        {
            "location": "/definition/continuous/#using-odeproblem-to-define-a-continuousds", 
            "text": "Here we will show how one can take advantage of the callback capabilities of  DifferentialEquations.jl  to define a system.   Callbacks do not propagate in variation vector methods!  Methods that evolve variation vectors in time (currenlty  gali  and  lyapunovs ) do not inherit callbacks present in the definition of a  ContinuousDS . The issue that keeps track of this is  here .   We will make a H\u00e9non\u2013Heiles that also satisfies energy conservation. We first write the equations of motion and the Jacobian functions in the instructed form:  function   hheom! ( t ,   u :: AbstractVector ,   du :: AbstractVector ) \n     du [ 1 ]   =   u [ 3 ] \n     du [ 2 ]   =   u [ 4 ] \n     du [ 3 ]   =   - u [ 1 ]   -   2 u [ 1 ] * u [ 2 ] \n     du [ 4 ]   =   - u [ 2 ]   -   ( u [ 1 ] ^ 2   -   u [ 2 ] ^ 2 ) \n     return   nothing  end  function   hhjacob! ( t ,   u :: AbstractVector ,   J :: AbstractMatrix ) \n     J [ 3 , 1 ]   =   - 1   -   2 u [ 2 ];   J [ 3 , 2 ]   =   - 2 u [ 1 ] \n     J [ 4 , 1 ]   =   - 2 u [ 1 ];   J [ 4 , 2 ]   =    - 1   +   2 u [ 2 ] \n     return   nothing  end   The Jacobian matrix will be initialized properly later. Now, we are going to use a  Callback  to conserve energy. First, define the energy functions  @inline   V ( q1 ,   q2 )   =   1 // 2   *   ( q1 ^ 2   +   q2 ^ 2   +   2 q1 ^ 2   *   q2   -   2 // 3   *   q2 ^ 3 )  @inline   T ( p1 ,   p2 )   =   1 // 2   *   ( p1 ^ 2   +   p2 ^ 2 )  @inline   H ( q1 ,   q2 ,   p1 ,   p2 )   =   T ( p1 ,   p2 )   +   V ( q1 ,   q2 )  @inline   H ( u :: AbstractVector )   =   H ( u ... )   Then, create a \"residual\" function, used in the  ManifoldProjection  callback:  u0   =   [ 0.1 ,   0 ,   0 ,   0.5 ]  const   E   =   H ( u0 [ 1 ], u0 [ 2 ], u0 [ 3 ], u0 [ 4 ])  function   g ( u ,   resid ) \n     resid [ 1 ]   =   H ( u [ 1 ], u [ 2 ], u [ 3 ], u [ 4 ])   -   E \n     resid [ 2 : 4 ]   .=   0  end   Next we create the  Callback , the  ODEProblem  and then dynamical system structure,  ContinuousDS :  # Pkg.add( DiffEqCallbacks )  using   DiffEqCallbacks ,   OrdinaryDiffEq  cb   =   ManifoldProjection ( g ,   nlopts = Dict ( : ftol = 1e-13 ),   save   =   false )  prob   =   ODEProblem ( hheom! ,   u0 ,   ( 0. ,   100.0 ),    callback = cb )  # Initialize Jacobian  o   =   0.0 ;   i   =   1.0 ;   J   =   zeros ( 4 , 4 )  J [ 1 , : ]   =   [ o ,      o ,       i ,      o ]  J [ 2 , : ]   =   [ o ,      o ,       o ,      i ]  J [ 3 , : ]   =   [   - i   -   2 u0 [ 2 ],     - 2 u0 [ 1 ],     o ,     o ]  J [ 4 , : ]   =   [ - 2 u0 [ 1 ],    - 1   +   2 u0 [ 2 ],    o ,     o ]  ds   =   ContinuousDS ( prob ,   hhjacob! ,   J )   Notice that using the argument  save = false  in the  ManifoldProjection  is crucial, because otherwise any data taken from the system, using e.g.  trajectory  will necessarily have saved points at every callback realization (which you  do not  want if you want timeseries of equi-sampled points).  Let's see now if our system does indeed conserve energy!  a1   =   trajectory ( ds ,   1000.0 )  a2   =   trajectory ( ds ,   1000.0 ,   diff_eq_kwargs   =   Dict ( : solver   =   Vern9 (),  : abstol   =   1e-9 ,   : reltol   =   1e-9 ))  energies1   =   [ H ( p )   for   p   in   a1 ]  energies2   =   [ H ( p )   for   p   in   a2 ]  println ( Default solver: \u0394E =  ,   std ( energies1 ))  println ( High-Accuracy solver: \u0394\u0395 =  ,   std ( energies2 ))   Default solver: \u0394E = 2.7868013699842223e-5\nHigh-Accuracy solver: \u0394\u0395 = 1.2345950190344736e-12  By combining a high-accuracy solver with a callback one can get an incredibly low energy error.", 
            "title": "Using ODEProblem to define a ContinuousDS"
        }, 
        {
            "location": "/definition/discrete/", 
            "text": "Discrete Systems\n\n\nDiscrete systems are of the form:\n\n\n\n\n\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\n\n\n\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\n\n\n\n\nDynamicalSystems.jl\n categorizes discrete systems in three cases, due to the extremely performant handling that \nStaticArrays\n offers for small dimensionalities.\n\n\nHandling of discrete systems is done exclusively from \nDynamicalSystems.jl\n and so there is no interaction with DifferentialEquations.jl. This also means that the definition of a discrete system may differ slightly from a continuous one.\n\n\nWhen defining a system using Functors, be sure to use \nAbstractVector\n and \nAbstractMatrix\n (see \nhere\n ).\n\n\n\n\nNon-autonomous systems\n\n\nTo define a discrete system that depends on \"time\" \nn\nn\n, extend the equations of motion by introducing a new variable \n\\tau\n\\tau\n such that \n\\tau_{n+1} =  \\tau_n + 1\n\\tau_{n+1} =  \\tau_n + 1\n and use this in the equations for the other variables.\n\n\n\n\n\n\nHigh-Dimensional\n\n\nAt around \nD=10\n dimensions, Static Arrays start to become less efficient than Julia's base Arrays, provided that the latter use in-place operations. For cases of discrete systems with much high dimensionality, we offer a type called \nBigDiscreteDS\n:\n\n\n#\n\n\nDynamicalSystemsBase.BigDiscreteDS\n \n \nType\n.\n\n\nBigDiscreteDS(state, eom! [, jacob! [, J]]) \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional discrete dynamical system (used for big \nD\n). The equations for this system perform all operations \nin-place\n.\n\n\nFields:\n\n\n\n\nstate::Vector{T}\n : Current state-vector of the system. Do \nstate(ds) .= u\n to change the state.\n\n\neom!\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom!(xnew, x)\n which means that given a state-vector \nx\n and another similar one \nxnew\n, it writes in-place the new state in \nxnew\n.\n\n\njacob!\n (function) : A function that calculates the system's jacobian matrix, based on the format: \njacob!(J, x)\n which means that given a state-vector \nx\n it writes in-place the Jacobian in \nJ\n.\n\n\nJ::Matrix{T}\n : Initialized Jacobian matrix (optional).\n\n\ndummystate::Vector{T}\n : Dummy vector, which most of the time fills the role of the previous state in e.g. \nevolve\n.\n\n\n\n\nOnly the first two fields of this type are displayed during print.\n\n\nAs mentioned in our \nofficial documentation\n, it is preferred to use Functors for both the equations of motion and the Jacobian.\n\n\nIf the \njacob\n is not provided by the user, it is created automatically using the module \nForwardDiff\n.\n\n\nsource\n\n\n\n\nThe source code of the pre-defined \ncoupled standard maps\n can serve as an example of a \nBigDiscreteDS\n definition \n(we do not show it here because it is very large\n).\n\n\nJust keep in mind that the equations of motion for \nBigDiscreteDS\n are of the form \neom!(xnew, xold)\n; in-place with the mutated argument \nfirst\n, in contrast to the continuous case. The same story goes for the Jacobian function!\n\n\n\n\nLow-dimensional\n\n\nThe definition of low-dimensional discrete systems differs fundamentally from high dimensional ones, because everything is \nmuch\n more efficiently done with statically sized vectors. The \nstruct\n representing such systems is called \nDiscreteDS\n:\n\n\n#\n\n\nDynamicalSystemsBase.DiscreteDS\n \n \nType\n.\n\n\nDiscreteDS(state, eom [, jacob]) \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional discrete dynamical system.\n\n\nFields:\n\n\n\n\nstate::SVector{D}\n : Current state-vector of the system, stored in the data format of \nStaticArray\n's \nSVector\n. Use \nstate(ds) = newstate\n to set a new state.\n\n\neom\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom(u) -\n SVector\n which means that given a state-vector \nu\n it returns an \nSVector\n containing the next state.\n\n\njacob\n (function) : A function that calculates the system's jacobian matrix, based on the format: \njacob(u) -\n SMatrix\n which means that given a state-vector \nu\n it returns an \nSMatrix\n containing the Jacobian at that state.\n\n\n\n\nOnly the first two fields of this type are displayed during print.\n\n\nIf the \njacob\n is not provided by the user, it is created automatically using the module \nForwardDiff\n.\n\n\nsource\n\n\n\n\n\n\nReturn form of the \neom\n function\n\n\nIt is \nheavily\n advised that the equations of motion \neom\n function returns an \nSVector\n from the julia package \nStaticArrays.jl\n and similarly the \njacob\n function returns an \nSMatrix\n in the case of \nDiscreteDS\n.\n\n\n\n\nSomething important to note when defining a \nDiscreteDS\n using Functors: since the function calls take only one argument (always a state), it is impossible to use multiple dispatch to differentiate between a call to the e.o.m. or the Jacobian functions.\n\n\nHowever, it is very easy to still define both function calls using a single \nstruct\n, by using a 2 argument function given to the constructor. For example:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nStaticArrays\n \n# only necessary when defining a system\n\n\n\nmutable\n \nstruct\n \nH\u00e9nonMap\n\n    \na\n::\nFloat64\n\n    \nb\n::\nFloat64\n\n\nend\n\n\n(\nf\n::\nH\u00e9nonMap\n)(\nx\n)\n \n=\n \nSVector\n{\n2\n}(\n1.0\n \n-\n \nf\n.\na\n*\nx\n[\n1\n]\n^\n2\n \n+\n \nx\n[\n2\n],\n \nf\n.\nb\n*\nx\n[\n1\n])\n\n\n(\nf\n::\nH\u00e9nonMap\n)(\nx\n,\n \nno\n::\nVoid\n)\n \n=\n \n@SMatrix\n \n[\n-\n2\n*\nf\n.\na\n*\nx\n[\n1\n]\n \n1.0\n;\n \nf\n.\nb\n \n0.0\n]\n\n\n\nfunction\n \nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n    \nhe\n \n=\n \nH\u00e9nonMap\n(\na\n,\nb\n)\n\n    \n# The jacobian function: (still uses the H\u00e9nonMap)\n\n    \n@inline\n \njacob_henon\n(\nx\n)\n \n=\n \nhe\n(\nx\n,\n \nnothing\n)\n\n    \nreturn\n \nDiscreteDS\n(\nu0\n,\n \nhe\n,\n \njacob_henon\n)\n\n\nend\n\n\n\nds\n \n=\n \nhenon\n()\n\n\n\n\n\n\n2-dimensional discrete system\n state: [0.0, 0.0]\n eom: ex-henon.H\u00e9nonMap\n\n\n\n\n\nHere the example uses the type \nVoid\n for dispatch, but you could use any other bittype like e.g. \n::Int64\n and pass in \n0\n.\n\n\nIn this example case, doing \nds.eom.a = 2.5\n would still affect \nboth\n the equations of motion as well as the Jacobian, making everything work perfectly!\n\n\n\n\nDefining a \nDynamicalSystem\n without Functors\n\n\nAs an example of defining a system without using Functors, let's create another one of the \nPredefined Systems\n offered by this package, the Folded Towel map.\n\n\nBecause this map doesn't have any parameters, it is unnecessary to associate a Functor with it.\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nStaticArrays\n \n# only necessary when defining a system\n\n\n\n@inline\n \n@inbounds\n \nfunction\n \neom_towel\n(\nx\n)\n\n\nx1\n,\n \nx2\n,\n \nx3\n \n=\n \nx\n[\n1\n],\n \nx\n[\n2\n],\n \nx\n[\n3\n]\n\n\nSVector\n(\n \n3.8\n*\nx1\n*\n(\n1\n-\nx1\n)\n \n-\n \n0.05\n*\n(\nx2\n+\n0.35\n)\n*\n(\n1\n-\n2\n*\nx3\n),\n\n\n0.1\n*\n(\n \n(\nx2\n+\n0.35\n)\n*\n(\n1\n-\n2\n*\nx3\n)\n \n-\n \n1\n \n)\n*\n(\n1\n \n-\n \n1.9\n*\nx1\n),\n\n\n3.78\n*\nx3\n*\n(\n1\n-\nx3\n)\n+\n0.2\n*\nx2\n \n)\n\n\nend\n\n\n\n@inline\n \n@inbounds\n \nfunction\n \njacob_towel\n(\nx\n)\n\n    \n@SMatrix\n \n[\n3.8\n*\n(\n1\n \n-\n \n2\nx\n[\n1\n])\n \n-\n0.05\n*\n(\n1\n-\n2\nx\n[\n3\n])\n \n0.1\n*\n(\nx\n[\n2\n]\n \n+\n \n0.35\n);\n\n    \n-\n0.19\n((\nx\n[\n2\n]\n \n+\n \n0.35\n)\n*\n(\n1\n-\n2\nx\n[\n3\n])\n \n-\n \n1\n)\n  \n0.1\n*\n(\n1\n-\n2\nx\n[\n3\n])\n*\n(\n1\n-\n1.9\nx\n[\n1\n])\n  \n-\n0.2\n*\n(\nx\n[\n2\n]\n \n+\n \n0.35\n)\n*\n(\n1\n-\n1.9\nx\n[\n1\n]);\n\n    \n0.0\n  \n0.2\n  \n3.78\n(\n1\n-\n2\nx\n[\n3\n])\n \n]\n\n\nend\n\n\n\nu0\n=\n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n]\n\n\ntowel\n \n=\n  \nDiscreteDS\n(\nu0\n,\n \neom_towel\n,\n \njacob_towel\n)\n\n\n\n\n\n\n3-dimensional discrete system\n state: [0.085, -0.121, 0.075]\n eom: ex-2.#eom_towel\n\n\n\n\n\nIf we did not want to write a Jacobian for it, we could do\n\n\ntowl_nojac\n \n=\n \nDiscreteDS\n(\nrand\n(\n3\n),\n \neom_towel\n)\n\n\n\n\n\n\nand the Jacobian function is created automatically.\n\n\n\n\nOne-Dimensional\n\n\nIn the case of maps, there a special structure for one-dimensional systems. The syntax is \nDiscreteDS1D(state, eom [, deriv])\n. In this one-dimensional case, you don't need to worry about StaticArrays.jl because everything is in plain numbers. For example:\n\n\nusing\n \nDynamicalSystems\n\n\n\nmutable\n \nstruct\n \nLogistic\n\n    \nr\n::\nFloat64\n\n\nend\n\n\n@inline\n \n(\nf\n::\nLogistic\n)(\nx\n::\nNumber\n)\n \n=\n \nf\n.\nr\n*\nx\n*\n(\n1\n-\nx\n)\n\n\n@inline\n \n(\nf\n::\nLogistic\n)(\nx\n::\nNumber\n,\n \nno\n::\nVoid\n)\n \n=\n \nf\n.\nr\n*\n(\n1\n-\n2\nx\n)\n\n\n\nr\n \n=\n \n3.7\n\n\nlol\n \n=\n \nLogistic\n(\nr\n)\n\n\nderiv_logistic\n(\nx\n)\n \n=\n \nlol\n(\nx\n,\n \nnothing\n)\n\n\nreturn\n \nDiscreteDS1D\n(\nrand\n(),\n \nlol\n,\n \nderiv_logistic\n)\n\n\n\n\n\n\n1-dimensional discrete dynamical system:\nstate: 0.494460184525209\neom: ex-3.Logistic\n\n\n\n\n\nOnce again, if you skip the derivative functions it will be calculated automatically using ForwardDiff.jl.", 
            "title": "Discrete Systems"
        }, 
        {
            "location": "/definition/discrete/#discrete-systems", 
            "text": "Discrete systems are of the form:   \n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).  \n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).   DynamicalSystems.jl  categorizes discrete systems in three cases, due to the extremely performant handling that  StaticArrays  offers for small dimensionalities.  Handling of discrete systems is done exclusively from  DynamicalSystems.jl  and so there is no interaction with DifferentialEquations.jl. This also means that the definition of a discrete system may differ slightly from a continuous one.  When defining a system using Functors, be sure to use  AbstractVector  and  AbstractMatrix  (see  here  ).   Non-autonomous systems  To define a discrete system that depends on \"time\"  n n , extend the equations of motion by introducing a new variable  \\tau \\tau  such that  \\tau_{n+1} =  \\tau_n + 1 \\tau_{n+1} =  \\tau_n + 1  and use this in the equations for the other variables.", 
            "title": "Discrete Systems"
        }, 
        {
            "location": "/definition/discrete/#high-dimensional", 
            "text": "At around  D=10  dimensions, Static Arrays start to become less efficient than Julia's base Arrays, provided that the latter use in-place operations. For cases of discrete systems with much high dimensionality, we offer a type called  BigDiscreteDS :  #  DynamicalSystemsBase.BigDiscreteDS     Type .  BigDiscreteDS(state, eom! [, jacob! [, J]])  : DynamicalSystem  D -dimensional discrete dynamical system (used for big  D ). The equations for this system perform all operations  in-place .  Fields:   state::Vector{T}  : Current state-vector of the system. Do  state(ds) .= u  to change the state.  eom!  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom!(xnew, x)  which means that given a state-vector  x  and another similar one  xnew , it writes in-place the new state in  xnew .  jacob!  (function) : A function that calculates the system's jacobian matrix, based on the format:  jacob!(J, x)  which means that given a state-vector  x  it writes in-place the Jacobian in  J .  J::Matrix{T}  : Initialized Jacobian matrix (optional).  dummystate::Vector{T}  : Dummy vector, which most of the time fills the role of the previous state in e.g.  evolve .   Only the first two fields of this type are displayed during print.  As mentioned in our  official documentation , it is preferred to use Functors for both the equations of motion and the Jacobian.  If the  jacob  is not provided by the user, it is created automatically using the module  ForwardDiff .  source   The source code of the pre-defined  coupled standard maps  can serve as an example of a  BigDiscreteDS  definition  (we do not show it here because it is very large ).  Just keep in mind that the equations of motion for  BigDiscreteDS  are of the form  eom!(xnew, xold) ; in-place with the mutated argument  first , in contrast to the continuous case. The same story goes for the Jacobian function!", 
            "title": "High-Dimensional"
        }, 
        {
            "location": "/definition/discrete/#low-dimensional", 
            "text": "The definition of low-dimensional discrete systems differs fundamentally from high dimensional ones, because everything is  much  more efficiently done with statically sized vectors. The  struct  representing such systems is called  DiscreteDS :  #  DynamicalSystemsBase.DiscreteDS     Type .  DiscreteDS(state, eom [, jacob])  : DynamicalSystem  D -dimensional discrete dynamical system.  Fields:   state::SVector{D}  : Current state-vector of the system, stored in the data format of  StaticArray 's  SVector . Use  state(ds) = newstate  to set a new state.  eom  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom(u) -  SVector  which means that given a state-vector  u  it returns an  SVector  containing the next state.  jacob  (function) : A function that calculates the system's jacobian matrix, based on the format:  jacob(u) -  SMatrix  which means that given a state-vector  u  it returns an  SMatrix  containing the Jacobian at that state.   Only the first two fields of this type are displayed during print.  If the  jacob  is not provided by the user, it is created automatically using the module  ForwardDiff .  source    Return form of the  eom  function  It is  heavily  advised that the equations of motion  eom  function returns an  SVector  from the julia package  StaticArrays.jl  and similarly the  jacob  function returns an  SMatrix  in the case of  DiscreteDS .   Something important to note when defining a  DiscreteDS  using Functors: since the function calls take only one argument (always a state), it is impossible to use multiple dispatch to differentiate between a call to the e.o.m. or the Jacobian functions.  However, it is very easy to still define both function calls using a single  struct , by using a 2 argument function given to the constructor. For example:  using   DynamicalSystems  using   StaticArrays   # only necessary when defining a system  mutable   struct   H\u00e9nonMap \n     a :: Float64 \n     b :: Float64  end  ( f :: H\u00e9nonMap )( x )   =   SVector { 2 }( 1.0   -   f . a * x [ 1 ] ^ 2   +   x [ 2 ],   f . b * x [ 1 ])  ( f :: H\u00e9nonMap )( x ,   no :: Void )   =   @SMatrix   [ - 2 * f . a * x [ 1 ]   1.0 ;   f . b   0.0 ]  function   henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 ) \n     he   =   H\u00e9nonMap ( a , b ) \n     # The jacobian function: (still uses the H\u00e9nonMap) \n     @inline   jacob_henon ( x )   =   he ( x ,   nothing ) \n     return   DiscreteDS ( u0 ,   he ,   jacob_henon )  end  ds   =   henon ()   2-dimensional discrete system\n state: [0.0, 0.0]\n eom: ex-henon.H\u00e9nonMap  Here the example uses the type  Void  for dispatch, but you could use any other bittype like e.g.  ::Int64  and pass in  0 .  In this example case, doing  ds.eom.a = 2.5  would still affect  both  the equations of motion as well as the Jacobian, making everything work perfectly!", 
            "title": "Low-dimensional"
        }, 
        {
            "location": "/definition/discrete/#defining-a-dynamicalsystem-without-functors", 
            "text": "As an example of defining a system without using Functors, let's create another one of the  Predefined Systems  offered by this package, the Folded Towel map.  Because this map doesn't have any parameters, it is unnecessary to associate a Functor with it.  using   DynamicalSystems  using   StaticArrays   # only necessary when defining a system  @inline   @inbounds   function   eom_towel ( x )  x1 ,   x2 ,   x3   =   x [ 1 ],   x [ 2 ],   x [ 3 ]  SVector (   3.8 * x1 * ( 1 - x1 )   -   0.05 * ( x2 + 0.35 ) * ( 1 - 2 * x3 ),  0.1 * (   ( x2 + 0.35 ) * ( 1 - 2 * x3 )   -   1   ) * ( 1   -   1.9 * x1 ),  3.78 * x3 * ( 1 - x3 ) + 0.2 * x2   )  end  @inline   @inbounds   function   jacob_towel ( x ) \n     @SMatrix   [ 3.8 * ( 1   -   2 x [ 1 ])   - 0.05 * ( 1 - 2 x [ 3 ])   0.1 * ( x [ 2 ]   +   0.35 ); \n     - 0.19 (( x [ 2 ]   +   0.35 ) * ( 1 - 2 x [ 3 ])   -   1 )    0.1 * ( 1 - 2 x [ 3 ]) * ( 1 - 1.9 x [ 1 ])    - 0.2 * ( x [ 2 ]   +   0.35 ) * ( 1 - 1.9 x [ 1 ]); \n     0.0    0.2    3.78 ( 1 - 2 x [ 3 ])   ]  end  u0 = [ 0.085 ,   - 0.121 ,   0.075 ]  towel   =    DiscreteDS ( u0 ,   eom_towel ,   jacob_towel )   3-dimensional discrete system\n state: [0.085, -0.121, 0.075]\n eom: ex-2.#eom_towel  If we did not want to write a Jacobian for it, we could do  towl_nojac   =   DiscreteDS ( rand ( 3 ),   eom_towel )   and the Jacobian function is created automatically.", 
            "title": "Defining a DynamicalSystem without Functors"
        }, 
        {
            "location": "/definition/discrete/#one-dimensional", 
            "text": "In the case of maps, there a special structure for one-dimensional systems. The syntax is  DiscreteDS1D(state, eom [, deriv]) . In this one-dimensional case, you don't need to worry about StaticArrays.jl because everything is in plain numbers. For example:  using   DynamicalSystems  mutable   struct   Logistic \n     r :: Float64  end  @inline   ( f :: Logistic )( x :: Number )   =   f . r * x * ( 1 - x )  @inline   ( f :: Logistic )( x :: Number ,   no :: Void )   =   f . r * ( 1 - 2 x )  r   =   3.7  lol   =   Logistic ( r )  deriv_logistic ( x )   =   lol ( x ,   nothing )  return   DiscreteDS1D ( rand (),   lol ,   deriv_logistic )   1-dimensional discrete dynamical system:\nstate: 0.494460184525209\neom: ex-3.Logistic  Once again, if you skip the derivative functions it will be calculated automatically using ForwardDiff.jl.", 
            "title": "One-Dimensional"
        }, 
        {
            "location": "/definition/evolve/", 
            "text": "Time Evolution of Systems\n\n\nDynamicalSystems.jl\n provides convenient interfaces for the evolution of systems.\n\n\n#\n\n\nDynamicalSystemsBase.evolve\n \n \nFunction\n.\n\n\nevolve\n(\nds\n::\nDynamicalSystem\n,\n \nT\n=\n1\n \n[\n,\n \nu0\n]\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n\n\n\n\n\n\nEvolve the \nstate(ds)\n (or \nu0\n if given) for total time \nT\n and return the \nfinal_state\n. For discrete systems \nT\n corresponds to steps and thus it must be integer.\n\n\nevolve\n \ndoes not store\n any information about intermediate steps. Use \ntrajectory\n if you want to produce a trajectory of the system. If you want to perform step-by-step evolution of a continuous system, use \nODEIntegrator(ds, args...)\n and the \nstep!(integrator)\n function provided by \nDifferentialEquations\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.trajectory\n \n \nFunction\n.\n\n\ntrajectory\n(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \nkwargs\n...\n)\n \n-\n \ndataset\n\n\n\n\n\n\nReturn a dataset what will contain the trajectory of the sytem, after evolving it for time \nT\n. See \nDataset\n for info on how to manipulate this object.\n\n\nFor the discrete case, \nT\n is an integer and a \nT\u00d7D\n dataset is returned (\nD\n is the system dimensionality). For the continuous case, a \nW\u00d7D\n dataset is returned, with \nW = length(0:dt:T)\n with \n0:dt:T\n representing the time vector (\nnot\n returned).\n\n\nKeyword Arguments\n\n\n\n\ndt = 0.05\n : (only for continuous) Time step of value output during the solving of the continuous system.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) A dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \nsolve\n of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :maxiters =\n 1e9)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\n\n\nsource\n\n\n\n\nEspecially in the continuous case, an API is provided for usage directly with \nDifferentialEquations.jl\n, by giving additional constructors:\n\n\n#\n\n\nOrdinaryDiffEq.ODEIntegrator\n \n \nType\n.\n\n\nODEIntegrator\n(\nds\n::\nContinuousDS\n,\n \nt\n \n[\n,\n \nstate\n]\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n\n\n\n\n\n\nReturn an \nODEIntegrator\n to be used directly with the interfaces of \nDifferentialEquations.jl\n.\n\n\ndiff_eq_kwargs = Dict()\n is a dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \ninit\n of \nDifferentialEquations.jl\n, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :tstops =\n 0:0.01:t)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.variational_integrator\n \n \nFunction\n.\n\n\nvariational_integrator(ds::ContinuousDS, k::Int, t, S::Matrix, kwargs...)\n\n\n\n\n\nReturn an \nODEIntegrator\n that represents the variational equations of motion for the system. \nt\n makes the \ntspan\n and if it is \nReal\n instead of \nTuple\n, initial time is assumed zero.\n\n\nThis integrator evolves in parallel the system and \nk\n deviation vectors \nw_i\nw_i\n such that \n\\dot{w}_i = J\\times w_i\n\\dot{w}_i = J\\times w_i\n with \nJ\nJ\n the Jacobian at the current state. \nS\n is the initial \"conditions\" which contain both the system's state as well as the initial diviation vectors: \nS = cat(2, state, ws)\n if \nws\n is a matrix that has as \ncolumns\n the initial deviation vectors.\n\n\nThe only keyword argument for this funcion is \ndiff_eq_kwargs = Dict()\n (see \ntrajectory\n).\n\n\nsource\n\n\n\n\nNotice that if you want to do repeated evolutions of different states of a continuous system, you should use the \nODEIntegrator(ds::DynamicalSystem)\n in conjunction with \nDifferentialEquations.reinit!(integrator, newstate)\n to avoid the intermediate initializations of the integrator each time.", 
            "title": "Time Evolution"
        }, 
        {
            "location": "/definition/evolve/#time-evolution-of-systems", 
            "text": "DynamicalSystems.jl  provides convenient interfaces for the evolution of systems.  #  DynamicalSystemsBase.evolve     Function .  evolve ( ds :: DynamicalSystem ,   T = 1   [ ,   u0 ] ;   diff_eq_kwargs   =   Dict ())   Evolve the  state(ds)  (or  u0  if given) for total time  T  and return the  final_state . For discrete systems  T  corresponds to steps and thus it must be integer.  evolve   does not store  any information about intermediate steps. Use  trajectory  if you want to produce a trajectory of the system. If you want to perform step-by-step evolution of a continuous system, use  ODEIntegrator(ds, args...)  and the  step!(integrator)  function provided by  DifferentialEquations .  source  #  DynamicalSystemsBase.trajectory     Function .  trajectory ( ds :: DynamicalSystem ,   T ;   kwargs ... )   -   dataset   Return a dataset what will contain the trajectory of the sytem, after evolving it for time  T . See  Dataset  for info on how to manipulate this object.  For the discrete case,  T  is an integer and a  T\u00d7D  dataset is returned ( D  is the system dimensionality). For the continuous case, a  W\u00d7D  dataset is returned, with  W = length(0:dt:T)  with  0:dt:T  representing the time vector ( not  returned).  Keyword Arguments   dt = 0.05  : (only for continuous) Time step of value output during the solving of the continuous system.  diff_eq_kwargs = Dict()  : (only for continuous) A dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  solve  of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :maxiters =  1e9) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.   source   Especially in the continuous case, an API is provided for usage directly with  DifferentialEquations.jl , by giving additional constructors:  #  OrdinaryDiffEq.ODEIntegrator     Type .  ODEIntegrator ( ds :: ContinuousDS ,   t   [ ,   state ] ;   diff_eq_kwargs   =   Dict ())   Return an  ODEIntegrator  to be used directly with the interfaces of  DifferentialEquations.jl .  diff_eq_kwargs = Dict()  is a dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  init  of  DifferentialEquations.jl , for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :tstops =  0:0.01:t) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.  source  #  DynamicalSystemsBase.variational_integrator     Function .  variational_integrator(ds::ContinuousDS, k::Int, t, S::Matrix, kwargs...)  Return an  ODEIntegrator  that represents the variational equations of motion for the system.  t  makes the  tspan  and if it is  Real  instead of  Tuple , initial time is assumed zero.  This integrator evolves in parallel the system and  k  deviation vectors  w_i w_i  such that  \\dot{w}_i = J\\times w_i \\dot{w}_i = J\\times w_i  with  J J  the Jacobian at the current state.  S  is the initial \"conditions\" which contain both the system's state as well as the initial diviation vectors:  S = cat(2, state, ws)  if  ws  is a matrix that has as  columns  the initial deviation vectors.  The only keyword argument for this funcion is  diff_eq_kwargs = Dict()  (see  trajectory ).  source   Notice that if you want to do repeated evolutions of different states of a continuous system, you should use the  ODEIntegrator(ds::DynamicalSystem)  in conjunction with  DifferentialEquations.reinit!(integrator, newstate)  to avoid the intermediate initializations of the integrator each time.", 
            "title": "Time Evolution of Systems"
        }, 
        {
            "location": "/definition/dataset/", 
            "text": "Numerical Data\n\n\nNumerical data in \nDynamicalSystems.jl\n is represented by a structure called \nDataset\n\n\n#\n\n\nDynamicalSystemsBase.Dataset\n \n \nType\n.\n\n\nDataset{D, T} \n: AbstractDataset{D,T}\n\n\n\n\n\nA dedicated interface for datasets, i.e. vectors of vectors. It contains \nequally-sized datapoints\n of length \nD\n, represented by \nSVector{D, T}\n, containing numbers of type \nT\n.\n\n\nThe internal data representation is more efficient than having a \nMatrix\n and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables. \ntrajectory\n always returns a \nDataset\n.\n\n\nFor example,\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n)\n \n#this returns a dataset\n\n\ndata\n[\n:\n,\n \n2\n]\n \n# this is the second variable timeseries\n\n\ndata\n[\n1\n]\n \n==\n \ndata\n[\n1\n,\n \n:\n]\n \n# this is the first datapoint (D-dimensional)\n\n\ndata\n[\n5\n,\n \n3\n]\n \n# value of the third variable, at the 5th timepoint\n\n\n\n\n\n\nUse \nMatrix(dataset)\n to create a \nMatrix\n, and \nDataset(matrix)\n to create a \nDataset\n from a matrix. Notice: \nDataset(matrix)\n assumes that each column of the matrix represents one dynamic variable. If instead each column of the matrix represents a datapoint, use \nreinterpret(Dataset, matrix)\n.\n\n\nIf you have various timeseries vectors \nx, y, z, ...\n pass them like \nDataset(x, y, z, ...)\n.\n\n\nSee also \nread_dataset\n, \nwrite_dataset\n and \nminmaxima\n.\n\n\nsource\n\n\n\n\nIn essence a \nDataset\n is simply a container for a \nVector\n of \nSVector\ns. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the \ncolumn\n direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n==\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nhen\n,\n \n10000\n)\n \n# this returns a dataset\n\n\nfor\n \npoint\n \nin\n \ndata\n\n\n# do stuff with each datapoint (vector with as many elements as system dimension)\n\n\nend\n\n\n\n\n\n\nAll functions of our ecosystem that manipulate and use data are expecting an \nAbstractDataset\n subtype. This allows us to define efficient methods that coordinate well with other packages, like e.g. \nneighborhood\n.\n\n\nIf given a matrix, we first convert to \nDataset\n. This means that you should \nfirst convert\n your data to a \nDataset\n if you want to call functions more than once, to avoid constantly converting.\n\n\n\n\nExtrema\n\n\nFunctions that find extrema of a dataset for each timeseries:\n\n\n#\n\n\nDynamicalSystemsBase.minima\n \n \nFunction\n.\n\n\nminima(dataset)\n\n\n\n\n\nReturn an \nSVector\n that contains the minimum elements of each timeseries of the dataset.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.maxima\n \n \nFunction\n.\n\n\nmaxima(dataset)\n\n\n\n\n\nReturn an \nSVector\n that contains the maximum elements of each timeseries of the dataset.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.minmaxima\n \n \nFunction\n.\n\n\nminmaxima(dataset)\n\n\n\n\n\nReturn \nminima(dataset), maxima(dataset)\n without doing the computation twice.\n\n\nsource\n\n\n\n\nDataset IO\n\n\nIn addition to the above, we also offer (very basic) functions that read/write a \nDataset\n from/to a delimited text file:\n\n\n#\n\n\nDynamicalSystemsBase.read_dataset\n \n \nFunction\n.\n\n\nread_dataset\n(\nfile\n,\n \nV\n::\nType\n{\nDataset{D,\n \nT\n}\n}\n,\n \ndelim\n::\nChar\n \n=\n \n  \n;\n \nskipstart\n \n=\n \n0\n)\n\n\n\n\n\n\nRead a \ndelim\n-delimited text file directly into a dataset of dimension \nD\n with numbers of type \nT\n.\n\n\nOptionally skip the first \nskipstart\n rows of the file (that may e.g. contain headers).\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.write_dataset\n \n \nFunction\n.\n\n\nwrite_dataset\n(\nfile\n,\n \ndataset\n::\nAbstractDataset\n,\n \ndelim\n::\nChar\n \n=\n \n   \n;\n \nopts\n...)\n\n\n\n\n\n\nWrite a \ndataset\n in a \ndelim\n-delimited text file.\n\n\nopts\n are keyword arguments passed into \nwritedlm\n.\n\n\nsource\n\n\n\n\nFor example\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n)\n\n\n\n# Write comma-delimited file:\n\n\nwrite_dataset\n(\ntest.csv\n,\n \ndata\n,\n \n,\n)\n\n\n# Read comma-delimited file:\n\n\nread_dataset\n(\ntest.csv\n,\n \nDataset\n{\n2\n,\n \nFloat64\n},\n \n,\n)", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/definition/dataset/#numerical-data", 
            "text": "Numerical data in  DynamicalSystems.jl  is represented by a structure called  Dataset  #  DynamicalSystemsBase.Dataset     Type .  Dataset{D, T}  : AbstractDataset{D,T}  A dedicated interface for datasets, i.e. vectors of vectors. It contains  equally-sized datapoints  of length  D , represented by  SVector{D, T} , containing numbers of type  T .  The internal data representation is more efficient than having a  Matrix  and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables.  trajectory  always returns a  Dataset .  For example,  ds   =   Systems . towel ()  data   =   trajectory ( ds ,   1000 )   #this returns a dataset  data [ : ,   2 ]   # this is the second variable timeseries  data [ 1 ]   ==   data [ 1 ,   : ]   # this is the first datapoint (D-dimensional)  data [ 5 ,   3 ]   # value of the third variable, at the 5th timepoint   Use  Matrix(dataset)  to create a  Matrix , and  Dataset(matrix)  to create a  Dataset  from a matrix. Notice:  Dataset(matrix)  assumes that each column of the matrix represents one dynamic variable. If instead each column of the matrix represents a datapoint, use  reinterpret(Dataset, matrix) .  If you have various timeseries vectors  x, y, z, ...  pass them like  Dataset(x, y, z, ...) .  See also  read_dataset ,  write_dataset  and  minmaxima .  source   In essence a  Dataset  is simply a container for a  Vector  of  SVector s. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the  column  direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:  using   DynamicalSystems  hen   ==   Systems . henon ()  data   =   trajectory ( hen ,   10000 )   # this returns a dataset  for   point   in   data  # do stuff with each datapoint (vector with as many elements as system dimension)  end   All functions of our ecosystem that manipulate and use data are expecting an  AbstractDataset  subtype. This allows us to define efficient methods that coordinate well with other packages, like e.g.  neighborhood .  If given a matrix, we first convert to  Dataset . This means that you should  first convert  your data to a  Dataset  if you want to call functions more than once, to avoid constantly converting.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/definition/dataset/#extrema", 
            "text": "Functions that find extrema of a dataset for each timeseries:  #  DynamicalSystemsBase.minima     Function .  minima(dataset)  Return an  SVector  that contains the minimum elements of each timeseries of the dataset.  source  #  DynamicalSystemsBase.maxima     Function .  maxima(dataset)  Return an  SVector  that contains the maximum elements of each timeseries of the dataset.  source  #  DynamicalSystemsBase.minmaxima     Function .  minmaxima(dataset)  Return  minima(dataset), maxima(dataset)  without doing the computation twice.  source", 
            "title": "Extrema"
        }, 
        {
            "location": "/definition/dataset/#dataset-io", 
            "text": "In addition to the above, we also offer (very basic) functions that read/write a  Dataset  from/to a delimited text file:  #  DynamicalSystemsBase.read_dataset     Function .  read_dataset ( file ,   V :: Type { Dataset{D,   T } } ,   delim :: Char   =      ;   skipstart   =   0 )   Read a  delim -delimited text file directly into a dataset of dimension  D  with numbers of type  T .  Optionally skip the first  skipstart  rows of the file (that may e.g. contain headers).  source  #  DynamicalSystemsBase.write_dataset     Function .  write_dataset ( file ,   dataset :: AbstractDataset ,   delim :: Char   =       ;   opts ...)   Write a  dataset  in a  delim -delimited text file.  opts  are keyword arguments passed into  writedlm .  source   For example  using   DynamicalSystems  ds   =   Systems . towel ()  data   =   trajectory ( ds ,   1000 )  # Write comma-delimited file:  write_dataset ( test.csv ,   data ,   , )  # Read comma-delimited file:  read_dataset ( test.csv ,   Dataset { 2 ,   Float64 },   , )", 
            "title": "Dataset IO"
        }, 
        {
            "location": "/definition/predefined/", 
            "text": "Predefined Systems\n\n\nPredefined systems exist in the \nSystems\n submodule exported by DynamicalSystemsBase.jl, in the form of functions that return a \nDynamicalSystem\n. They are accessed like:\n\n\nusing\n \nDynamicalSystems\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n\n\ntypeof\n(\nds\n)\n \n# ContinuousDS\n\n\nts\n \n=\n \ntrajectory\n(\nds\n,\n \n10.0\n)\n\n\n\n\n\n\nSo far, the predefined systems that exist in the \nSystems\n sub-module are:\n\n\n#\n\n\nDynamicalSystemsBase.Systems.coupledstandardmaps\n \n \nFunction\n.\n\n\ncoupledstandardmaps\n(\nM\n::\nInt\n,\n \nu0\n \n=\n \n0.001\nrand\n(\n2\nM\n);\n \nks\n \n=\n \nones\n(\nM\n),\n \n\u0393\n \n=\n \n1.0\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' \n= \\theta_i + p_{i}' \\\\\np_{i}' \n= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\nA discrete system of \nM\n nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The \ntotal\n dimension of the system is \n2M\n. The maps are coupled through \n\u0393\n and the \ni\n-th map has a nonlinear parameter \nks[i]\n.\n\n\nThe \neom!\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom!.parameter = value\n.\n\n\n[1] : H. Kantz \n P. Grassberger, J. Phys. A \n21\n, pp 127\u2013133 (1988)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.double_pendulum\n \n \nFunction\n.\n\n\ndouble_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)\n\n\n\n\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\n\nThe variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].\n\n\nJacobian is created automatically (thus methods that use the Jacobian will be slower)!\n\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\n\nThe \neom!\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom!.parameter = value\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.duffing\n \n \nFunction\n.\n\n\nduffing(u0 = [rand(), rand(), 0]; \u03c9 = 2.2, f = 27.0, d = 0.2, \u03b2 = 1)\n\n\n\n\n\nThe (forced) duffing oscillator, that satisfies the equation\n\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\nwith \nf, \u03c9\n the forcing strength and frequency and \nd\n the dampening.\n\n\nThe \neom!\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom!.parameter = value\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henon\n \n \nFunction\n.\n\n\nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= 1 - ax^2_n+y_n \\\\\ny_{n+1} \n = bx_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.\n\n\nThe \neom\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom.parameter = value\n.\n\n\n[1] : M. H\u00e9non, Commun.Math. Phys. \n50\n, pp 69 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henonhelies\n \n \nFunction\n.\n\n\nhenonhelies(u0=[0, -0.25, 0.42081,0]; \u03bb = 1)\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= p_x \\\\\n\\dot{y} \n= p_y \\\\\n\\dot{p}_x \n= -x -2\\lambda xy \\\\\n\\dot{p}_y \n= -y -\\lambda (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2\\lambda xy \\\\\n\\dot{p}_y &= -y -\\lambda (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.\n\n\nThe default initial condition is a typical chaotic orbit.\n\n\nThe \neom!\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom!.parameter = value\n.\n\n\n[1] : H\u00e9non, M. \n Heiles, C., The Astronomical Journal \n69\n, pp 73\u201379 (1964)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.logistic\n \n \nFunction\n.\n\n\nlogistic\n(\nx0\n \n=\n \nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n\n\n\n\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\n\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].\n\n\nThe \neom\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom.parameter = value\n.\n\n\n[1] : R. M. May, Nature \n261\n, pp 459 (1976)\n\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. \n19\n, pp 25 (1978)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz\n \n \nFunction\n.\n\n\nlorenz\n(\nu0\n=\n[\n0.0\n,\n \n10.0\n,\n \n0.0\n];\n \n\u03c3\n \n=\n \n10.0\n,\n \n\u03c1\n \n=\n \n28.0\n,\n \n\u03b2\n \n=\n \n8\n/\n3\n)\n \n-\n \nds\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{X} \n= \\sigma(Y-X) \\\\\n\\dot{Y} \n= -XZ + \\rho X -Y \\\\\n\\dot{Z} \n= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\n\nThe \neom!\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom!.parameter = value\n.\n\n\n[1] : E. N. Lorenz, J. atmos. Sci. \n20\n, pp 130 (1963)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz96\n \n \nFunction\n.\n\n\nlorenz96\n(\nN\n::\nInt\n,\n \nu0\n \n=\n \nrand\n(\nM\n);\n \nF\n=\n0\n.\n01\n)\n\n\n\n\n\n\nN\n is the chain length, \nF\n the forcing. Jacobian is created automatically.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.roessler\n \n \nFunction\n.\n\n\nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= -y-z \\\\\n\\dot{y} \n= x+ay \\\\\n\\dot{z} \n= -b + z(x-c)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= -b + z(x-c)\n\\end{aligned}\n\n\n\n\n\nThis three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the \nlorenz\n system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\n\nThe \neom!\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom!.parameter = value\n.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n57A\n, pp 397 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.shinriki\n \n \nFunction\n.\n\n\nshinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)\n\n\n\n\n\nShinriki oscillator with all other parameters (besides \nR1\n) set to constants.\n\n\nAlways use \ndiff_eq_kwargs = Dict(:abstol=\n1e-9, :reltol =\n 1e-9)\n when solving this system because it involves an exponential function.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.standardmap\n \n \nFunction\n.\n\n\nstandardmap\n(\nu0\n=\n0.001\nrand\n(\n2\n);\n \nk\n \n=\n \n0.971635\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} \n= \\theta_n + p_{n+1} \\\\\np_{n+1} \n= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\n\nThe map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter \nk\n transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\n\nThe default parameter \nk\n is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable \n\u03b8\n to be the first, and the angular momentum \np\n to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).\n\n\nThe \neom\n field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using \nds.eom.parameter = value\n.\n\n\n[1] : B. V. Chirikov, Preprint N. \n267\n, Institute of Nuclear Physics, Novosibirsk (1969)\n\n\n[2] : J. M. Greene, J. Math. Phys. \n20\n, pp 1183 (1979)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.towel\n \n \nFunction\n.\n\n\ntowel\n(\nu0\n \n=\n \n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} \n= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} \n= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\nThe folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n71A\n, pp 155 (1979)\n\n\nsource", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/definition/predefined/#predefined-systems", 
            "text": "Predefined systems exist in the  Systems  submodule exported by DynamicalSystemsBase.jl, in the form of functions that return a  DynamicalSystem . They are accessed like:  using   DynamicalSystems  ds   =   Systems . lorenz ( \u03c1   =   32.0 )  typeof ( ds )   # ContinuousDS  ts   =   trajectory ( ds ,   10.0 )   So far, the predefined systems that exist in the  Systems  sub-module are:  #  DynamicalSystemsBase.Systems.coupledstandardmaps     Function .  coupledstandardmaps ( M :: Int ,   u0   =   0.001 rand ( 2 M );   ks   =   ones ( M ),   \u0393   =   1.0 )    \n\\begin{aligned}\n\\theta_{i}'  = \\theta_i + p_{i}' \\\\\np_{i}'  = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}   A discrete system of  M  nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The  total  dimension of the system is  2M . The maps are coupled through  \u0393  and the  i -th map has a nonlinear parameter  ks[i] .  The  eom!  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom!.parameter = value .  [1] : H. Kantz   P. Grassberger, J. Phys. A  21 , pp 127\u2013133 (1988)  source  #  DynamicalSystemsBase.Systems.double_pendulum     Function .  double_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)  Famous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).  The variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].  Jacobian is created automatically (thus methods that use the Jacobian will be slower)!  (please contribute the Jacobian and the e.o.m. in LaTeX :smile:)  The  eom!  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom!.parameter = value .  source  #  DynamicalSystemsBase.Systems.duffing     Function .  duffing(u0 = [rand(), rand(), 0]; \u03c9 = 2.2, f = 27.0, d = 0.2, \u03b2 = 1)  The (forced) duffing oscillator, that satisfies the equation   \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)  \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)   with  f, \u03c9  the forcing strength and frequency and  d  the dampening.  The  eom!  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom!.parameter = value .  source  #  DynamicalSystemsBase.Systems.henon     Function .  henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 )    \n\\begin{aligned}\nx_{n+1}  = 1 - ax^2_n+y_n \\\\\ny_{n+1}   = bx_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}   The H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.  According to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.  The  eom  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom.parameter = value .  [1] : M. H\u00e9non, Commun.Math. Phys.  50 , pp 69 (1976)  source  #  DynamicalSystemsBase.Systems.henonhelies     Function .  henonhelies(u0=[0, -0.25, 0.42081,0]; \u03bb = 1)   \n\\begin{aligned}\n\\dot{x}  = p_x \\\\\n\\dot{y}  = p_y \\\\\n\\dot{p}_x  = -x -2\\lambda xy \\\\\n\\dot{p}_y  = -y -\\lambda (x^2 - y^2)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2\\lambda xy \\\\\n\\dot{p}_y &= -y -\\lambda (x^2 - y^2)\n\\end{aligned}   The H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.  The default initial condition is a typical chaotic orbit.  The  eom!  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom!.parameter = value .  [1] : H\u00e9non, M.   Heiles, C., The Astronomical Journal  69 , pp 73\u201379 (1964)  source  #  DynamicalSystemsBase.Systems.logistic     Function .  logistic ( x0   =   rand ();   r   =   4.0 )    \nx_{n+1} = rx_n(1-x_n)  \nx_{n+1} = rx_n(1-x_n)   The logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.  Originally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].  The  eom  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom.parameter = value .  [1] : R. M. May, Nature  261 , pp 459 (1976)  [2] : M. J. Feigenbaum, J. Stat. Phys.  19 , pp 25 (1978)  source  #  DynamicalSystemsBase.Systems.lorenz     Function .  lorenz ( u0 = [ 0.0 ,   10.0 ,   0.0 ];   \u03c3   =   10.0 ,   \u03c1   =   28.0 ,   \u03b2   =   8 / 3 )   -   ds    \n\\begin{aligned}\n\\dot{X}  = \\sigma(Y-X) \\\\\n\\dot{Y}  = -XZ + \\rho X -Y \\\\\n\\dot{Z}  = XY - \\beta Z\n\\end{aligned}  \n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}   The famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.  Currently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.  The  eom!  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom!.parameter = value .  [1] : E. N. Lorenz, J. atmos. Sci.  20 , pp 130 (1963)  source  #  DynamicalSystemsBase.Systems.lorenz96     Function .  lorenz96 ( N :: Int ,   u0   =   rand ( M );   F = 0 . 01 )   N  is the chain length,  F  the forcing. Jacobian is created automatically.  source  #  DynamicalSystemsBase.Systems.roessler     Function .  roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 )    \n\\begin{aligned}\n\\dot{x}  = -y-z \\\\\n\\dot{y}  = x+ay \\\\\n\\dot{z}  = -b + z(x-c)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= -b + z(x-c)\n\\end{aligned}   This three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the  lorenz  system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.  The  eom!  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom!.parameter = value .  [1] : O. E. R\u00f6ssler, Phys. Lett.  57A , pp 397 (1976)  source  #  DynamicalSystemsBase.Systems.shinriki     Function .  shinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)  Shinriki oscillator with all other parameters (besides  R1 ) set to constants.  Always use  diff_eq_kwargs = Dict(:abstol= 1e-9, :reltol =  1e-9)  when solving this system because it involves an exponential function.  source  #  DynamicalSystemsBase.Systems.standardmap     Function .  standardmap ( u0 = 0.001 rand ( 2 );   k   =   0.971635 )    \n\\begin{aligned}\n\\theta_{n+1}  = \\theta_n + p_{n+1} \\\\\np_{n+1}  = p_n + k\\sin(\\theta_n)\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}   The standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.  The map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter  k  transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.  The default parameter  k  is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable  \u03b8  to be the first, and the angular momentum  p  to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).  The  eom  field of the returned system has as fields the keyword arguments of this function. You can access them and change their value at any point using  ds.eom.parameter = value .  [1] : B. V. Chirikov, Preprint N.  267 , Institute of Nuclear Physics, Novosibirsk (1969)  [2] : J. M. Greene, J. Math. Phys.  20 , pp 1183 (1979)  source  #  DynamicalSystemsBase.Systems.towel     Function .  towel ( u0   =   [ 0.085 ,   - 0.121 ,   0.075 ])    \n\\begin{aligned}\nx_{n+1}  = a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1}  = 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1}  = 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}   The folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.  Default values are the ones used in the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  71A , pp 155 (1979)  source", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/chaos/overview/", 
            "text": "Features Overview\n\n\nThe features offered in this documentation section come from the package \nChaosTools.jl\n. If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.\n\n\n\n\nOrbit Diagrams\n\n\n\n\nOrbit diagrams (aka bifurcation diagrams) of maps: \norbitdiagram\n.\n\n\nPoincar\u00e9 surfaces of section for continuous systems: \npoincaresos\n.\n\n\nAutomated production of orbit diagrams for continuous systems: \nproduce_orbitdiagram\n.\n\n\n\n\n\n\nLyapunov Exponents\n\n\nThe following treat systems where the equations of motion are known:\n\n\n\n\nMaximum Lyapunov exponent for both discrete and continuous systems: \nlyapunov\n.\n\n\nLyapunov \nspectrum\n for both discrete and continuous systems: \nlyapunovs\n.\n\n\n\n\n\n\nEntropies and Dimensions\n\n\n\n\nGeneralized (Renyi) entropy and all related entropies: \ngenentropy\n.\n\n\nVery fast and very cheap (memory-wise) method for computing entropies of large datasets.\n\n\nGeneralized dimensions (e.g. capacity dimension, information dimension, etc.): \ngeneralized_dim\n.\n\n\nKaplan-Yorke dimension: \nkaplanyorke_dim\n.\n\n\nAutomated detection of best algorithmic parameters for calculating attractor dimensions.\n\n\n\n\nAnd, in order to automatically deduce dimensions, we also offer methods for:\n\n\n\n\nPartitioning a function \ny(x)\ny(x)\n vs. \nx\nx\n into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See \nlinear_regions\n.\n\n\nDetection of largest linear region of a function \ny(x)\ny(x)\n vs. \nx\nx\n and extraction of the slope of this region.\n\n\n\n\n\n\nNonlinear Timeseries Analysis\n\n\n\n\nFlexible and abstracted \nReconstruction\n interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.\n\n\nMethods for estimating good \nReconstruction\n parameters.\n\n\n\n\nFour different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries: \nnumericallyapunov\n.\n\n\n\n\nFast computation of the above algorithms made possible by combining the\n\n\n\n\nperformance of \nNearestNeighbors.jl\n with  the abstraction of ChaosTools.jl.\n\n\n\n\n\n\n\n\nPeriodicity\n\n\n\n\n\n\nNumerical method to find unstable and stable fixed points of \nany order\n \nn\nn\n of a discrete map (of any dimensionality): \nperiodicorbits\n.\n\n\n\n\nConvenience functions for defining and realizing all possible combinations of \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrices required in the above method.\n\n\n\n\n\n\n\n\n\n\nChaos Detection\n\n\n\n\n\n\nThe Generalized Alignment Index: \n\\text{GALI}_k\n\\text{GALI}_k\n : \ngali\n.\n\n\n\n\nImplemented for both discrete and continuous systems.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#features-overview", 
            "text": "The features offered in this documentation section come from the package  ChaosTools.jl . If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#orbit-diagrams", 
            "text": "Orbit diagrams (aka bifurcation diagrams) of maps:  orbitdiagram .  Poincar\u00e9 surfaces of section for continuous systems:  poincaresos .  Automated production of orbit diagrams for continuous systems:  produce_orbitdiagram .", 
            "title": "Orbit Diagrams"
        }, 
        {
            "location": "/chaos/overview/#lyapunov-exponents", 
            "text": "The following treat systems where the equations of motion are known:   Maximum Lyapunov exponent for both discrete and continuous systems:  lyapunov .  Lyapunov  spectrum  for both discrete and continuous systems:  lyapunovs .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/overview/#entropies-and-dimensions", 
            "text": "Generalized (Renyi) entropy and all related entropies:  genentropy .  Very fast and very cheap (memory-wise) method for computing entropies of large datasets.  Generalized dimensions (e.g. capacity dimension, information dimension, etc.):  generalized_dim .  Kaplan-Yorke dimension:  kaplanyorke_dim .  Automated detection of best algorithmic parameters for calculating attractor dimensions.   And, in order to automatically deduce dimensions, we also offer methods for:   Partitioning a function  y(x) y(x)  vs.  x x  into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See  linear_regions .  Detection of largest linear region of a function  y(x) y(x)  vs.  x x  and extraction of the slope of this region.", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/overview/#nonlinear-timeseries-analysis", 
            "text": "Flexible and abstracted  Reconstruction  interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.  Methods for estimating good  Reconstruction  parameters.   Four different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries:  numericallyapunov .   Fast computation of the above algorithms made possible by combining the   performance of  NearestNeighbors.jl  with  the abstraction of ChaosTools.jl.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/overview/#periodicity", 
            "text": "Numerical method to find unstable and stable fixed points of  any order   n n  of a discrete map (of any dimensionality):  periodicorbits .   Convenience functions for defining and realizing all possible combinations of  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrices required in the above method.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/overview/#chaos-detection", 
            "text": "The Generalized Alignment Index:  \\text{GALI}_k \\text{GALI}_k  :  gali .   Implemented for both discrete and continuous systems.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/orbitdiagram/", 
            "text": "Orbit Diagrams of Maps\n\n\nAn orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed\n\n\n#\n\n\nChaosTools.orbitdiagram\n \n \nFunction\n.\n\n\norbitdiagram\n(\nds\n::\nDiscreteDynamicalSystem\n,\n \ni\n::\nInt\n,\n \nparameter\n::\nSymbol\n,\n \npvalues\n;\n\n\nn\n::\nInt\n \n=\n \n100\n,\n \nTtr\n::\nInt\n \n=\n \n1000\n,\n \nics\n \n=\n \n[\nstate\n(\nds\n)\n]\n)\n \n-\n \noutput\n\n\n\n\n\n\nCompute the orbit diagram (also called bifurcation diagram) of the given system for the \ni\n-th variable for parameter values \npvalues\n. The \nparameter\n specifies which parameter of the equations of motion is to be changed.\n\n\nThis function assumes that you have created the \nContinuousDS\n using functors; see the \nofficial documentation\n for more.\n\n\nKeyword Arguments\n\n\n\n\nics = [state(ds)]\n : container of initial conditions that are used at each parameter value to evolve orbits.\n\n\nTtr::Int = 1000\n : Transient steps; each orbit is evolved for \nTtr\n first before saving output.\n\n\nn::Int = 100\n : Amount of points to save for each initial condition.\n\n\n\n\nDescription\n\n\nThe method works by computing orbits at each parameter value in \npvalues\n for each initial condition in \nics\n. The symbol of the parameter is used to set \nds.eom.parameter\n or \nds.eom!.parameter\n.\n\n\nThe returned \noutput\n is a vector of vectors. \noutput[j]\n are the orbit points of the \ni\n-th variable of the system, at parameter value \npvalues[j]\n.\n\n\nSee also \npoincaresos\n and \nproduce_orbitdiagram\n.\n\n\nsource\n\n\n\n\nFor example, let's compute the famous orbit diagram of the logistic map:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\ni\n \n=\n \n1\n\n\npvalues\n \n=\n \n2\n:\n0.001\n:\n4\n\n\nics\n \n=\n \n[\nrand\n()\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n50\n\n\nTtr\n \n=\n \n5000\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \n:\nr\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nr\n\\$\n);\n \nylabel\n(\n\\$\nx\n\\$\n)\n\n\n\n\n\n\n\n\nNotice that if you are using \nPyPlot\n, the plotting process will be slow, since it is slow at plotting big numbers of points.\n\n\nThe function is not limited to 1D maps, and can be applied just as well to any discrete system.\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\ni\n \n=\n \n2\n\n\n\npvalues\n \n=\n \n0\n:\n0.005\n:\n2\n\n\nics\n \n=\n \n[\n0.001\nrand\n(\n2\n)\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n50\n\n\nTtr\n \n=\n \n5000\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \n:\nk\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n,\n \nics\n \n=\n \nics\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nk\n\\$\n);\n \nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\n\n\n\n\nPoincar\u00e9 Surface of Section\n\n\nAlso called \nPoincar\u00e9 map\n is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:\n\n\n#\n\n\nChaosTools.poincaresos\n \n \nFunction\n.\n\n\npoincaresos\n(\nds\n::\nContinuousDS\n,\n \nj\n,\n \ntfinal\n \n=\n \n100\n.\n0\n;\n \nkwargs\n...)\n\n\n\n\n\n\nCalculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1,2] of the given system on the plane of the \nj\n-th variable of the system. The system is evolved for total time of \ntfinal\n.\n\n\nReturns a \nDataset\n of the points that are on the surface of section.\n\n\nThis function assumes that you have created the \nContinuousDS\n using functors; see the \nofficial documentation\n for more.\n\n\nKeyword Arguments\n\n\n\n\ndirection = 1\n and \noffset = 0.0\n : The surface of section is defined as the (hyper-) plane where \nstate[j] = offset\n. Only crossings of the plane that have direction \nsign(direction)\n are considered to belong to the surface of section.\n\n\nTtr = 0.0\n : Transient time to evolve the system before starting to compute the PSOS.\n\n\ndiff_eq_kwargs = Dict()\n : See \ntrajectory\n.\n\n\ncallback_kwargs = Dict(:abstol=\n1e-6)\n : Keyword arguments passed into the \nContinuousCallback\n type of \nDifferentialEquations\n. The option \ncallback_kwargs[:idxs] = j\n is enforced.\n\n\n\n\nReferences\n\n\n[1] : H. Poincar\u00e9, \nLes Methods Nouvelles de la M\u00e9canique Celeste\n, Paris: Gauthier-Villars (1892)\n\n\n[2] : M. Tabor, \nChaos and Integrability in Nonlinear Dynamics: An Introduction\n, \u00a74.1, in pp. 118-126, New York: Wiley (1989)\n\n\nSee also \norbitdiagram\n, \nproduce_orbitdiagram\n.\n\n\nsource\n\n\n\n\nAn example of the \nHenon-Helies\n system using a quasi-periodic solution\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n([\n0.\n,\n \n0.1\n,\n \n0.5\n,\n \n0.\n])\n\n\noutput\n \n=\n \npoincaresos\n(\nds\n,\n \n3\n,\n \n1000.0\n,\n \ndiff_eq_kwargs\n=\nDict\n(\n:\nsolver\n=\nVern9\n()))\n\n\n\nfigure\n()\n\n\nplot\n(\noutput\n[\n:\n,\n \n2\n],\n \noutput\n[\n:\n,\n \n4\n],\n \nlw\n \n=\n \n0.0\n,\n \nmarker\n=\n.\n)\n\n\nxlabel\n(\n\\$\nq_2\n\\$\n);\n \nylabel\n(\n\\$\np_2\n\\$\n);\n\n\n\n\n\n\n\n\nHere the surface of section was the (hyper-) plane that \np_1 = 0\np_1 = 0\n. As expected the section is 1-dimensional, because the torus the solution lives in is 2-dimensional. if we produced the PSOS for much longer times, the result would be a filled line instead of individual points.\n\n\n\n\nStroboscopic Map\n\n\nA special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the \nDuffing oscillator\n.\n\n\nA PSOS at this case can be produced at every period \nT = 2\\pi/\\omega\nT = 2\\pi/\\omega\n. There is no reason to use \npoincaresos\n for this case though, because you can simply use \ntrajectory\n and get the solution with a certain time distance:\n\n\nds\n \n=\n \nSystems\n.\nduffing\n(\n\u03b2\n \n=\n \n-\n1\n,\n \n\u03c9\n \n=\n \n1\n,\n \nf\n \n=\n \n0.3\n)\n \n# non-autonomous chaotic system\n\n\na\n \n=\n \ntrajectory\n(\nds\n,\n \n100000.0\n,\n \ndt\n \n=\n \n2\n\u03c0\n)\n \n# every period T = 2\u03c0/\u03c9\n\n\nplot\n(\na\n[\n:\n,\n \n1\n],\n \na\n[\n:\n,\n \n2\n],\n \nlw\n \n=\n \n0\n,\n \nmarker\n \n=\no\n,\n \nms\n \n=\n \n1\n)\n\n\nxlabel\n(\n\\$\nx\n\\$\n);\n \nylabel\n(\n\\$\\\\\ndot{x}\n\\$\n)\n\n\n\n\n\n\n What a cool looking attractor is that!\n\n\n\n\nProducing Orbit Diagrams for Continuous Flows\n\n\nThe \norbitdiagram\n does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for \norbitdiagram\n to have meaning one must have a map.\n\n\nIf only there was a way to turn a continuous system into a map... \nOH WAIT!\n That is what \npoincaresos\n does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.\n\n\nWe have bundled this process in the following function:\n\n\n#\n\n\nChaosTools.produce_orbitdiagram\n \n \nFunction\n.\n\n\nproduce_orbitdiagram\n(\nds\n::\nContinuousDS\n,\n \nj\n,\n \ni\n,\n \nparameter\n::\nSymbol\n,\n \npvalues\n;\n \nkwargs\n...)\n\n\n\n\n\n\nProduce an orbit diagram (also called bifurcation diagram) for the \ni\n-th variable of the given continuous system by computing Poincar\u00e9 surfaces of section of the \nj\n-th variable of the system for the given parameter values.\n\n\nThis funtion assumes that you have created the \nContinuousDS\n using functors; see the \nofficial documentation\n for more.\n\n\nKeyword Arguments\n\n\n\n\ndirection\n, \noffset\n, \ndiff_eq_kwargs\n, \ncallback_kwargs\n, \nTtr\n : Passed into \npoincaresos\n.\n\n\nprintparams::Bool = false\n : Whether to print the parameter used during computation in order to keep track of running time.\n\n\nics = [state(ds)]\n : Collection of initial conditions. For every \nstate \u2208 ics\n a PSOS will be produced.\n\n\n\n\nDescription\n\n\nparameter\n is a symbol that indicates which parameter of \nds.prob.f\n should be updated. \npvalues\n is a collection with all the parameter values that the orbit diagram will be computed for.\n\n\nFor each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for one of the \ni \u2260 j\n variables of the system, just like it is done in \norbitdiagram\n.\n\n\nThe returned \noutput\n is a vector of vectors. \noutput[k]\n are the \"orbit diagram\" points of the \ni\n-th variable of the system, at parameter value \npvalues[k]\n.\n\n\nPerformance Notes\n\n\nThe total amount of PSOS produced will be \nlength(ics)*length(pvalues)\n.\n\n\nSee also \npoincaresos\n, \norbitdiagram\n.\n\n\nsource\n\n\n\n\nFor example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!\n\n\nds\n \n=\n \nSystems\n.\nshinriki\n([\n-\n2\n,\n \n0\n,\n \n0.2\n])\n\n\n\npvalues\n \n=\n \nlinspace\n(\n19\n,\n22\n,\n201\n)\n\n\ni\n \n=\n \n1\n\n\nj\n \n=\n \n2\n\n\ntf\n \n=\n \n200.0\n\n\n\nde\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n \n=\n \n1e-9\n)\n \n#necessary due to exponential function\n\n\n\noutput\n \n=\n \nproduce_orbitdiagram\n(\nds\n,\n \nj\n,\n \ni\n,\n \n:\nR1\n,\n \npvalues\n;\n \ntfinal\n \n=\n \ntf\n,\n\n\nTtr\n \n=\n \n200.0\n,\n \ndiff_eq_kwargs\n \n=\n \nde\n,\n \ndirection\n \n=\n \n-\n1\n,\n \nprintparams\n \n=\n \ntrue\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nR_1\n\\$\n);\n \nylabel\n(\n\\$\nV_1\n\\$\n)", 
            "title": "Orbit Diagrams & PSOS"
        }, 
        {
            "location": "/chaos/orbitdiagram/#orbit-diagrams-of-maps", 
            "text": "An orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed  #  ChaosTools.orbitdiagram     Function .  orbitdiagram ( ds :: DiscreteDynamicalSystem ,   i :: Int ,   parameter :: Symbol ,   pvalues ;  n :: Int   =   100 ,   Ttr :: Int   =   1000 ,   ics   =   [ state ( ds ) ] )   -   output   Compute the orbit diagram (also called bifurcation diagram) of the given system for the  i -th variable for parameter values  pvalues . The  parameter  specifies which parameter of the equations of motion is to be changed.  This function assumes that you have created the  ContinuousDS  using functors; see the  official documentation  for more.  Keyword Arguments   ics = [state(ds)]  : container of initial conditions that are used at each parameter value to evolve orbits.  Ttr::Int = 1000  : Transient steps; each orbit is evolved for  Ttr  first before saving output.  n::Int = 100  : Amount of points to save for each initial condition.   Description  The method works by computing orbits at each parameter value in  pvalues  for each initial condition in  ics . The symbol of the parameter is used to set  ds.eom.parameter  or  ds.eom!.parameter .  The returned  output  is a vector of vectors.  output[j]  are the orbit points of the  i -th variable of the system, at parameter value  pvalues[j] .  See also  poincaresos  and  produce_orbitdiagram .  source   For example, let's compute the famous orbit diagram of the logistic map:  using   DynamicalSystems  using   PyPlot  ds   =   Systems . logistic ()  i   =   1  pvalues   =   2 : 0.001 : 4  ics   =   [ rand ()   for   m   in   1 : 10 ]  n   =   50  Ttr   =   5000  output   =   orbitdiagram ( ds ,   i ,   : r ,   pvalues ;   n   =   n ,   Ttr   =   Ttr )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ r \\$ );   ylabel ( \\$ x \\$ )    Notice that if you are using  PyPlot , the plotting process will be slow, since it is slow at plotting big numbers of points.  The function is not limited to 1D maps, and can be applied just as well to any discrete system.  ds   =   Systems . standardmap ()  i   =   2  pvalues   =   0 : 0.005 : 2  ics   =   [ 0.001 rand ( 2 )   for   m   in   1 : 10 ]  n   =   50  Ttr   =   5000  output   =   orbitdiagram ( ds ,   i ,   : k ,   pvalues ;   n   =   n ,   Ttr   =   Ttr ,   ics   =   ics )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ k \\$ );   ylabel ( \\$ p \\$ )", 
            "title": "Orbit Diagrams of Maps"
        }, 
        {
            "location": "/chaos/orbitdiagram/#poincare-surface-of-section", 
            "text": "Also called  Poincar\u00e9 map  is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:  #  ChaosTools.poincaresos     Function .  poincaresos ( ds :: ContinuousDS ,   j ,   tfinal   =   100 . 0 ;   kwargs ...)   Calculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1,2] of the given system on the plane of the  j -th variable of the system. The system is evolved for total time of  tfinal .  Returns a  Dataset  of the points that are on the surface of section.  This function assumes that you have created the  ContinuousDS  using functors; see the  official documentation  for more.  Keyword Arguments   direction = 1  and  offset = 0.0  : The surface of section is defined as the (hyper-) plane where  state[j] = offset . Only crossings of the plane that have direction  sign(direction)  are considered to belong to the surface of section.  Ttr = 0.0  : Transient time to evolve the system before starting to compute the PSOS.  diff_eq_kwargs = Dict()  : See  trajectory .  callback_kwargs = Dict(:abstol= 1e-6)  : Keyword arguments passed into the  ContinuousCallback  type of  DifferentialEquations . The option  callback_kwargs[:idxs] = j  is enforced.   References  [1] : H. Poincar\u00e9,  Les Methods Nouvelles de la M\u00e9canique Celeste , Paris: Gauthier-Villars (1892)  [2] : M. Tabor,  Chaos and Integrability in Nonlinear Dynamics: An Introduction , \u00a74.1, in pp. 118-126, New York: Wiley (1989)  See also  orbitdiagram ,  produce_orbitdiagram .  source   An example of the  Henon-Helies  system using a quasi-periodic solution  ds   =   Systems . henonhelies ([ 0. ,   0.1 ,   0.5 ,   0. ])  output   =   poincaresos ( ds ,   3 ,   1000.0 ,   diff_eq_kwargs = Dict ( : solver = Vern9 ()))  figure ()  plot ( output [ : ,   2 ],   output [ : ,   4 ],   lw   =   0.0 ,   marker = . )  xlabel ( \\$ q_2 \\$ );   ylabel ( \\$ p_2 \\$ );    Here the surface of section was the (hyper-) plane that  p_1 = 0 p_1 = 0 . As expected the section is 1-dimensional, because the torus the solution lives in is 2-dimensional. if we produced the PSOS for much longer times, the result would be a filled line instead of individual points.", 
            "title": "Poincar\u00e9 Surface of Section"
        }, 
        {
            "location": "/chaos/orbitdiagram/#stroboscopic-map", 
            "text": "A special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the  Duffing oscillator .  A PSOS at this case can be produced at every period  T = 2\\pi/\\omega T = 2\\pi/\\omega . There is no reason to use  poincaresos  for this case though, because you can simply use  trajectory  and get the solution with a certain time distance:  ds   =   Systems . duffing ( \u03b2   =   - 1 ,   \u03c9   =   1 ,   f   =   0.3 )   # non-autonomous chaotic system  a   =   trajectory ( ds ,   100000.0 ,   dt   =   2 \u03c0 )   # every period T = 2\u03c0/\u03c9  plot ( a [ : ,   1 ],   a [ : ,   2 ],   lw   =   0 ,   marker   = o ,   ms   =   1 )  xlabel ( \\$ x \\$ );   ylabel ( \\$\\\\ dot{x} \\$ )    What a cool looking attractor is that!", 
            "title": "Stroboscopic Map"
        }, 
        {
            "location": "/chaos/orbitdiagram/#producing-orbit-diagrams-for-continuous-flows", 
            "text": "The  orbitdiagram  does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for  orbitdiagram  to have meaning one must have a map.  If only there was a way to turn a continuous system into a map...  OH WAIT!  That is what  poincaresos  does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.  We have bundled this process in the following function:  #  ChaosTools.produce_orbitdiagram     Function .  produce_orbitdiagram ( ds :: ContinuousDS ,   j ,   i ,   parameter :: Symbol ,   pvalues ;   kwargs ...)   Produce an orbit diagram (also called bifurcation diagram) for the  i -th variable of the given continuous system by computing Poincar\u00e9 surfaces of section of the  j -th variable of the system for the given parameter values.  This funtion assumes that you have created the  ContinuousDS  using functors; see the  official documentation  for more.  Keyword Arguments   direction ,  offset ,  diff_eq_kwargs ,  callback_kwargs ,  Ttr  : Passed into  poincaresos .  printparams::Bool = false  : Whether to print the parameter used during computation in order to keep track of running time.  ics = [state(ds)]  : Collection of initial conditions. For every  state \u2208 ics  a PSOS will be produced.   Description  parameter  is a symbol that indicates which parameter of  ds.prob.f  should be updated.  pvalues  is a collection with all the parameter values that the orbit diagram will be computed for.  For each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for one of the  i \u2260 j  variables of the system, just like it is done in  orbitdiagram .  The returned  output  is a vector of vectors.  output[k]  are the \"orbit diagram\" points of the  i -th variable of the system, at parameter value  pvalues[k] .  Performance Notes  The total amount of PSOS produced will be  length(ics)*length(pvalues) .  See also  poincaresos ,  orbitdiagram .  source   For example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!  ds   =   Systems . shinriki ([ - 2 ,   0 ,   0.2 ])  pvalues   =   linspace ( 19 , 22 , 201 )  i   =   1  j   =   2  tf   =   200.0  de   =   Dict ( : abstol = 1e-9 ,   : reltol   =   1e-9 )   #necessary due to exponential function  output   =   produce_orbitdiagram ( ds ,   j ,   i ,   : R1 ,   pvalues ;   tfinal   =   tf ,  Ttr   =   200.0 ,   diff_eq_kwargs   =   de ,   direction   =   - 1 ,   printparams   =   true )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ R_1 \\$ );   ylabel ( \\$ V_1 \\$ )", 
            "title": "Producing Orbit Diagrams for Continuous Flows"
        }, 
        {
            "location": "/chaos/lyapunovs/", 
            "text": "Lyapunov Exponents\n\n\nLyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The \nWikipedia\n and the \nScholarpedia\n entries have a lot of valuable information about the history and usage of these quantities.\n\n\nThis page treats systems where the equations of motion are known. If instead you have numerical data, see the \nnonlinear timeseries analysis page\n.\n\n\n\n\nLyapunov Spectrum\n\n\nThe function \nlyapunovs\n calculates the entire spectrum of the Lyapunov exponents of a system:\n\n\n#\n\n\nChaosTools.lyapunovs\n \n \nFunction\n.\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n;\n \nkwargs\n...\n)\n \n-\n \n[\n\u03bb1\n,\n \n\u03bb2\n,\n \n...\n,\n \n\u03bbD\n]\n\n\n\n\n\n\nCalculate the spectrum of Lyapunov exponents [1] of \nds\n by applying a QR-decomposition on the parallelepiped matrix \nN\n times. Return the spectrum sorted from maximum to minimum.\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\ndt = 1.0\n : (only for continuous) Time of individual evolutions between successive orthonormalization steps.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\n\n\nDescription\n\n\nThe method we employ is \"H2\" of [2], originally stated in [3]. The vectors defining a \nD\n-dimensional parallepiped are evolved using the tangent dynamics (known also as variational equations) of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over \nN\n successive steps, yielding the lyapunov exponent spectrum.\n\n\nFor discrete systems the QR-decomposition is performed at \nevery\n step \ni \u2208 1:N\n.\n\n\nReferences\n\n\n[1] : A. M. Lyapunov, \nThe General Problem of the Stability of Motion\n, Taylor \n Francis (1992)\n\n\n[2] : K. Geist \net al.\n, Progr. Theor. Phys. \n83\n, pp 875 (1990)\n\n\n[3] : G. Benettin \net al.\n, Meccanica \n15\n, pp 9-20 \n 21-30 (1980)\n\n\nsource\n\n\n\n\nAs you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the \nfolded towel map\n is calculated as:\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nds\n,\n \n10000\n)\n\n\n\n\n\n\n[\n0.432253\n,\n \n0.371617\n,\n \n-\n3.29632\n]\n\n\n\n\n\n\nSimilarly, for a continuous system, e.g. the Lorenz system, you would do:\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n \n#this is not the original parameter!\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nlor\n,\n \n10000\n,\n\n\ndt\n \n=\n \n0.1\n,\n \ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nabstol\n \n=\n \n1e-9\n,\n \n:\nreltol\n \n=\n \n1e-9\n))\n\n\n\n\n\n\n[\n0.985688\n,\n \n0.00271333\n,\n \n-\n14.6551\n]\n\n\n\n\n\n\n\n\nMaximum Lyapunov Exponent\n\n\nThe function \nlyapunov\n calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of \nlyapunovs\n:\n\n\n#\n\n\nChaosTools.lyapunov\n \n \nFunction\n.\n\n\nlyapunov\n(\nds\n::\nDynamicalSystem\n,\n \n\u03a4\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCalculate the maximum Lyapunov exponent \n\u03bb\n using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one. \nT\n  denotes the total time of evolution (should be \nInt\n for discrete systems).\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\nd0 = 1e-9\n : Initial \n rescaling distance between the two neighboring trajectories.\n\n\nthreshold = 1e-5\n : Distance threshold for rescaling.\n\n\ndiff_eq_kwargs = Dict(:abstol=\nd0, :reltol=\nd0)\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\ndt = 0.1\n : (only for continuous) Time of evolution between each check of distance exceeding the \nthreshold\n.\n\n\ninittest = (st1, d0) -\n st1 .+ d0/sqrt(D)\n : A function that given \n(st1, d0)\n initializes the test state with distance \nd0\n from the given state \nst1\n (\nD\n is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.\n\n\n\n\nDescription\n\n\nTwo neighboring trajectories with initial distance \nd0\n are evolved in time. At time \nd(t_i)\nd(t_i)\n their distance exceeds the \nthreshold\n, which initializes a rescaling of the test trajectory back to having distance \nd0\n from the given one, while the rescaling keeps the distance vector along the maximal expansion direction.\n\n\nThe maximum Lyapunov exponent is the average of the time-local Lyapunov exponents\n\n\n\n\n\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\nPerformance Notes\n\n\nFor the continuous case, the algorithm becomes faster with increasing \ndt\n, since integration is interrupted less frequenty. For the fastest performance you want to fine-tune \ndt, d0, threshold\n such that you have the minimum amount of rescalings \nwhile still being well within the linearized dynamics region\n.\n\n\nYou can easily modify the source code to return the convergence timeseries of the exponent, if need be.\n\n\nReferences\n\n\n[1] : G. Benettin \net al.\n, Phys. Rev. A \n14\n, pp 2338 (1976)\n\n\nsource\n\n\n\n\nFor example:\n\n\nusing\n \nDynamicalSystems\n\n\n\nhenon\n \n=\n \nSystems\n.\nhenon\n()\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nhenon\n,\n \n10000\n,\n \nd0\n \n=\n \n1e-7\n,\n \nthreshold\n \n=\n \n1e-4\n,\n \nTtr\n \n=\n \n100\n)\n\n\n\n\n\n\n0.42007471604734054\n\n\n\n\n\nThe same is done for continuous systems:\n\n\nusing\n \nDynamicalSystems\n,\n \nOrdinaryDiffEq\n\n\n\nross\n \n=\n \nSystems\n.\nroessler\n(\na\n \n=\n \n0.1\n,\n \nb\n \n=\n \n0.1\n,\n \nc\n \n=\n \n14.0\n)\n \n#not original parameters\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nross\n,\n \n100000\n,\n \ndt\n \n=\n \n10.0\n,\n\n\ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nsolver\n \n=\n \nVern8\n(),\n \n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n),\n\n\nTtr\n \n=\n \n100.0\n)\n\n\n\n\n\n\n0.07127399326422117", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-exponents", 
            "text": "Lyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The  Wikipedia  and the  Scholarpedia  entries have a lot of valuable information about the history and usage of these quantities.  This page treats systems where the equations of motion are known. If instead you have numerical data, see the  nonlinear timeseries analysis page .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-spectrum", 
            "text": "The function  lyapunovs  calculates the entire spectrum of the Lyapunov exponents of a system:  #  ChaosTools.lyapunovs     Function .  lyapunovs ( ds :: DynamicalSystem ,   N ;   kwargs ... )   -   [ \u03bb1 ,   \u03bb2 ,   ... ,   \u03bbD ]   Calculate the spectrum of Lyapunov exponents [1] of  ds  by applying a QR-decomposition on the parallelepiped matrix  N  times. Return the spectrum sorted from maximum to minimum.  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  dt = 1.0  : (only for continuous) Time of individual evolutions between successive orthonormalization steps.  diff_eq_kwargs = Dict()  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).   Description  The method we employ is \"H2\" of [2], originally stated in [3]. The vectors defining a  D -dimensional parallepiped are evolved using the tangent dynamics (known also as variational equations) of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over  N  successive steps, yielding the lyapunov exponent spectrum.  For discrete systems the QR-decomposition is performed at  every  step  i \u2208 1:N .  References  [1] : A. M. Lyapunov,  The General Problem of the Stability of Motion , Taylor   Francis (1992)  [2] : K. Geist  et al. , Progr. Theor. Phys.  83 , pp 875 (1990)  [3] : G. Benettin  et al. , Meccanica  15 , pp 9-20   21-30 (1980)  source   As you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the  folded towel map  is calculated as:  using   DynamicalSystems  ds   =   Systems . towel ()  \u03bb\u03bb   =   lyapunovs ( ds ,   10000 )   [ 0.432253 ,   0.371617 ,   - 3.29632 ]   Similarly, for a continuous system, e.g. the Lorenz system, you would do:  lor   =   Systems . lorenz ( \u03c1   =   32.0 )   #this is not the original parameter!  \u03bb\u03bb   =   lyapunovs ( lor ,   10000 ,  dt   =   0.1 ,   diff_eq_kwargs   =   Dict ( : abstol   =   1e-9 ,   : reltol   =   1e-9 ))   [ 0.985688 ,   0.00271333 ,   - 14.6551 ]", 
            "title": "Lyapunov Spectrum"
        }, 
        {
            "location": "/chaos/lyapunovs/#maximum-lyapunov-exponent", 
            "text": "The function  lyapunov  calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of  lyapunovs :  #  ChaosTools.lyapunov     Function .  lyapunov ( ds :: DynamicalSystem ,   \u03a4 ;   kwargs ... )   Calculate the maximum Lyapunov exponent  \u03bb  using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one.  T   denotes the total time of evolution (should be  Int  for discrete systems).  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  d0 = 1e-9  : Initial   rescaling distance between the two neighboring trajectories.  threshold = 1e-5  : Distance threshold for rescaling.  diff_eq_kwargs = Dict(:abstol= d0, :reltol= d0)  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).  dt = 0.1  : (only for continuous) Time of evolution between each check of distance exceeding the  threshold .  inittest = (st1, d0) -  st1 .+ d0/sqrt(D)  : A function that given  (st1, d0)  initializes the test state with distance  d0  from the given state  st1  ( D  is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.   Description  Two neighboring trajectories with initial distance  d0  are evolved in time. At time  d(t_i) d(t_i)  their distance exceeds the  threshold , which initializes a rescaling of the test trajectory back to having distance  d0  from the given one, while the rescaling keeps the distance vector along the maximal expansion direction.  The maximum Lyapunov exponent is the average of the time-local Lyapunov exponents   \n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.  \n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.   Performance Notes  For the continuous case, the algorithm becomes faster with increasing  dt , since integration is interrupted less frequenty. For the fastest performance you want to fine-tune  dt, d0, threshold  such that you have the minimum amount of rescalings  while still being well within the linearized dynamics region .  You can easily modify the source code to return the convergence timeseries of the exponent, if need be.  References  [1] : G. Benettin  et al. , Phys. Rev. A  14 , pp 2338 (1976)  source   For example:  using   DynamicalSystems  henon   =   Systems . henon ()  \u03bb   =   lyapunov ( henon ,   10000 ,   d0   =   1e-7 ,   threshold   =   1e-4 ,   Ttr   =   100 )   0.42007471604734054  The same is done for continuous systems:  using   DynamicalSystems ,   OrdinaryDiffEq  ross   =   Systems . roessler ( a   =   0.1 ,   b   =   0.1 ,   c   =   14.0 )   #not original parameters  \u03bb   =   lyapunov ( ross ,   100000 ,   dt   =   10.0 ,  diff_eq_kwargs   =   Dict ( : solver   =   Vern8 (),   : abstol = 1e-9 ,   : reltol = 1e-9 ),  Ttr   =   100.0 )   0.07127399326422117", 
            "title": "Maximum Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/entropies/", 
            "text": "Entropies and Dimensions\n\n\n\n\nEntropies\n\n\nIn the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known \nthermodynamic ones\n, used in Statistical Physics. Rather, they are more like the to the entropies of \ninformation theory\n, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.\n\n\n\n\nGeneralized Entropy\n\n\n#\n\n\nChaosTools.genentropy\n \n \nFunction\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n)\n\n\n\n\n\n\nCompute the \n\u03b1\n order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length \n\u03b5\n using \nnon0hist\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \np\n::\nAbstractArray\n)\n\n\n\n\n\n\nCompute the entropy of an array \np\n directly, assuming that \np\n is sum-normalized.\n\n\nlog base-e is used in both cases, i.e. units of \"nat\".\n\n\nDescription\n\n\nThe R\u00e9nyi entropy\n\n\n\n\n\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha\n\n\n\n\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha\n\n\n\n\n\ngeneralizes other known entropies, like e.g. the information entropy (\n\\alpha = 1\n\\alpha = 1\n, see [2]), the maximum entropy (\n\\alpha=0\n\\alpha=0\n, also known as Hartley entropy), or the correlation entropy (\n\\alpha = 2\n\\alpha = 2\n, also known as collision entropy).\n\n\nThe following aliases are provided:\n\n\n\n\nrenyi = genentropy\n\n\nshannon(args...) = genentropy(1, args...)\n\n\nhartley(args...) = genentropy(0, args...)\n\n\n\n\nReferences\n\n\n[1] : A. R\u00e9nyi, \nProceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability\n, pp 547 (1960)\n\n\n[2] : C. E. Shannon, Bell Systems Technical Journal \n27\n, pp 379 (1948)\n\n\nsource\n\n\n\n\nBasically, given a \ndataset\n you can partition it into boxes to calculate an entropy.\n\n\n\n\nWorried about memory overflow? Don't be!\n\n\nPartitioning the dataset (i.e. doing a \nhistogram\n) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size \n\u03b5\n. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!\n\n\nIn fact, there is an upper bound to the memory allocated by \nnon0hist\n: A constant multiplied by the length of the array, \nN = length(p)\n. No matter how small \n\u03b5\n or how many dimensions the data has, the method can at most assign \nN\n dictionary entries.\n\n\n\n\nThe function used internally by \ngenentropy\n is \nnon0hist\n:\n\n\n#\n\n\nChaosTools.non0hist\n \n \nFunction\n.\n\n\nnon0hist\n(\n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n)\n\n\n\n\n\n\nPartition a dataset into tabulated intervals (boxes) of size \n\u03b5\n and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements.\n\n\nPerformances Notes\n\n\nThis method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins. This allows computation of entropies of high-dimensional datasets and with small box sizes \n\u03b5\n without memory overflow.\n\n\nUse e.g. \nfit(Histogram, ...)\n from \nStatsBase\n if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\nsource\n\n\n\n\nFor example, the Shannon entropy of a coin-flip process should be one bit, \nby definition\n. Let's see...\n\n\nusing\n \nDynamicalSystems\n\n\ny\n \n=\n \nFloat64\n.\n(\nrand\n(\nBool\n,\n \n1000000\n))\n \n# just some coin tosses\n\n\nsh\n \n=\n \nshannon\n(\n0.1\n,\n \ny\n)\n  \n# \u2261 genentropy(1, 0.0, y)\n\n\nisapprox\n(\nsh\n,\n \nlog\n(\n2\n),\n  \nrtol\n \n=\n \n1e-6\n)\n\n\n\n\n\n\ntrue\n\n\n\n\n\n\nBecause all entropies are calculated on base-\ne\ne\n, the unit of measurement is \"nat\" and one bit is \n\\log(2)\\times\n\\log(2)\\times\nnat.\n\n\n\n\nAttractor Dimension Estimation\n\n\nThere are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the \nFractal dimension\n. This real number can offer a lot of information about the object that the dataset represents.\n\n\n\n\nGeneralized Dimensions\n\n\nBased on the definition of the \ngeneralized entropy\n, one can calculate an appropriate dimension, called \ngeneralized dimension\n:\n\n\n#\n\n\nChaosTools.generalized_dim\n \n \nFunction\n.\n\n\ngeneralized_dim(\u03b1, dataset [, sizes]) -\n D_\u03b1\n\n\n\n\n\nReturn the \n\u03b1\n order generalized dimension of the \ndataset\n, by calculating the \ngenentropy\n for each \n\u03b5 \u2208 sizes\n.\n\n\nDescription\n\n\nThe returned dimension is approximated by the (inverse) power law exponent of the scaling of the \ngenentropy\n versus the box size \n\u03b5\n, where \n\u03b5 \u2208 sizes\n.\n\n\nCalling this function performs a lot of automated steps:\n\n\n\n\nA vector of box sizes is decided by calling \nsizes = estimate_boxsizes(dataset)\n, if \nsizes\n is not given.\n\n\nFor each element of \nsizes\n the appropriate entropy is calculated, through \nd[i] = genentropy(\u03b1, sizes[i], dataset)\n. Let \nx = -log.(sizes)\n.\n\n\nThe curve \nd(x)\n is decomposed into linear regions, using \nlinear_regions\n(x, d)\n.\n\n\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the function \nlinear_region\n.\n\n\nThis fitted slope is returned.\n\n\n\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\n\nThe following aliases are provided:\n\n\n\n\n\u03b1 = 0 : \nboxcounting_dim\n, \ncapacity_dim\n\n\n\u03b1 = 1 : \ninformation_dim\n\n\n\u03b1 = 2 : \ncorrelation_dim\n\n\n\n\nsource\n\n\n\n\n\n\nBe wary when using \ngeneralized_dim\n\n\nAs stated clearly by the documentation string, calling \ngeneralized_dim\n performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.\n\n\n\n\n#\n\n\nChaosTools.estimate_boxsizes\n \n \nFunction\n.\n\n\nestimate_boxsizes\n(\ndataset\n::\nAbstractDataset\n;\n \nk\n::\nInt\n \n=\n \n12\n,\n \nz\n \n=\n \n-1\n,\n \nw\n \n=\n \n1\n)\n\n\n\n\n\n\nReturn a \nk\n-element \nlogspace\n from \nlower + w\n to \nupper + z\n,\n\n\nlower\n is the magnitude of the minimum pair-wise distance between datapoints while \nupper\n is the magnitude of the maximum difference between greatest and smallest number among each timeseries.\n\n\n\"Magnitude\" here stands for order of magnitude, i.e. \nround(log10(x))\n.\n\n\nsource\n\n\n#\n\n\nChaosTools.linear_regions\n \n \nFunction\n.\n\n\nlinear_regions(x, y; dxi::Int = 1, tol = 0.2) -\n (lrs, tangents)\n\n\n\n\n\nIdentify regions where the curve \ny(x)\n is linear, by scanning the \nx\n-axis every \ndxi\n indices (e.g. at \nx[1] to x[5], x[5] to x[10], x[10] to x[15]\n and so on if \ndxi=5\n).\n\n\nIf the slope (calculated using \nLsqFit\n) of a region of width \ndxi\n is approximatelly equal to that of the previous region, within tolerance \ntol\n, then these two regions belong to the same linear region.\n\n\nReturn the indices of \nx\n that correspond to linear regions, \nlrs\n, and the approximated \ntangents\n at each region. \nlrs\n is a vector of \nInt\n.\n\n\nA function \nplot_linear_regions\n visualizes the result of using this \nlinear_regions\n (requires \nPyPlot\n).\n\n\nsource\n\n\n#\n\n\nChaosTools.linear_region\n \n \nFunction\n.\n\n\nlinear_region(x, y; dxi::Int = 1, tol = 0.2) -\n ([ind1, ind2], slope)\n\n\n\n\n\nCall \nlinear_regions\n, identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops (\nx[ind1:ind2]\n) as well as the approximated slope.\n\n\nsource\n\n\n\n\n\n\nExample\n\n\nFor example, the dimension of the strange attractor of the \nH\u00e9non map\n is:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n(\n-\nrand\n(\n2\n))\n\n\nts\n \n=\n \ntrajectory\n(\nhen\n,\n \n1000000\n)\n\n\nD_hen\n \n=\n \ninformation_dim\n(\nts\n)\n\n\n\n\n\n\n1.19735650096483\n\n\n\n\n\nAs a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D \n56\n, pp 185-187 (1992)).\n\n\n\n\n\n\nKaplan-Yorke Dimension\n\n\n#\n\n\nChaosTools.kaplanyorke_dim\n \n \nFunction\n.\n\n\nkaplanyorke_dim(lyapunovs::AbstractVector)\n\n\n\n\n\nCalculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].\n\n\nDescription\n\n\nThe Kaplan-Yorke dimension is simply the point where \ncumsum(lyapunovs)\n becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.\n\n\nUseful in combination with \nlyapunovs\n.\n\n\nReferences\n\n\n[1] :  J. Kaplan \n J. Yorke, \nChaotic behavior of multidimensional difference equations\n, Lecture Notes in Mathematics vol. \n730\n, Springer (1979)\n\n\nsource\n\n\n\n\nNotice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nD_kp\n \n=\n \nkaplanyorke_dim\n(\nlyapunovs\n(\nhen\n,\n \n100000\n))\n\n\n\n\n\n\n1.258709281073041", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies-and-dimensions", 
            "text": "", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies", 
            "text": "In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known  thermodynamic ones , used in Statistical Physics. Rather, they are more like the to the entropies of  information theory , which represents information contained within a dataset, or information about the dimensional scaling of a dataset.", 
            "title": "Entropies"
        }, 
        {
            "location": "/chaos/entropies/#generalized-entropy", 
            "text": "#  ChaosTools.genentropy     Function .  genentropy ( \u03b1 ,   \u03b5 ,   dataset :: AbstractDataset )   Compute the  \u03b1  order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length  \u03b5  using  non0hist .  genentropy ( \u03b1 ,   p :: AbstractArray )   Compute the entropy of an array  p  directly, assuming that  p  is sum-normalized.  log base-e is used in both cases, i.e. units of \"nat\".  Description  The R\u00e9nyi entropy   \nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha  \nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha   generalizes other known entropies, like e.g. the information entropy ( \\alpha = 1 \\alpha = 1 , see [2]), the maximum entropy ( \\alpha=0 \\alpha=0 , also known as Hartley entropy), or the correlation entropy ( \\alpha = 2 \\alpha = 2 , also known as collision entropy).  The following aliases are provided:   renyi = genentropy  shannon(args...) = genentropy(1, args...)  hartley(args...) = genentropy(0, args...)   References  [1] : A. R\u00e9nyi,  Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability , pp 547 (1960)  [2] : C. E. Shannon, Bell Systems Technical Journal  27 , pp 379 (1948)  source   Basically, given a  dataset  you can partition it into boxes to calculate an entropy.   Worried about memory overflow? Don't be!  Partitioning the dataset (i.e. doing a  histogram ) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size  \u03b5 . However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!  In fact, there is an upper bound to the memory allocated by  non0hist : A constant multiplied by the length of the array,  N = length(p) . No matter how small  \u03b5  or how many dimensions the data has, the method can at most assign  N  dictionary entries.   The function used internally by  genentropy  is  non0hist :  #  ChaosTools.non0hist     Function .  non0hist ( \u03b5 ,   dataset :: AbstractDataset )   Partition a dataset into tabulated intervals (boxes) of size  \u03b5  and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements.  Performances Notes  This method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins. This allows computation of entropies of high-dimensional datasets and with small box sizes  \u03b5  without memory overflow.  Use e.g.  fit(Histogram, ...)  from  StatsBase  if you wish to keep information about the edges of the binning as well as the zero elements.  source   For example, the Shannon entropy of a coin-flip process should be one bit,  by definition . Let's see...  using   DynamicalSystems  y   =   Float64 . ( rand ( Bool ,   1000000 ))   # just some coin tosses  sh   =   shannon ( 0.1 ,   y )    # \u2261 genentropy(1, 0.0, y)  isapprox ( sh ,   log ( 2 ),    rtol   =   1e-6 )   true   Because all entropies are calculated on base- e e , the unit of measurement is \"nat\" and one bit is  \\log(2)\\times \\log(2)\\times nat.", 
            "title": "Generalized Entropy"
        }, 
        {
            "location": "/chaos/entropies/#attractor-dimension-estimation", 
            "text": "There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the  Fractal dimension . This real number can offer a lot of information about the object that the dataset represents.", 
            "title": "Attractor Dimension Estimation"
        }, 
        {
            "location": "/chaos/entropies/#generalized-dimensions", 
            "text": "Based on the definition of the  generalized entropy , one can calculate an appropriate dimension, called  generalized dimension :  #  ChaosTools.generalized_dim     Function .  generalized_dim(\u03b1, dataset [, sizes]) -  D_\u03b1  Return the  \u03b1  order generalized dimension of the  dataset , by calculating the  genentropy  for each  \u03b5 \u2208 sizes .  Description  The returned dimension is approximated by the (inverse) power law exponent of the scaling of the  genentropy  versus the box size  \u03b5 , where  \u03b5 \u2208 sizes .  Calling this function performs a lot of automated steps:   A vector of box sizes is decided by calling  sizes = estimate_boxsizes(dataset) , if  sizes  is not given.  For each element of  sizes  the appropriate entropy is calculated, through  d[i] = genentropy(\u03b1, sizes[i], dataset) . Let  x = -log.(sizes) .  The curve  d(x)  is decomposed into linear regions, using  linear_regions (x, d) .  The biggest linear region is chosen, and a fit for the slope of that region is performed using the function  linear_region .  This fitted slope is returned.   By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.  The following aliases are provided:   \u03b1 = 0 :  boxcounting_dim ,  capacity_dim  \u03b1 = 1 :  information_dim  \u03b1 = 2 :  correlation_dim   source    Be wary when using  generalized_dim  As stated clearly by the documentation string, calling  generalized_dim  performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.   #  ChaosTools.estimate_boxsizes     Function .  estimate_boxsizes ( dataset :: AbstractDataset ;   k :: Int   =   12 ,   z   =   -1 ,   w   =   1 )   Return a  k -element  logspace  from  lower + w  to  upper + z ,  lower  is the magnitude of the minimum pair-wise distance between datapoints while  upper  is the magnitude of the maximum difference between greatest and smallest number among each timeseries.  \"Magnitude\" here stands for order of magnitude, i.e.  round(log10(x)) .  source  #  ChaosTools.linear_regions     Function .  linear_regions(x, y; dxi::Int = 1, tol = 0.2) -  (lrs, tangents)  Identify regions where the curve  y(x)  is linear, by scanning the  x -axis every  dxi  indices (e.g. at  x[1] to x[5], x[5] to x[10], x[10] to x[15]  and so on if  dxi=5 ).  If the slope (calculated using  LsqFit ) of a region of width  dxi  is approximatelly equal to that of the previous region, within tolerance  tol , then these two regions belong to the same linear region.  Return the indices of  x  that correspond to linear regions,  lrs , and the approximated  tangents  at each region.  lrs  is a vector of  Int .  A function  plot_linear_regions  visualizes the result of using this  linear_regions  (requires  PyPlot ).  source  #  ChaosTools.linear_region     Function .  linear_region(x, y; dxi::Int = 1, tol = 0.2) -  ([ind1, ind2], slope)  Call  linear_regions , identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops ( x[ind1:ind2] ) as well as the approximated slope.  source", 
            "title": "Generalized Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#example", 
            "text": "For example, the dimension of the strange attractor of the  H\u00e9non map  is:  using   DynamicalSystems  hen   =   Systems . henon ( - rand ( 2 ))  ts   =   trajectory ( hen ,   1000000 )  D_hen   =   information_dim ( ts )   1.19735650096483  As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D  56 , pp 185-187 (1992)).", 
            "title": "Example"
        }, 
        {
            "location": "/chaos/entropies/#kaplan-yorke-dimension", 
            "text": "#  ChaosTools.kaplanyorke_dim     Function .  kaplanyorke_dim(lyapunovs::AbstractVector)  Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].  Description  The Kaplan-Yorke dimension is simply the point where  cumsum(lyapunovs)  becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.  Useful in combination with  lyapunovs .  References  [1] :  J. Kaplan   J. Yorke,  Chaotic behavior of multidimensional difference equations , Lecture Notes in Mathematics vol.  730 , Springer (1979)  source   Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:  using   DynamicalSystems  hen   =   Systems . henon ()  D_kp   =   kaplanyorke_dim ( lyapunovs ( hen ,   100000 ))   1.258709281073041", 
            "title": "Kaplan-Yorke Dimension"
        }, 
        {
            "location": "/chaos/nlts/", 
            "text": "Nonlinear Timeseries Analysis\n\n\n\n\nNeighborhoods in a Dataset\n\n\nIncorporating the excellent performance of \nNearestNeighbors.jl\n and the flexibility of \nAbstractDataset\n allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. other points near it. The different \"types\" of the neighborhoods are subtypes of \nAbstractNeighborhood\n.\n\n\n#\n\n\nChaosTools.neighborhood\n \n \nFunction\n.\n\n\nneighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)\n\n\n\n\n\nReturn a vector of indices which are the neighborhood of \npoint\n, whose index in the original data is \nn\n.\n\n\nIf the original data is \ndata \n: AbstractDataset\n, then use \ntree = KDTree(data)\n to obtain the \ntree\n instance (which also contains a copy of the data). Both \npoint\n and \nn\n must be provided because the \ntree\n has indices in different sorting.\n\n\nThe \nmethod\n can be a subtype of \nAbstractNeighborhood\n.\n\n\nneighborhood\n works for \nany\n subtype of \nAbstractDataset\n, for example\n\n\nR\n \n=\n \nsome_dataset\n\n\ntree\n \n=\n \nKDTree\n(\nR\n)\n\n\nneigh\n \n=\n \nneighborhood\n(\nn\n,\n \nR\n[\nn\n],\n \ntree\n,\n \nmethod\n)\n\n\n\n\n\n\nReferences\n\n\nneighborhood\n simply interfaces the functions \nknn\n and \ninrange\n from \nNearestNeighbors.jl\n by using the last argument, \nmethod\n.\n\n\nsource\n\n\n#\n\n\nChaosTools.AbstractNeighborhood\n \n \nType\n.\n\n\nAbstractNeighborhood\n\n\n\n\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\n\nConcrete subtypes:\n\n\n\n\nFixedMassNeighborhood(K::Int)\n  : The neighborhood of a point consists of the \nK\n nearest neighbors of the point.\n\n\nFixedSizeNeighborhood(\u03b5::Real)\n : The neighborhood of a point consists of all neighbors that have distance \n \n\u03b5\n from the point.\n\n\n\n\nNotice that these distances are always computed using the \nEuclidean()\n distance in \nD\n-dimensional space.\n\n\nSee also \nneighborhood\n or \nnumericallyapunov\n.\n\n\nsource\n\n\n\n\n\n\nDelay Coordinates Reconstruction\n\n\nA timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as \ndelay coordinates embedding\n.\n\n\nThis is done through the \nReconstruction\n interface:\n\n\n#\n\n\nDynamicalSystemsBase.Reconstruction\n \n \nType\n.\n\n\nReconstruction{D, T, \u03c4} \n: AbstractDataset{D, T}\n\n\n\n\n\nD\n-dimensional delay-coordinates reconstruction object with delay \n\u03c4\n, created from a timeseries \ns\n with \nT\n type numbers.\n\n\nUse \nReconstruction(s::AbstractVector{T}, D, \u03c4)\n to create an instance.\n\n\nDescription\n\n\nThe \nn\nn\nth row of a \nReconstruction\n is the \nD\n-dimensional vector\n\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\n\n\n\n\nThe reconstruction object \nR\n can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper \nD\n and \n\u03c4\n [1, 2].\n\n\nR\n can be accessed similarly to a \nDataset\n:\n\n\ns\n \n=\n \nrand\n(\n1e6\n)\n\n\nR\n \n=\n \nReconstruction\n(\ns\n,\n \n4\n,\n \n1\n)\n \n# dimension 4 and delay 1\n\n\nR\n[\n3\n]\n \n# third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])\n\n\nR\n[\n1\n,\n \n2\n]\n \n# Second element of first point of reconstruction, \u2261 s[2]\n\n\n\n\n\n\nand can also be given to all functions that accept a \nDataset\n (like e.g. \ngeneralized_dim\n from module \nChaosTools\n).\n\n\nThe functions \ndimension(R)\n and \ndelay(R)\n return \nD\n and \n\u03c4\n respectively.\n\n\nReferences\n\n\n[1] : F. Takens, \nDetecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence\n, Lecture Notes in Mathematics \n366\n, Springer (1981)\n\n\n[2] : T. Sauer \net al.\n, J. Stat. Phys. \n65\n, pp 579 (1991)\n\n\nsource\n\n\n\n\nAs an example, let's pass a \nReconstruction\n into e.g. a method that calculates the attractor dimension:\n\n\nusing\n \nDynamicalSystems\n\n\nhe\n \n=\n \nSystems\n.\nhenon\n()\n\n\nts\n \n=\n \ntrajectory\n(\nhe\n,\n \n100000\n)\n\n\nD1\n \n=\n \ninformation_dim\n(\nts\n)\n \n# around 1.20\n\n\nx\n \n=\n \nts\n[\n:\n,\n \n1\n]\n \n# some \nrecorded\n timeseries\n\n\nR\n \n=\n \nReconstruction\n(\nx\n,\n \n2\n,\n \n1\n)\n \n# delay coords. reconstruction\n\n\nR\n[\n1\n]\n \n# first point of reconstruction, \u2261 (x[1], x[2])\n\n\nR\n[\n:\n,\n \n2\n]\n \n# Second COLUMN of the reconstruction, \u2261 x[2:end] since \u03c4=1\n\n\nD2\n \n=\n \ninformation_dim\n(\nR\n)\n \n#around 1.20\n\n\nprintln\n(\nD2 - D1 = \n$\n(\nabs\n(\nD2\n-\n \nD1\n))\n)\n\n\n\n\n\n\nD2 - D1 = 0.03530817423731247\n\n\n\n\n\nThe 2 numbers \nD1\n and \nD2\n are \nvery close\n, but of course I knew before-hand good parameter values for \nD\n and \n\u03c4\n (I cheated, huhu!).\n\n\n\n\nEstimating Reconstruction Parameters\n\n\nThe following functions estimate good values that can be used in \nReconstruction\n:\n\n\n#\n\n\nDynamicalSystemsBase.estimate_delay\n \n \nFunction\n.\n\n\nestimate_delay(s) -\n \u03c4\n\n\n\n\n\nEstimate an optimal delay to be used in \nReconstruction\n, by performing an exponential fit to the \nabs.(c)\n with \nc\n the auto-correlation function of \ns\n. Return the exponential decay time \n\u03c4\n rounded to an integer.\n\n\nsource\n\n\n\n\n\n\nNumerical Lyapunov Exponent\n\n\nGiven any timeseries, one can first obtain a \nReconstruction\n from it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with\n\n\n#\n\n\nChaosTools.numericallyapunov\n \n \nFunction\n.\n\n\nnumericallyapunov\n(\nR\n::\nReconstruction\n,\n \nks\n;\n  \nrefstates\n,\n \ndistance\n,\n \nmethod\n)\n\n\n\n\n\n\nReturn \nE = [E(k) for k \u2208 ks]\n, where \nE(k)\n is the average logarithmic distance for nearby states that are evolved in time for \nk\n steps (\nk\n must be integer).\n\n\nKeyword Arguments\n\n\n\n\nrefstates::AbstractVector{Int} = 1:(length(R) - ks[end])\n : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in \nrefstates\n.\n\n\nmethod::AbstractNeighborhood = FixedMassNeighborhood(1)\n : The method to be used when evaluating the neighborhood of each reference state. See \nAbstractNeighborhood\n or \nneighborhood\n for more info.\n\n\ndistance::Metric = Cityblock()\n : The distance function used in the logarithmic distance of nearby states. The allowed distances are \nCityblock()\n and \nEuclidean()\n. See below for more info.\n\n\n\n\nDescription\n\n\nIf the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold\n\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\n\nfor a \nwell defined region\n in the \nk\n axis, where \n\\lambda\n\\lambda\n is the approximated maximum Lyapunov exponent. \n\\Delta t\n\\Delta t\n is the time between samples in the original timeseries. You can use \nlinear_region\n with arguments \n(ks .* \u0394t, E)\n to identify the slope (= \n\\lambda\n\\lambda\n) immediatelly, assuming you have choosen sufficiently good \nks\n such that the linear scaling region is bigger than the saturated region.\n\n\nThe algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index \nk\n increases. The average of the above over all neighborhood states over all reference states is the returned result.\n\n\nIf the \nMetric\n is \nEuclidean()\n then use the Euclidean distance of the full \nD\n-dimensional points (distance \nd_E\nd_E\n in ref. [1]). If however the \nMetric\n is \nCityblock()\n, calculate the absolute distance of \nonly the first elements\n of the \nm+k\n and \nn+k\n points of the reconstruction \nR\n(distance \nd_F\nd_F\n in ref. [1]). Notice that the distances used are defined in the package \nDistances.jl\n, but are re-exported here for ease-of-use.\n\n\nThis function assumes that the Theiler window (see [1]) is the same as the delay time, \nw  = \\tau\nw  = \\tau\n.\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 1 (section 1.3.2), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n[2] : Kantz, H., Phys. Lett. A \n185\n, pp 77\u201387 (1994)\n\n\nsource\n\n\n\n\nThe function \nnumericallyapunov\n has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.\n\n\n\n\nExample of Numerical Lyapunov computation\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n \n#fake measurements for the win!\n\n\n\nks\n \n=\n \n1\n:\n20\n\n\n\u211c\n \n=\n \n1\n:\n10000\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n6\n))\n\n\ni\n \n=\n \n1\n\n\n\nfor\n \n(\ni\n,\n \ndi\n)\n \nin\n \nenumerate\n([\nEuclidean\n(),\n \nCityblock\n()])\n\n  \nsubplot\n(\n1\n,\n \n2\n,\n \ni\n)\n\n  \ni\n+=\n1\n\n  \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n)\n\n\n  \ntitle\n(\nDistance: \n$\n(\ndi\n)\n,\n \nsize\n \n=\n \n18\n)\n\n  \nfor\n \nD\n \nin\n \n[\n2\n,\n \n4\n,\n \n7\n]\n\n    \nR\n \n=\n \nReconstruction\n(\nx\n,\n \nD\n,\n \n1\n)\n\n    \nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n;\n\n    \nrefstates\n \n=\n \n\u211c\n,\n \ndistance\n \n=\n \ndi\n,\n \nmethod\n \n=\n \nmethod\n)\n\n    \n# The following operation:\n\n    \n\u0394t\n \n=\n \n1\n\n    \n\u03bb\n \n=\n \nlinear_region\n(\nks\n.*\n\u0394t\n,\n \nE\n)[\n2\n]\n\n    \n# gives the linear slope, i.e. the Lyapunov exponent\n\n    \nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$D\n, \u03bb=\n$\n(\nround\n(\n\u03bb\n,\n \n3\n))\n)\n\n    \nlegend\n()\n\n    \ntight_layout\n()\n\n  \nend\n\n\n\n\nend\n\n\n\n\n\n\nwhich gives the result \n\n\n\n\nBad Time-axis (\nks\n) length\n\n\n\n\nLarge \nks\n\n\nThis simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!\n\n\n\n\nLet's revisit the example of the previous section:\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\n\n\n\nThe timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following\n\n\nks\n \n=\n \n1\n:\n100\n\n\nR\n \n=\n \nReconstruction\n(\nx\n,\n \n2\n,\n \n1\n)\n\n\nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n,\n \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n))\n\n\nfigure\n()\n\n\nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n])\n\n\nprintln\n(\nLyappunov: \n,\n \nlinear_region\n(\nks\n,\n \nE\n)[\n2\n])\n\n\n\n\n\n\ngives this plot: \n and prints\n\n\nLyapunov\n:\n \n0.4161\n...\n\n\n\n\n\n\nNotice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function \nlinear_region\n would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)\n\n\n\n\nCase of a Continuous system\n\n\nThe process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n \n# Max lyapunov is around 0.90\n\n\n# create a timeseries of 1 dimension\n\n\ndt\n \n=\n \n0.05\n\n\nx\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n;\n \ndt\n \n=\n \ndt\n)[\n:\n,\n \n1\n]\n\n\n\n\u03c41\n \n=\n \nestimate_delay\n(\nx\n)\n \n#gives 7\n\n\n\n# Reconstruct it\n\n\nfigure\n()\n\n\nfor\n \nD\n \nin\n \n[\n4\n,\n \n8\n],\n \n\u03c4\n \nin\n \n[\n\u03c41\n,\n \n15\n]\n\n    \nR\n \n=\n \nReconstruction\n(\nx\n,\n \nD\n,\n \n\u03c4\n)\n\n\n    \n# I now know that I have to use much bigger ks than 1:20, because this is a\n\n    \n# continuous case! (See reference given in `numericallyapunovs`)\n\n    \nks1\n \n=\n \n0\n:\n200\n\n    \n# I also know that I do not need that dense computations, since 1 increment\n\n    \n# in k means increment of 0.05 real time\n\n    \nks2\n \n=\n \n0\n:\n4\n:\n200\n\n\n    \n# Calculate lyapunovs:\n\n    \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n5\n)\n \n#5 nearest neighbors of each state\n\n\n    \n# E1 = numericallyapunov(R, ks1; method = method)\n\n    \n# \u03bb1 = linear_region(ks1 .* dt, E1)[2]\n\n    \nE2\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks2\n;\n \nmethod\n \n=\n \nmethod\n)\n\n    \n\u03bb2\n \n=\n \nlinear_region\n(\nks2\n \n.*\n \ndt\n,\n \nE2\n)[\n2\n]\n\n\n\n    \n# plot(ks1,E1.-E1[1], label = \ndense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3))\n)\n\n    \nplot\n(\nks2\n,\nE2\n.-\nE2\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$\n(\nD\n)\n, \u03c4=\n$\n(\n\u03c4\n)\n, \u03bb=\n$\n(\nround\n(\n\u03bb2\n,\n \n3\n))\n)\n\n\nend\n\n\n\nlegend\n()\n\n\nxlabel\n(\nk (0.05\u00d7t)\n)\n\n\nylabel\n(\nE - E(0)\n)\n\n\ntitle\n(\nContinuous Reconstruction Lyapunov\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\nwhich produces: \n As you can see, using \n\u03c4 = 15\n makes almost no sense! The estimates with \n\u03c4 = 7\n though are very good (the actual value is around \n\u03bb \u2248 0.89...\n).", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#nonlinear-timeseries-analysis", 
            "text": "", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#neighborhoods-in-a-dataset", 
            "text": "Incorporating the excellent performance of  NearestNeighbors.jl  and the flexibility of  AbstractDataset  allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. other points near it. The different \"types\" of the neighborhoods are subtypes of  AbstractNeighborhood .  #  ChaosTools.neighborhood     Function .  neighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)  Return a vector of indices which are the neighborhood of  point , whose index in the original data is  n .  If the original data is  data  : AbstractDataset , then use  tree = KDTree(data)  to obtain the  tree  instance (which also contains a copy of the data). Both  point  and  n  must be provided because the  tree  has indices in different sorting.  The  method  can be a subtype of  AbstractNeighborhood .  neighborhood  works for  any  subtype of  AbstractDataset , for example  R   =   some_dataset  tree   =   KDTree ( R )  neigh   =   neighborhood ( n ,   R [ n ],   tree ,   method )   References  neighborhood  simply interfaces the functions  knn  and  inrange  from  NearestNeighbors.jl  by using the last argument,  method .  source  #  ChaosTools.AbstractNeighborhood     Type .  AbstractNeighborhood  Supertype of methods for deciding the neighborhood of points for a given point.  Concrete subtypes:   FixedMassNeighborhood(K::Int)   : The neighborhood of a point consists of the  K  nearest neighbors of the point.  FixedSizeNeighborhood(\u03b5::Real)  : The neighborhood of a point consists of all neighbors that have distance    \u03b5  from the point.   Notice that these distances are always computed using the  Euclidean()  distance in  D -dimensional space.  See also  neighborhood  or  numericallyapunov .  source", 
            "title": "Neighborhoods in a Dataset"
        }, 
        {
            "location": "/chaos/nlts/#delay-coordinates-reconstruction", 
            "text": "A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as  delay coordinates embedding .  This is done through the  Reconstruction  interface:  #  DynamicalSystemsBase.Reconstruction     Type .  Reconstruction{D, T, \u03c4}  : AbstractDataset{D, T}  D -dimensional delay-coordinates reconstruction object with delay  \u03c4 , created from a timeseries  s  with  T  type numbers.  Use  Reconstruction(s::AbstractVector{T}, D, \u03c4)  to create an instance.  Description  The  n n th row of a  Reconstruction  is the  D -dimensional vector   \n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))  \n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))   The reconstruction object  R  can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper  D  and  \u03c4  [1, 2].  R  can be accessed similarly to a  Dataset :  s   =   rand ( 1e6 )  R   =   Reconstruction ( s ,   4 ,   1 )   # dimension 4 and delay 1  R [ 3 ]   # third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])  R [ 1 ,   2 ]   # Second element of first point of reconstruction, \u2261 s[2]   and can also be given to all functions that accept a  Dataset  (like e.g.  generalized_dim  from module  ChaosTools ).  The functions  dimension(R)  and  delay(R)  return  D  and  \u03c4  respectively.  References  [1] : F. Takens,  Detecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence , Lecture Notes in Mathematics  366 , Springer (1981)  [2] : T. Sauer  et al. , J. Stat. Phys.  65 , pp 579 (1991)  source   As an example, let's pass a  Reconstruction  into e.g. a method that calculates the attractor dimension:  using   DynamicalSystems  he   =   Systems . henon ()  ts   =   trajectory ( he ,   100000 )  D1   =   information_dim ( ts )   # around 1.20  x   =   ts [ : ,   1 ]   # some  recorded  timeseries  R   =   Reconstruction ( x ,   2 ,   1 )   # delay coords. reconstruction  R [ 1 ]   # first point of reconstruction, \u2261 (x[1], x[2])  R [ : ,   2 ]   # Second COLUMN of the reconstruction, \u2261 x[2:end] since \u03c4=1  D2   =   information_dim ( R )   #around 1.20  println ( D2 - D1 =  $ ( abs ( D2 -   D1 )) )   D2 - D1 = 0.03530817423731247  The 2 numbers  D1  and  D2  are  very close , but of course I knew before-hand good parameter values for  D  and  \u03c4  (I cheated, huhu!).", 
            "title": "Delay Coordinates Reconstruction"
        }, 
        {
            "location": "/chaos/nlts/#estimating-reconstruction-parameters", 
            "text": "The following functions estimate good values that can be used in  Reconstruction :  #  DynamicalSystemsBase.estimate_delay     Function .  estimate_delay(s) -  \u03c4  Estimate an optimal delay to be used in  Reconstruction , by performing an exponential fit to the  abs.(c)  with  c  the auto-correlation function of  s . Return the exponential decay time  \u03c4  rounded to an integer.  source", 
            "title": "Estimating Reconstruction Parameters"
        }, 
        {
            "location": "/chaos/nlts/#numerical-lyapunov-exponent", 
            "text": "Given any timeseries, one can first obtain a  Reconstruction  from it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with  #  ChaosTools.numericallyapunov     Function .  numericallyapunov ( R :: Reconstruction ,   ks ;    refstates ,   distance ,   method )   Return  E = [E(k) for k \u2208 ks] , where  E(k)  is the average logarithmic distance for nearby states that are evolved in time for  k  steps ( k  must be integer).  Keyword Arguments   refstates::AbstractVector{Int} = 1:(length(R) - ks[end])  : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in  refstates .  method::AbstractNeighborhood = FixedMassNeighborhood(1)  : The method to be used when evaluating the neighborhood of each reference state. See  AbstractNeighborhood  or  neighborhood  for more info.  distance::Metric = Cityblock()  : The distance function used in the logarithmic distance of nearby states. The allowed distances are  Cityblock()  and  Euclidean() . See below for more info.   Description  If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold   \nE(k) \\approx \\lambda\\Delta t k + E(0)  \nE(k) \\approx \\lambda\\Delta t k + E(0)   for a  well defined region  in the  k  axis, where  \\lambda \\lambda  is the approximated maximum Lyapunov exponent.  \\Delta t \\Delta t  is the time between samples in the original timeseries. You can use  linear_region  with arguments  (ks .* \u0394t, E)  to identify the slope (=  \\lambda \\lambda ) immediatelly, assuming you have choosen sufficiently good  ks  such that the linear scaling region is bigger than the saturated region.  The algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index  k  increases. The average of the above over all neighborhood states over all reference states is the returned result.  If the  Metric  is  Euclidean()  then use the Euclidean distance of the full  D -dimensional points (distance  d_E d_E  in ref. [1]). If however the  Metric  is  Cityblock() , calculate the absolute distance of  only the first elements  of the  m+k  and  n+k  points of the reconstruction  R (distance  d_F d_F  in ref. [1]). Notice that the distances used are defined in the package  Distances.jl , but are re-exported here for ease-of-use.  This function assumes that the Theiler window (see [1]) is the same as the delay time,  w  = \\tau w  = \\tau .  References  [1] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 1 (section 1.3.2), Lecture Notes in Physics  915 , Springer (2016)  [2] : Kantz, H., Phys. Lett. A  185 , pp 77\u201387 (1994)  source   The function  numericallyapunov  has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.", 
            "title": "Numerical Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/nlts/#example-of-numerical-lyapunov-computation", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   #fake measurements for the win!  ks   =   1 : 20  \u211c   =   1 : 10000  fig   =   figure ( figsize = ( 10 , 6 ))  i   =   1  for   ( i ,   di )   in   enumerate ([ Euclidean (),   Cityblock ()]) \n   subplot ( 1 ,   2 ,   i ) \n   i += 1 \n   method   =   FixedMassNeighborhood ( 2 ) \n\n   title ( Distance:  $ ( di ) ,   size   =   18 ) \n   for   D   in   [ 2 ,   4 ,   7 ] \n     R   =   Reconstruction ( x ,   D ,   1 ) \n     E   =   numericallyapunov ( R ,   ks ; \n     refstates   =   \u211c ,   distance   =   di ,   method   =   method ) \n     # The following operation: \n     \u0394t   =   1 \n     \u03bb   =   linear_region ( ks .* \u0394t ,   E )[ 2 ] \n     # gives the linear slope, i.e. the Lyapunov exponent \n     plot ( ks - 1 ,   E - E [ 1 ],   label   =   D= $D , \u03bb= $ ( round ( \u03bb ,   3 )) ) \n     legend () \n     tight_layout () \n   end  end   which gives the result", 
            "title": "Example of Numerical Lyapunov computation"
        }, 
        {
            "location": "/chaos/nlts/#bad-time-axis-ks-length", 
            "text": "Large  ks  This simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!   Let's revisit the example of the previous section:  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   The timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following  ks   =   1 : 100  R   =   Reconstruction ( x ,   2 ,   1 )  E   =   numericallyapunov ( R ,   ks ,   method   =   FixedMassNeighborhood ( 2 ))  figure ()  plot ( ks - 1 ,   E - E [ 1 ])  println ( Lyappunov:  ,   linear_region ( ks ,   E )[ 2 ])   gives this plot:   and prints  Lyapunov :   0.4161 ...   Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function  linear_region  would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)", 
            "title": "Bad Time-axis (ks) length"
        }, 
        {
            "location": "/chaos/nlts/#case-of-a-continuous-system", 
            "text": "The process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . lorenz ()   # Max lyapunov is around 0.90  # create a timeseries of 1 dimension  dt   =   0.05  x   =   trajectory ( ds ,   1000.0 ;   dt   =   dt )[ : ,   1 ]  \u03c41   =   estimate_delay ( x )   #gives 7  # Reconstruct it  figure ()  for   D   in   [ 4 ,   8 ],   \u03c4   in   [ \u03c41 ,   15 ] \n     R   =   Reconstruction ( x ,   D ,   \u03c4 ) \n\n     # I now know that I have to use much bigger ks than 1:20, because this is a \n     # continuous case! (See reference given in `numericallyapunovs`) \n     ks1   =   0 : 200 \n     # I also know that I do not need that dense computations, since 1 increment \n     # in k means increment of 0.05 real time \n     ks2   =   0 : 4 : 200 \n\n     # Calculate lyapunovs: \n     method   =   FixedMassNeighborhood ( 5 )   #5 nearest neighbors of each state \n\n     # E1 = numericallyapunov(R, ks1; method = method) \n     # \u03bb1 = linear_region(ks1 .* dt, E1)[2] \n     E2   =   numericallyapunov ( R ,   ks2 ;   method   =   method ) \n     \u03bb2   =   linear_region ( ks2   .*   dt ,   E2 )[ 2 ] \n\n\n     # plot(ks1,E1.-E1[1], label =  dense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3)) ) \n     plot ( ks2 , E2 .- E2 [ 1 ],   label   =   D= $ ( D ) , \u03c4= $ ( \u03c4 ) , \u03bb= $ ( round ( \u03bb2 ,   3 )) )  end  legend ()  xlabel ( k (0.05\u00d7t) )  ylabel ( E - E(0) )  title ( Continuous Reconstruction Lyapunov )  tight_layout ()   which produces:   As you can see, using  \u03c4 = 15  makes almost no sense! The estimates with  \u03c4 = 7  though are very good (the actual value is around  \u03bb \u2248 0.89... ).", 
            "title": "Case of a Continuous system"
        }, 
        {
            "location": "/chaos/periodicity/", 
            "text": "Detecting Stable and Unstable Periodic Orbits of Maps\n\n\nChaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the \nperiodic orbits\n existing in the chaotic sea.\n\n\nFinding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher \n Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at \nunstable\n ones.\n\n\nThe functions \nperiodicorbits\n and \nlambdamatrix\n implement the algorithm:\n\n\n#\n\n\nChaosTools.periodicorbits\n \n \nFunction\n.\n\n\nperiodicorbits\n(\nds\n::\nDiscreteDS\n,\n \no\n,\n \nics\n \n[\n,\n \n\u03bb\ns\n,\n \nindss\n,\n \nsingss\n]\n \n;\n \nkwargs\n...)\n \n-\n \nFP\n\n\n\n\n\n\nFind stable and unstable fixed points \nFP\n of order \no\n for the map \nds\n using the algorithm due to Schmelcher \n Diakonos [1]. \nics\n is a collection of initial conditions (container of \nSVector\ns) to be evolved.\n\n\nOptional Arguments\n\n\nThe optional arguments \n\u03bbs, indss, singss\n \nmust be containers\n of appropriate values, besides \n\u03bbs\n which can also be a number. The elements of those containers are passed to: \nlambdamatrix(\u03bb, inds, sings)\n, which creates the appropriate \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrix (see \nlambdamatrix\n for more). If these arguments are not given, a random permutation will be chosen for them, with \n\u03bb=0.001\n.\n\n\nKeyword Arguments\n\n\n\n\nmaxiters::Int = 100000\n : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\n\n\ndisttol = 1e-10\n : Distance tolerance. If the 2-norm of a previous state with  the next one is \n\u2264 disttol\n then it has converged to a fixed point.\n\n\ninftol = 10.0\n : If a state reaches \nnorm(state) \u2265 inftol\n it is assumed that  it has escaped to infinity (and is thus abandoned).\n\n\nroundtol::Int = 4\n : The found fixed points are rounded  to \nroundtol\n digits before pushed into the list of returned fixed points \nFP\n,  \nif\n they are not already contained in \nFP\n.  This is done so that \nFP\n doesn't contain duplicate fixed points (notice  that this has nothing to do with \ndisttol\n). Turn this to \ntypemax(Int)\n  to get the full precision of the algorithm.\n\n\n\n\nDescription\n\n\nThe algorithm used can detect stable/unstable periodic orbits by turning stable/unstable fixed points of the original map \nds\n to dissipatively stable ones, through the transformation\n\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\nwith \nf\nf\n = \nds.eom\n. The index \nk\nk\n counts the various possible \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n.\n\n\nNote that algorithm is intented for \nunstable\n orbits, and thus there are cases where it may not work for stable orbits.\n\n\nPerformance Notes\n\n\nAll\n initial conditions are evolved for \nall\n \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n which can very quickly lead to long computation times.\n\n\nReferences\n\n\n[1] : P. Schmelcher \n F. K. Diakonos, Phys. Rev. Lett. \n78\n, pp 4733 (1997)\n\n\nsource\n\n\n#\n\n\nChaosTools.lambdamatrix\n \n \nFunction\n.\n\n\nlambdamatrix(\u03bb, inds::Vector{Int}, sings) -\n \u039bk\n\n\n\n\n\nReturn the matrix \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n used to create a new dynamical system with some unstable fixed points turned to stable in the function \nperiodicorbits\n.\n\n\nArguments\n\n\n\n\n\u03bb\n:Real\n : the multiplier of the \nC_k\nC_k\n matrix, with \n0\n\u03bb\n1\n.\n\n\ninds::Vector{Int}\n : The \ni\nth entry of this vector gives the \nrow\n of the nonzero element of the \ni\nth column of \nC_k\nC_k\n.\n\n\nsings::Vector{\n:Real}\n : The element of the \ni\nth column of \nC_k\nC_k\n is +1 if \nsigns[i] \n 0\n and -1 otherwise (\nsings\n can also be \nBool\n vector).\n\n\n\n\nCalling \nlambdamatrix(\u03bb, D::Int)\n creates a random \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n by randomly generating an \ninds\n and a \nsigns\n from all possible combinations. The \ncollections\n of all these combinations can be obtained from the function \nlambdaperms\n.\n\n\nDescription\n\n\nEach element of \ninds\n \nmust be unique\n such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.\n\n\nDeciding the appropriate values for \n\u03bb, inds, sings\n is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for \n\u03bb\n, one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.\n\n\nReferences\n\n\n[2] : D. Pingel \net al.\n, Phys. Rev. E \n62\n, pp 2119 (2000)\n\n\n[3] : F. K. Diakonos \net al.\n, Phys. Rev. Lett. \n81\n, pp 4349 (1998)\n\n\nsource\n\n\n#\n\n\nChaosTools.lambdaperms\n \n \nFunction\n.\n\n\nlambdaperms(D) -\n indperms, singperms\n\n\n\n\n\nReturn two collections that each contain all possible combinations of indices (total of \nD!\nD!\n) and signs (total of \n2^D\n2^D\n) for dimension \nD\n (see \nlambdamatrix\n).\n\n\nsource\n\n\n\n\n\n\nStandard Map example\n\n\nFor example, let's find the fixed points of the \nStandard Map\n of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the \nsigns\n but only one for the \ninds\n. We will also only use one \n\u03bb\n value, and a 21\u00d721 density of initial conditions:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\nxs\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \n21\n);\n \nys\n \n=\n \ncopy\n(\nxs\n)\n\n\nics\n \n=\n \n[\nSVector\n{\n2\n}(\nx\n,\ny\n)\n \nfor\n \nx\n \nin\n \nxs\n \nfor\n \ny\n \nin\n \nys\n]\n\n\n\n# All permutations of [\u00b11, \u00b11]:\n\n\nsingss\n \n=\n \nlambdaperms\n(\n2\n)[\n2\n]\n \n# second entry are the signs\n\n\n\n# I know from personal research I only need this `inds`:\n\n\nindss\n \n=\n \n[[\n1\n,\n2\n]]\n \n# \n- must be container of vectors!!!\n\n\n\n\u03bbs\n \n=\n \n0.005\n \n# \n- only this allowed to not be vector (could also be vector)\n\n\n\norders\n \n=\n \n[\n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n,\n \n8\n]\n\n\nALLFP\n \n=\n \nVector\n{\nSVector\n{\n2\n,\n \nFloat64\n}}[]\n\n\n\nttt\n \n=\n \ntime\n()\n\n\nfor\n \no\n \nin\n \norders\n\n    \nFP\n \n=\n \nperiodicorbits\n(\nds\n,\n \no\n,\n \nics\n,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n)\n\n    \npush!\n(\nALLFP\n,\n \nFP\n)\n\n\nend\n\n\nprintln\n(\nTotal time: \n$\n((\ntime\n()\n \n-\n \nttt\n)\n/\n60\n)\n mins.\n)\n\n\n# It takes a good 3-5 minutes to do all computations!\n\n\n\n\n# Create phase-space plot:\n\n\niters\n \n=\n \n1000\n\n\ndataset\n \n=\n \ntrajectory\n(\nds\n,\n \niters\n)\n\n\nfor\n \nx\n \nin\n \nxs\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\nx\n,\n \ny\n)\n\n        \nappend!\n(\ndataset\n,\n \ntrajectory\n(\nds\n,\n \niters\n))\n\n    \nend\n\n\nend\n\n\nm\n \n=\n \nMatrix\n(\ndataset\n)\n\n\nPyPlot\n.\nscatter\n(\nview\n(\nm\n,\n \n:\n,\n \n1\n),\n \nview\n(\nm\n,\n \n:\n,\n \n2\n),\n \ns\n=\n \n1\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nPyPlot\n.\nxlim\n(\nxs\n[\n1\n],\n \nxs\n[\nend\n])\n\n\nPyPlot\n.\nylim\n(\nys\n[\n1\n],\n \nys\n[\nend\n])\n\n\n\n# Plot fixed points:\n\n\nmarkers\n \n=\n \n[\nD\n,\n \n^\n,\n \ns\n,\n \np\n,\n \nh\n,\n \n8\n]\n\n\ncolors\n \n=\n \n[\nb\n,\n \ng\n,\n \nr\n,\n \nc\n,\n \nm\n,\n \ngrey\n]\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n6\n\n    \nFP\n \n=\n \nALLFP\n[\ni\n]\n\n    \no\n \n=\n \norders\n[\ni\n]\n\n    \nPyPlot\n.\nplot\n([\ns\n[\n1\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n \n[\ns\n[\n2\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n\n    \nmarker\n=\nmarkers\n[\ni\n],\n \ncolor\n \n=\n \ncolors\n[\ni\n],\n \nmarkersize\n=\n10.0\n \n+\n \n(\n8\n-\no\n),\n \nlinewidth\n=\n0.0\n,\n\n    \nlabel\n \n=\n \norder \n$o\n,\n \nmarkeredgecolor\n \n=\n \nyellow\n,\n \nmarkeredgewidth\n \n=\n \n0.5\n)\n\n\nend\n\n\nlegend\n(\nloc\n=\nupper right\n,\n \nframealpha\n=\n0.9\n)\n\n\nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n\nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\nAfter 3 to 5 minutes, you will get this plot: \n\n\nYou can confirm for yourself that this is correct, for many reasons:\n\n\n\n\nIt is the same \nfig. 12 of this publication\n.\n\n\nFixed points of order \nn\nn\n are also fixed points of order \n2n, 3n, 4n, ...\n2n, 3n, 4n, ...\n\n\nBesides fixed points of previous orders, \noriginal\n fixed points of order \nn\nn\n come in (possible multiples of) \n2n\n2n\n-sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/periodicity/#detecting-stable-and-unstable-periodic-orbits-of-maps", 
            "text": "Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the  periodic orbits  existing in the chaotic sea.  Finding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher   Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at  unstable  ones.  The functions  periodicorbits  and  lambdamatrix  implement the algorithm:  #  ChaosTools.periodicorbits     Function .  periodicorbits ( ds :: DiscreteDS ,   o ,   ics   [ ,   \u03bb s ,   indss ,   singss ]   ;   kwargs ...)   -   FP   Find stable and unstable fixed points  FP  of order  o  for the map  ds  using the algorithm due to Schmelcher   Diakonos [1].  ics  is a collection of initial conditions (container of  SVector s) to be evolved.  Optional Arguments  The optional arguments  \u03bbs, indss, singss   must be containers  of appropriate values, besides  \u03bbs  which can also be a number. The elements of those containers are passed to:  lambdamatrix(\u03bb, inds, sings) , which creates the appropriate  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrix (see  lambdamatrix  for more). If these arguments are not given, a random permutation will be chosen for them, with  \u03bb=0.001 .  Keyword Arguments   maxiters::Int = 100000  : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.  disttol = 1e-10  : Distance tolerance. If the 2-norm of a previous state with  the next one is  \u2264 disttol  then it has converged to a fixed point.  inftol = 10.0  : If a state reaches  norm(state) \u2265 inftol  it is assumed that  it has escaped to infinity (and is thus abandoned).  roundtol::Int = 4  : The found fixed points are rounded  to  roundtol  digits before pushed into the list of returned fixed points  FP ,   if  they are not already contained in  FP .  This is done so that  FP  doesn't contain duplicate fixed points (notice  that this has nothing to do with  disttol ). Turn this to  typemax(Int)   to get the full precision of the algorithm.   Description  The algorithm used can detect stable/unstable periodic orbits by turning stable/unstable fixed points of the original map  ds  to dissipatively stable ones, through the transformation   \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)  \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)   with  f f  =  ds.eom . The index  k k  counts the various possible  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k .  Note that algorithm is intented for  unstable  orbits, and thus there are cases where it may not work for stable orbits.  Performance Notes  All  initial conditions are evolved for  all   \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  which can very quickly lead to long computation times.  References  [1] : P. Schmelcher   F. K. Diakonos, Phys. Rev. Lett.  78 , pp 4733 (1997)  source  #  ChaosTools.lambdamatrix     Function .  lambdamatrix(\u03bb, inds::Vector{Int}, sings) -  \u039bk  Return the matrix  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  used to create a new dynamical system with some unstable fixed points turned to stable in the function  periodicorbits .  Arguments   \u03bb :Real  : the multiplier of the  C_k C_k  matrix, with  0 \u03bb 1 .  inds::Vector{Int}  : The  i th entry of this vector gives the  row  of the nonzero element of the  i th column of  C_k C_k .  sings::Vector{ :Real}  : The element of the  i th column of  C_k C_k  is +1 if  signs[i]   0  and -1 otherwise ( sings  can also be  Bool  vector).   Calling  lambdamatrix(\u03bb, D::Int)  creates a random  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  by randomly generating an  inds  and a  signs  from all possible combinations. The  collections  of all these combinations can be obtained from the function  lambdaperms .  Description  Each element of  inds   must be unique  such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.  Deciding the appropriate values for  \u03bb, inds, sings  is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for  \u03bb , one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.  References  [2] : D. Pingel  et al. , Phys. Rev. E  62 , pp 2119 (2000)  [3] : F. K. Diakonos  et al. , Phys. Rev. Lett.  81 , pp 4349 (1998)  source  #  ChaosTools.lambdaperms     Function .  lambdaperms(D) -  indperms, singperms  Return two collections that each contain all possible combinations of indices (total of  D! D! ) and signs (total of  2^D 2^D ) for dimension  D  (see  lambdamatrix ).  source", 
            "title": "Detecting Stable and Unstable Periodic Orbits of Maps"
        }, 
        {
            "location": "/chaos/periodicity/#standard-map-example", 
            "text": "For example, let's find the fixed points of the  Standard Map  of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the  signs  but only one for the  inds . We will also only use one  \u03bb  value, and a 21\u00d721 density of initial conditions:  using   DynamicalSystems ,   PyPlot ,   StaticArrays  ds   =   Systems . standardmap ()  xs   =   linspace ( 0 ,   2 \u03c0 ,   21 );   ys   =   copy ( xs )  ics   =   [ SVector { 2 }( x , y )   for   x   in   xs   for   y   in   ys ]  # All permutations of [\u00b11, \u00b11]:  singss   =   lambdaperms ( 2 )[ 2 ]   # second entry are the signs  # I know from personal research I only need this `inds`:  indss   =   [[ 1 , 2 ]]   #  - must be container of vectors!!!  \u03bbs   =   0.005   #  - only this allowed to not be vector (could also be vector)  orders   =   [ 2 ,   3 ,   4 ,   5 ,   6 ,   8 ]  ALLFP   =   Vector { SVector { 2 ,   Float64 }}[]  ttt   =   time ()  for   o   in   orders \n     FP   =   periodicorbits ( ds ,   o ,   ics ,   \u03bbs ,   indss ,   singss ) \n     push! ( ALLFP ,   FP )  end  println ( Total time:  $ (( time ()   -   ttt ) / 60 )  mins. )  # It takes a good 3-5 minutes to do all computations!  # Create phase-space plot:  iters   =   1000  dataset   =   trajectory ( ds ,   iters )  for   x   in   xs \n     for   y   in   ys \n         ds . state   =   SVector { 2 }( x ,   y ) \n         append! ( dataset ,   trajectory ( ds ,   iters )) \n     end  end  m   =   Matrix ( dataset )  PyPlot . scatter ( view ( m ,   : ,   1 ),   view ( m ,   : ,   2 ),   s =   1 ,   color   =   black )  PyPlot . xlim ( xs [ 1 ],   xs [ end ])  PyPlot . ylim ( ys [ 1 ],   ys [ end ])  # Plot fixed points:  markers   =   [ D ,   ^ ,   s ,   p ,   h ,   8 ]  colors   =   [ b ,   g ,   r ,   c ,   m ,   grey ]  for   i   in   1 : 6 \n     FP   =   ALLFP [ i ] \n     o   =   orders [ i ] \n     PyPlot . plot ([ s [ 1 ]   for   s   in   FP ],   [ s [ 2 ]   for   s   in   FP ], \n     marker = markers [ i ],   color   =   colors [ i ],   markersize = 10.0   +   ( 8 - o ),   linewidth = 0.0 , \n     label   =   order  $o ,   markeredgecolor   =   yellow ,   markeredgewidth   =   0.5 )  end  legend ( loc = upper right ,   framealpha = 0.9 )  xlabel ( \\$\\\\ theta \\$ )  ylabel ( \\$ p \\$ )   After 3 to 5 minutes, you will get this plot:   You can confirm for yourself that this is correct, for many reasons:   It is the same  fig. 12 of this publication .  Fixed points of order  n n  are also fixed points of order  2n, 3n, 4n, ... 2n, 3n, 4n, ...  Besides fixed points of previous orders,  original  fixed points of order  n n  come in (possible multiples of)  2n 2n -sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Standard Map example"
        }, 
        {
            "location": "/chaos/chaos_detection/", 
            "text": "Chaos Detection\n\n\nBeing able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum \nlyapunov\n exponent and a bounded system indicate chaos.\n\n\nHowever, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in DynamicalSystems.jl.\n\n\n\n\nGeneralized Alignment Index\n\n\n\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis \n Antonopoulos.\n\n\n#\n\n\nChaosTools.gali\n \n \nFunction\n.\n\n\ngali\n(\nds\n::\nDynamicalSystem\n,\n \nk\n::\nInt\n,\n \ntmax\n \n[\n,\n \nws\n]\n;\n \nkwargs\n...)\n \n-\n \nGALI_k\n,\n \nt\n\n\n\n\n\n\nCompute \n\\text{GALI}_k\n\\text{GALI}_k\n [1] for a given \nk\n up to time \ntmax\n. Return \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n and time vector \nt\nt\n.\n\n\nws\n is an optional argument containing the deviation vectors \nw_i\nw_i\n for \ni \\in [1,k]\ni \\in [1,k]\n, expected either as a matrix with each column a deviation vector, or as a vector of vectors. If not given, random orthonormal vectors are chosen.\n\n\nKeyword Arguments\n\n\n\n\nthreshold\n : If \nGALI_k\n falls below the \nthreshold\n iteration is terminated. Default value is \n1e-12\n.\n\n\ndt=1.0\n : Time step between variational vector normalizations for continuous systems.\n\n\ndiff_eq_kwargs\n : See \ntrajectory\n.\n\n\n\n\nDescription\n\n\nThe Generalized Alignment Index, \n\\text{GALI}_k\n\\text{GALI}_k\n, is an efficient (and very fast) indicator of chaotic or regular behavior type in \nD\nD\n-dimensional Hamiltonian systems (\nD\nD\n is number of variables). The \nasymptotic\n behavior of \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n depends critically of the type of orbit resulting from the initial condition \nstate(ds)\n. If it is a chaotic orbit, then\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\nwith \n\\lambda_1\n\\lambda_1\n being the maximum \nlyapunov\n exponent. If on the other hand the orbit is regular, corresponding to movement in \nd\nd\n-dimensional torus with \n1 \\le d \\le D/2\n1 \\le d \\le D/2\n then it holds\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, \n \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d \n 1 \\\\\n      t^{-(k - d)}, \n \\text{if} \\;\\;  d \n k \\le D - d \\\\\n      t^{-(2k - D)}, \n \\text{if} \\;\\;  D - d \n k \\le D\n    \\end{cases}\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}\n\n\n\n\n\nTraditionally, if \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n does not become less than the \nthreshold\n until \ntmax\n the given orbit is said to be chaotic, otherwise it is regular.\n\n\nThe entirety of our implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of \nA\nA\n, a matrix that has as \ncolumns\n the deviation vectors.\n\n\nPerformance Notes\n\n\nIf you want to do repeated evaluations of \ngali\n for many initial conditions and for continuous systems, you can take advantage of the function:\n\n\ngali(integrator, k, W, tmax, dt, threshold)\n\n\n\n\n\nin conjuction with \nreinit!(integrator, W)\n for various \nW=cat(2, state, ws)\n. See the source code on how to set-up the \nintegrator\n and \nW\n for the first time.\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, Physica D \n231\n, pp 30\u201354 (2007)\n\n\n[2] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\nsource\n\n\n\n\n\n\nDiscrete Example\n\n\nWe will use 3 coupled standard maps as an example for a discrete system:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n;\n \nfigure\n()\n\n\nM\n \n=\n \n3\n;\n \nks\n \n=\n \n3\nones\n(\nM\n);\n \n\u0393\n \n=\n \n0.1\n;\n\n\nstable\n \n=\n \n[\n\u03c0\n,\n \n\u03c0\n,\n \n\u03c0\n,\n \n0.01\n,\n \n0\n,\n \n0\n]\n \n.+\n \n0.1\n\n\nchaotic\n \n=\n \nrand\n(\n2\nM\n)\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nstable\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\n\nsubplot\n(\n2\n,\n2\n,\n1\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nstable\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n#\n\n\nsubplot\n(\n2\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n,\n \n5\n,\n \n6\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1e5\n;\n \nthreshold\n=\n1e-12\n)\n\n    \nlt\n \n=\n \nlog10\n.\n(\nt\n);\n \nlg\n \n=\n \nlog10\n.\n(\ng\n)\n\n\n    \nplot\n(\nlt\n,\n \nlg\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlt\n \n=\n \n2\n:\n0.5\n:\n5.5\n\n\nplot\n(\nlt\n,\n \nzeros\n(\nlt\n),\n \nlabel\n=\nconst\n)\n\n\nplot\n(\nlt\n,\n \n-\n2\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -2\n)\n\n\nplot\n(\nlt\n,\n \n-\n4\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -4\n)\n\n\nplot\n(\nlt\n,\n \n-\n6\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -6\n)\n\n\n\nxlim\n(\n2\n,\n \n5.5\n)\n\n\nylim\n(\n-\n12\n,\n \n1\n)\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nchaotic\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nsubplot\n(\n2\n,\n2\n,\n3\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nchaotic\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\n\nsubplot\n(\n2\n,\n2\n,\n4\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n100000\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n,\n5\n \n,\n6\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1000\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\nxlim\n(\n0\n,\n50\n)\n\n\nylim\n(\n1e-12\n,\n \n1\n)\n\n\n\n\n\n\n\n\n\n\nContinuous Example\n\n\nAs an example of a continuous system, let's see the \nhenonhelies\n:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\nfigure\n(\nfigsize\n=\n(\n10\n,\n \n12\n))\n\n\nsp\n \n=\n \n[\n0\n,\n \n.\n295456\n,\n \n.\n407308431\n,\n \n0\n]\n \n#stable periodic orbit: 1D torus\n\n\nqp\n \n=\n \n[\n0\n,\n \n.\n483000\n,\n \n.\n278980390\n,\n \n0\n]\n \n#quasiperiodic orbit: 2D torus\n\n\nch\n \n=\n \n[\n0\n,\n \n-\n0.25\n,\n \n0.42081\n,\n \n0\n]\n \n# chaotic orbit\n\n\ndt\n \n=\n \n1.0\n\n\n\nsubplot\n(\n3\n,\n2\n,\n1\n)\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n(\nsp\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nsp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n50000.0\n;\n \ndt\n \n=\n \ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n    \nif\n \nk\n \n \n4\n\n        \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\nk\n-\n1\n),\n \nlabel\n=\nslope -\n$\n(\nk\n-\n1\n)\n)\n\n    \nelse\n\n        \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nend\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\n\nsubplot\n(\n3\n,\n2\n,\n3\n)\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n(\nqp\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nqp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n4\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n10000.0\n;\n \ndt\n \n=\n \ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n    \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n(\nch\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-6\n,\n \n:\nreltol\n=\n1e-6\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n50000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nsubplot\n(\n3\n,\n2\n,\n5\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nch\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n6\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n5000.0\n,\n \ndt\n=\ndt\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1000\n;\n \ndt\n \n=\n \ndt\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n As you can see, the results of both discrete and continuous match very well the theory described in \ngali\n.\n\n\n\n\nUsing GALI\n\n\nNo-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations.\n\n\nThe most common usage of \n\\text{GALI}_k\n\\text{GALI}_k\n is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether \n\\text{GALI}_k\n\\text{GALI}_k\n stays below it, for a (sufficiently) big \nk\nk\n.\n\n\nFor example one could do\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\n\nchaoticness\n(\nds\n)\n \n=\n \ngali\n(\nds\n,\n \n2\n,\n \n500.0\n)[\n2\n][\nend\n]\n\n\n\nfunction\n \nmain\n(\nk\n)\n\n\n    \ndens\n \n=\n \n201\n\n    \nchaoticity\n \n=\n \nzeros\n(\ndens\n,\ndens\n)\n\n    \n\u03b8s\n \n=\n \nps\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \ndens\n+\n1\n)\n\n    \nds\n \n=\n \nSystems\n.\nstandardmap\n(\nk\n \n=\n \nk\n)\n\n\n    \nfor\n \n(\ni\n,\n \n\u03b8\n)\n \n\u2208\n \nenumerate\n(\n\u03b8s\n[\n1\n:\ndens\n])\n\n        \nfor\n \n(\nj\n,\n \np\n)\n \n\u2208\n \nenumerate\n(\nps\n[\n1\n:\ndens\n])\n\n            \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\n\u03b8\n,\n \np\n)\n\n            \nchaoticity\n[\ni\n,\n \nj\n]\n \n=\n \nchaoticness\n(\nds\n)\n\n        \nend\n\n    \nend\n\n\n    \npcolormesh\n(\n\u03b8s\n \n.-\n \n(\n\u03b8s\n[\n2\n]\n \n-\n \n\u03b8s\n[\n1\n])\n/\n2\n,\n \nps\n \n.-\n \n(\nps\n[\n2\n]\n \n-\n \nps\n[\n1\n])\n/\n2\n,\n\n    \nchaoticity\n)\n\n    \ncolorbar\n()\n\n\n\nend\n\n\n\nmain\n(\n0.9\n)\n\n\n\n\n\n\nand after about two minutes you will get:", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#chaos-detection", 
            "text": "Being able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum  lyapunov  exponent and a bounded system indicate chaos.  However, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in DynamicalSystems.jl.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#generalized-alignment-index", 
            "text": "\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis   Antonopoulos.  #  ChaosTools.gali     Function .  gali ( ds :: DynamicalSystem ,   k :: Int ,   tmax   [ ,   ws ] ;   kwargs ...)   -   GALI_k ,   t   Compute  \\text{GALI}_k \\text{GALI}_k  [1] for a given  k  up to time  tmax . Return  \\text{GALI}_k(t) \\text{GALI}_k(t)  and time vector  t t .  ws  is an optional argument containing the deviation vectors  w_i w_i  for  i \\in [1,k] i \\in [1,k] , expected either as a matrix with each column a deviation vector, or as a vector of vectors. If not given, random orthonormal vectors are chosen.  Keyword Arguments   threshold  : If  GALI_k  falls below the  threshold  iteration is terminated. Default value is  1e-12 .  dt=1.0  : Time step between variational vector normalizations for continuous systems.  diff_eq_kwargs  : See  trajectory .   Description  The Generalized Alignment Index,  \\text{GALI}_k \\text{GALI}_k , is an efficient (and very fast) indicator of chaotic or regular behavior type in  D D -dimensional Hamiltonian systems ( D D  is number of variables). The  asymptotic  behavior of  \\text{GALI}_k(t) \\text{GALI}_k(t)  depends critically of the type of orbit resulting from the initial condition  state(ds) . If it is a chaotic orbit, then   \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]  \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]   with  \\lambda_1 \\lambda_1  being the maximum  lyapunov  exponent. If on the other hand the orbit is regular, corresponding to movement in  d d -dimensional torus with  1 \\le d \\le D/2 1 \\le d \\le D/2  then it holds   \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.},   \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d   1 \\\\\n      t^{-(k - d)},   \\text{if} \\;\\;  d   k \\le D - d \\\\\n      t^{-(2k - D)},   \\text{if} \\;\\;  D - d   k \\le D\n    \\end{cases}  \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}   Traditionally, if  \\text{GALI}_k(t) \\text{GALI}_k(t)  does not become less than the  threshold  until  tmax  the given orbit is said to be chaotic, otherwise it is regular.  The entirety of our implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of  A A , a matrix that has as  columns  the deviation vectors.  Performance Notes  If you want to do repeated evaluations of  gali  for many initial conditions and for continuous systems, you can take advantage of the function:  gali(integrator, k, W, tmax, dt, threshold)  in conjuction with  reinit!(integrator, W)  for various  W=cat(2, state, ws) . See the source code on how to set-up the  integrator  and  W  for the first time.  References  [1] : Skokos, C. H.  et al. , Physica D  231 , pp 30\u201354 (2007)  [2] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics  915 , Springer (2016)  source", 
            "title": "Generalized Alignment Index"
        }, 
        {
            "location": "/chaos/chaos_detection/#discrete-example", 
            "text": "We will use 3 coupled standard maps as an example for a discrete system:  using   DynamicalSystems  using   PyPlot ;   figure ()  M   =   3 ;   ks   =   3 ones ( M );   \u0393   =   0.1 ;  stable   =   [ \u03c0 ,   \u03c0 ,   \u03c0 ,   0.01 ,   0 ,   0 ]   .+   0.1  chaotic   =   rand ( 2 M )  ds   =   Systems . coupledstandardmaps ( M ,   stable ;   ks = ks ,   \u0393   =   \u0393 )  tr   =   trajectory ( ds ,   100000 )  subplot ( 2 , 2 , 1 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = stable , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  #  subplot ( 2 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ,   5 ,   6 ] \n     g ,   t   =   gali ( ds ,   k ,   1e5 ;   threshold = 1e-12 ) \n     lt   =   log10 . ( t );   lg   =   log10 . ( g ) \n\n     plot ( lt ,   lg ,   label = GALI_ $ ( k ) )  end  lt   =   2 : 0.5 : 5.5  plot ( lt ,   zeros ( lt ),   label = const )  plot ( lt ,   - 2 ( lt   -   3 ),   label = slope -2 )  plot ( lt ,   - 4 ( lt   -   3 ),   label = slope -4 )  plot ( lt ,   - 6 ( lt   -   3 ),   label = slope -6 )  xlim ( 2 ,   5.5 )  ylim ( - 12 ,   1 )  legend ( fontsize = 12 )  tight_layout ()  ds   =   Systems . coupledstandardmaps ( M ,   chaotic ;   ks = ks ,   \u0393   =   \u0393 )  tr   =   trajectory ( ds ,   100000 )  subplot ( 2 , 2 , 3 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = chaotic , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  subplot ( 2 , 2 , 4 )  ls   =   lyapunovs ( ds ,   100000 )  for   k   in   [ 2 , 3 , 4 , 5   , 6 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   k ,   1000 ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  xlim ( 0 , 50 )  ylim ( 1e-12 ,   1 )", 
            "title": "Discrete Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#continuous-example", 
            "text": "As an example of a continuous system, let's see the  henonhelies :  using   DynamicalSystems  using   PyPlot  figure ( figsize = ( 10 ,   12 ))  sp   =   [ 0 ,   . 295456 ,   . 407308431 ,   0 ]   #stable periodic orbit: 1D torus  qp   =   [ 0 ,   . 483000 ,   . 278980390 ,   0 ]   #quasiperiodic orbit: 2D torus  ch   =   [ 0 ,   - 0.25 ,   0.42081 ,   0 ]   # chaotic orbit  dt   =   1.0  subplot ( 3 , 2 , 1 )  ds   =   Systems . henonhelies ( sp )  diffeq   =   Dict ( : abstol = 1e-9 ,   : reltol = 1e-9 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   10000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = sp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   k ,   50000.0 ;   dt   =   dt ,   diff_eq_kwargs   =   diffeq ) \n     if   k     4 \n         loglog ( t ,   1. / t .^ ( k - 1 ),   label = slope - $ ( k - 1 ) ) \n     else \n         loglog ( t ,   1. / t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     end \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  subplot ( 3 , 2 , 3 )  ds   =   Systems . henonhelies ( qp )  diffeq   =   Dict ( : abstol = 1e-9 ,   : reltol = 1e-9 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   10000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = qp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 4 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   k ,   10000.0 ;   dt   =   dt ,   diff_eq_kwargs   =   diffeq ) \n     loglog ( t ,   1. / t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  tight_layout ()  ds   =   Systems . henonhelies ( ch )  diffeq   =   Dict ( : abstol = 1e-6 ,   : reltol = 1e-6 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   50000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  subplot ( 3 , 2 , 5 )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = ch , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 6 )  ls   =   lyapunovs ( ds ,   5000.0 ,   dt = dt )  for   k   in   [ 2 , 3 , 4 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   k ,   1000 ;   dt   =   dt ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  tight_layout ()    As you can see, the results of both discrete and continuous match very well the theory described in  gali .", 
            "title": "Continuous Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#using-gali", 
            "text": "No-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations.  The most common usage of  \\text{GALI}_k \\text{GALI}_k  is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether  \\text{GALI}_k \\text{GALI}_k  stays below it, for a (sufficiently) big  k k .  For example one could do  using   DynamicalSystems  using   PyPlot  chaoticness ( ds )   =   gali ( ds ,   2 ,   500.0 )[ 2 ][ end ]  function   main ( k ) \n\n     dens   =   201 \n     chaoticity   =   zeros ( dens , dens ) \n     \u03b8s   =   ps   =   linspace ( 0 ,   2 \u03c0 ,   dens + 1 ) \n     ds   =   Systems . standardmap ( k   =   k ) \n\n     for   ( i ,   \u03b8 )   \u2208   enumerate ( \u03b8s [ 1 : dens ]) \n         for   ( j ,   p )   \u2208   enumerate ( ps [ 1 : dens ]) \n             ds . state   =   SVector { 2 }( \u03b8 ,   p ) \n             chaoticity [ i ,   j ]   =   chaoticness ( ds ) \n         end \n     end \n\n     pcolormesh ( \u03b8s   .-   ( \u03b8s [ 2 ]   -   \u03b8s [ 1 ]) / 2 ,   ps   .-   ( ps [ 2 ]   -   ps [ 1 ]) / 2 , \n     chaoticity ) \n     colorbar ()  end  main ( 0.9 )   and after about two minutes you will get:", 
            "title": "Using GALI"
        }, 
        {
            "location": "/chaos/visualization/", 
            "text": "DynamicalSystems.jl\n offers some basic methods for visualizing chaotic systems in the form of the functions described in this documentation page.\n\n\nAll plotting is done through the \nPyPlot.jl\n package. However, this is not a dependency of DynamicalSystems.jl. Instead, all functions described here are brought into scope as soon as the user executes \nusing PyPlot\n, which works regardless if \nPyPlot\n module was loaded before or after \nDynamicalSystems\n. This is possible through the \nRequires.jl\n package.\n\n\nUse the help mode (press \n?\n and then the function name) to access the documentation strings for e.g. using keyword arguments.\n\n\n\n\nVisualization Library\n\n\n\n\nphasespace\n : Plots the phasespace of a 2D \nDiscreteDS\n.\n\n\nplot_linear_regions\n : Plots the results of \nlnear_regions\n.", 
            "title": "Visualization"
        }, 
        {
            "location": "/chaos/visualization/#visualization-library", 
            "text": "phasespace  : Plots the phasespace of a 2D  DiscreteDS .  plot_linear_regions  : Plots the results of  lnear_regions .", 
            "title": "Visualization Library"
        }, 
        {
            "location": "/contributors_guide/", 
            "text": "Contributor Guide\n\n\nYou can contribute to this package even if you not are very good with coding with Julia.\n\n\n\n\nReporting Bugs and other Issues\n\n\nThe easiest and most common way to improve this package is simply by \nusing it\n and reporting any unexpected behavior! You can use the \nDynamicalSystems.jl Issues\n page or, if you think it is something minor not worth opening an issue, just come over to our \ngitter chatroom\n and let us know what the problem is.\n\n\n\n\nContributing New Methods and Algorithms\n\n\nThe ultimate goal for DynamicalSystems.jl is to be a useful tool for scientists working on chaos, nonlinear dynamics and in general dynamical systems.\n\n\nFor such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!\n\n\nFor a something to be implemented in this package, the following steps have to happen:\n\n\n\n\nA suggestion that a method should be included\n has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.\n\n\nAn algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.\n\n\nThe source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the \nreliability of the implementation\n.\n\n\n\n\nIt is clear that one can contribute to \nDynamicalSystems.jl\n by contributing in steps (1) and (2). Neither of those require any hardcore coding knowledge with Julia.\n\n\nFor step (1), you can open a new issue at the \nDynamicalSystems.jl Issues\n page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features \nhere\n and see for yourself if you can contribute to some of them!\n\n\nIf you have any idea about how to improve this package please do not hesitate to \njoin our chatroom\n and share your ideas!\n\n\n\n\nExamples of new things you could contribute\n\n\n\n\nAny method that calculates a quantity that has been used in at least one scientific (and peer-reviewed) journal.\n\n\nAny kind of new \nType\n of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of \nDynamicalSystem\n. I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.\n\n\nAny kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the \nfamous_systems.jl\n file).\n\n\n\n\nNotice that the above are not conclusive, but only examples!\n\n\n\n\nHow you should contribute \ncode\n\n\nCode should be contributed to the appropriate repository, e.g. \nDynamicalSystemsBase.jl\n, \nChaosTools.jl\n etc.. Recall that the repository of DynamicalSystems.jl is mainly a documentation host.\n\n\n\n\nFor new methods and systems please follow the convention of the documentation strings (do e.g. \n?lyapunov\n to see how they are structured).\n\n\nHave enough comments in your code so that somebody that knows the method, can also understand the code immediately.\n\n\nAlways have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.\n\n\n\n\nWhen enhancing already existing code, make sure to:\n\n\n\n\nHave enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributor-guide", 
            "text": "You can contribute to this package even if you not are very good with coding with Julia.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#reporting-bugs-and-other-issues", 
            "text": "The easiest and most common way to improve this package is simply by  using it  and reporting any unexpected behavior! You can use the  DynamicalSystems.jl Issues  page or, if you think it is something minor not worth opening an issue, just come over to our  gitter chatroom  and let us know what the problem is.", 
            "title": "Reporting Bugs and other Issues"
        }, 
        {
            "location": "/contributors_guide/#contributing-new-methods-and-algorithms", 
            "text": "The ultimate goal for DynamicalSystems.jl is to be a useful tool for scientists working on chaos, nonlinear dynamics and in general dynamical systems.  For such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!  For a something to be implemented in this package, the following steps have to happen:   A suggestion that a method should be included  has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.  An algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.  The source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the  reliability of the implementation .   It is clear that one can contribute to  DynamicalSystems.jl  by contributing in steps (1) and (2). Neither of those require any hardcore coding knowledge with Julia.  For step (1), you can open a new issue at the  DynamicalSystems.jl Issues  page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features  here  and see for yourself if you can contribute to some of them!  If you have any idea about how to improve this package please do not hesitate to  join our chatroom  and share your ideas!", 
            "title": "Contributing New Methods and Algorithms"
        }, 
        {
            "location": "/contributors_guide/#examples-of-new-things-you-could-contribute", 
            "text": "Any method that calculates a quantity that has been used in at least one scientific (and peer-reviewed) journal.  Any kind of new  Type  of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of  DynamicalSystem . I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.  Any kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the  famous_systems.jl  file).   Notice that the above are not conclusive, but only examples!", 
            "title": "Examples of new things you could contribute"
        }, 
        {
            "location": "/contributors_guide/#how-you-should-contribute-code", 
            "text": "Code should be contributed to the appropriate repository, e.g.  DynamicalSystemsBase.jl ,  ChaosTools.jl  etc.. Recall that the repository of DynamicalSystems.jl is mainly a documentation host.   For new methods and systems please follow the convention of the documentation strings (do e.g.  ?lyapunov  to see how they are structured).  Have enough comments in your code so that somebody that knows the method, can also understand the code immediately.  Always have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.   When enhancing already existing code, make sure to:   Have enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "How you should contribute code"
        }
    ]
}