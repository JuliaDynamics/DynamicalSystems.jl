{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nDynamicalSystems.jl\n is a Julia suite for the exploration of chaos and nonlinear dynamics.\n\n\nYou can \njoin our chatroom\n for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!\n\n\nBe sure to visit the \nContributor Guide\n page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on \nGitHub\n! This gives us an accurate lower bound of users that this package has already helped!\n\n\n\n\nUse latest documentation\n\n\nWe highly suggest our users to read the  \nlatest\n documentation   and not the \nstable\n one.\n\n\n\n\nThe current documentation was built with the following versions\n\n\n - DynamicalSystemsBase          0.5.0\n - ChaosTools                    0.5.0\n\n\n\n\n\n\n\nOur Goals\n\n\nOur aim is for the \nDynamicalSystems.jl\n to be a useful and powerful companion for students and scientists working on chaos and nonlinear dynamics, by accomplishing the following three points:\n\n\n\n\nBe concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the \nLorenz attractor\n, or a high dimensional discrete map like \ncoupled standard maps\n.\n\n\nBe accurate, reliable and performant.\n\n\nBe transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.\n\n\n\n\nFor example, provided you have first defined a \nDynamicalSystem\n (which simply reduces to writing a function for the equations of motion), you should be able to e.g. calculate the Lyapunov spectrum for it in a single line:\n\n\nlyapunovs\n(\nsystem\n,\n \ntimes_to_do_QR\n;\n \nkeywords\n...\n)\n\n\n\n\n\n\nThe same function call works with any system, no discriminations here!\n\n\n\n\nInstallation\n\n\nSimply use \nPkg.add(\"DynamicalSystems\")\n to install \neverything\n.\n\n\n\n\nLow Dependency usage\n\n\nBy running \nPkg.add(\"DynamicalSystems\")\n you install all packages of the ecosystem. That is not necessary however, since \nDynamicalSystems.jl\n is a bridging package that exports everything and hosts the documentation.\n\n\nFor example, if you only need the features of \nChaosTools.jl\n then you can get away by doing only \nPkg.add(\"ChaosTools\")\n and all other dependencies will be resolved accordingly.\n\n\n\n\nContents\n\n\n\n\nDynamicalSystemsBase.jl\n\n\n\n\nIntuitive, consistent APIs for the definition of general dynamical systems.\n\n\nDiscrete Maps\n\n\nContinuous Flows\n\n\nDedicated interface for \nNumerical Data\n\n\nAutomatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\n\n\nWell-defined functions for (numerically) evolving dynamical systems.\n\n\nLibrary of \npredefined well-known dynamical systems\n that have been used extensively in scientific research.\n\n\n\n\n\n\nChaosTools.jl\n\n\nPlease see the \noverview section\n for a full list of features.\n\n\nQuick summary:\n\n\n\n\nPoincare S.O.S. and orbit diagrams\n\n\nLyapunov Exponents\n\n\nEntropies and Dimensions\n\n\nDelay Coordinates Embedding\n\n\nNeighborhood estimation\n\n\nLyapunov exponent of a timeseries\n\n\nFinding Fixed Points of Maps\n\n\nDetecting Chaos\n\n\n\n\n\n\nWanted Features\n\n\nThe following lists state features that are wanted by the \nDynamicalSystems.jl\n ecosystem and are open to contributors. These are structured in the form of GitHub Issues, with the label \nwanted_feature\n:\n\n\n\n\nDynamicalSystemsBase.jl wanted features\n\n\nChaosTools.jl wanted features", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "DynamicalSystems.jl  is a Julia suite for the exploration of chaos and nonlinear dynamics.  You can  join our chatroom  for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!  Be sure to visit the  Contributor Guide  page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on  GitHub ! This gives us an accurate lower bound of users that this package has already helped!   Use latest documentation  We highly suggest our users to read the   latest  documentation   and not the  stable  one.   The current documentation was built with the following versions   - DynamicalSystemsBase          0.5.0\n - ChaosTools                    0.5.0", 
            "title": "Introduction"
        }, 
        {
            "location": "/#our-goals", 
            "text": "Our aim is for the  DynamicalSystems.jl  to be a useful and powerful companion for students and scientists working on chaos and nonlinear dynamics, by accomplishing the following three points:   Be concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the  Lorenz attractor , or a high dimensional discrete map like  coupled standard maps .  Be accurate, reliable and performant.  Be transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.   For example, provided you have first defined a  DynamicalSystem  (which simply reduces to writing a function for the equations of motion), you should be able to e.g. calculate the Lyapunov spectrum for it in a single line:  lyapunovs ( system ,   times_to_do_QR ;   keywords ... )   The same function call works with any system, no discriminations here!", 
            "title": "Our Goals"
        }, 
        {
            "location": "/#installation", 
            "text": "Simply use  Pkg.add(\"DynamicalSystems\")  to install  everything .", 
            "title": "Installation"
        }, 
        {
            "location": "/#low-dependency-usage", 
            "text": "By running  Pkg.add(\"DynamicalSystems\")  you install all packages of the ecosystem. That is not necessary however, since  DynamicalSystems.jl  is a bridging package that exports everything and hosts the documentation.  For example, if you only need the features of  ChaosTools.jl  then you can get away by doing only  Pkg.add(\"ChaosTools\")  and all other dependencies will be resolved accordingly.", 
            "title": "Low Dependency usage"
        }, 
        {
            "location": "/#contents", 
            "text": "", 
            "title": "Contents"
        }, 
        {
            "location": "/#dynamicalsystemsbasejl", 
            "text": "Intuitive, consistent APIs for the definition of general dynamical systems.  Discrete Maps  Continuous Flows  Dedicated interface for  Numerical Data  Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.  Well-defined functions for (numerically) evolving dynamical systems.  Library of  predefined well-known dynamical systems  that have been used extensively in scientific research.", 
            "title": "DynamicalSystemsBase.jl"
        }, 
        {
            "location": "/#chaostoolsjl", 
            "text": "Please see the  overview section  for a full list of features.  Quick summary:   Poincare S.O.S. and orbit diagrams  Lyapunov Exponents  Entropies and Dimensions  Delay Coordinates Embedding  Neighborhood estimation  Lyapunov exponent of a timeseries  Finding Fixed Points of Maps  Detecting Chaos", 
            "title": "ChaosTools.jl"
        }, 
        {
            "location": "/#wanted-features", 
            "text": "The following lists state features that are wanted by the  DynamicalSystems.jl  ecosystem and are open to contributors. These are structured in the form of GitHub Issues, with the label  wanted_feature :   DynamicalSystemsBase.jl wanted features  ChaosTools.jl wanted features", 
            "title": "Wanted Features"
        }, 
        {
            "location": "/definition/general/", 
            "text": "All core definitions for \nDynamicalSystems.jl\n are contained in \nDynamicalSystemsBase.jl\n.\n\n\nFor \nDynamicalSystems.jl\n a \"dynamical system\" is a simple structure with three fundamental parts:\n\n\n\n\nThe state,\n\n\nThe equations of motion function and\n\n\nThe Jacobian function.\n\n\n\n\nThe last two are \nfunctions\n that take as an input a state as well as the parameters of the model. Depending on the type, some dynamical system types may also have some other fields that are of minor importance.\n\n\nThe above \"definition\" of course stands for systems where one already \nknows\n the equations of motion. if instead, your \"system\" is in the form of \nnumerical data\n, then see the appropriate section.\n\n\n\n\nTrajectory and Timeseries\n\n\nThe word \"timeseries\" can be very confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in \nDynamicalSystems.jl\n we have the following convention: \n\"timeseries\"\n always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word \n\"trajectory\"\n is used to refer to a \nmulti-dimensional\n timeseries, which is of course simply a group/set of one-dimensional timeseries.\n\n\nNote that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a \nDataset\n, which is a \nVector\n of \nSVector\ns, and each \nSVector\n represents a data-point (the values of the variables at a given time-point).\n\n\n\n\n\n\n\n\nDefinition Table\n\n\nHere is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:\n\n\n\n\n\n\n\n\nSystem Type\n\n\nEquations of Motion\n\n\nJacobian\n\n\n\n\n\n\n\n\n\n\nContinuousDS\n\n\neom!(du, u, p, t)\n\n\njacob!(J, u, p, t)\n\n\n\n\n\n\nBigDiscreteDS\n\n\neom!(xnew, x, p)\n\n\njacob!(J, x, p)\n\n\n\n\n\n\nDiscreteDS\n\n\neom(x, p) -\n SVector\n\n\njacob(x, p) -\n SMatrix\n\n\n\n\n\n\nDiscreteDS1D\n\n\neom(x, p) -\n Number\n\n\nderiv(x, p) -\n Number\n\n\n\n\n\n\n\n\n\n\nUse mutable containers for the parameters\n\n\nIt is highly suggested to use a subtype of \nArray\n or \nLMArray\n for the container of the model's parameters. Some functions offered by \nDynamicalSystems.jl\n, like e.g. \norbitdiagram\n, assume that the parameters can be first accessed by \np[x]\n with \nx\n some qualifier as well as that this value can be set by \np[x] = newvalue\n.\n\n\nThe \nLabelled Arrays\n package offers \nArray\n implementations that can be accessed both by index as well as by some name.\n\n\n\n\n\n\nGeneral Functions\n\n\nThe following functions are defined for convenience for any dynamical system:\n\n\n#\n\n\nDynamicalSystemsBase.dimension\n \n \nFunction\n.\n\n\ndimension(ds::DynamicalSystem) -\n D\n\n\n\n\n\nReturn the dimension of the system.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.state\n \n \nFunction\n.\n\n\nstate(ds::DynamicalSystem) -\n u\n\n\n\n\n\nReturn the state of the system.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.jacobian\n \n \nFunction\n.\n\n\njacobian(ds::DynamicalSystem) -\n J\n\n\n\n\n\nReturn the Jacobian matrix of the equations of motion at the system's current state and parameters.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.set_state!\n \n \nFunction\n.\n\n\nset_state!(ds::DynamicalSystem, newstate)\n\n\n\n\n\nSet the state of the system to \nnewstate\n.\n\n\nsource", 
            "title": "General Remarks"
        }, 
        {
            "location": "/definition/general/#definition-table", 
            "text": "Here is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:     System Type  Equations of Motion  Jacobian      ContinuousDS  eom!(du, u, p, t)  jacob!(J, u, p, t)    BigDiscreteDS  eom!(xnew, x, p)  jacob!(J, x, p)    DiscreteDS  eom(x, p) -  SVector  jacob(x, p) -  SMatrix    DiscreteDS1D  eom(x, p) -  Number  deriv(x, p) -  Number      Use mutable containers for the parameters  It is highly suggested to use a subtype of  Array  or  LMArray  for the container of the model's parameters. Some functions offered by  DynamicalSystems.jl , like e.g.  orbitdiagram , assume that the parameters can be first accessed by  p[x]  with  x  some qualifier as well as that this value can be set by  p[x] = newvalue .  The  Labelled Arrays  package offers  Array  implementations that can be accessed both by index as well as by some name.", 
            "title": "Definition Table"
        }, 
        {
            "location": "/definition/general/#general-functions", 
            "text": "The following functions are defined for convenience for any dynamical system:  #  DynamicalSystemsBase.dimension     Function .  dimension(ds::DynamicalSystem) -  D  Return the dimension of the system.  source  #  DynamicalSystemsBase.state     Function .  state(ds::DynamicalSystem) -  u  Return the state of the system.  source  #  DynamicalSystemsBase.jacobian     Function .  jacobian(ds::DynamicalSystem) -  J  Return the Jacobian matrix of the equations of motion at the system's current state and parameters.  source  #  DynamicalSystemsBase.set_state!     Function .  set_state!(ds::DynamicalSystem, newstate)  Set the state of the system to  newstate .  source", 
            "title": "General Functions"
        }, 
        {
            "location": "/definition/continuous/", 
            "text": "Continuous Systems\n\n\nContinuous systems of the form\n\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),\n\n\n\n\n\nare defined using the \nContinuousDS\n structure:\n\n\n#\n\n\nDynamicalSystemsBase.ContinuousDS\n \n \nType\n.\n\n\nContinuousDS \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional continuous dynamical system.\n\n\nFields\n\n\n\n\nprob::ODEProblem\n : The fundamental structure used to describe a continuous dynamical system and also used in the \nDifferentialEquations.jl\n suite. Contains the system's state (\nprob.u0\n), the equations of motion (\nprob.f\n), the parameters of the equations of motion (\nprob.p\n) and optionally other information like e.g. \ncallbacks\n.\n\n\njacob!\n (function) : The function that represents the Jacobian of the system, given in the format: \njacob!(J, u, p, t)\n which means given a state \nu\n, a parameter container \np\n and a time \nt\n, it writes the system's Jacobian in-place in \nJ\n.\n\n\nJ::Matrix{T}\n : Initialized Jacobian matrix.\n\n\n\n\nThe equations of motion function is contained in \nprob.f\n, the state is contained in \nprob.u0\n and the parameters are contained in \nprob.p\n.\n\n\nCreating a \nContinuousDS\n\n\nThe equations of motion function \nmust be\n in the form \neom!(du, u, p, t)\n, as requested by DifferentialEquations.jl. They are \nin-place\n with the mutated argument \ndu\n being first. \np\n stands for the parameters of the model and \nt\n stands for the time variable (independent variable). Actually using \np\n and \nt\n inside \neom!\n is completely optional, however \nboth must be used in the definition of the function\n! Both \nu, du\n \nmust be\n \nVector\ns.\n\n\nIf you have the \neom!\n function, and optionally a function for the Jacobian, you can use the constructor\n\n\nContinuousDS\n(\nstate\n,\n \neom!\n \n[,\n \njacob!\n \n[,\n \nJ\n]];\n\n             \ntspan\n \n=\n \n(\n0.0\n,\n \n100.0\n),\n \nparameters\n \n=\n \nnothing\n)\n\n\n\n\n\n\nwith \nstate\n the initial condition of the system. \nparameters\n is a keyword corresponding to the initial parameters of the model, and if not given it is assumed to be \nnothing\n (which of course means that the model does not have any parameters).\n\n\nIf instead you already have an \nODEProblem\n because you also want to take advantage of the callback functionality of DifferentialEquations.jl, you may use the constructor\n\n\nContinuousDS\n(\nodeproblem\n \n[,\n \njacob!\n \n[,\n \nJ\n]])\n\n\n\n\n\n\nIf the \njacob!\n is not provided by the user, it is created automatically using the module \nForwardDiff\n, which always passes \np = odeproblem.p, t=0\n at the \neom!\n (this interaction is well-behavied for all functions exported by the DynamicalSystems.jl suite because the parameter container is passed by reference and thus mutations in parameters propagate correctly).\n\n\nContinuousDS\n by default are evolved using solver \nVern9()\n and tolerances \n:abstol =\n 1e-9, :reltol =\n 1e-9\n.\n\n\nSee also \nset_state!\n.\n\n\nsource\n\n\n\n\nIn the following examples we will demonstrate how one can use both constructors.\n\n\n\n\nDefining a \nContinuousDS\n using \neom!\n\n\nHere we will use the constructor\n\n\nContinuousDS\n(\nstate\n,\n\u00a0\neom!\n\u00a0\n[,\n\u00a0\njacob!\n\u00a0\n[,\n\u00a0\nJ\n]];\n\u00a0\ntspan\n\u00a0\n=\n\u00a0\n(\n0.0\n,\n\u00a0\n100.0\n))\n\n\n\n\n\n\nand create the continuous R\u00f6ssler system, from our \nPredefined Systems\n:\n\n\nusing\n \nDynamicalSystems\n\n\n\n@inline\n \n@inbounds\n \nfunction\n \nroessler_eom\n(\ndu\n,\n \nu\n,\n \np\n,\n \nt\n)\n\n    \na\n,\n \nb\n,\n \nc\n \n=\n \np\n\n    \ndu\n[\n1\n]\n \n=\n \n-\nu\n[\n2\n]\n-\nu\n[\n3\n]\n\n    \ndu\n[\n2\n]\n \n=\n \nu\n[\n1\n]\n \n+\n \na\n*\nu\n[\n2\n]\n\n    \ndu\n[\n3\n]\n \n=\n \nb\n \n+\n \nu\n[\n3\n]\n*\n(\nu\n[\n1\n]\n \n-\n \nc\n)\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n@inline\n \n@inbounds\n \nfunction\n \nroessler_jacob\n(\nJ\n,\n \nu\n,\n \np\n,\n \nt\n)\n\n    \nJ\n[\n2\n,\n2\n]\n \n=\n \np\n[\n1\n]\n\n    \nJ\n[\n3\n,\n1\n]\n \n=\n \nu\n[\n3\n];\n \nJ\n[\n3\n,\n3\n]\n \n=\n \nu\n[\n1\n]\n \n-\n \np\n[\n3\n]\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nThe first code-block defines defines the equations of motion of the system. The second code-block then defines the Jacobian function of the system.\n\n\nThe possibility of providing an initialized Jacobian to the \nContinuousDS\n constructor allows us to \"cheat\". Notice that the Jacobian function only accesses fields that depend on the parameters and/or the state variables, because the other fields are constants and will be initialized properly later.\n\n\nNext, we define a \"set-up\" function, that returns a \nContinuousDS\n:\n\n\nfunction\n \nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n    \ni\n \n=\n \none\n(\neltype\n(\nu0\n))\n\n    \no\n \n=\n \nzero\n(\neltype\n(\nu0\n))\n\n    \nJ\n \n=\n \nzeros\n(\neltype\n(\nu0\n),\n \n3\n,\n \n3\n)\n\n    \nJ\n[\n1\n,\n:\n]\n \n.=\n \n[\no\n,\n \n-\ni\n,\n      \n-\ni\n]\n\n    \nJ\n[\n2\n,\n:\n]\n \n.=\n \n[\ni\n,\n  \na\n,\n       \no\n]\n\n    \nJ\n[\n3\n,\n:\n]\n \n.=\n \n[\nu0\n[\n3\n],\n \no\n,\n \nu0\n[\n1\n]\n \n-\n \nc\n]\n\n\n    \nreturn\n \nContinuousDS\n(\nu0\n,\n \nroessler_eom\n,\n \nroessler_jacob\n,\n \nJ\n;\n \nparameters\n \n=\n \n[\na\n,\n \nb\n,\n \nc\n])\n\n\nend\n\n\n\nds\n \n=\n \nroessler\n()\n\n\n# Equivalent with our predefined system:\n\n\nds\n \n=\n \nSystems\n.\nroessler\n()\n\n\n\n\n\n\n3-dimensional continuous dynamical system:\nstate: [0.021655, 0.530449, 0.0227049]\ne.o.m.: DynamicalSystemsBase.Systems.roessler_eom\n\n\n\n\n\nThen, it is trivial to change a parameter of the system by e.g. doing \nds.prob.p[3] = 2.2\n. Notice that this parameter change will affect both the equations of motion as well as the Jacobian function, making everything concise and easy-to-use!\n\n\n\n\nDefining a \nContinuousDS\n using \nODEProblem\n\n\nHere we will show how one can take advantage of the callback capabilities of \nDifferentialEquations.jl\n to define a system.\n\n\n\n\nCallbacks do not propagate in variation vector methods!\n\n\nMethods that evolve variation vectors in time (currenlty \ngali\n and \nlyapunovs\n) do not inherit callbacks present in the definition of a \nContinuousDS\n. The issue that keeps track of this is \nhere\n.\n\n\n\n\nWe will make a H\u00e9non\u2013Heiles that also satisfies energy conservation. This is also available in the \npredefined systems\n, but we will use it here as an example.\n\n\nWe first write the equations of motion and the Jacobian functions in the instructed form:\n\n\nfunction\n \nhheom!\n(\ndu\n,\n \nu\n,\n \np\n,\n \nt\n)\n\n    \ndu\n[\n1\n]\n \n=\n \nu\n[\n3\n]\n\n    \ndu\n[\n2\n]\n \n=\n \nu\n[\n4\n]\n\n    \ndu\n[\n3\n]\n \n=\n \n-\nu\n[\n1\n]\n \n-\n \n2\nu\n[\n1\n]\n*\nu\n[\n2\n]\n\n    \ndu\n[\n4\n]\n \n=\n \n-\nu\n[\n2\n]\n \n-\n \n(\nu\n[\n1\n]\n^\n2\n \n-\n \nu\n[\n2\n]\n^\n2\n)\n\n    \nreturn\n \nnothing\n\n\nend\n\n\nfunction\n \nhhjacob!\n(\nJ\n,\n \nu\n,\n \np\n,\n \nt\n)\n\n    \nJ\n[\n3\n,\n1\n]\n \n=\n \n-\n1\n \n-\n \n2\nu\n[\n2\n];\n \nJ\n[\n3\n,\n2\n]\n \n=\n \n-\n2\nu\n[\n1\n]\n\n    \nJ\n[\n4\n,\n1\n]\n \n=\n \n-\n2\nu\n[\n1\n];\n \nJ\n[\n4\n,\n2\n]\n \n=\n  \n-\n1\n \n+\n \n2\nu\n[\n2\n]\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nThe Jacobian matrix will be initialized properly later. Now, we are going to use a \nCallback\n to conserve energy. First, define the energy functions\n\n\n@inline\n \nV\n(\nq1\n,\n \nq2\n)\n \n=\n \n1\n//\n2\n \n*\n \n(\nq1\n^\n2\n \n+\n \nq2\n^\n2\n \n+\n \n2\nq1\n^\n2\n \n*\n \nq2\n \n-\n \n2\n//\n3\n \n*\n \nq2\n^\n3\n)\n\n\n@inline\n \nT\n(\np1\n,\n \np2\n)\n \n=\n \n1\n//\n2\n \n*\n \n(\np1\n^\n2\n \n+\n \np2\n^\n2\n)\n\n\n@inline\n \nH\n(\nq1\n,\n \nq2\n,\n \np1\n,\n \np2\n)\n \n=\n \nT\n(\np1\n,\n \np2\n)\n \n+\n \nV\n(\nq1\n,\n \nq2\n)\n\n\n@inline\n \nH\n(\nu\n::\nAbstractVector\n)\n \n=\n \nH\n(\nu\n...\n)\n\n\n\n\n\n\nThen, create a \"residual\" function, used in the \nManifoldProjection\n callback:\n\n\nu0\n \n=\n \n[\n0.1\n,\n \n0\n,\n \n0\n,\n \n0.5\n]\n\n\nconst\n \nE\n \n=\n \nH\n(\nu0\n[\n1\n],\nu0\n[\n2\n],\nu0\n[\n3\n],\nu0\n[\n4\n])\n\n\n\nfunction\n \ng!\n(\nresid\n,\n \nu\n)\n\n    \nresid\n[\n1\n]\n \n=\n \nH\n(\nu\n[\n1\n],\nu\n[\n2\n],\nu\n[\n3\n],\nu\n[\n4\n])\n \n-\n \nE\n\n    \nresid\n[\n2\n:\n4\n]\n \n.=\n \n0\n\n\nend\n\n\n\n\n\n\nNext we create the \nCallback\n, the \nODEProblem\n and then dynamical system structure, \nContinuousDS\n:\n\n\n# Pkg.add(\nDiffEqCallbacks\n)\n\n\nusing\n \nDiffEqCallbacks\n,\n \nOrdinaryDiffEq\n\n\n\ncb\n \n=\n \nManifoldProjection\n(\ng!\n,\n \nnlopts\n=\nDict\n(\n:\nftol\n=\n1e-13\n),\n \nsave\n \n=\n \nfalse\n)\n\n\nprob\n \n=\n \nODEProblem\n(\nhheom!\n,\n \nu0\n,\n \n(\n0.\n,\n \n100.0\n),\n  \ncallback\n=\ncb\n)\n\n\n\n# Initialize Jacobian\n\n\no\n \n=\n \n0.0\n;\n \ni\n \n=\n \n1.0\n;\n \nJ\n \n=\n \nzeros\n(\n4\n,\n4\n)\n\n\nJ\n[\n1\n,\n:\n]\n \n=\n \n[\no\n,\n    \no\n,\n     \ni\n,\n    \no\n]\n\n\nJ\n[\n2\n,\n:\n]\n \n=\n \n[\no\n,\n    \no\n,\n     \no\n,\n    \ni\n]\n\n\nJ\n[\n3\n,\n:\n]\n \n=\n \n[\n \n-\ni\n \n-\n \n2\nu0\n[\n2\n],\n   \n-\n2\nu0\n[\n1\n],\n   \no\n,\n   \no\n]\n\n\nJ\n[\n4\n,\n:\n]\n \n=\n \n[\n-\n2\nu0\n[\n1\n],\n  \n-\n1\n \n+\n \n2\nu0\n[\n2\n],\n  \no\n,\n   \no\n]\n\n\n\nds\n \n=\n \nContinuousDS\n(\nprob\n,\n \nhhjacob!\n,\n \nJ\n)\n\n\n\n\n\n\nNotice that using the argument \nsave = false\n in the \nManifoldProjection\n is crucial, because otherwise any data taken from the system, using e.g. \ntrajectory\n will necessarily have saved points at every callback realization (which you \ndo not\n want if you want timeseries sampled at regular intervals, which is also the whole purpose of \ntrajectory\n).\n\n\nLet's see now if our system does indeed conserve energy!\n\n\na1\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n)\n\n\nenergies1\n \n=\n \n[\nH\n(\np\n)\n \nfor\n \np\n \nin\n \na1\n]\n\n\nmaxer\n \n=\n \nmaximum\n(\n@\n.\n \nenergies1\n \n-\n \nE\n)\n\n\nprintln\n(\nDefault accuracy: max(\u0394E) = \n$maxer\n)\n\n\n\n\n\n\nDefault accuracy: max(\u0394E) = 9.926393040871062e-12\n\n\n\n\n\nReminder: by default \nDynamicalSystems.jl\n uses the solver \nVern9()\n and error tolerances of \n1e-9\n.", 
            "title": "Continuous Systems"
        }, 
        {
            "location": "/definition/continuous/#continuous-systems", 
            "text": "Continuous systems of the form   \n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),  \n\\frac{d\\vec{u}}{dt} = \\vec{f}(t, \\vec{u}),   are defined using the  ContinuousDS  structure:  #  DynamicalSystemsBase.ContinuousDS     Type .  ContinuousDS  : DynamicalSystem  D -dimensional continuous dynamical system.  Fields   prob::ODEProblem  : The fundamental structure used to describe a continuous dynamical system and also used in the  DifferentialEquations.jl  suite. Contains the system's state ( prob.u0 ), the equations of motion ( prob.f ), the parameters of the equations of motion ( prob.p ) and optionally other information like e.g.  callbacks .  jacob!  (function) : The function that represents the Jacobian of the system, given in the format:  jacob!(J, u, p, t)  which means given a state  u , a parameter container  p  and a time  t , it writes the system's Jacobian in-place in  J .  J::Matrix{T}  : Initialized Jacobian matrix.   The equations of motion function is contained in  prob.f , the state is contained in  prob.u0  and the parameters are contained in  prob.p .  Creating a  ContinuousDS  The equations of motion function  must be  in the form  eom!(du, u, p, t) , as requested by DifferentialEquations.jl. They are  in-place  with the mutated argument  du  being first.  p  stands for the parameters of the model and  t  stands for the time variable (independent variable). Actually using  p  and  t  inside  eom!  is completely optional, however  both must be used in the definition of the function ! Both  u, du   must be   Vector s.  If you have the  eom!  function, and optionally a function for the Jacobian, you can use the constructor  ContinuousDS ( state ,   eom!   [,   jacob!   [,   J ]]; \n              tspan   =   ( 0.0 ,   100.0 ),   parameters   =   nothing )   with  state  the initial condition of the system.  parameters  is a keyword corresponding to the initial parameters of the model, and if not given it is assumed to be  nothing  (which of course means that the model does not have any parameters).  If instead you already have an  ODEProblem  because you also want to take advantage of the callback functionality of DifferentialEquations.jl, you may use the constructor  ContinuousDS ( odeproblem   [,   jacob!   [,   J ]])   If the  jacob!  is not provided by the user, it is created automatically using the module  ForwardDiff , which always passes  p = odeproblem.p, t=0  at the  eom!  (this interaction is well-behavied for all functions exported by the DynamicalSystems.jl suite because the parameter container is passed by reference and thus mutations in parameters propagate correctly).  ContinuousDS  by default are evolved using solver  Vern9()  and tolerances  :abstol =  1e-9, :reltol =  1e-9 .  See also  set_state! .  source   In the following examples we will demonstrate how one can use both constructors.", 
            "title": "Continuous Systems"
        }, 
        {
            "location": "/definition/continuous/#defining-a-continuousds-using-eom", 
            "text": "Here we will use the constructor  ContinuousDS ( state , \u00a0 eom! \u00a0 [, \u00a0 jacob! \u00a0 [, \u00a0 J ]]; \u00a0 tspan \u00a0 = \u00a0 ( 0.0 , \u00a0 100.0 ))   and create the continuous R\u00f6ssler system, from our  Predefined Systems :  using   DynamicalSystems  @inline   @inbounds   function   roessler_eom ( du ,   u ,   p ,   t ) \n     a ,   b ,   c   =   p \n     du [ 1 ]   =   - u [ 2 ] - u [ 3 ] \n     du [ 2 ]   =   u [ 1 ]   +   a * u [ 2 ] \n     du [ 3 ]   =   b   +   u [ 3 ] * ( u [ 1 ]   -   c ) \n     return   nothing  end  @inline   @inbounds   function   roessler_jacob ( J ,   u ,   p ,   t ) \n     J [ 2 , 2 ]   =   p [ 1 ] \n     J [ 3 , 1 ]   =   u [ 3 ];   J [ 3 , 3 ]   =   u [ 1 ]   -   p [ 3 ] \n     return   nothing  end   The first code-block defines defines the equations of motion of the system. The second code-block then defines the Jacobian function of the system.  The possibility of providing an initialized Jacobian to the  ContinuousDS  constructor allows us to \"cheat\". Notice that the Jacobian function only accesses fields that depend on the parameters and/or the state variables, because the other fields are constants and will be initialized properly later.  Next, we define a \"set-up\" function, that returns a  ContinuousDS :  function   roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 ) \n     i   =   one ( eltype ( u0 )) \n     o   =   zero ( eltype ( u0 )) \n     J   =   zeros ( eltype ( u0 ),   3 ,   3 ) \n     J [ 1 , : ]   .=   [ o ,   - i ,        - i ] \n     J [ 2 , : ]   .=   [ i ,    a ,         o ] \n     J [ 3 , : ]   .=   [ u0 [ 3 ],   o ,   u0 [ 1 ]   -   c ] \n\n     return   ContinuousDS ( u0 ,   roessler_eom ,   roessler_jacob ,   J ;   parameters   =   [ a ,   b ,   c ])  end  ds   =   roessler ()  # Equivalent with our predefined system:  ds   =   Systems . roessler ()   3-dimensional continuous dynamical system:\nstate: [0.021655, 0.530449, 0.0227049]\ne.o.m.: DynamicalSystemsBase.Systems.roessler_eom  Then, it is trivial to change a parameter of the system by e.g. doing  ds.prob.p[3] = 2.2 . Notice that this parameter change will affect both the equations of motion as well as the Jacobian function, making everything concise and easy-to-use!", 
            "title": "Defining a ContinuousDS using eom!"
        }, 
        {
            "location": "/definition/continuous/#defining-a-continuousds-using-odeproblem", 
            "text": "Here we will show how one can take advantage of the callback capabilities of  DifferentialEquations.jl  to define a system.   Callbacks do not propagate in variation vector methods!  Methods that evolve variation vectors in time (currenlty  gali  and  lyapunovs ) do not inherit callbacks present in the definition of a  ContinuousDS . The issue that keeps track of this is  here .   We will make a H\u00e9non\u2013Heiles that also satisfies energy conservation. This is also available in the  predefined systems , but we will use it here as an example.  We first write the equations of motion and the Jacobian functions in the instructed form:  function   hheom! ( du ,   u ,   p ,   t ) \n     du [ 1 ]   =   u [ 3 ] \n     du [ 2 ]   =   u [ 4 ] \n     du [ 3 ]   =   - u [ 1 ]   -   2 u [ 1 ] * u [ 2 ] \n     du [ 4 ]   =   - u [ 2 ]   -   ( u [ 1 ] ^ 2   -   u [ 2 ] ^ 2 ) \n     return   nothing  end  function   hhjacob! ( J ,   u ,   p ,   t ) \n     J [ 3 , 1 ]   =   - 1   -   2 u [ 2 ];   J [ 3 , 2 ]   =   - 2 u [ 1 ] \n     J [ 4 , 1 ]   =   - 2 u [ 1 ];   J [ 4 , 2 ]   =    - 1   +   2 u [ 2 ] \n     return   nothing  end   The Jacobian matrix will be initialized properly later. Now, we are going to use a  Callback  to conserve energy. First, define the energy functions  @inline   V ( q1 ,   q2 )   =   1 // 2   *   ( q1 ^ 2   +   q2 ^ 2   +   2 q1 ^ 2   *   q2   -   2 // 3   *   q2 ^ 3 )  @inline   T ( p1 ,   p2 )   =   1 // 2   *   ( p1 ^ 2   +   p2 ^ 2 )  @inline   H ( q1 ,   q2 ,   p1 ,   p2 )   =   T ( p1 ,   p2 )   +   V ( q1 ,   q2 )  @inline   H ( u :: AbstractVector )   =   H ( u ... )   Then, create a \"residual\" function, used in the  ManifoldProjection  callback:  u0   =   [ 0.1 ,   0 ,   0 ,   0.5 ]  const   E   =   H ( u0 [ 1 ], u0 [ 2 ], u0 [ 3 ], u0 [ 4 ])  function   g! ( resid ,   u ) \n     resid [ 1 ]   =   H ( u [ 1 ], u [ 2 ], u [ 3 ], u [ 4 ])   -   E \n     resid [ 2 : 4 ]   .=   0  end   Next we create the  Callback , the  ODEProblem  and then dynamical system structure,  ContinuousDS :  # Pkg.add( DiffEqCallbacks )  using   DiffEqCallbacks ,   OrdinaryDiffEq  cb   =   ManifoldProjection ( g! ,   nlopts = Dict ( : ftol = 1e-13 ),   save   =   false )  prob   =   ODEProblem ( hheom! ,   u0 ,   ( 0. ,   100.0 ),    callback = cb )  # Initialize Jacobian  o   =   0.0 ;   i   =   1.0 ;   J   =   zeros ( 4 , 4 )  J [ 1 , : ]   =   [ o ,      o ,       i ,      o ]  J [ 2 , : ]   =   [ o ,      o ,       o ,      i ]  J [ 3 , : ]   =   [   - i   -   2 u0 [ 2 ],     - 2 u0 [ 1 ],     o ,     o ]  J [ 4 , : ]   =   [ - 2 u0 [ 1 ],    - 1   +   2 u0 [ 2 ],    o ,     o ]  ds   =   ContinuousDS ( prob ,   hhjacob! ,   J )   Notice that using the argument  save = false  in the  ManifoldProjection  is crucial, because otherwise any data taken from the system, using e.g.  trajectory  will necessarily have saved points at every callback realization (which you  do not  want if you want timeseries sampled at regular intervals, which is also the whole purpose of  trajectory ).  Let's see now if our system does indeed conserve energy!  a1   =   trajectory ( ds ,   1000.0 )  energies1   =   [ H ( p )   for   p   in   a1 ]  maxer   =   maximum ( @ .   energies1   -   E )  println ( Default accuracy: max(\u0394E) =  $maxer )   Default accuracy: max(\u0394E) = 9.926393040871062e-12  Reminder: by default  DynamicalSystems.jl  uses the solver  Vern9()  and error tolerances of  1e-9 .", 
            "title": "Defining a ContinuousDS using ODEProblem"
        }, 
        {
            "location": "/definition/discrete/", 
            "text": "Discrete Systems\n\n\nDiscrete systems are of the form:\n\n\n\n\n\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\n\n\n\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\n\n\n\n\nDynamicalSystems.jl\n categorizes discrete systems in three cases, due to the extremely performant handling that \nStaticArrays\n offers for small dimensionalities.\n\n\nHandling of discrete systems is done exclusively from \nDynamicalSystems.jl\n and so there is no interaction with DifferentialEquations.jl. This also means that the definition of a discrete system may differ slightly from a continuous one.\n\n\n\n\nNon-autonomous systems\n\n\nTo define a discrete system that depends on \"time\" \nn\nn\n, extend the equations of motion by introducing a new variable \n\\tau\n\\tau\n such that \n\\tau_{n+1} =  \\tau_n + 1\n\\tau_{n+1} =  \\tau_n + 1\n and use this in the equations for the other variables.\n\n\n\n\n\n\nHigh-Dimensional\n\n\nAt around \nD=10\n dimensions, Static Arrays start to become less efficient than Julia's base Arrays, provided that the latter use in-place operations. For cases of discrete systems with much high dimensionality, we offer a type called \nBigDiscreteDS\n:\n\n\n#\n\n\nDynamicalSystemsBase.BigDiscreteDS\n \n \nType\n.\n\n\nBigDiscreteDS \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional discrete dynamical system (used for big \nD\n). The equations for this system perform all operations \nin-place\n.\n\n\nFields:\n\n\n\n\nstate::Vector{T}\n : Current state-vector of the system. Do \nstate(ds) .= u\n to change the state.\n\n\neom!\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom!(xnew, x, p)\n which means that given a state \nVector\n \nx\n and some parameter container \np\n, it writes in-place the new state in \nxnew\n.\n\n\njacob!\n (function) : A function that calculates the system's jacobian matrix, based on the format: \njacob!(J, x, p)\n which means that given a state \nVector\n \nx\n it writes in-place the Jacobian in \nJ\n.\n\n\nJ::Matrix{T}\n : Initialized Jacobian matrix (optional).\n\n\np\n : Some kind of container of (initial) parameters. Highly suggested to use a subtype of \nArray\n or \nLMArray\n.\n\n\ndummystate::Vector{T}\n : Dummy vector, which most of the time fills the role of the previous state in e.g. \nevolve\n.\n\n\n\n\nIt is not necessary that \np\n is used inside the functions (e.g. a model without parameters), however the functions \nmust be\n declared in this format.\n\n\nUse \nset_state!\n to change the system's state.\n\n\nConstructor\n\n\nBigDiscreteDS\n(\nstate\n,\n \neom!\n \n[,\n \njacob!\n \n[,\n \nJ\n]];\n \nparameters\n \n=\n \nnothing\n)\n\n\n\n\n\n\nIf the \njacob\n is not provided by the user, it is created automatically using the module \nForwardDiff\n. Notice that if your model has parameters, you \nmust\n give them via the keyword argument \nparameters\n.\n\n\nAutomatic differentiation and parameter changes works only if the container \np\n is changed in-place!\n\n\nsource\n\n\n\n\nThe source code of the pre-defined \ncoupled standard maps\n can serve as an example of a \nBigDiscreteDS\n definition \n(we do not show it here because it is very large and very complicated\n).\n\n\nJust keep in mind that the equations of motion for \nBigDiscreteDS\n are of the form \neom!(xnew, x, p)\n!\n\n\n\n\nLow-dimensional\n\n\nThe definition of low-dimensional discrete systems differs fundamentally from high dimensional ones, because everything is \nmuch\n more efficiently done with statically sized vectors. The \nstruct\n representing such systems is called \nDiscreteDS\n:\n\n\n#\n\n\nDynamicalSystemsBase.DiscreteDS\n \n \nType\n.\n\n\nDiscreteDS \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional discrete dynamical system.\n\n\nFields\n\n\n\n\nstate::SVector{D}\n : Current state-vector of the system, stored in the data format of \nStaticArray\n's \nSVector\n.\n\n\neom\n (function) : The function that represents the system's equations of motion (also called vector field). It \nmust\n be in the form \neom(x, p) -\n SVector\n which means that given a state \nx::SVector\n and some parameter container \np\n it returns an \nSVector\n containing the next state.\n\n\njacob\n (function) : A function that calculates the system's jacobian matrix. It \nmust be\n in the form \njacob(x, p) -\n SMatrix\n which means that given a state \nx::Svector\n and a parameter container \np\n it returns an \nSMatrix\n containing the Jacobian at that state.\n\n\np\n : Some kind of container of (initial) parameters. Highly suggested to use a subtype of \nArray\n or \nLMArray\n.\n\n\n\n\nIt is not necessary that \np\n is used inside the functions (e.g. a model without parameters), however the functions \nmust be\n declared in this format.\n\n\nUse \nset_state!\n to change the system's state.\n\n\nConstructor\n\n\nDiscreteDS\n(\nstate\n,\n \neom\n \n[,\n \njacob\n];\n \nparameters\n \n=\n \nnothing\n)\n\n\n\n\n\n\nIf the \njacob\n is not provided by the user, it is created automatically using the module \nForwardDiff\n. Notice that if your model has parameters, you \nmust\n give them via the keyword argument \nparameters\n.\n\n\nAutomatic differentiation and parameter changes works only if the container \np\n is changed in-place!\n\n\nsource\n\n\n\n\n\n\nReturn form of the \neom\n function\n\n\nIt is \nheavily\n advised that the equations of motion \neom\n function returns an \nSVector\n from the julia package \nStaticArrays.jl\n and similarly the \njacob\n function returns an \nSMatrix\n in the case of \nDiscreteDS\n.\n\n\n\n\nFor example, here is the case of the pre-defined \nhenon map\n:\n\n\nfunction\n \nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n    \nhenon_eom\n(\nx\n,\n \np\n)\n \n=\n \nSVector\n{\n2\n}(\n1.0\n \n-\n \np\n[\n1\n]\n*\nx\n[\n1\n]\n^\n2\n \n+\n \nx\n[\n2\n],\n \np\n[\n2\n]\n*\nx\n[\n1\n])\n\n    \nhenon_jacob\n(\nx\n,\n \np\n)\n \n=\n \n@SMatrix\n \n[\n-\n2\n*\np\n[\n1\n]\n*\nx\n[\n1\n]\n \n1.0\n;\n \np\n[\n2\n]\n \n0.0\n]\n\n    \nreturn\n \nDiscreteDS\n(\nu0\n,\n \nhenon_eom\n,\n \nhenon_jacob\n;\n \nparameters\n \n=\n \n[\na\n,\n \nb\n])\n\n\nend\n\n\n\n\n\n\nTo change the parameter \na\n you would use \nds.p[1] = 123\n and the change will affect \nboth\n the equations of motion as well as the Jacobian!\n\n\n\n\nOne-Dimensional\n\n\nIn the case of maps, there a special structure for one-dimensional systems. The syntax is \nDiscreteDS1D(state, eom [, deriv]; parameters = nothing)\n. In this one-dimensional case, you don't need to worry about StaticArrays.jl because everything is in plain numbers.\n\n\nFor example, the \nlogistic map\n is defined as:\n\n\nfunction\n \nlogistic\n(\nx0\n=\nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n    \n@inline\n \nlogistic_eom\n(\nx\n,\n \np\n)\n \n=\n \np\n[\n1\n]\n*\nx\n*\n(\n1\n-\nx\n)\n\n    \n@inline\n \nlogistic_jacob\n(\nx\n,\n \np\n)\n \n=\n \np\n[\n1\n]\n*\n(\n1\n-\n2\nx\n)\n\n    \nreturn\n \nDiscreteDS1D\n(\nx0\n,\n \nlogistic_eom\n,\n \nlogistic_jacob\n;\n \nparameters\n \n=\n \n[\nr\n])\n\n\nend\n\n\n\n\n\n\nOnce again, if you skip the derivative functions it will be calculated automatically using ForwardDiff.jl.", 
            "title": "Discrete Systems"
        }, 
        {
            "location": "/definition/discrete/#discrete-systems", 
            "text": "Discrete systems are of the form:   \n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).  \n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).   DynamicalSystems.jl  categorizes discrete systems in three cases, due to the extremely performant handling that  StaticArrays  offers for small dimensionalities.  Handling of discrete systems is done exclusively from  DynamicalSystems.jl  and so there is no interaction with DifferentialEquations.jl. This also means that the definition of a discrete system may differ slightly from a continuous one.   Non-autonomous systems  To define a discrete system that depends on \"time\"  n n , extend the equations of motion by introducing a new variable  \\tau \\tau  such that  \\tau_{n+1} =  \\tau_n + 1 \\tau_{n+1} =  \\tau_n + 1  and use this in the equations for the other variables.", 
            "title": "Discrete Systems"
        }, 
        {
            "location": "/definition/discrete/#high-dimensional", 
            "text": "At around  D=10  dimensions, Static Arrays start to become less efficient than Julia's base Arrays, provided that the latter use in-place operations. For cases of discrete systems with much high dimensionality, we offer a type called  BigDiscreteDS :  #  DynamicalSystemsBase.BigDiscreteDS     Type .  BigDiscreteDS  : DynamicalSystem  D -dimensional discrete dynamical system (used for big  D ). The equations for this system perform all operations  in-place .  Fields:   state::Vector{T}  : Current state-vector of the system. Do  state(ds) .= u  to change the state.  eom!  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom!(xnew, x, p)  which means that given a state  Vector   x  and some parameter container  p , it writes in-place the new state in  xnew .  jacob!  (function) : A function that calculates the system's jacobian matrix, based on the format:  jacob!(J, x, p)  which means that given a state  Vector   x  it writes in-place the Jacobian in  J .  J::Matrix{T}  : Initialized Jacobian matrix (optional).  p  : Some kind of container of (initial) parameters. Highly suggested to use a subtype of  Array  or  LMArray .  dummystate::Vector{T}  : Dummy vector, which most of the time fills the role of the previous state in e.g.  evolve .   It is not necessary that  p  is used inside the functions (e.g. a model without parameters), however the functions  must be  declared in this format.  Use  set_state!  to change the system's state.  Constructor  BigDiscreteDS ( state ,   eom!   [,   jacob!   [,   J ]];   parameters   =   nothing )   If the  jacob  is not provided by the user, it is created automatically using the module  ForwardDiff . Notice that if your model has parameters, you  must  give them via the keyword argument  parameters .  Automatic differentiation and parameter changes works only if the container  p  is changed in-place!  source   The source code of the pre-defined  coupled standard maps  can serve as an example of a  BigDiscreteDS  definition  (we do not show it here because it is very large and very complicated ).  Just keep in mind that the equations of motion for  BigDiscreteDS  are of the form  eom!(xnew, x, p) !", 
            "title": "High-Dimensional"
        }, 
        {
            "location": "/definition/discrete/#low-dimensional", 
            "text": "The definition of low-dimensional discrete systems differs fundamentally from high dimensional ones, because everything is  much  more efficiently done with statically sized vectors. The  struct  representing such systems is called  DiscreteDS :  #  DynamicalSystemsBase.DiscreteDS     Type .  DiscreteDS  : DynamicalSystem  D -dimensional discrete dynamical system.  Fields   state::SVector{D}  : Current state-vector of the system, stored in the data format of  StaticArray 's  SVector .  eom  (function) : The function that represents the system's equations of motion (also called vector field). It  must  be in the form  eom(x, p) -  SVector  which means that given a state  x::SVector  and some parameter container  p  it returns an  SVector  containing the next state.  jacob  (function) : A function that calculates the system's jacobian matrix. It  must be  in the form  jacob(x, p) -  SMatrix  which means that given a state  x::Svector  and a parameter container  p  it returns an  SMatrix  containing the Jacobian at that state.  p  : Some kind of container of (initial) parameters. Highly suggested to use a subtype of  Array  or  LMArray .   It is not necessary that  p  is used inside the functions (e.g. a model without parameters), however the functions  must be  declared in this format.  Use  set_state!  to change the system's state.  Constructor  DiscreteDS ( state ,   eom   [,   jacob ];   parameters   =   nothing )   If the  jacob  is not provided by the user, it is created automatically using the module  ForwardDiff . Notice that if your model has parameters, you  must  give them via the keyword argument  parameters .  Automatic differentiation and parameter changes works only if the container  p  is changed in-place!  source    Return form of the  eom  function  It is  heavily  advised that the equations of motion  eom  function returns an  SVector  from the julia package  StaticArrays.jl  and similarly the  jacob  function returns an  SMatrix  in the case of  DiscreteDS .   For example, here is the case of the pre-defined  henon map :  function   henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 ) \n     henon_eom ( x ,   p )   =   SVector { 2 }( 1.0   -   p [ 1 ] * x [ 1 ] ^ 2   +   x [ 2 ],   p [ 2 ] * x [ 1 ]) \n     henon_jacob ( x ,   p )   =   @SMatrix   [ - 2 * p [ 1 ] * x [ 1 ]   1.0 ;   p [ 2 ]   0.0 ] \n     return   DiscreteDS ( u0 ,   henon_eom ,   henon_jacob ;   parameters   =   [ a ,   b ])  end   To change the parameter  a  you would use  ds.p[1] = 123  and the change will affect  both  the equations of motion as well as the Jacobian!", 
            "title": "Low-dimensional"
        }, 
        {
            "location": "/definition/discrete/#one-dimensional", 
            "text": "In the case of maps, there a special structure for one-dimensional systems. The syntax is  DiscreteDS1D(state, eom [, deriv]; parameters = nothing) . In this one-dimensional case, you don't need to worry about StaticArrays.jl because everything is in plain numbers.  For example, the  logistic map  is defined as:  function   logistic ( x0 = rand ();   r   =   4.0 ) \n     @inline   logistic_eom ( x ,   p )   =   p [ 1 ] * x * ( 1 - x ) \n     @inline   logistic_jacob ( x ,   p )   =   p [ 1 ] * ( 1 - 2 x ) \n     return   DiscreteDS1D ( x0 ,   logistic_eom ,   logistic_jacob ;   parameters   =   [ r ])  end   Once again, if you skip the derivative functions it will be calculated automatically using ForwardDiff.jl.", 
            "title": "One-Dimensional"
        }, 
        {
            "location": "/definition/evolve/", 
            "text": "Time Evolution of Systems\n\n\nDynamicalSystems.jl\n provides convenient interfaces for the evolution of systems.\n\n\n#\n\n\nDynamicalSystemsBase.evolve\n \n \nFunction\n.\n\n\nevolve\n(\nds\n::\nDynamicalSystem\n,\n \nT\n \n[\n,\n \nu0\n]\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n\n\n\n\n\n\nEvolve the \nstate(ds)\n (or \nu0\n if given) for total time \nT\n and return the \nfinal_state\n. For discrete systems \nT\n corresponds to steps and thus it must be integer. For continuous systems \nT\n can also be a tuple (for \ntspan\n).\n\n\nevolve\n \ndoes not store\n any information about intermediate steps. Use \ntrajectory\n if you want to produce a trajectory of the system.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.evolve!\n \n \nFunction\n.\n\n\nevolve\n!(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n\n\n\n\n\n\nSame as \nevolve\n but updates the system's state (in-place) with the final state.\n\n\nNotice that for continuous systems \nds.prob.u0\n is a \nreference\n to a vector. Modifying it modifies all other references to this vector, including the state of other \nContinuousDS\n that share the same reference.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.trajectory\n \n \nFunction\n.\n\n\ntrajectory\n(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \nkwargs\n...\n)\n \n-\n \ndataset\n\n\n\n\n\n\nReturn a dataset what will contain the trajectory of the sytem, after evolving it for time \nT\n. See \nDataset\n for info on how to manipulate this object.\n\n\nFor the discrete case, \nT\n is an integer and a \nT\u00d7D\n dataset is returned (\nD\n is the system dimensionality). For the continuous case, a \nW\u00d7D\n dataset is returned, with \nW = length(0:dt:T)\n with \n0:dt:T\n representing the time vector (\nnot\n returned).\n\n\nKeyword Arguments\n\n\n\n\ndt = 0.05\n : (only for continuous) Time step of value output during the solving of the continuous system.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) A dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \nsolve\n of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :maxiters =\n 1e9)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.get_sol\n \n \nFunction\n.\n\n\nget_sol(prob::ODEProblem [, diff_eq_kwargs::Dict, extra_kwargs::Dict])\n\n\n\n\n\nSolve the \nprob\n using \nsolve\n and return the solutions vector as well as the time vector. Always uses the keyword argument \nsave_everystep=false\n.\n\n\nThe second and third arguments are optional \nposition\n arguments, passed to \nsolve\n as keyword arguments. They both have to be dictionaries of \nSymbol\n keys. Only the second argument may contain a solver via the \n:solver\n key.\n\n\nget_sol\n correctly uses \ntstops\n if necessary (e.g. in the presence of \nDiscreteCallback\ns).\n\n\nsource\n\n\n#\n\n\nDiffEqBase.ODEProblem\n \n \nType\n.\n\n\nODEProblem\n(\nds\n::\nContinuousDS\n;\n \nkwargs\n...)\n\n\n\n\n\n\nCreate a new \nODEProblem\n for the given dynamical system by optionally changing specific aspects of the existing \nODEProblem\n.\n\n\nKeyword arguments: \nstate, t, parameters, callback, mass_matrix, tspan\n. If \ncallback\n is given and a callback also exists already in \nds.prob\n (i.e. \nds.prob.cb \u2260 nothing\n) then the two callbacks are merged into a \nCallbackSet\n.\n\n\nIf \nt\n is given, a \ntspan\n is created with initial time assumed zero. If \ntspan\n is given directly, the keyword \nt\n is disregarded.\n\n\nsource\n\n\n\n\nNotice that if you want to do repeated evolutions of different states of a continuous system, you should use the \nDiffEqBase.ODEIntegrator\n in conjunction with \nDiffEqBase.reinit!(integrator, newstate)\n to avoid the intermediate initializations of the integrator each time.\n\n\n\n\nSolution precision for continuous systems\n\n\nA numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.\n\n\nDifferentialEquations.jl offers a tool, called \nUncertainty Quantification\n, which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of \nDynamicalSystems.jl\n, the Lorenz system is accurate up to time \nt = 50.0\n.\n\n\nHowever, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the \nshadowing theorem\n (or \nshadowing lemma\n):\n\n\n\n\nShadowing Theorem\n\n\nAlthough a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.\n\n\n\n\nThis simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book \nChaos in Dynamical Systems\n by E. Ott, or the \nscholarpedia\n entry.", 
            "title": "Time Evolution"
        }, 
        {
            "location": "/definition/evolve/#time-evolution-of-systems", 
            "text": "DynamicalSystems.jl  provides convenient interfaces for the evolution of systems.  #  DynamicalSystemsBase.evolve     Function .  evolve ( ds :: DynamicalSystem ,   T   [ ,   u0 ] ;   diff_eq_kwargs   =   Dict ())   Evolve the  state(ds)  (or  u0  if given) for total time  T  and return the  final_state . For discrete systems  T  corresponds to steps and thus it must be integer. For continuous systems  T  can also be a tuple (for  tspan ).  evolve   does not store  any information about intermediate steps. Use  trajectory  if you want to produce a trajectory of the system.  source  #  DynamicalSystemsBase.evolve!     Function .  evolve !( ds :: DynamicalSystem ,   T ;   diff_eq_kwargs   =   Dict ())   Same as  evolve  but updates the system's state (in-place) with the final state.  Notice that for continuous systems  ds.prob.u0  is a  reference  to a vector. Modifying it modifies all other references to this vector, including the state of other  ContinuousDS  that share the same reference.  source  #  DynamicalSystemsBase.trajectory     Function .  trajectory ( ds :: DynamicalSystem ,   T ;   kwargs ... )   -   dataset   Return a dataset what will contain the trajectory of the sytem, after evolving it for time  T . See  Dataset  for info on how to manipulate this object.  For the discrete case,  T  is an integer and a  T\u00d7D  dataset is returned ( D  is the system dimensionality). For the continuous case, a  W\u00d7D  dataset is returned, with  W = length(0:dt:T)  with  0:dt:T  representing the time vector ( not  returned).  Keyword Arguments   dt = 0.05  : (only for continuous) Time step of value output during the solving of the continuous system.  diff_eq_kwargs = Dict()  : (only for continuous) A dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  solve  of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :maxiters =  1e9) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.   source  #  DynamicalSystemsBase.get_sol     Function .  get_sol(prob::ODEProblem [, diff_eq_kwargs::Dict, extra_kwargs::Dict])  Solve the  prob  using  solve  and return the solutions vector as well as the time vector. Always uses the keyword argument  save_everystep=false .  The second and third arguments are optional  position  arguments, passed to  solve  as keyword arguments. They both have to be dictionaries of  Symbol  keys. Only the second argument may contain a solver via the  :solver  key.  get_sol  correctly uses  tstops  if necessary (e.g. in the presence of  DiscreteCallback s).  source  #  DiffEqBase.ODEProblem     Type .  ODEProblem ( ds :: ContinuousDS ;   kwargs ...)   Create a new  ODEProblem  for the given dynamical system by optionally changing specific aspects of the existing  ODEProblem .  Keyword arguments:  state, t, parameters, callback, mass_matrix, tspan . If  callback  is given and a callback also exists already in  ds.prob  (i.e.  ds.prob.cb \u2260 nothing ) then the two callbacks are merged into a  CallbackSet .  If  t  is given, a  tspan  is created with initial time assumed zero. If  tspan  is given directly, the keyword  t  is disregarded.  source   Notice that if you want to do repeated evolutions of different states of a continuous system, you should use the  DiffEqBase.ODEIntegrator  in conjunction with  DiffEqBase.reinit!(integrator, newstate)  to avoid the intermediate initializations of the integrator each time.", 
            "title": "Time Evolution of Systems"
        }, 
        {
            "location": "/definition/evolve/#solution-precision-for-continuous-systems", 
            "text": "A numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.  DifferentialEquations.jl offers a tool, called  Uncertainty Quantification , which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of  DynamicalSystems.jl , the Lorenz system is accurate up to time  t = 50.0 .  However, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the  shadowing theorem  (or  shadowing lemma ):   Shadowing Theorem  Although a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.   This simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book  Chaos in Dynamical Systems  by E. Ott, or the  scholarpedia  entry.", 
            "title": "Solution precision for continuous systems"
        }, 
        {
            "location": "/definition/dataset/", 
            "text": "Numerical Data\n\n\nNumerical data in \nDynamicalSystems.jl\n is represented by a structure called \nDataset\n\n\n#\n\n\nDynamicalSystemsBase.Dataset\n \n \nType\n.\n\n\nDataset{D, T} \n: AbstractDataset{D,T}\n\n\n\n\n\nA dedicated interface for datasets, i.e. vectors of vectors. It contains \nequally-sized datapoints\n of length \nD\n, represented by \nSVector{D, T}\n, containing numbers of type \nT\n.\n\n\nThe internal data representation is more efficient than having a \nMatrix\n and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables. \ntrajectory\n always returns a \nDataset\n.\n\n\nFor example,\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n)\n \n#this returns a dataset\n\n\ndata\n[\n:\n,\n \n2\n]\n \n# this is the second variable timeseries\n\n\ndata\n[\n1\n]\n \n==\n \ndata\n[\n1\n,\n \n:\n]\n \n# this is the first datapoint (D-dimensional)\n\n\ndata\n[\n5\n,\n \n3\n]\n \n# value of the third variable, at the 5th timepoint\n\n\n\n\n\n\nUse \nMatrix(dataset)\n or \nreinterpret(Matrix, dataset)\n to create a \nMatrix\n from a \ndataset\n, the first method returning a matrix where each column is a a timeseries while the second returning a matrix where each column is a datapoint. Similarly, use \nDataset(matrix)\n or \nreinterpret(Dataset, matrix)\n to create a \nDataset\n from a \nmatrix\n that has structure as noted by the \nMatrix\n methods.\n\n\nIf you have various timeseries vectors \nx, y, z, ...\n pass them like \nDataset(x, y, z, ...)\n. You can use \ncolumns(dataset)\n to obtain the reverse, i.e. all columns of the dataset in a tuple.\n\n\nsource\n\n\n\n\nIn essence a \nDataset\n is simply a container for a \nVector\n of \nSVector\ns. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the \ncolumn\n direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nhen\n,\n \n10000\n)\n \n# this returns a dataset\n\n\nfor\n \npoint\n \nin\n \ndata\n\n\n# do stuff with each datapoint (vector with as many elements as system dimension)\n\n\nend\n\n\n\n\n\n\nAll functions from \nDynamicalSystems.jl\n that manipulate and use data are expecting an \nAbstractDataset\n subtype. This allows us to define efficient methods that coordinate well with other packages, like e.g. \nneighborhood\n.\n\n\nIf given a matrix, we first convert to \nDataset\n. This means that you should \nfirst convert\n your data to a \nDataset\n if you want to call functions more than once, to avoid constantly converting.\n\n\n\n\nDataset Functions\n\n\nFunctions that operate on datasets.\n\n\n#\n\n\nDynamicalSystemsBase.minima\n \n \nFunction\n.\n\n\nminima(dataset)\n\n\n\n\n\nReturn an \nSVector\n that contains the minimum elements of each timeseries of the dataset.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.maxima\n \n \nFunction\n.\n\n\nmaxima(dataset)\n\n\n\n\n\nReturn an \nSVector\n that contains the maximum elements of each timeseries of the dataset.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.minmaxima\n \n \nFunction\n.\n\n\nminmaxima(dataset)\n\n\n\n\n\nReturn \nminima(dataset), maxima(dataset)\n without doing the computation twice.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.columns\n \n \nFunction\n.\n\n\ncolumns(dataset) -\n x, y, z, ...\n\n\n\n\n\nReturn the individual columns of the dataset\n\n\nsource\n\n\n\n\n\n\nDataset IO\n\n\nIn addition to the above, we also offer (very basic) functions that read/write a \nDataset\n from/to a delimited text file:\n\n\n#\n\n\nDynamicalSystemsBase.read_dataset\n \n \nFunction\n.\n\n\nread_dataset\n(\nfile\n,\n \n::\nType\n{\n:Dataset\n}\n,\n \ndelim\n::\nChar\n \n=\n \n   \n;\n \nskipstart\n \n=\n \n0\n)\n\n\n\n\n\n\nRead a \ndelim\n-delimited text file directly into a dataset of dimension \nD\n with numbers of type \nT\n.\n\n\nOptionally skip the first \nskipstart\n rows of the file (that may e.g. contain headers).\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.write_dataset\n \n \nFunction\n.\n\n\nwrite_dataset\n(\nfile\n,\n \ndataset\n::\nAbstractDataset\n,\n \ndelim\n::\nChar\n \n=\n \n   \n;\n \nopts\n...)\n\n\n\n\n\n\nWrite a \ndataset\n in a \ndelim\n-delimited text file.\n\n\nopts\n are keyword arguments passed into \nwritedlm\n.\n\n\nsource\n\n\n\n\nFor example\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n)\n\n\n\n# Write comma-delimited file:\n\n\nwrite_dataset\n(\ntest.csv\n,\n \ndata\n,\n \n,\n)\n\n\n# Read comma-delimited file:\n\n\nread_dataset\n(\ntest.csv\n,\n \nDataset\n{\n2\n,\n \nFloat64\n},\n \n,\n)", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/definition/dataset/#numerical-data", 
            "text": "Numerical data in  DynamicalSystems.jl  is represented by a structure called  Dataset  #  DynamicalSystemsBase.Dataset     Type .  Dataset{D, T}  : AbstractDataset{D,T}  A dedicated interface for datasets, i.e. vectors of vectors. It contains  equally-sized datapoints  of length  D , represented by  SVector{D, T} , containing numbers of type  T .  The internal data representation is more efficient than having a  Matrix  and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables.  trajectory  always returns a  Dataset .  For example,  ds   =   Systems . towel ()  data   =   trajectory ( ds ,   1000 )   #this returns a dataset  data [ : ,   2 ]   # this is the second variable timeseries  data [ 1 ]   ==   data [ 1 ,   : ]   # this is the first datapoint (D-dimensional)  data [ 5 ,   3 ]   # value of the third variable, at the 5th timepoint   Use  Matrix(dataset)  or  reinterpret(Matrix, dataset)  to create a  Matrix  from a  dataset , the first method returning a matrix where each column is a a timeseries while the second returning a matrix where each column is a datapoint. Similarly, use  Dataset(matrix)  or  reinterpret(Dataset, matrix)  to create a  Dataset  from a  matrix  that has structure as noted by the  Matrix  methods.  If you have various timeseries vectors  x, y, z, ...  pass them like  Dataset(x, y, z, ...) . You can use  columns(dataset)  to obtain the reverse, i.e. all columns of the dataset in a tuple.  source   In essence a  Dataset  is simply a container for a  Vector  of  SVector s. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the  column  direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:  using   DynamicalSystems  hen   =   Systems . henon ()  data   =   trajectory ( hen ,   10000 )   # this returns a dataset  for   point   in   data  # do stuff with each datapoint (vector with as many elements as system dimension)  end   All functions from  DynamicalSystems.jl  that manipulate and use data are expecting an  AbstractDataset  subtype. This allows us to define efficient methods that coordinate well with other packages, like e.g.  neighborhood .  If given a matrix, we first convert to  Dataset . This means that you should  first convert  your data to a  Dataset  if you want to call functions more than once, to avoid constantly converting.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/definition/dataset/#dataset-functions", 
            "text": "Functions that operate on datasets.  #  DynamicalSystemsBase.minima     Function .  minima(dataset)  Return an  SVector  that contains the minimum elements of each timeseries of the dataset.  source  #  DynamicalSystemsBase.maxima     Function .  maxima(dataset)  Return an  SVector  that contains the maximum elements of each timeseries of the dataset.  source  #  DynamicalSystemsBase.minmaxima     Function .  minmaxima(dataset)  Return  minima(dataset), maxima(dataset)  without doing the computation twice.  source  #  DynamicalSystemsBase.columns     Function .  columns(dataset) -  x, y, z, ...  Return the individual columns of the dataset  source", 
            "title": "Dataset Functions"
        }, 
        {
            "location": "/definition/dataset/#dataset-io", 
            "text": "In addition to the above, we also offer (very basic) functions that read/write a  Dataset  from/to a delimited text file:  #  DynamicalSystemsBase.read_dataset     Function .  read_dataset ( file ,   :: Type { :Dataset } ,   delim :: Char   =       ;   skipstart   =   0 )   Read a  delim -delimited text file directly into a dataset of dimension  D  with numbers of type  T .  Optionally skip the first  skipstart  rows of the file (that may e.g. contain headers).  source  #  DynamicalSystemsBase.write_dataset     Function .  write_dataset ( file ,   dataset :: AbstractDataset ,   delim :: Char   =       ;   opts ...)   Write a  dataset  in a  delim -delimited text file.  opts  are keyword arguments passed into  writedlm .  source   For example  using   DynamicalSystems  ds   =   Systems . towel ()  data   =   trajectory ( ds ,   1000 )  # Write comma-delimited file:  write_dataset ( test.csv ,   data ,   , )  # Read comma-delimited file:  read_dataset ( test.csv ,   Dataset { 2 ,   Float64 },   , )", 
            "title": "Dataset IO"
        }, 
        {
            "location": "/definition/predefined/", 
            "text": "Predefined Systems\n\n\nPredefined systems exist in the \nSystems\n submodule exported by DynamicalSystemsBase.jl, in the form of functions that return a \nDynamicalSystem\n. They are accessed like:\n\n\nusing\n \nDynamicalSystems\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n\n\ntypeof\n(\nds\n)\n \n# ContinuousDS\n\n\nts\n \n=\n \ntrajectory\n(\nds\n,\n \n10.0\n)\n\n\n\n\n\n\nSo far, the predefined systems that exist in the \nSystems\n sub-module are:\n\n\n#\n\n\nDynamicalSystemsBase.Systems.circlemap\n \n \nFunction\n.\n\n\ncirclemap(x0=rand(); \u03a9 = 1.0, K = 0.99)\n\n\n\n\n\n\n\n\n\\theta_{n+1} = \\theta_n + 2\\pi\\Omega - K\\sin(\\theta_n)\n\n\n\n\n\\theta_{n+1} = \\theta_n + 2\\pi\\Omega - K\\sin(\\theta_n)\n\n\n\n\n\nNotice that the map \ndoes not use\n \nmod2pi\n at the equation of motion.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.coupledstandardmaps\n \n \nFunction\n.\n\n\ncoupledstandardmaps\n(\nM\n::\nInt\n,\n \nu0\n \n=\n \n0.001\nrand\n(\n2\nM\n);\n \nks\n \n=\n \nones\n(\nM\n),\n \n\u0393\n \n=\n \n1.0\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' \n= \\theta_i + p_{i}' \\\\\np_{i}' \n= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\nA discrete system of \nM\n nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The \ntotal\n dimension of the system is \n2M\n. The maps are coupled through \n\u0393\n and the \ni\n-th map has a nonlinear parameter \nks[i]\n.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : H. Kantz \n P. Grassberger, J. Phys. A \n21\n, pp 127\u2013133 (1988)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.double_pendulum\n \n \nFunction\n.\n\n\ndouble_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)\n\n\n\n\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\n\nThe variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].\n\n\nJacobian is created automatically (thus methods that use the Jacobian will be slower)!\n\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.duffing\n \n \nFunction\n.\n\n\nduffing(u0 = [rand(), rand(), 0]; \u03c9 = 2.2, f = 27.0, d = 0.2, \u03b2 = 1)\n\n\n\n\n\nThe (forced) duffing oscillator, that satisfies the equation\n\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\nwith \nf, \u03c9\n the forcing strength and frequency and \nd\n the dampening.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.gissinger\n \n \nFunction\n.\n\n\ngissinger\n(\nu0\n \n=\n \n3\nrand\n(\n3\n);\n \n\u03bc\n \n=\n \n0.119\n,\n \n\u03bd\n \n=\n \n0.1\n,\n \n\u0393\n \n=\n \n0.9\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{Q} \n= \\mu Q - VD \\\\\n\\dot{D} \n= -\\nu D + VQ \\\\\n\\dot{V} \n= \\Gamma -V + QD\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{Q} &= \\mu Q - VD \\\\\n\\dot{D} &= -\\nu D + VQ \\\\\n\\dot{V} &= \\Gamma -V + QD\n\\end{aligned}\n\n\n\n\n\nA continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : C. Gissinger, Eur. Phys. J. B \n85\n, 4, pp 1-12 (2012)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henon\n \n \nFunction\n.\n\n\nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= 1 - ax^2_n+y_n \\\\\ny_{n+1} \n = bx_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : M. H\u00e9non, Commun.Math. Phys. \n50\n, pp 69 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henonhelies\n \n \nFunction\n.\n\n\nhenonhelies(u0=[0, -0.25, 0.42081,0]; conserveE = true)\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= p_x \\\\\n\\dot{y} \n= p_y \\\\\n\\dot{p}_x \n= -x -2 xy \\\\\n\\dot{p}_y \n= -y - (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2 xy \\\\\n\\dot{p}_y &= -y - (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.\n\n\nThe default initial condition is a typical chaotic orbit.\n\n\nYou can optionally choose to conserve energy, up to \n1e-14\n error level, but having slower integration as a drawback.\n\n\n[1] : H\u00e9non, M. \n Heiles, C., The Astronomical Journal \n69\n, pp 73\u201379 (1964)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.logistic\n \n \nFunction\n.\n\n\nlogistic\n(\nx0\n \n=\n \nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n\n\n\n\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\n\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : R. M. May, Nature \n261\n, pp 459 (1976)\n\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. \n19\n, pp 25 (1978)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz\n \n \nFunction\n.\n\n\nlorenz\n(\nu0\n=\n[\n0.0\n,\n \n10.0\n,\n \n0.0\n];\n \n\u03c3\n \n=\n \n10.0\n,\n \n\u03c1\n \n=\n \n28.0\n,\n \n\u03b2\n \n=\n \n8\n/\n3\n)\n \n-\n \nds\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{X} \n= \\sigma(Y-X) \\\\\n\\dot{Y} \n= -XZ + \\rho X -Y \\\\\n\\dot{Z} \n= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : E. N. Lorenz, J. atmos. Sci. \n20\n, pp 130 (1963)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz96\n \n \nFunction\n.\n\n\nlorenz96\n(\nN\n::\nInt\n,\n \nu0\n \n=\n \nrand\n(\nM\n);\n \nF\n=\n0\n.\n01\n)\n\n\n\n\n\n\nN\n is the chain length, \nF\n the forcing. Jacobian is created automatically. (parameter container only contains \nF\n)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.roessler\n \n \nFunction\n.\n\n\nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= -y-z \\\\\n\\dot{y} \n= x+ay \\\\\n\\dot{z} \n= -b + z(x-c)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= -b + z(x-c)\n\\end{aligned}\n\n\n\n\n\nThis three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the \nlorenz\n system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n57A\n, pp 397 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.shinriki\n \n \nFunction\n.\n\n\nshinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)\n\n\n\n\n\nShinriki oscillator with all other parameters (besides \nR1\n) set to constants. \nThis is a stiff problem, be careful when choosing solvers and tolerances\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.standardmap\n \n \nFunction\n.\n\n\nstandardmap\n(\nu0\n=\n0.001\nrand\n(\n2\n);\n \nk\n \n=\n \n0.971635\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} \n= \\theta_n + p_{n+1} \\\\\np_{n+1} \n= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\n\nThe map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter \nk\n transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\n\nThe default parameter \nk\n is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable \n\u03b8\n to be the first, and the angular momentum \np\n to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : B. V. Chirikov, Preprint N. \n267\n, Institute of Nuclear Physics, Novosibirsk (1969)\n\n\n[2] : J. M. Greene, J. Math. Phys. \n20\n, pp 1183 (1979)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.towel\n \n \nFunction\n.\n\n\ntowel\n(\nu0\n \n=\n \n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} \n= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} \n= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\nThe folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n71A\n, pp 155 (1979)\n\n\nsource", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/definition/predefined/#predefined-systems", 
            "text": "Predefined systems exist in the  Systems  submodule exported by DynamicalSystemsBase.jl, in the form of functions that return a  DynamicalSystem . They are accessed like:  using   DynamicalSystems  ds   =   Systems . lorenz ( \u03c1   =   32.0 )  typeof ( ds )   # ContinuousDS  ts   =   trajectory ( ds ,   10.0 )   So far, the predefined systems that exist in the  Systems  sub-module are:  #  DynamicalSystemsBase.Systems.circlemap     Function .  circlemap(x0=rand(); \u03a9 = 1.0, K = 0.99)   \n\\theta_{n+1} = \\theta_n + 2\\pi\\Omega - K\\sin(\\theta_n)  \n\\theta_{n+1} = \\theta_n + 2\\pi\\Omega - K\\sin(\\theta_n)   Notice that the map  does not use   mod2pi  at the equation of motion.  The parameter container has the parameters in the same order as stated in this function's documentation string.  source  #  DynamicalSystemsBase.Systems.coupledstandardmaps     Function .  coupledstandardmaps ( M :: Int ,   u0   =   0.001 rand ( 2 M );   ks   =   ones ( M ),   \u0393   =   1.0 )    \n\\begin{aligned}\n\\theta_{i}'  = \\theta_i + p_{i}' \\\\\np_{i}'  = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}   A discrete system of  M  nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The  total  dimension of the system is  2M . The maps are coupled through  \u0393  and the  i -th map has a nonlinear parameter  ks[i] .  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : H. Kantz   P. Grassberger, J. Phys. A  21 , pp 127\u2013133 (1988)  source  #  DynamicalSystemsBase.Systems.double_pendulum     Function .  double_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)  Famous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).  The variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].  Jacobian is created automatically (thus methods that use the Jacobian will be slower)!  (please contribute the Jacobian and the e.o.m. in LaTeX :smile:)  The parameter container has the parameters in the same order as stated in this function's documentation string.  source  #  DynamicalSystemsBase.Systems.duffing     Function .  duffing(u0 = [rand(), rand(), 0]; \u03c9 = 2.2, f = 27.0, d = 0.2, \u03b2 = 1)  The (forced) duffing oscillator, that satisfies the equation   \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)  \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)   with  f, \u03c9  the forcing strength and frequency and  d  the dampening.  The parameter container has the parameters in the same order as stated in this function's documentation string.  source  #  DynamicalSystemsBase.Systems.gissinger     Function .  gissinger ( u0   =   3 rand ( 3 );   \u03bc   =   0.119 ,   \u03bd   =   0.1 ,   \u0393   =   0.9 )    \n\\begin{aligned}\n\\dot{Q}  = \\mu Q - VD \\\\\n\\dot{D}  = -\\nu D + VQ \\\\\n\\dot{V}  = \\Gamma -V + QD\n\\end{aligned}  \n\\begin{aligned}\n\\dot{Q} &= \\mu Q - VD \\\\\n\\dot{D} &= -\\nu D + VQ \\\\\n\\dot{V} &= \\Gamma -V + QD\n\\end{aligned}   A continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : C. Gissinger, Eur. Phys. J. B  85 , 4, pp 1-12 (2012)  source  #  DynamicalSystemsBase.Systems.henon     Function .  henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 )    \n\\begin{aligned}\nx_{n+1}  = 1 - ax^2_n+y_n \\\\\ny_{n+1}   = bx_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}   The H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.  According to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : M. H\u00e9non, Commun.Math. Phys.  50 , pp 69 (1976)  source  #  DynamicalSystemsBase.Systems.henonhelies     Function .  henonhelies(u0=[0, -0.25, 0.42081,0]; conserveE = true)   \n\\begin{aligned}\n\\dot{x}  = p_x \\\\\n\\dot{y}  = p_y \\\\\n\\dot{p}_x  = -x -2 xy \\\\\n\\dot{p}_y  = -y - (x^2 - y^2)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2 xy \\\\\n\\dot{p}_y &= -y - (x^2 - y^2)\n\\end{aligned}   The H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.  The default initial condition is a typical chaotic orbit.  You can optionally choose to conserve energy, up to  1e-14  error level, but having slower integration as a drawback.  [1] : H\u00e9non, M.   Heiles, C., The Astronomical Journal  69 , pp 73\u201379 (1964)  source  #  DynamicalSystemsBase.Systems.logistic     Function .  logistic ( x0   =   rand ();   r   =   4.0 )    \nx_{n+1} = rx_n(1-x_n)  \nx_{n+1} = rx_n(1-x_n)   The logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.  Originally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : R. M. May, Nature  261 , pp 459 (1976)  [2] : M. J. Feigenbaum, J. Stat. Phys.  19 , pp 25 (1978)  source  #  DynamicalSystemsBase.Systems.lorenz     Function .  lorenz ( u0 = [ 0.0 ,   10.0 ,   0.0 ];   \u03c3   =   10.0 ,   \u03c1   =   28.0 ,   \u03b2   =   8 / 3 )   -   ds    \n\\begin{aligned}\n\\dot{X}  = \\sigma(Y-X) \\\\\n\\dot{Y}  = -XZ + \\rho X -Y \\\\\n\\dot{Z}  = XY - \\beta Z\n\\end{aligned}  \n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}   The famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.  Currently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : E. N. Lorenz, J. atmos. Sci.  20 , pp 130 (1963)  source  #  DynamicalSystemsBase.Systems.lorenz96     Function .  lorenz96 ( N :: Int ,   u0   =   rand ( M );   F = 0 . 01 )   N  is the chain length,  F  the forcing. Jacobian is created automatically. (parameter container only contains  F )  source  #  DynamicalSystemsBase.Systems.roessler     Function .  roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 )    \n\\begin{aligned}\n\\dot{x}  = -y-z \\\\\n\\dot{y}  = x+ay \\\\\n\\dot{z}  = -b + z(x-c)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= -b + z(x-c)\n\\end{aligned}   This three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the  lorenz  system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : O. E. R\u00f6ssler, Phys. Lett.  57A , pp 397 (1976)  source  #  DynamicalSystemsBase.Systems.shinriki     Function .  shinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)  Shinriki oscillator with all other parameters (besides  R1 ) set to constants.  This is a stiff problem, be careful when choosing solvers and tolerances .  source  #  DynamicalSystemsBase.Systems.standardmap     Function .  standardmap ( u0 = 0.001 rand ( 2 );   k   =   0.971635 )    \n\\begin{aligned}\n\\theta_{n+1}  = \\theta_n + p_{n+1} \\\\\np_{n+1}  = p_n + k\\sin(\\theta_n)\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}   The standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.  The map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter  k  transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.  The default parameter  k  is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable  \u03b8  to be the first, and the angular momentum  p  to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : B. V. Chirikov, Preprint N.  267 , Institute of Nuclear Physics, Novosibirsk (1969)  [2] : J. M. Greene, J. Math. Phys.  20 , pp 1183 (1979)  source  #  DynamicalSystemsBase.Systems.towel     Function .  towel ( u0   =   [ 0.085 ,   - 0.121 ,   0.075 ])    \n\\begin{aligned}\nx_{n+1}  = a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1}  = 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1}  = 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}   The folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.  Default values are the ones used in the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  71A , pp 155 (1979)  source", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/chaos/overview/", 
            "text": "Features Overview\n\n\nThe features offered in this documentation section come from the package \nChaosTools.jl\n. If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.\n\n\n\n\nOrbit Diagrams\n\n\n\n\nOrbit diagrams (aka bifurcation diagrams) of maps: \norbitdiagram\n.\n\n\nPoincar\u00e9 surfaces of section for continuous systems: \npoincaresos\n.\n\n\nAutomated production of orbit diagrams for continuous systems: \nproduce_orbitdiagram\n.\n\n\n\n\n\n\nLyapunov Exponents\n\n\nThe following treat systems where the equations of motion are known:\n\n\n\n\nMaximum Lyapunov exponent for both discrete and continuous systems: \nlyapunov\n.\n\n\nLyapunov \nspectrum\n for both discrete and continuous systems: \nlyapunovs\n.\n\n\n\n\n\n\nEntropies and Dimensions\n\n\n\n\nGeneralized (Renyi) entropy: \ngenentropy\n.\n\n\nPermutation entropy: \npermentropy\n.\n\n\nFast and cheap (memory-wise) method for computing entropies of large datasets.\n\n\nGeneralized dimensions (e.g. capacity dimension, information dimension, etc.): \ngeneralized_dim\n.\n\n\nKaplan-Yorke dimension: \nkaplanyorke_dim\n.\n\n\nAutomated detection of best algorithmic parameters for calculating attractor dimensions.\n\n\n\n\nAnd, in order to automatically deduce dimensions, we also offer methods for:\n\n\n\n\nPartitioning a function \ny(x)\ny(x)\n vs. \nx\nx\n into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See \nlinear_regions\n.\n\n\nDetection of largest linear region of a function \ny(x)\ny(x)\n vs. \nx\nx\n and extraction of the slope of this region.\n\n\n\n\n\n\nNonlinear Timeseries Analysis\n\n\n\n\nFlexible and abstracted \nReconstruction\n interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.\n\n\nMethods for estimating good \nReconstruction\n parameters.\n\n\nBroomhead-King coordinates: \nbroomhead_king\n.\n\n\n\n\nFour different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries: \nnumericallyapunov\n.\n\n\n\n\nFast computation of the above algorithms made possible by combining the\n\n\n\n\nperformance of \nNearestNeighbors.jl\n with  the abstraction of ChaosTools.jl.\n\n\n\n\n\n\n\n\nPeriodicity\n\n\n\n\n\n\nNumerical method to find unstable and stable fixed points of \nany order\n \nn\nn\n of a discrete map (of any dimensionality): \nperiodicorbits\n.\n\n\n\n\nConvenience functions for defining and realizing all possible combinations of \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrices required in the above method.\n\n\n\n\n\n\n\n\n\n\nChaos Detection\n\n\n\n\n\n\nThe Generalized Alignment Index: \n\\text{GALI}_k\n\\text{GALI}_k\n : \ngali\n.\n\n\n\n\nImplemented for both discrete and continuous systems.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#features-overview", 
            "text": "The features offered in this documentation section come from the package  ChaosTools.jl . If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#orbit-diagrams", 
            "text": "Orbit diagrams (aka bifurcation diagrams) of maps:  orbitdiagram .  Poincar\u00e9 surfaces of section for continuous systems:  poincaresos .  Automated production of orbit diagrams for continuous systems:  produce_orbitdiagram .", 
            "title": "Orbit Diagrams"
        }, 
        {
            "location": "/chaos/overview/#lyapunov-exponents", 
            "text": "The following treat systems where the equations of motion are known:   Maximum Lyapunov exponent for both discrete and continuous systems:  lyapunov .  Lyapunov  spectrum  for both discrete and continuous systems:  lyapunovs .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/overview/#entropies-and-dimensions", 
            "text": "Generalized (Renyi) entropy:  genentropy .  Permutation entropy:  permentropy .  Fast and cheap (memory-wise) method for computing entropies of large datasets.  Generalized dimensions (e.g. capacity dimension, information dimension, etc.):  generalized_dim .  Kaplan-Yorke dimension:  kaplanyorke_dim .  Automated detection of best algorithmic parameters for calculating attractor dimensions.   And, in order to automatically deduce dimensions, we also offer methods for:   Partitioning a function  y(x) y(x)  vs.  x x  into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See  linear_regions .  Detection of largest linear region of a function  y(x) y(x)  vs.  x x  and extraction of the slope of this region.", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/overview/#nonlinear-timeseries-analysis", 
            "text": "Flexible and abstracted  Reconstruction  interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.  Methods for estimating good  Reconstruction  parameters.  Broomhead-King coordinates:  broomhead_king .   Four different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries:  numericallyapunov .   Fast computation of the above algorithms made possible by combining the   performance of  NearestNeighbors.jl  with  the abstraction of ChaosTools.jl.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/overview/#periodicity", 
            "text": "Numerical method to find unstable and stable fixed points of  any order   n n  of a discrete map (of any dimensionality):  periodicorbits .   Convenience functions for defining and realizing all possible combinations of  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrices required in the above method.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/overview/#chaos-detection", 
            "text": "The Generalized Alignment Index:  \\text{GALI}_k \\text{GALI}_k  :  gali .   Implemented for both discrete and continuous systems.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/orbitdiagram/", 
            "text": "Orbit Diagrams of Maps\n\n\nAn orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed\n\n\n#\n\n\nChaosTools.orbitdiagram\n \n \nFunction\n.\n\n\norbitdiagram\n(\nds\n::\nDiscreteDynamicalSystem\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \nkwargs\n...)\n\n\n\n\n\n\nCompute the orbit diagram (also called bifurcation diagram) of the given system for the \ni\n-th variable for parameter values \npvalues\n. The \np_index\n specifies which parameter of the equations of motion is to be changed, through \nds.p[p_index]\n.\n\n\nKeyword Arguments\n\n\n\n\nics = [state(ds)]\n : container of initial conditions that are used at each parameter value to evolve orbits.\n\n\nTtr::Int = 1000\n : Transient steps; each orbit is evolved for \nTtr\n first before saving output.\n\n\nn::Int = 100\n : Amount of points to save for each initial condition.\n\n\n\n\nDescription\n\n\nThe method works by computing orbits at each parameter value in \npvalues\n for each initial condition in \nics\n.\n\n\nThe parameter change is done as \nds.p[p_index] = ...\n and thus you must use a parameter container that supports this (either \nArray\n, \nLMArray\n or other).\n\n\nThe returned \noutput\n is a vector of vectors. \noutput[j]\n are the orbit points of the \ni\n-th variable of the system, at parameter value \npvalues[j]\n.\n\n\nSee also \npoincaresos\n and \nproduce_orbitdiagram\n.\n\n\nsource\n\n\n\n\nFor example, let's compute the famous orbit diagram of the logistic map:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\ni\n \n=\n \n1\n\n\npvalues\n \n=\n \n2\n:\n0.001\n:\n4\n\n\nics\n \n=\n \n[\nrand\n()\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n50\n\n\nTtr\n \n=\n \n5000\n\n\np_index\n \n=\n \n1\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nr\n\\$\n);\n \nylabel\n(\n\\$\nx\n\\$\n)\n\n\n\n\n\n\n\n\nNotice that if you are using \nPyPlot\n, the plotting process will be slow, since it is slow at plotting big numbers of points.\n\n\nThe function is not limited to 1D maps, and can be applied just as well to any discrete system.\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\ni\n \n=\n \n2\n\n\n\npvalues\n \n=\n \n0\n:\n0.005\n:\n2\n\n\nics\n \n=\n \n[\n0.001\nrand\n(\n2\n)\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n50\n\n\nTtr\n \n=\n \n5000\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \n:\nk\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n,\n \nics\n \n=\n \nics\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nk\n\\$\n);\n \nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\n\n\n\n\nPoincar\u00e9 Surface of Section\n\n\nAlso called \nPoincar\u00e9 map\n is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:\n\n\n#\n\n\nChaosTools.poincaresos\n \n \nFunction\n.\n\n\npoincaresos\n(\nds\n::\nContinuousDS\n,\n \nj\n,\n \ntfinal\n \n=\n \n100\n.\n0\n;\n \nkwargs\n...)\n\n\n\n\n\n\nCalculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1, 2] of the given system on the plane of the \nj\n-th variable of the system. The system is evolved for total time of \ntfinal\n.\n\n\nReturns a \nDataset\n of the points that are on the surface of section.\n\n\nThis function assumes that you have created the \nContinuousDS\n using functors; see the \nofficial documentation\n for more.\n\n\nKeyword Arguments\n\n\n\n\ndirection = 1\n and \noffset = 0.0\n : The surface of section is defined as the (hyper-) plane where \nstate[j] = offset\n. Only crossings of the plane that have direction \nsign(direction)\n are considered to belong to the surface of section.\n\n\nTtr = 0.0\n : Transient time to evolve the system before starting to compute the PSOS.\n\n\ndiff_eq_kwargs = Dict()\n : See \ntrajectory\n.\n\n\ncallback_kwargs = Dict(:abstol=\n1e-9)\n : Keyword arguments passed into the \nContinuousCallback\n type of \nDifferentialEquations\n. The option \ncallback_kwargs[:idxs] = j\n is enforced.\n\n\n\n\nReferences\n\n\n[1] : H. Poincar\u00e9, \nLes Methods Nouvelles de la M\u00e9canique Celeste\n, Paris: Gauthier-Villars (1892)\n\n\n[2] : M. Tabor, \nChaos and Integrability in Nonlinear Dynamics: An Introduction\n, \u00a74.1, in pp. 118-126, New York: Wiley (1989)\n\n\nSee also \norbitdiagram\n, \nproduce_orbitdiagram\n.\n\n\nsource\n\n\n\n\nAn example of the \nHenon-Helies\n system using a quasi-periodic solution\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n([\n0.\n,\n \n0.1\n,\n \n0.5\n,\n \n0.\n])\n\n\noutput\n \n=\n \npoincaresos\n(\nds\n,\n \n3\n,\n \n1000.0\n)\n\n\n\nfigure\n()\n\n\nplot\n(\noutput\n[\n:\n,\n \n2\n],\n \noutput\n[\n:\n,\n \n4\n],\n \nlw\n \n=\n \n0.0\n,\n \nmarker\n=\n.\n)\n\n\nxlabel\n(\n\\$\nq_2\n\\$\n);\n \nylabel\n(\n\\$\np_2\n\\$\n);\n\n\n\n\n\n\n\n\nHere the surface of section was the (hyper-) plane that \np_1 = 0\np_1 = 0\n. As expected the section is 1-dimensional, because the torus the solution lives in is 2-dimensional. if we produced the PSOS for much longer times, the result would be a filled line instead of individual points.\n\n\n\n\nStroboscopic Map\n\n\nA special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the \nDuffing oscillator\n.\n\n\nA \"cut\" through the phase-space can be produced at every period \nT = 2\\pi/\\omega\nT = 2\\pi/\\omega\n. There is no reason to use \npoincaresos\n for this though, because you can simply use \ntrajectory\n and get the solution with a certain time sampling rate:\n\n\nds\n \n=\n \nSystems\n.\nduffing\n(\n\u03b2\n \n=\n \n-\n1\n,\n \n\u03c9\n \n=\n \n1\n,\n \nf\n \n=\n \n0.3\n)\n \n# non-autonomous chaotic system\n\n\na\n \n=\n \ntrajectory\n(\nds\n,\n \n100000.0\n,\n \ndt\n \n=\n \n2\n\u03c0\n)\n \n# every period T = 2\u03c0/\u03c9\n\n\nplot\n(\na\n[\n:\n,\n \n1\n],\n \na\n[\n:\n,\n \n2\n],\n \nlw\n \n=\n \n0\n,\n \nmarker\n \n=\no\n,\n \nms\n \n=\n \n1\n)\n\n\nxlabel\n(\n\\$\nx\n\\$\n);\n \nylabel\n(\n\\$\\\\\ndot{x}\n\\$\n)\n\n\n\n\n\n\n What a cool looking attractor is that!\n\n\n\n\nProducing Orbit Diagrams for Continuous Flows\n\n\nThe \norbitdiagram\n does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for \norbitdiagram\n to have meaning one must have a map.\n\n\nIf only there was a way to turn a continuous system into a map... \nOH WAIT!\n That is what \npoincaresos\n does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.\n\n\nWe have bundled this process in the following function:\n\n\n#\n\n\nChaosTools.produce_orbitdiagram\n \n \nFunction\n.\n\n\nproduce_orbitdiagram(ds::ContinuousDynamicalSystem, j, i,\n                     p_index, pvalues; kwargs...)\n\n\n\n\n\nProduce an orbit diagram (also called bifurcation diagram) for the \ni\n-th variable of the given continuous system by computing Poincar\u00e9 surfaces of section of the \nj\n-th variable of the system for the given parameter values.\n\n\nKeyword Arguments\n\n\n\n\ndirection\n, \noffset\n, \ndiff_eq_kwargs\n, \ncallback_kwargs\n, \nTtr\n : Passed into \npoincaresos\n.\n\n\nprintparams::Bool = false\n : Whether to print the parameter used during computation in order to keep track of running time.\n\n\nics = [state(ds)]\n : Collection of initial conditions. For every \nstate \u2208 ics\n a PSOS will be produced.\n\n\n\n\nDescription\n\n\nFor each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for one of the \ni \u2260 j\n variables of the system, just like it is done in \norbitdiagram\n.\n\n\nThe parameter change is done as \nds.prob.p[p_index] = ...\n taking values from \npvalues\n and thus you must use a parameter container that supports this (either \nArray\n, \nLMArray\n or other).\n\n\nThe returned \noutput\n is a vector of vectors. \noutput[k]\n are the \"orbit diagram\" points of the \ni\n-th variable of the system, at parameter value \npvalues[k]\n.\n\n\nPerformance Notes\n\n\nThe total amount of PSOS produced will be \nlength(ics)*length(pvalues)\n.\n\n\nSee also \npoincaresos\n, \norbitdiagram\n.\n\n\nsource\n\n\n\n\nFor example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!\n\n\nds\n \n=\n \nSystems\n.\nshinriki\n([\n-\n2\n,\n \n0\n,\n \n0.2\n])\n\n\n\npvalues\n \n=\n \nlinspace\n(\n19\n,\n22\n,\n201\n)\n\n\ni\n \n=\n \n1\n\n\nj\n \n=\n \n2\n\n\ntf\n \n=\n \n200.0\n\n\np_index\n \n=\n \n1\n\n\n\noutput\n \n=\n \nproduce_orbitdiagram\n(\nds\n,\n \nj\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \ntfinal\n \n=\n \ntf\n,\n\n\nTtr\n \n=\n \n200.0\n,\n \ndiff_eq_kwargs\n \n=\n \nde\n,\n \ndirection\n \n=\n \n-\n1\n,\n \nprintparams\n \n=\n \ntrue\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nR_1\n\\$\n);\n \nylabel\n(\n\\$\nV_1\n\\$\n)", 
            "title": "Orbit Diagrams & PSOS"
        }, 
        {
            "location": "/chaos/orbitdiagram/#orbit-diagrams-of-maps", 
            "text": "An orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed  #  ChaosTools.orbitdiagram     Function .  orbitdiagram ( ds :: DiscreteDynamicalSystem ,   i ,   p_index ,   pvalues ;   kwargs ...)   Compute the orbit diagram (also called bifurcation diagram) of the given system for the  i -th variable for parameter values  pvalues . The  p_index  specifies which parameter of the equations of motion is to be changed, through  ds.p[p_index] .  Keyword Arguments   ics = [state(ds)]  : container of initial conditions that are used at each parameter value to evolve orbits.  Ttr::Int = 1000  : Transient steps; each orbit is evolved for  Ttr  first before saving output.  n::Int = 100  : Amount of points to save for each initial condition.   Description  The method works by computing orbits at each parameter value in  pvalues  for each initial condition in  ics .  The parameter change is done as  ds.p[p_index] = ...  and thus you must use a parameter container that supports this (either  Array ,  LMArray  or other).  The returned  output  is a vector of vectors.  output[j]  are the orbit points of the  i -th variable of the system, at parameter value  pvalues[j] .  See also  poincaresos  and  produce_orbitdiagram .  source   For example, let's compute the famous orbit diagram of the logistic map:  using   DynamicalSystems  using   PyPlot  ds   =   Systems . logistic ()  i   =   1  pvalues   =   2 : 0.001 : 4  ics   =   [ rand ()   for   m   in   1 : 10 ]  n   =   50  Ttr   =   5000  p_index   =   1  output   =   orbitdiagram ( ds ,   i ,   p_index ,   pvalues ;   n   =   n ,   Ttr   =   Ttr )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ r \\$ );   ylabel ( \\$ x \\$ )    Notice that if you are using  PyPlot , the plotting process will be slow, since it is slow at plotting big numbers of points.  The function is not limited to 1D maps, and can be applied just as well to any discrete system.  ds   =   Systems . standardmap ()  i   =   2  pvalues   =   0 : 0.005 : 2  ics   =   [ 0.001 rand ( 2 )   for   m   in   1 : 10 ]  n   =   50  Ttr   =   5000  output   =   orbitdiagram ( ds ,   i ,   : k ,   pvalues ;   n   =   n ,   Ttr   =   Ttr ,   ics   =   ics )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ k \\$ );   ylabel ( \\$ p \\$ )", 
            "title": "Orbit Diagrams of Maps"
        }, 
        {
            "location": "/chaos/orbitdiagram/#poincare-surface-of-section", 
            "text": "Also called  Poincar\u00e9 map  is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:  #  ChaosTools.poincaresos     Function .  poincaresos ( ds :: ContinuousDS ,   j ,   tfinal   =   100 . 0 ;   kwargs ...)   Calculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1, 2] of the given system on the plane of the  j -th variable of the system. The system is evolved for total time of  tfinal .  Returns a  Dataset  of the points that are on the surface of section.  This function assumes that you have created the  ContinuousDS  using functors; see the  official documentation  for more.  Keyword Arguments   direction = 1  and  offset = 0.0  : The surface of section is defined as the (hyper-) plane where  state[j] = offset . Only crossings of the plane that have direction  sign(direction)  are considered to belong to the surface of section.  Ttr = 0.0  : Transient time to evolve the system before starting to compute the PSOS.  diff_eq_kwargs = Dict()  : See  trajectory .  callback_kwargs = Dict(:abstol= 1e-9)  : Keyword arguments passed into the  ContinuousCallback  type of  DifferentialEquations . The option  callback_kwargs[:idxs] = j  is enforced.   References  [1] : H. Poincar\u00e9,  Les Methods Nouvelles de la M\u00e9canique Celeste , Paris: Gauthier-Villars (1892)  [2] : M. Tabor,  Chaos and Integrability in Nonlinear Dynamics: An Introduction , \u00a74.1, in pp. 118-126, New York: Wiley (1989)  See also  orbitdiagram ,  produce_orbitdiagram .  source   An example of the  Henon-Helies  system using a quasi-periodic solution  ds   =   Systems . henonhelies ([ 0. ,   0.1 ,   0.5 ,   0. ])  output   =   poincaresos ( ds ,   3 ,   1000.0 )  figure ()  plot ( output [ : ,   2 ],   output [ : ,   4 ],   lw   =   0.0 ,   marker = . )  xlabel ( \\$ q_2 \\$ );   ylabel ( \\$ p_2 \\$ );    Here the surface of section was the (hyper-) plane that  p_1 = 0 p_1 = 0 . As expected the section is 1-dimensional, because the torus the solution lives in is 2-dimensional. if we produced the PSOS for much longer times, the result would be a filled line instead of individual points.", 
            "title": "Poincar\u00e9 Surface of Section"
        }, 
        {
            "location": "/chaos/orbitdiagram/#stroboscopic-map", 
            "text": "A special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the  Duffing oscillator .  A \"cut\" through the phase-space can be produced at every period  T = 2\\pi/\\omega T = 2\\pi/\\omega . There is no reason to use  poincaresos  for this though, because you can simply use  trajectory  and get the solution with a certain time sampling rate:  ds   =   Systems . duffing ( \u03b2   =   - 1 ,   \u03c9   =   1 ,   f   =   0.3 )   # non-autonomous chaotic system  a   =   trajectory ( ds ,   100000.0 ,   dt   =   2 \u03c0 )   # every period T = 2\u03c0/\u03c9  plot ( a [ : ,   1 ],   a [ : ,   2 ],   lw   =   0 ,   marker   = o ,   ms   =   1 )  xlabel ( \\$ x \\$ );   ylabel ( \\$\\\\ dot{x} \\$ )    What a cool looking attractor is that!", 
            "title": "Stroboscopic Map"
        }, 
        {
            "location": "/chaos/orbitdiagram/#producing-orbit-diagrams-for-continuous-flows", 
            "text": "The  orbitdiagram  does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for  orbitdiagram  to have meaning one must have a map.  If only there was a way to turn a continuous system into a map...  OH WAIT!  That is what  poincaresos  does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.  We have bundled this process in the following function:  #  ChaosTools.produce_orbitdiagram     Function .  produce_orbitdiagram(ds::ContinuousDynamicalSystem, j, i,\n                     p_index, pvalues; kwargs...)  Produce an orbit diagram (also called bifurcation diagram) for the  i -th variable of the given continuous system by computing Poincar\u00e9 surfaces of section of the  j -th variable of the system for the given parameter values.  Keyword Arguments   direction ,  offset ,  diff_eq_kwargs ,  callback_kwargs ,  Ttr  : Passed into  poincaresos .  printparams::Bool = false  : Whether to print the parameter used during computation in order to keep track of running time.  ics = [state(ds)]  : Collection of initial conditions. For every  state \u2208 ics  a PSOS will be produced.   Description  For each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for one of the  i \u2260 j  variables of the system, just like it is done in  orbitdiagram .  The parameter change is done as  ds.prob.p[p_index] = ...  taking values from  pvalues  and thus you must use a parameter container that supports this (either  Array ,  LMArray  or other).  The returned  output  is a vector of vectors.  output[k]  are the \"orbit diagram\" points of the  i -th variable of the system, at parameter value  pvalues[k] .  Performance Notes  The total amount of PSOS produced will be  length(ics)*length(pvalues) .  See also  poincaresos ,  orbitdiagram .  source   For example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!  ds   =   Systems . shinriki ([ - 2 ,   0 ,   0.2 ])  pvalues   =   linspace ( 19 , 22 , 201 )  i   =   1  j   =   2  tf   =   200.0  p_index   =   1  output   =   produce_orbitdiagram ( ds ,   j ,   i ,   p_index ,   pvalues ;   tfinal   =   tf ,  Ttr   =   200.0 ,   diff_eq_kwargs   =   de ,   direction   =   - 1 ,   printparams   =   true )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ R_1 \\$ );   ylabel ( \\$ V_1 \\$ )", 
            "title": "Producing Orbit Diagrams for Continuous Flows"
        }, 
        {
            "location": "/chaos/lyapunovs/", 
            "text": "Lyapunov Exponents\n\n\nLyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The \nWikipedia\n and the \nScholarpedia\n entries have a lot of valuable information about the history and usage of these quantities.\n\n\nThis page treats systems where the equations of motion are known. If instead you have numerical data, see the \nnonlinear timeseries analysis page\n.\n\n\n\n\nLyapunov Spectrum\n\n\nThe function \nlyapunovs\n calculates the entire spectrum of the Lyapunov exponents of a system:\n\n\n#\n\n\nChaosTools.lyapunovs\n \n \nFunction\n.\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n;\n \nkwargs\n...\n)\n \n-\n \n[\n\u03bb1\n,\n \n\u03bb2\n,\n \n...\n,\n \n\u03bbD\n]\n\n\n\n\n\n\nCalculate the spectrum of Lyapunov exponents [1] of \nds\n by applying a QR-decomposition on the parallelepiped matrix \nN\n times. Return the spectrum sorted from maximum to minimum.\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\ndt = 1.0\n : (only for continuous) Time of individual evolutions between successive orthonormalization steps.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\n\n\nDescription\n\n\nThe method we employ is \"H2\" of [2], originally stated in [3]. The vectors defining a \nD\n-dimensional parallepiped are evolved using the tangent dynamics (known also as variational equations) of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over \nN\n successive steps, yielding the lyapunov exponent spectrum.\n\n\nFor discrete systems the QR-decomposition is performed at \nevery\n step \ni \u2208 1:N\n.\n\n\nReferences\n\n\n[1] : A. M. Lyapunov, \nThe General Problem of the Stability of Motion\n, Taylor \n Francis (1992)\n\n\n[2] : K. Geist \net al.\n, Progr. Theor. Phys. \n83\n, pp 875 (1990)\n\n\n[3] : G. Benettin \net al.\n, Meccanica \n15\n, pp 9-20 \n 21-30 (1980)\n\n\nsource\n\n\n\n\nAs you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the \nfolded towel map\n is calculated as:\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nds\n,\n \n10000\n)\n\n\n\n\n\n\n[\n0.432253\n,\n \n0.371617\n,\n \n-\n3.29632\n]\n\n\n\n\n\n\nSimilarly, for a continuous system, e.g. the Lorenz system, you would do:\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n \n#this is not the original parameter!\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nlor\n,\n \n10000\n,\n \ndt\n \n=\n \n0.1\n)\n\n\n\n\n\n\n[\n0.985688\n,\n \n0.00271333\n,\n \n-\n14.6551\n]\n\n\n\n\n\n\n\n\nMaximum Lyapunov Exponent\n\n\nThe function \nlyapunov\n calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of \nlyapunovs\n:\n\n\n#\n\n\nChaosTools.lyapunov\n \n \nFunction\n.\n\n\nlyapunov\n(\nds\n::\nDynamicalSystem\n,\n \n\u03a4\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCalculate the maximum Lyapunov exponent \n\u03bb\n using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one. \nT\n  denotes the total time of evolution (should be \nInt\n for discrete systems).\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\nd0 = 1e-9\n : Initial \n rescaling distance between the two neighboring trajectories.\n\n\nthreshold = 1e-5\n : Distance threshold for rescaling.\n\n\ndiff_eq_kwargs = Dict(:abstol=\nd0, :reltol=\nd0)\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\ndt = 0.1\n : (only for continuous) Time of evolution between each check of distance exceeding the \nthreshold\n.\n\n\ninittest = (st1, d0) -\n st1 .+ d0/sqrt(D)\n : A function that given \n(st1, d0)\n initializes the test state with distance \nd0\n from the given state \nst1\n (\nD\n is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.\n\n\n\n\nDescription\n\n\nTwo neighboring trajectories with initial distance \nd0\n are evolved in time. At time \nd(t_i)\nd(t_i)\n their distance exceeds the \nthreshold\n, which initializes a rescaling of the test trajectory back to having distance \nd0\n from the given one, while the rescaling keeps the distance vector along the maximal expansion direction.\n\n\nThe maximum Lyapunov exponent is the average of the time-local Lyapunov exponents\n\n\n\n\n\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\nPerformance Notes\n\n\nFor the continuous case, the algorithm becomes faster with increasing \ndt\n, since integration is interrupted less frequenty. For the fastest performance you want to fine-tune \ndt, d0, threshold\n such that you have the minimum amount of rescalings \nwhile still being well within the linearized dynamics region\n.\n\n\nYou can easily modify the source code to return the convergence timeseries of the exponent, if need be.\n\n\nReferences\n\n\n[1] : G. Benettin \net al.\n, Phys. Rev. A \n14\n, pp 2338 (1976)\n\n\nsource\n\n\n\n\nFor example:\n\n\nusing\n \nDynamicalSystems\n\n\n\nhenon\n \n=\n \nSystems\n.\nhenon\n()\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nhenon\n,\n \n10000\n,\n \nd0\n \n=\n \n1e-7\n,\n \nthreshold\n \n=\n \n1e-4\n,\n \nTtr\n \n=\n \n100\n)\n\n\n\n\n\n\n0.42007471604734054\n\n\n\n\n\nThe same is done for continuous systems:\n\n\nusing\n \nDynamicalSystems\n,\n \nOrdinaryDiffEq\n\n\n\nross\n \n=\n \nSystems\n.\nroessler\n(\na\n \n=\n \n0.1\n,\n \nb\n \n=\n \n0.1\n,\n \nc\n \n=\n \n14.0\n)\n \n#not original parameters\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nross\n,\n \n100000\n,\n \ndt\n \n=\n \n10.0\n,\n \nTtr\n \n=\n \n100.0\n)\n\n\n\n\n\n\n0.07127399326422117", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-exponents", 
            "text": "Lyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The  Wikipedia  and the  Scholarpedia  entries have a lot of valuable information about the history and usage of these quantities.  This page treats systems where the equations of motion are known. If instead you have numerical data, see the  nonlinear timeseries analysis page .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-spectrum", 
            "text": "The function  lyapunovs  calculates the entire spectrum of the Lyapunov exponents of a system:  #  ChaosTools.lyapunovs     Function .  lyapunovs ( ds :: DynamicalSystem ,   N ;   kwargs ... )   -   [ \u03bb1 ,   \u03bb2 ,   ... ,   \u03bbD ]   Calculate the spectrum of Lyapunov exponents [1] of  ds  by applying a QR-decomposition on the parallelepiped matrix  N  times. Return the spectrum sorted from maximum to minimum.  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  dt = 1.0  : (only for continuous) Time of individual evolutions between successive orthonormalization steps.  diff_eq_kwargs = Dict()  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).   Description  The method we employ is \"H2\" of [2], originally stated in [3]. The vectors defining a  D -dimensional parallepiped are evolved using the tangent dynamics (known also as variational equations) of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over  N  successive steps, yielding the lyapunov exponent spectrum.  For discrete systems the QR-decomposition is performed at  every  step  i \u2208 1:N .  References  [1] : A. M. Lyapunov,  The General Problem of the Stability of Motion , Taylor   Francis (1992)  [2] : K. Geist  et al. , Progr. Theor. Phys.  83 , pp 875 (1990)  [3] : G. Benettin  et al. , Meccanica  15 , pp 9-20   21-30 (1980)  source   As you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the  folded towel map  is calculated as:  using   DynamicalSystems  ds   =   Systems . towel ()  \u03bb\u03bb   =   lyapunovs ( ds ,   10000 )   [ 0.432253 ,   0.371617 ,   - 3.29632 ]   Similarly, for a continuous system, e.g. the Lorenz system, you would do:  lor   =   Systems . lorenz ( \u03c1   =   32.0 )   #this is not the original parameter!  \u03bb\u03bb   =   lyapunovs ( lor ,   10000 ,   dt   =   0.1 )   [ 0.985688 ,   0.00271333 ,   - 14.6551 ]", 
            "title": "Lyapunov Spectrum"
        }, 
        {
            "location": "/chaos/lyapunovs/#maximum-lyapunov-exponent", 
            "text": "The function  lyapunov  calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of  lyapunovs :  #  ChaosTools.lyapunov     Function .  lyapunov ( ds :: DynamicalSystem ,   \u03a4 ;   kwargs ... )   Calculate the maximum Lyapunov exponent  \u03bb  using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one.  T   denotes the total time of evolution (should be  Int  for discrete systems).  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  d0 = 1e-9  : Initial   rescaling distance between the two neighboring trajectories.  threshold = 1e-5  : Distance threshold for rescaling.  diff_eq_kwargs = Dict(:abstol= d0, :reltol= d0)  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).  dt = 0.1  : (only for continuous) Time of evolution between each check of distance exceeding the  threshold .  inittest = (st1, d0) -  st1 .+ d0/sqrt(D)  : A function that given  (st1, d0)  initializes the test state with distance  d0  from the given state  st1  ( D  is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.   Description  Two neighboring trajectories with initial distance  d0  are evolved in time. At time  d(t_i) d(t_i)  their distance exceeds the  threshold , which initializes a rescaling of the test trajectory back to having distance  d0  from the given one, while the rescaling keeps the distance vector along the maximal expansion direction.  The maximum Lyapunov exponent is the average of the time-local Lyapunov exponents   \n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.  \n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.   Performance Notes  For the continuous case, the algorithm becomes faster with increasing  dt , since integration is interrupted less frequenty. For the fastest performance you want to fine-tune  dt, d0, threshold  such that you have the minimum amount of rescalings  while still being well within the linearized dynamics region .  You can easily modify the source code to return the convergence timeseries of the exponent, if need be.  References  [1] : G. Benettin  et al. , Phys. Rev. A  14 , pp 2338 (1976)  source   For example:  using   DynamicalSystems  henon   =   Systems . henon ()  \u03bb   =   lyapunov ( henon ,   10000 ,   d0   =   1e-7 ,   threshold   =   1e-4 ,   Ttr   =   100 )   0.42007471604734054  The same is done for continuous systems:  using   DynamicalSystems ,   OrdinaryDiffEq  ross   =   Systems . roessler ( a   =   0.1 ,   b   =   0.1 ,   c   =   14.0 )   #not original parameters  \u03bb   =   lyapunov ( ross ,   100000 ,   dt   =   10.0 ,   Ttr   =   100.0 )   0.07127399326422117", 
            "title": "Maximum Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/entropies/", 
            "text": "Entropies and Dimensions\n\n\n\n\nEntropies\n\n\nIn the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known \nthermodynamic ones\n, used in Statistical Physics. Rather, they are more like the to the entropies of \ninformation theory\n, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.\n\n\n\n\nGeneralized Entropy\n\n\n#\n\n\nChaosTools.genentropy\n \n \nFunction\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the \n\u03b1\n order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length \n\u03b5\n using \nnon0hist\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \np\n::\nAbstractArray\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the entropy of an array \np\n directly, assuming that \np\n is sum-normalized.\n\n\nOptionally use \nbase\n for the logarithms.\n\n\nDescription\n\n\nThe R\u00e9nyi entropy\n\n\n\n\n\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha\n\n\n\n\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha\n\n\n\n\n\ngeneralizes other known entropies, like e.g. the information entropy (\n\\alpha = 1\n\\alpha = 1\n, see [2]), the maximum entropy (\n\\alpha=0\n\\alpha=0\n, also known as Hartley entropy), or the correlation entropy (\n\\alpha = 2\n\\alpha = 2\n, also known as collision entropy).\n\n\nThe following aliases are provided:\n\n\n\n\nrenyi = genentropy\n\n\nshannon(args...) = genentropy(1, args...)\n\n\nhartley(args...) = genentropy(0, args...)\n\n\n\n\nReferences\n\n\n[1] : A. R\u00e9nyi, \nProceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability\n, pp 547 (1960)\n\n\n[2] : C. E. Shannon, Bell Systems Technical Journal \n27\n, pp 379 (1948)\n\n\nsource\n\n\n\n\nBasically, given a \ndataset\n you can partition it into boxes to calculate an entropy.\n\n\n\n\nWorried about memory overflow? Don't be!\n\n\nPartitioning the dataset (i.e. doing a \nhistogram\n) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size \n\u03b5\n. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!\n\n\nIn fact, there is an upper bound to the memory allocated by \nnon0hist\n: A constant multiplied by the length of the array, \nN = length(p)\n. No matter how small \n\u03b5\n or how many dimensions the data has, the method can at most assign \nN\n dictionary entries.\n\n\n\n\nThe function used internally by \ngenentropy\n is \nnon0hist\n:\n\n\n#\n\n\nChaosTools.non0hist\n \n \nFunction\n.\n\n\nnon0hist\n(\n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n)\n\n\n\n\n\n\nPartition a dataset into tabulated intervals (boxes) of size \n\u03b5\n and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements.\n\n\nPerformances Notes\n\n\nThis method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins. This allows computation of entropies of high-dimensional datasets and with small box sizes \n\u03b5\n without memory overflow.\n\n\nUse e.g. \nfit(Histogram, ...)\n from \nStatsBase\n if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\nsource\n\n\n\n\nFor example, the Shannon entropy of a coin-flip process should be one bit, \nby definition\n. Let's see...\n\n\nusing\n \nDynamicalSystems\n\n\ny\n \n=\n \nFloat64\n.\n(\nrand\n(\nBool\n,\n \n1000000\n))\n \n# just some coin tosses\n\n\nsh\n \n=\n \nshannon\n(\n0.1\n,\n \ny\n)\n  \n# \u2261 genentropy(1, 0.0, y)\n\n\nisapprox\n(\nsh\n,\n \nlog\n(\n2\n),\n  \nrtol\n \n=\n \n1e-6\n)\n\n\n\n\n\n\ntrue\n\n\n\n\n\n\nBecause all entropies are by default calculated on base-\ne\ne\n, the unit of measurement is \"nat\" and one bit is \n\\log(2)\\times\n\\log(2)\\times\nnat.\n\n\n\n\nPermutation Entropy\n\n\nThe permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.\n\n\n#\n\n\nChaosTools.permentropy\n \n \nFunction\n.\n\n\npermentropy\n(\nx\n::\nAbstractVector\n,\n \norder\n \n[\n,\n \ninterval\n=\n1\n]\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the permutation entropy (Bandt \n Pompe, 2002) of given \norder\n from the \nx\n timeseries.  \n\n\nOptionally, \ninterval\n can be specified to use \nx[t0:interval:t1]\n when calculating permutation of the sliding windows between \nt0\n and \nt1 = t0 + interval * (order - 1)\n.\n\n\nOptionally use \nbase\n for the logarithms.\n\n\nReferences\n\n\n[1] : Bandt, C., \n Pompe, B., \nPhys. Rev. Lett. \n88\n (17), pp 174102 (2002)\n\n\nsource\n\n\nFor example, we will compute and compare the \nlyapunov\n exponent of the logistic map with the order-6 permutation entropy, like in the original paper.\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\nrs\n \n=\n \n3.5\n:\n0.001\n:\n4\n\n\nls\n \n=\n \nFloat64\n[];\n \nhs\n \n=\n \nFloat64\n[]\n\n\nfor\n \nr\n \nin\n \nrs\n\n    \nds\n.\np\n[\n1\n]\n \n=\n \nr\n\n    \npush!\n(\nls\n,\n \nlyapunov\n(\nds\n,\n \n100000\n))\n\n    \n# For 1D systems `trajectory` returns a vector\n\n    \npush!\n(\nhs\n,\n \npermentropy\n(\ntrajectory\n(\nds\n,\n \n10000\n),\n \n6\n))\n\n\nend\n\n\n\nf\n \n=\n \nfigure\n(\nfigsize\n \n=\n \n(\n10\n,\n6\n))\n\n\na1\n \n=\n \nsubplot\n(\n211\n)\n\n\nplot\n(\nrs\n,\n \nls\n);\n \nylim\n(\n-\n2\n,\n \nlog\n(\n2\n));\n \nylabel\n(\n\\$\\\\\nlambda\n\\$\n)\n\n\na1\n[\n:\naxes\n][\n:\nget_xaxis\n]()[\n:\nset_ticklabels\n]([])\n\n\nxlim\n(\nrs\n[\n1\n],\n \nrs\n[\nend\n]);\n\n\n\na2\n \n=\n \nsubplot\n(\n212\n)\n\n\nplot\n(\nrs\n,\n \nhs\n;\n \ncolor\n \n=\n \nC1\n);\n \nylabel\n(\n\\$\nh_6\n\\$\n)\n\n\nxlim\n(\nrs\n[\n1\n],\n \nrs\n[\nend\n]);\n \nxlabel\n(\n\\$\nr\n\\$\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\n\n\nAttractor Dimension Estimation\n\n\nThere are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the \nFractal dimension\n. This real number can offer a lot of information about the object that the dataset represents.\n\n\n\n\nGeneralized Dimensions\n\n\nBased on the definition of the \ngeneralized entropy\n, one can calculate an appropriate dimension, called \ngeneralized dimension\n:\n\n\n#\n\n\nChaosTools.generalized_dim\n \n \nFunction\n.\n\n\ngeneralized_dim(\u03b1, dataset [, sizes]) -\n D_\u03b1\n\n\n\n\n\nReturn the \n\u03b1\n order generalized dimension of the \ndataset\n, by calculating the \ngenentropy\n for each \n\u03b5 \u2208 sizes\n.\n\n\nDescription\n\n\nThe returned dimension is approximated by the (inverse) power law exponent of the scaling of the \ngenentropy\n versus the box size \n\u03b5\n, where \n\u03b5 \u2208 sizes\n.\n\n\nCalling this function performs a lot of automated steps:\n\n\n\n\nA vector of box sizes is decided by calling \nsizes = estimate_boxsizes(dataset)\n, if \nsizes\n is not given.\n\n\nFor each element of \nsizes\n the appropriate entropy is calculated, through \nd = genentropy.(\u03b1, sizes, dataset)\n. Let \nx = -log.(sizes)\n.\n\n\nThe curve \nd(x)\n is decomposed into linear regions, using \nlinear_regions\n(x, d)\n.\n\n\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the function \nlinear_region\n. This slope is the return value of \ngeneralized_dim\n.\n\n\n\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\n\nThe following aliases are provided:\n\n\n\n\n\u03b1 = 0 : \nboxcounting_dim\n, \ncapacity_dim\n\n\n\u03b1 = 1 : \ninformation_dim\n\n\n\u03b1 = 2 : \ncorrelation_dim\n\n\n\n\nsource\n\n\n\n\n\n\nBe wary when using \ngeneralized_dim\n\n\nAs stated clearly by the documentation string, calling \ngeneralized_dim\n performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.\n\n\n\n\n#\n\n\nChaosTools.estimate_boxsizes\n \n \nFunction\n.\n\n\nestimate_boxsizes\n(\ndataset\n::\nAbstractDataset\n;\n \nk\n::\nInt\n \n=\n \n12\n,\n \nz\n \n=\n \n-1\n,\n \nw\n \n=\n \n1\n)\n\n\n\n\n\n\nReturn a \nk\n-element \nlogspace\n from \nlower + w\n to \nupper + z\n,\n\n\nlower\n is the magnitude of the minimum pair-wise distance between datapoints while \nupper\n is the magnitude of the maximum difference between greatest and smallest number among each timeseries.\n\n\n\"Magnitude\" here stands for order of magnitude, i.e. \nround(log10(x))\n.\n\n\nsource\n\n\n#\n\n\nChaosTools.linear_regions\n \n \nFunction\n.\n\n\nlinear_regions(x, y; dxi::Int = 1, tol = 0.2) -\n (lrs, tangents)\n\n\n\n\n\nIdentify regions where the curve \ny(x)\n is linear, by scanning the \nx\n-axis every \ndxi\n indices (e.g. at \nx[1] to x[5], x[5] to x[10], x[10] to x[15]\n and so on if \ndxi=5\n).\n\n\nIf the slope (calculated using \nLsqFit\n) of a region of width \ndxi\n is approximatelly equal to that of the previous region, within tolerance \ntol\n, then these two regions belong to the same linear region.\n\n\nReturn the indices of \nx\n that correspond to linear regions, \nlrs\n, and the approximated \ntangents\n at each region. \nlrs\n is a vector of \nInt\n.\n\n\nA function \nplot_linear_regions\n visualizes the result of using this \nlinear_regions\n (requires \nPyPlot\n).\n\n\nsource\n\n\n#\n\n\nChaosTools.linear_region\n \n \nFunction\n.\n\n\nlinear_region(x, y; dxi::Int = 1, tol = 0.2) -\n ([ind1, ind2], slope)\n\n\n\n\n\nCall \nlinear_regions\n, identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops (\nx[ind1:ind2]\n) as well as the approximated slope.\n\n\nsource\n\n\n\n\n\n\nExample\n\n\nFor example, the dimension of the strange attractor of the \nH\u00e9non map\n is:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n(\n-\nrand\n(\n2\n))\n\n\nts\n \n=\n \ntrajectory\n(\nhen\n,\n \n1000000\n)\n\n\nD_hen\n \n=\n \ninformation_dim\n(\nts\n)\n\n\n\n\n\n\n1.19735650096483\n\n\n\n\n\nAs a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D \n56\n, pp 185-187 (1992)).\n\n\n\n\n\n\nKaplan-Yorke Dimension\n\n\n#\n\n\nChaosTools.kaplanyorke_dim\n \n \nFunction\n.\n\n\nkaplanyorke_dim(lyapunovs::AbstractVector)\n\n\n\n\n\nCalculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].\n\n\nDescription\n\n\nThe Kaplan-Yorke dimension is simply the point where \ncumsum(lyapunovs)\n becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.\n\n\nUseful in combination with \nlyapunovs\n.\n\n\nReferences\n\n\n[1] :  J. Kaplan \n J. Yorke, \nChaotic behavior of multidimensional difference equations\n, Lecture Notes in Mathematics vol. \n730\n, Springer (1979)\n\n\nsource\n\n\n\n\nNotice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nD_kp\n \n=\n \nkaplanyorke_dim\n(\nlyapunovs\n(\nhen\n,\n \n100000\n))\n\n\n\n\n\n\n1.258709281073041", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies-and-dimensions", 
            "text": "", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies", 
            "text": "In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known  thermodynamic ones , used in Statistical Physics. Rather, they are more like the to the entropies of  information theory , which represents information contained within a dataset, or information about the dimensional scaling of a dataset.", 
            "title": "Entropies"
        }, 
        {
            "location": "/chaos/entropies/#generalized-entropy", 
            "text": "#  ChaosTools.genentropy     Function .  genentropy ( \u03b1 ,   \u03b5 ,   dataset :: AbstractDataset ;   base   =   e )   Compute the  \u03b1  order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length  \u03b5  using  non0hist .  genentropy ( \u03b1 ,   p :: AbstractArray ;   base   =   e )   Compute the entropy of an array  p  directly, assuming that  p  is sum-normalized.  Optionally use  base  for the logarithms.  Description  The R\u00e9nyi entropy   \nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha  \nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha   generalizes other known entropies, like e.g. the information entropy ( \\alpha = 1 \\alpha = 1 , see [2]), the maximum entropy ( \\alpha=0 \\alpha=0 , also known as Hartley entropy), or the correlation entropy ( \\alpha = 2 \\alpha = 2 , also known as collision entropy).  The following aliases are provided:   renyi = genentropy  shannon(args...) = genentropy(1, args...)  hartley(args...) = genentropy(0, args...)   References  [1] : A. R\u00e9nyi,  Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability , pp 547 (1960)  [2] : C. E. Shannon, Bell Systems Technical Journal  27 , pp 379 (1948)  source   Basically, given a  dataset  you can partition it into boxes to calculate an entropy.   Worried about memory overflow? Don't be!  Partitioning the dataset (i.e. doing a  histogram ) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size  \u03b5 . However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!  In fact, there is an upper bound to the memory allocated by  non0hist : A constant multiplied by the length of the array,  N = length(p) . No matter how small  \u03b5  or how many dimensions the data has, the method can at most assign  N  dictionary entries.   The function used internally by  genentropy  is  non0hist :  #  ChaosTools.non0hist     Function .  non0hist ( \u03b5 ,   dataset :: AbstractDataset )   Partition a dataset into tabulated intervals (boxes) of size  \u03b5  and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements.  Performances Notes  This method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins. This allows computation of entropies of high-dimensional datasets and with small box sizes  \u03b5  without memory overflow.  Use e.g.  fit(Histogram, ...)  from  StatsBase  if you wish to keep information about the edges of the binning as well as the zero elements.  source   For example, the Shannon entropy of a coin-flip process should be one bit,  by definition . Let's see...  using   DynamicalSystems  y   =   Float64 . ( rand ( Bool ,   1000000 ))   # just some coin tosses  sh   =   shannon ( 0.1 ,   y )    # \u2261 genentropy(1, 0.0, y)  isapprox ( sh ,   log ( 2 ),    rtol   =   1e-6 )   true   Because all entropies are by default calculated on base- e e , the unit of measurement is \"nat\" and one bit is  \\log(2)\\times \\log(2)\\times nat.", 
            "title": "Generalized Entropy"
        }, 
        {
            "location": "/chaos/entropies/#permutation-entropy", 
            "text": "The permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.  #  ChaosTools.permentropy     Function .  permentropy ( x :: AbstractVector ,   order   [ ,   interval = 1 ] ;   base   =   e )   Compute the permutation entropy (Bandt   Pompe, 2002) of given  order  from the  x  timeseries.    Optionally,  interval  can be specified to use  x[t0:interval:t1]  when calculating permutation of the sliding windows between  t0  and  t1 = t0 + interval * (order - 1) .  Optionally use  base  for the logarithms.  References  [1] : Bandt, C.,   Pompe, B.,  Phys. Rev. Lett.  88  (17), pp 174102 (2002)  source  For example, we will compute and compare the  lyapunov  exponent of the logistic map with the order-6 permutation entropy, like in the original paper.  ds   =   Systems . logistic ()  rs   =   3.5 : 0.001 : 4  ls   =   Float64 [];   hs   =   Float64 []  for   r   in   rs \n     ds . p [ 1 ]   =   r \n     push! ( ls ,   lyapunov ( ds ,   100000 )) \n     # For 1D systems `trajectory` returns a vector \n     push! ( hs ,   permentropy ( trajectory ( ds ,   10000 ),   6 ))  end  f   =   figure ( figsize   =   ( 10 , 6 ))  a1   =   subplot ( 211 )  plot ( rs ,   ls );   ylim ( - 2 ,   log ( 2 ));   ylabel ( \\$\\\\ lambda \\$ )  a1 [ : axes ][ : get_xaxis ]()[ : set_ticklabels ]([])  xlim ( rs [ 1 ],   rs [ end ]);  a2   =   subplot ( 212 )  plot ( rs ,   hs ;   color   =   C1 );   ylabel ( \\$ h_6 \\$ )  xlim ( rs [ 1 ],   rs [ end ]);   xlabel ( \\$ r \\$ )  tight_layout ()", 
            "title": "Permutation Entropy"
        }, 
        {
            "location": "/chaos/entropies/#attractor-dimension-estimation", 
            "text": "There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the  Fractal dimension . This real number can offer a lot of information about the object that the dataset represents.", 
            "title": "Attractor Dimension Estimation"
        }, 
        {
            "location": "/chaos/entropies/#generalized-dimensions", 
            "text": "Based on the definition of the  generalized entropy , one can calculate an appropriate dimension, called  generalized dimension :  #  ChaosTools.generalized_dim     Function .  generalized_dim(\u03b1, dataset [, sizes]) -  D_\u03b1  Return the  \u03b1  order generalized dimension of the  dataset , by calculating the  genentropy  for each  \u03b5 \u2208 sizes .  Description  The returned dimension is approximated by the (inverse) power law exponent of the scaling of the  genentropy  versus the box size  \u03b5 , where  \u03b5 \u2208 sizes .  Calling this function performs a lot of automated steps:   A vector of box sizes is decided by calling  sizes = estimate_boxsizes(dataset) , if  sizes  is not given.  For each element of  sizes  the appropriate entropy is calculated, through  d = genentropy.(\u03b1, sizes, dataset) . Let  x = -log.(sizes) .  The curve  d(x)  is decomposed into linear regions, using  linear_regions (x, d) .  The biggest linear region is chosen, and a fit for the slope of that region is performed using the function  linear_region . This slope is the return value of  generalized_dim .   By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.  The following aliases are provided:   \u03b1 = 0 :  boxcounting_dim ,  capacity_dim  \u03b1 = 1 :  information_dim  \u03b1 = 2 :  correlation_dim   source    Be wary when using  generalized_dim  As stated clearly by the documentation string, calling  generalized_dim  performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.   #  ChaosTools.estimate_boxsizes     Function .  estimate_boxsizes ( dataset :: AbstractDataset ;   k :: Int   =   12 ,   z   =   -1 ,   w   =   1 )   Return a  k -element  logspace  from  lower + w  to  upper + z ,  lower  is the magnitude of the minimum pair-wise distance between datapoints while  upper  is the magnitude of the maximum difference between greatest and smallest number among each timeseries.  \"Magnitude\" here stands for order of magnitude, i.e.  round(log10(x)) .  source  #  ChaosTools.linear_regions     Function .  linear_regions(x, y; dxi::Int = 1, tol = 0.2) -  (lrs, tangents)  Identify regions where the curve  y(x)  is linear, by scanning the  x -axis every  dxi  indices (e.g. at  x[1] to x[5], x[5] to x[10], x[10] to x[15]  and so on if  dxi=5 ).  If the slope (calculated using  LsqFit ) of a region of width  dxi  is approximatelly equal to that of the previous region, within tolerance  tol , then these two regions belong to the same linear region.  Return the indices of  x  that correspond to linear regions,  lrs , and the approximated  tangents  at each region.  lrs  is a vector of  Int .  A function  plot_linear_regions  visualizes the result of using this  linear_regions  (requires  PyPlot ).  source  #  ChaosTools.linear_region     Function .  linear_region(x, y; dxi::Int = 1, tol = 0.2) -  ([ind1, ind2], slope)  Call  linear_regions , identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops ( x[ind1:ind2] ) as well as the approximated slope.  source", 
            "title": "Generalized Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#example", 
            "text": "For example, the dimension of the strange attractor of the  H\u00e9non map  is:  using   DynamicalSystems  hen   =   Systems . henon ( - rand ( 2 ))  ts   =   trajectory ( hen ,   1000000 )  D_hen   =   information_dim ( ts )   1.19735650096483  As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D  56 , pp 185-187 (1992)).", 
            "title": "Example"
        }, 
        {
            "location": "/chaos/entropies/#kaplan-yorke-dimension", 
            "text": "#  ChaosTools.kaplanyorke_dim     Function .  kaplanyorke_dim(lyapunovs::AbstractVector)  Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].  Description  The Kaplan-Yorke dimension is simply the point where  cumsum(lyapunovs)  becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.  Useful in combination with  lyapunovs .  References  [1] :  J. Kaplan   J. Yorke,  Chaotic behavior of multidimensional difference equations , Lecture Notes in Mathematics vol.  730 , Springer (1979)  source   Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:  using   DynamicalSystems  hen   =   Systems . henon ()  D_kp   =   kaplanyorke_dim ( lyapunovs ( hen ,   100000 ))   1.258709281073041", 
            "title": "Kaplan-Yorke Dimension"
        }, 
        {
            "location": "/chaos/nlts/", 
            "text": "Nonlinear Timeseries Analysis\n\n\n\n\nNeighborhoods in a Dataset\n\n\nCombining the excellent performance of \nNearestNeighbors.jl\n with the \nAbstractDataset\n allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of \nAbstractNeighborhood\n.\n\n\n#\n\n\nChaosTools.neighborhood\n \n \nFunction\n.\n\n\nneighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)\n\n\n\n\n\nReturn a vector of indices which are the neighborhood of \npoint\n, whose index in the original data is \nn\n.\n\n\nIf the original data is \ndata \n: AbstractDataset\n, then use \ntree = KDTree(data)\n to obtain the \ntree\n instance (which also contains a copy of the data). Both \npoint\n and \nn\n must be provided because the \ntree\n has indices in different sorting.\n\n\nThe \nmethod\n can be a subtype of \nAbstractNeighborhood\n.\n\n\nneighborhood\n works for \nany\n subtype of \nAbstractDataset\n, for example\n\n\nR\n \n=\n \nsome_dataset\n\n\ntree\n \n=\n \nKDTree\n(\nR\n)\n\n\nneigh\n \n=\n \nneighborhood\n(\nn\n,\n \nR\n[\nn\n],\n \ntree\n,\n \nmethod\n)\n\n\n\n\n\n\nReferences\n\n\nneighborhood\n simply interfaces the functions \nknn\n and \ninrange\n from \nNearestNeighbors.jl\n by using the last argument, \nmethod\n.\n\n\nsource\n\n\n#\n\n\nChaosTools.AbstractNeighborhood\n \n \nType\n.\n\n\nAbstractNeighborhood\n\n\n\n\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\n\nConcrete subtypes:\n\n\n\n\nFixedMassNeighborhood(K::Int)\n  : The neighborhood of a point consists of the \nK\n nearest neighbors of the point.\n\n\nFixedSizeNeighborhood(\u03b5::Real)\n : The neighborhood of a point consists of all neighbors that have distance \n \n\u03b5\n from the point.\n\n\n\n\nNotice that these distances are always computed using the \nEuclidean()\n distance in \nD\n-dimensional space.\n\n\nSee also \nneighborhood\n or \nnumericallyapunov\n.\n\n\nsource\n\n\n\n\n\n\nDelay Coordinates Reconstruction\n\n\nA timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as \ndelay coordinates embedding\n.\n\n\nThis is done through the \nReconstruction\n interface:\n\n\n#\n\n\nDynamicalSystemsBase.Reconstruction\n \n \nType\n.\n\n\nReconstruction{D, T, \u03c4} \n: AbstractDataset{D, T}\n\n\n\n\n\nD\n-dimensional delay-coordinates reconstruction object with delay \n\u03c4\n, created from a timeseries \ns\n with \nT\n type numbers.\n\n\nUse \nReconstruction(s::AbstractVector{T}, D, \u03c4)\n to create an instance.\n\n\nDescription\n\n\nThe \nn\nn\nth row of a \nReconstruction\n is the \nD\n-dimensional vector\n\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\n\n\n\n\nThe reconstruction object \nR\n can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper \nD\n and \n\u03c4\n [1, 2].\n\n\nR\n can be accessed similarly to a \nDataset\n:\n\n\ns\n \n=\n \nrand\n(\n1e6\n)\n\n\nR\n \n=\n \nReconstruction\n(\ns\n,\n \n4\n,\n \n1\n)\n \n# dimension 4 and delay 1\n\n\nR\n[\n3\n]\n \n# third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])\n\n\nR\n[\n1\n,\n \n2\n]\n \n# Second element of first point of reconstruction, \u2261 s[2]\n\n\n\n\n\n\nand can also be given to all functions that accept a \nDataset\n (like e.g. \ngeneralized_dim\n from module \nChaosTools\n).\n\n\nThe functions \ndimension(R)\n and \ndelay(R)\n return \nD\n and \n\u03c4\n respectively.\n\n\nReferences\n\n\n[1] : F. Takens, \nDetecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence\n, Lecture Notes in Mathematics \n366\n, Springer (1981)\n\n\n[2] : T. Sauer \net al.\n, J. Stat. Phys. \n65\n, pp 579 (1991)\n\n\nsource\n\n\n\n\nHere are some examples of \nReconstruction\ns of a 3D continuous chaotic system:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\ngissinger\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n)\n\n\n\nxyz\n \n=\n \ncolumns\n(\ndata\n)\n\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n12\n,\n10\n))\n\n\nk\n \n=\n \n1\n\n\nfor\n \ni\n \nin\n \n1\n:\n3\n\n    \nfor\n \n\u03c4\n \nin\n \n[\n5\n,\n \n30\n,\n \n100\n]\n\n        \nR\n \n=\n \nReconstruction\n(\nxyz\n[\ni\n],\n \n2\n,\n \n\u03c4\n)\n\n        \nax\n \n=\n \nsubplot\n(\n3\n,\n3\n,\nk\n)\n\n        \nplot\n(\nR\n[\n:\n,\n \n1\n],\n \nR\n[\n:\n,\n \n2\n],\n \ncolor\n \n=\n \nC\n$\n(\nk\n-\n1\n)\n,\n \nlw\n \n=\n \n0.8\n)\n\n        \ntitle\n(\nvar = \n$i\n, \u03c4 = \n$\u03c4\n)\n\n        \nk\n+=\n1\n\n    \nend\n\n\nend\n\n\n\ntight_layout\n()\n\n\nsuptitle\n(\n2D Reconstructions\n)\n\n\nsubplots_adjust\n(\ntop\n=\n0.9\n)\n\n\n\n\n\n\n\n\n\n\nEstimating Reconstruction Parameters\n\n\nThe following functions can (sometimes) estimate good values that can be used in \nReconstruction\n. There are no guarantees though!\n\n\n#\n\n\nChaosTools.estimate_delay\n \n \nFunction\n.\n\n\nestimate_delay(s) -\n \u03c4\n\n\n\n\n\nEstimate an optimal delay to be used in \nReconstruction\n, by performing an exponential fit to the \nabs.(c)\n with \nc\n the auto-correlation function of \ns\n. Return the exponential decay time \n\u03c4\n rounded to an integer.\n\n\nsource\n\n\n\n\n\n\nNumerical Lyapunov Exponent\n\n\nGiven any timeseries, one can first obtain a \nReconstruction\n from it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with\n\n\n#\n\n\nChaosTools.numericallyapunov\n \n \nFunction\n.\n\n\nnumericallyapunov\n(\nR\n::\nReconstruction\n,\n \nks\n;\n  \nrefstates\n,\n \ndistance\n,\n \nmethod\n)\n\n\n\n\n\n\nReturn \nE = [E(k) for k \u2208 ks]\n, where \nE(k)\n is the average logarithmic distance for nearby states that are evolved in time for \nk\n steps (\nk\n must be integer).\n\n\nKeyword Arguments\n\n\n\n\nrefstates::AbstractVector{Int} = 1:(length(R) - ks[end])\n : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in \nrefstates\n.\n\n\nmethod::AbstractNeighborhood = FixedMassNeighborhood(1)\n : The method to be used when evaluating the neighborhood of each reference state. See \nAbstractNeighborhood\n or \nneighborhood\n for more info.\n\n\ndistance::Metric = Cityblock()\n : The distance function used in the logarithmic distance of nearby states. The allowed distances are \nCityblock()\n and \nEuclidean()\n. See below for more info.\n\n\n\n\nDescription\n\n\nIf the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold\n\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\n\nfor a \nwell defined region\n in the \nk\n axis, where \n\\lambda\n\\lambda\n is the approximated maximum Lyapunov exponent. \n\\Delta t\n\\Delta t\n is the time between samples in the original timeseries. You can use \nlinear_region\n with arguments \n(ks .* \u0394t, E)\n to identify the slope (= \n\\lambda\n\\lambda\n) immediatelly, assuming you have choosen sufficiently good \nks\n such that the linear scaling region is bigger than the saturated region.\n\n\nThe algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index \nk\n increases. The average of the above over all neighborhood states over all reference states is the returned result.\n\n\nIf the \nMetric\n is \nEuclidean()\n then use the Euclidean distance of the full \nD\n-dimensional points (distance \nd_E\nd_E\n in ref. [1]). If however the \nMetric\n is \nCityblock()\n, calculate the absolute distance of \nonly the first elements\n of the \nm+k\n and \nn+k\n points of the reconstruction \nR\n(distance \nd_F\nd_F\n in ref. [1]). Notice that the distances used are defined in the package \nDistances.jl\n, but are re-exported here for ease-of-use.\n\n\nThis function assumes that the Theiler window (see [1]) is the same as the delay time, \nw  = \\tau\nw  = \\tau\n.\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 1 (section 1.3.2), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n[2] : Kantz, H., Phys. Lett. A \n185\n, pp 77\u201387 (1994)\n\n\nsource\n\n\n\n\nThe function \nnumericallyapunov\n has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.\n\n\n\n\nExample of Numerical Lyapunov computation\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n \n#fake measurements for the win!\n\n\n\nks\n \n=\n \n1\n:\n20\n\n\n\u211c\n \n=\n \n1\n:\n10000\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n6\n))\n\n\ni\n \n=\n \n1\n\n\n\nfor\n \n(\ni\n,\n \ndi\n)\n \nin\n \nenumerate\n([\nEuclidean\n(),\n \nCityblock\n()])\n\n  \nsubplot\n(\n1\n,\n \n2\n,\n \ni\n)\n\n  \ni\n+=\n1\n\n  \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n)\n\n\n  \ntitle\n(\nDistance: \n$\n(\ndi\n)\n,\n \nsize\n \n=\n \n18\n)\n\n  \nfor\n \nD\n \nin\n \n[\n2\n,\n \n4\n,\n \n7\n]\n\n    \nR\n \n=\n \nReconstruction\n(\nx\n,\n \nD\n,\n \n1\n)\n\n    \nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n;\n\n    \nrefstates\n \n=\n \n\u211c\n,\n \ndistance\n \n=\n \ndi\n,\n \nmethod\n \n=\n \nmethod\n)\n\n    \n# The following operation:\n\n    \n\u0394t\n \n=\n \n1\n\n    \n\u03bb\n \n=\n \nlinear_region\n(\nks\n.*\n\u0394t\n,\n \nE\n)[\n2\n]\n\n    \n# gives the linear slope, i.e. the Lyapunov exponent\n\n    \nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$D\n, \u03bb=\n$\n(\nround\n(\n\u03bb\n,\n \n3\n))\n)\n\n    \nlegend\n()\n\n    \ntight_layout\n()\n\n  \nend\n\n\n\n\nend\n\n\n\n\n\n\nwhich gives the result \n\n\n\n\nBad Time-axis (\nks\n) length\n\n\n\n\nLarge \nks\n\n\nThis simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!\n\n\n\n\nLet's revisit the example of the previous section:\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\n\n\n\nThe timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following\n\n\nks\n \n=\n \n1\n:\n100\n\n\nR\n \n=\n \nReconstruction\n(\nx\n,\n \n2\n,\n \n1\n)\n\n\nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n,\n \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n))\n\n\nfigure\n()\n\n\nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n])\n\n\nprintln\n(\nLyappunov: \n,\n \nlinear_region\n(\nks\n,\n \nE\n)[\n2\n])\n\n\n\n\n\n\ngives this plot: \n and prints\n\n\nLyapunov\n:\n \n0.4161\n...\n\n\n\n\n\n\nNotice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function \nlinear_region\n would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)\n\n\n\n\nCase of a Continuous system\n\n\nThe process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n \n# Max lyapunov is around 0.90\n\n\n# create a timeseries of 1 dimension\n\n\ndt\n \n=\n \n0.05\n\n\nx\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n;\n \ndt\n \n=\n \ndt\n)[\n:\n,\n \n1\n]\n\n\n\n\u03c41\n \n=\n \nestimate_delay\n(\nx\n)\n \n#gives 7\n\n\n\n# Reconstruct it\n\n\nfigure\n()\n\n\nfor\n \nD\n \nin\n \n[\n4\n,\n \n8\n],\n \n\u03c4\n \nin\n \n[\n\u03c41\n,\n \n15\n]\n\n    \nR\n \n=\n \nReconstruction\n(\nx\n,\n \nD\n,\n \n\u03c4\n)\n\n\n    \n# I now know that I have to use much bigger ks than 1:20, because this is a\n\n    \n# continuous case! (See reference given in `numericallyapunovs`)\n\n    \nks1\n \n=\n \n0\n:\n200\n\n    \n# I also know that I do not need that dense computations, since 1 increment\n\n    \n# in k means increment of 0.05 real time\n\n    \nks2\n \n=\n \n0\n:\n4\n:\n200\n\n\n    \n# Calculate lyapunovs:\n\n    \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n5\n)\n \n#5 nearest neighbors of each state\n\n\n    \n# E1 = numericallyapunov(R, ks1; method = method)\n\n    \n# \u03bb1 = linear_region(ks1 .* dt, E1)[2]\n\n    \nE2\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks2\n;\n \nmethod\n \n=\n \nmethod\n)\n\n    \n\u03bb2\n \n=\n \nlinear_region\n(\nks2\n \n.*\n \ndt\n,\n \nE2\n)[\n2\n]\n\n\n\n    \n# plot(ks1,E1.-E1[1], label = \ndense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3))\n)\n\n    \nplot\n(\nks2\n,\nE2\n.-\nE2\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$\n(\nD\n)\n, \u03c4=\n$\n(\n\u03c4\n)\n, \u03bb=\n$\n(\nround\n(\n\u03bb2\n,\n \n3\n))\n)\n\n\nend\n\n\n\nlegend\n()\n\n\nxlabel\n(\nk (0.05\u00d7t)\n)\n\n\nylabel\n(\nE - E(0)\n)\n\n\ntitle\n(\nContinuous Reconstruction Lyapunov\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\nwhich produces: \n As you can see, using \n\u03c4 = 15\n makes almost no sense! The estimates with \n\u03c4 = 7\n though are very good (the actual value is around \n\u03bb \u2248 0.89...\n).\n\n\n\n\nBroomhead-King Coordinates\n\n\n#\n\n\nChaosTools.broomhead_king\n \n \nFunction\n.\n\n\nbroomhead_king(x::AbstractVector, d::Int) -\n U, S, Vtr\n\n\n\n\n\nReturn the Broomhead-King coordinates of a timeseries \nx\n by performing \nsvd\n on the so-called trajectory matrix with dimension \nd\n.\n\n\nDescription\n\n\nBroomhead and King coordinates is a method proposed in [1] that applies the Karhunen\u2013Lo\u00e8ve theorem to delay coordinates embedding with smallest possible delay.\n\n\nThe function performs singular value decomposition on the \nd\n-dimensional trajectory matrix \nX\nX\n of \nx\nx\n,\n\n\n\n\n\nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 \n x_2 \n \\ldots \n x_d \\\\\nx_2 \n x_3 \n \\ldots \n x_{d+1}\\\\\n\\vdots \n \\vdots \n \\vdots \n \\vdots \\\\\nx_{N-d+1} \n x_{N-d+2} \n\\ldots \n x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.\n\n\n\n\nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 & x_2 & \\ldots & x_d \\\\\nx_2 & x_3 & \\ldots & x_{d+1}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nx_{N-d+1} & x_{N-d+2} &\\ldots & x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.\n\n\n\n\n\nThe columns of \nU\nU\n can then be used as a new coordinate system, and by considering the values of the singular values \nS\nS\n you can decide how many columns of \nU\nU\n are \"important\". See the documentation page for example application.\n\n\nReferences\n\n\n[1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A \n20\n, 9, pp L563 (1987)\n\n\nsource\n\n\n\n\nThis alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.\n\n\nTake the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\nusing\n \nDistributions\n \n# for random numbers\n\n\n\nds\n \n=\n \nSystems\n.\ngissinger\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n \n\n\nL\n \n=\n \nlength\n(\nx\n)\n\n\ndistrib\n \n=\n \nNormal\n(\n0\n,\n \n0.1\n)\n\n\ns\n \n=\n \nx\n \n.+\n \nrand\n(\ndistrib\n,\n \nL\n)\n\n\n\nU\n,\n \nS\n \n=\n \nbroomhead_king\n(\ns\n,\n \n40\n)\n\n\n\nfigure\n(\nfigsize\n=\n \n(\n10\n,\n6\n))\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\nplot\n(\nU\n[\n:\n,\n \n1\n],\n \nU\n[\n:\n,\n \n2\n])\n\n\ntitle\n(\nBroomhead-King of s\n)\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nR\n \n=\n \nReconstruction\n(\ns\n,\n \n2\n,\n \n30\n)\n\n\nplot\n(\ncolumns\n(\nR\n)\n...\n;\n \ncolor\n \n=\n \nC3\n)\n\n\ntitle\n(\n2D Reconstruction of s\n)\n\n\n\ntight_layout\n()\n\n\n\n\n\n\n we have used the same system as in the \ndelay coordinates reconstruction\n example, and picked the optimal delay time of \n\u03c4 = 30\n. Regardless, the vanilla delay coordinates fail spectacularly when compared with the Broomhead-King coordinates.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#nonlinear-timeseries-analysis", 
            "text": "", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#neighborhoods-in-a-dataset", 
            "text": "Combining the excellent performance of  NearestNeighbors.jl  with the  AbstractDataset  allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of  AbstractNeighborhood .  #  ChaosTools.neighborhood     Function .  neighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)  Return a vector of indices which are the neighborhood of  point , whose index in the original data is  n .  If the original data is  data  : AbstractDataset , then use  tree = KDTree(data)  to obtain the  tree  instance (which also contains a copy of the data). Both  point  and  n  must be provided because the  tree  has indices in different sorting.  The  method  can be a subtype of  AbstractNeighborhood .  neighborhood  works for  any  subtype of  AbstractDataset , for example  R   =   some_dataset  tree   =   KDTree ( R )  neigh   =   neighborhood ( n ,   R [ n ],   tree ,   method )   References  neighborhood  simply interfaces the functions  knn  and  inrange  from  NearestNeighbors.jl  by using the last argument,  method .  source  #  ChaosTools.AbstractNeighborhood     Type .  AbstractNeighborhood  Supertype of methods for deciding the neighborhood of points for a given point.  Concrete subtypes:   FixedMassNeighborhood(K::Int)   : The neighborhood of a point consists of the  K  nearest neighbors of the point.  FixedSizeNeighborhood(\u03b5::Real)  : The neighborhood of a point consists of all neighbors that have distance    \u03b5  from the point.   Notice that these distances are always computed using the  Euclidean()  distance in  D -dimensional space.  See also  neighborhood  or  numericallyapunov .  source", 
            "title": "Neighborhoods in a Dataset"
        }, 
        {
            "location": "/chaos/nlts/#delay-coordinates-reconstruction", 
            "text": "A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as  delay coordinates embedding .  This is done through the  Reconstruction  interface:  #  DynamicalSystemsBase.Reconstruction     Type .  Reconstruction{D, T, \u03c4}  : AbstractDataset{D, T}  D -dimensional delay-coordinates reconstruction object with delay  \u03c4 , created from a timeseries  s  with  T  type numbers.  Use  Reconstruction(s::AbstractVector{T}, D, \u03c4)  to create an instance.  Description  The  n n th row of a  Reconstruction  is the  D -dimensional vector   \n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))  \n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))   The reconstruction object  R  can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper  D  and  \u03c4  [1, 2].  R  can be accessed similarly to a  Dataset :  s   =   rand ( 1e6 )  R   =   Reconstruction ( s ,   4 ,   1 )   # dimension 4 and delay 1  R [ 3 ]   # third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])  R [ 1 ,   2 ]   # Second element of first point of reconstruction, \u2261 s[2]   and can also be given to all functions that accept a  Dataset  (like e.g.  generalized_dim  from module  ChaosTools ).  The functions  dimension(R)  and  delay(R)  return  D  and  \u03c4  respectively.  References  [1] : F. Takens,  Detecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence , Lecture Notes in Mathematics  366 , Springer (1981)  [2] : T. Sauer  et al. , J. Stat. Phys.  65 , pp 579 (1991)  source   Here are some examples of  Reconstruction s of a 3D continuous chaotic system:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . gissinger ()  data   =   trajectory ( ds ,   1000.0 )  xyz   =   columns ( data )  figure ( figsize   =   ( 12 , 10 ))  k   =   1  for   i   in   1 : 3 \n     for   \u03c4   in   [ 5 ,   30 ,   100 ] \n         R   =   Reconstruction ( xyz [ i ],   2 ,   \u03c4 ) \n         ax   =   subplot ( 3 , 3 , k ) \n         plot ( R [ : ,   1 ],   R [ : ,   2 ],   color   =   C $ ( k - 1 ) ,   lw   =   0.8 ) \n         title ( var =  $i , \u03c4 =  $\u03c4 ) \n         k += 1 \n     end  end  tight_layout ()  suptitle ( 2D Reconstructions )  subplots_adjust ( top = 0.9 )", 
            "title": "Delay Coordinates Reconstruction"
        }, 
        {
            "location": "/chaos/nlts/#estimating-reconstruction-parameters", 
            "text": "The following functions can (sometimes) estimate good values that can be used in  Reconstruction . There are no guarantees though!  #  ChaosTools.estimate_delay     Function .  estimate_delay(s) -  \u03c4  Estimate an optimal delay to be used in  Reconstruction , by performing an exponential fit to the  abs.(c)  with  c  the auto-correlation function of  s . Return the exponential decay time  \u03c4  rounded to an integer.  source", 
            "title": "Estimating Reconstruction Parameters"
        }, 
        {
            "location": "/chaos/nlts/#numerical-lyapunov-exponent", 
            "text": "Given any timeseries, one can first obtain a  Reconstruction  from it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with  #  ChaosTools.numericallyapunov     Function .  numericallyapunov ( R :: Reconstruction ,   ks ;    refstates ,   distance ,   method )   Return  E = [E(k) for k \u2208 ks] , where  E(k)  is the average logarithmic distance for nearby states that are evolved in time for  k  steps ( k  must be integer).  Keyword Arguments   refstates::AbstractVector{Int} = 1:(length(R) - ks[end])  : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in  refstates .  method::AbstractNeighborhood = FixedMassNeighborhood(1)  : The method to be used when evaluating the neighborhood of each reference state. See  AbstractNeighborhood  or  neighborhood  for more info.  distance::Metric = Cityblock()  : The distance function used in the logarithmic distance of nearby states. The allowed distances are  Cityblock()  and  Euclidean() . See below for more info.   Description  If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold   \nE(k) \\approx \\lambda\\Delta t k + E(0)  \nE(k) \\approx \\lambda\\Delta t k + E(0)   for a  well defined region  in the  k  axis, where  \\lambda \\lambda  is the approximated maximum Lyapunov exponent.  \\Delta t \\Delta t  is the time between samples in the original timeseries. You can use  linear_region  with arguments  (ks .* \u0394t, E)  to identify the slope (=  \\lambda \\lambda ) immediatelly, assuming you have choosen sufficiently good  ks  such that the linear scaling region is bigger than the saturated region.  The algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index  k  increases. The average of the above over all neighborhood states over all reference states is the returned result.  If the  Metric  is  Euclidean()  then use the Euclidean distance of the full  D -dimensional points (distance  d_E d_E  in ref. [1]). If however the  Metric  is  Cityblock() , calculate the absolute distance of  only the first elements  of the  m+k  and  n+k  points of the reconstruction  R (distance  d_F d_F  in ref. [1]). Notice that the distances used are defined in the package  Distances.jl , but are re-exported here for ease-of-use.  This function assumes that the Theiler window (see [1]) is the same as the delay time,  w  = \\tau w  = \\tau .  References  [1] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 1 (section 1.3.2), Lecture Notes in Physics  915 , Springer (2016)  [2] : Kantz, H., Phys. Lett. A  185 , pp 77\u201387 (1994)  source   The function  numericallyapunov  has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.", 
            "title": "Numerical Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/nlts/#example-of-numerical-lyapunov-computation", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   #fake measurements for the win!  ks   =   1 : 20  \u211c   =   1 : 10000  fig   =   figure ( figsize = ( 10 , 6 ))  i   =   1  for   ( i ,   di )   in   enumerate ([ Euclidean (),   Cityblock ()]) \n   subplot ( 1 ,   2 ,   i ) \n   i += 1 \n   method   =   FixedMassNeighborhood ( 2 ) \n\n   title ( Distance:  $ ( di ) ,   size   =   18 ) \n   for   D   in   [ 2 ,   4 ,   7 ] \n     R   =   Reconstruction ( x ,   D ,   1 ) \n     E   =   numericallyapunov ( R ,   ks ; \n     refstates   =   \u211c ,   distance   =   di ,   method   =   method ) \n     # The following operation: \n     \u0394t   =   1 \n     \u03bb   =   linear_region ( ks .* \u0394t ,   E )[ 2 ] \n     # gives the linear slope, i.e. the Lyapunov exponent \n     plot ( ks - 1 ,   E - E [ 1 ],   label   =   D= $D , \u03bb= $ ( round ( \u03bb ,   3 )) ) \n     legend () \n     tight_layout () \n   end  end   which gives the result", 
            "title": "Example of Numerical Lyapunov computation"
        }, 
        {
            "location": "/chaos/nlts/#bad-time-axis-ks-length", 
            "text": "Large  ks  This simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!   Let's revisit the example of the previous section:  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   The timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following  ks   =   1 : 100  R   =   Reconstruction ( x ,   2 ,   1 )  E   =   numericallyapunov ( R ,   ks ,   method   =   FixedMassNeighborhood ( 2 ))  figure ()  plot ( ks - 1 ,   E - E [ 1 ])  println ( Lyappunov:  ,   linear_region ( ks ,   E )[ 2 ])   gives this plot:   and prints  Lyapunov :   0.4161 ...   Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function  linear_region  would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)", 
            "title": "Bad Time-axis (ks) length"
        }, 
        {
            "location": "/chaos/nlts/#case-of-a-continuous-system", 
            "text": "The process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . lorenz ()   # Max lyapunov is around 0.90  # create a timeseries of 1 dimension  dt   =   0.05  x   =   trajectory ( ds ,   1000.0 ;   dt   =   dt )[ : ,   1 ]  \u03c41   =   estimate_delay ( x )   #gives 7  # Reconstruct it  figure ()  for   D   in   [ 4 ,   8 ],   \u03c4   in   [ \u03c41 ,   15 ] \n     R   =   Reconstruction ( x ,   D ,   \u03c4 ) \n\n     # I now know that I have to use much bigger ks than 1:20, because this is a \n     # continuous case! (See reference given in `numericallyapunovs`) \n     ks1   =   0 : 200 \n     # I also know that I do not need that dense computations, since 1 increment \n     # in k means increment of 0.05 real time \n     ks2   =   0 : 4 : 200 \n\n     # Calculate lyapunovs: \n     method   =   FixedMassNeighborhood ( 5 )   #5 nearest neighbors of each state \n\n     # E1 = numericallyapunov(R, ks1; method = method) \n     # \u03bb1 = linear_region(ks1 .* dt, E1)[2] \n     E2   =   numericallyapunov ( R ,   ks2 ;   method   =   method ) \n     \u03bb2   =   linear_region ( ks2   .*   dt ,   E2 )[ 2 ] \n\n\n     # plot(ks1,E1.-E1[1], label =  dense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3)) ) \n     plot ( ks2 , E2 .- E2 [ 1 ],   label   =   D= $ ( D ) , \u03c4= $ ( \u03c4 ) , \u03bb= $ ( round ( \u03bb2 ,   3 )) )  end  legend ()  xlabel ( k (0.05\u00d7t) )  ylabel ( E - E(0) )  title ( Continuous Reconstruction Lyapunov )  tight_layout ()   which produces:   As you can see, using  \u03c4 = 15  makes almost no sense! The estimates with  \u03c4 = 7  though are very good (the actual value is around  \u03bb \u2248 0.89... ).", 
            "title": "Case of a Continuous system"
        }, 
        {
            "location": "/chaos/nlts/#broomhead-king-coordinates", 
            "text": "#  ChaosTools.broomhead_king     Function .  broomhead_king(x::AbstractVector, d::Int) -  U, S, Vtr  Return the Broomhead-King coordinates of a timeseries  x  by performing  svd  on the so-called trajectory matrix with dimension  d .  Description  Broomhead and King coordinates is a method proposed in [1] that applies the Karhunen\u2013Lo\u00e8ve theorem to delay coordinates embedding with smallest possible delay.  The function performs singular value decomposition on the  d -dimensional trajectory matrix  X X  of  x x ,   \nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1   x_2   \\ldots   x_d \\\\\nx_2   x_3   \\ldots   x_{d+1}\\\\\n\\vdots   \\vdots   \\vdots   \\vdots \\\\\nx_{N-d+1}   x_{N-d+2}  \\ldots   x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.  \nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 & x_2 & \\ldots & x_d \\\\\nx_2 & x_3 & \\ldots & x_{d+1}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nx_{N-d+1} & x_{N-d+2} &\\ldots & x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.   The columns of  U U  can then be used as a new coordinate system, and by considering the values of the singular values  S S  you can decide how many columns of  U U  are \"important\". See the documentation page for example application.  References  [1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A  20 , 9, pp L563 (1987)  source   This alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.  Take the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:  using   DynamicalSystems ,   PyPlot  using   Distributions   # for random numbers  ds   =   Systems . gissinger ()  data   =   trajectory ( ds ,   1000.0 )  x   =   data [ : ,   1 ]   L   =   length ( x )  distrib   =   Normal ( 0 ,   0.1 )  s   =   x   .+   rand ( distrib ,   L )  U ,   S   =   broomhead_king ( s ,   40 )  figure ( figsize =   ( 10 , 6 ))  subplot ( 1 , 2 , 1 )  plot ( U [ : ,   1 ],   U [ : ,   2 ])  title ( Broomhead-King of s )  subplot ( 1 , 2 , 2 )  R   =   Reconstruction ( s ,   2 ,   30 )  plot ( columns ( R ) ... ;   color   =   C3 )  title ( 2D Reconstruction of s )  tight_layout ()    we have used the same system as in the  delay coordinates reconstruction  example, and picked the optimal delay time of  \u03c4 = 30 . Regardless, the vanilla delay coordinates fail spectacularly when compared with the Broomhead-King coordinates.", 
            "title": "Broomhead-King Coordinates"
        }, 
        {
            "location": "/chaos/periodicity/", 
            "text": "Detecting Stable and Unstable Periodic Orbits of Maps\n\n\nChaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the \nperiodic orbits\n existing in the chaotic sea.\n\n\nFinding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher \n Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at \nunstable\n ones.\n\n\nThe functions \nperiodicorbits\n and \nlambdamatrix\n implement the algorithm:\n\n\n#\n\n\nChaosTools.periodicorbits\n \n \nFunction\n.\n\n\nperiodicorbits\n(\nds\n::\nDiscreteDS\n,\n \no\n,\n \nics\n \n[\n,\n \n\u03bb\ns\n,\n \nindss\n,\n \nsingss\n]\n \n;\n \nkwargs\n...)\n \n-\n \nFP\n\n\n\n\n\n\nFind stable and unstable fixed points \nFP\n of order \no\n for the map \nds\n using the algorithm due to Schmelcher \n Diakonos [1]. \nics\n is a collection of initial conditions (container of \nSVector\ns) to be evolved.\n\n\nOptional Arguments\n\n\nThe optional arguments \n\u03bbs, indss, singss\n \nmust be containers\n of appropriate values, besides \n\u03bbs\n which can also be a number. The elements of those containers are passed to: \nlambdamatrix(\u03bb, inds, sings)\n, which creates the appropriate \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrix (see \nlambdamatrix\n for more). If these arguments are not given, a random permutation will be chosen for them, with \n\u03bb=0.001\n.\n\n\nKeyword Arguments\n\n\n\n\nmaxiters::Int = 100000\n : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\n\n\ndisttol = 1e-10\n : Distance tolerance. If the 2-norm of a previous state with  the next one is \n\u2264 disttol\n then it has converged to a fixed point.\n\n\ninftol = 10.0\n : If a state reaches \nnorm(state) \u2265 inftol\n it is assumed that  it has escaped to infinity (and is thus abandoned).\n\n\nroundtol::Int = 4\n : The found fixed points are rounded  to \nroundtol\n digits before pushed into the list of returned fixed points \nFP\n,  \nif\n they are not already contained in \nFP\n.  This is done so that \nFP\n doesn't contain duplicate fixed points (notice  that this has nothing to do with \ndisttol\n). Turn this to \ntypemax(Int)\n  to get the full precision of the algorithm.\n\n\n\n\nDescription\n\n\nThe algorithm used can detect stable/unstable periodic orbits by turning stable/unstable fixed points of the original map \nds\n to dissipatively stable ones, through the transformation\n\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\nwith \nf\nf\n = \nds.eom\n. The index \nk\nk\n counts the various possible \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n.\n\n\nNote that algorithm is intented for \nunstable\n orbits, and thus there are cases where it may not work for stable orbits.\n\n\nPerformance Notes\n\n\nAll\n initial conditions are evolved for \nall\n \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n which can very quickly lead to long computation times.\n\n\nReferences\n\n\n[1] : P. Schmelcher \n F. K. Diakonos, Phys. Rev. Lett. \n78\n, pp 4733 (1997)\n\n\nsource\n\n\n#\n\n\nChaosTools.lambdamatrix\n \n \nFunction\n.\n\n\nlambdamatrix(\u03bb, inds::Vector{Int}, sings) -\n \u039bk\n\n\n\n\n\nReturn the matrix \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n used to create a new dynamical system with some unstable fixed points turned to stable in the function \nperiodicorbits\n.\n\n\nArguments\n\n\n\n\n\u03bb\n:Real\n : the multiplier of the \nC_k\nC_k\n matrix, with \n0\n\u03bb\n1\n.\n\n\ninds::Vector{Int}\n : The \ni\nth entry of this vector gives the \nrow\n of the nonzero element of the \ni\nth column of \nC_k\nC_k\n.\n\n\nsings::Vector{\n:Real}\n : The element of the \ni\nth column of \nC_k\nC_k\n is +1 if \nsigns[i] \n 0\n and -1 otherwise (\nsings\n can also be \nBool\n vector).\n\n\n\n\nCalling \nlambdamatrix(\u03bb, D::Int)\n creates a random \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n by randomly generating an \ninds\n and a \nsigns\n from all possible combinations. The \ncollections\n of all these combinations can be obtained from the function \nlambdaperms\n.\n\n\nDescription\n\n\nEach element of \ninds\n \nmust be unique\n such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.\n\n\nDeciding the appropriate values for \n\u03bb, inds, sings\n is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for \n\u03bb\n, one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.\n\n\nReferences\n\n\n[2] : D. Pingel \net al.\n, Phys. Rev. E \n62\n, pp 2119 (2000)\n\n\n[3] : F. K. Diakonos \net al.\n, Phys. Rev. Lett. \n81\n, pp 4349 (1998)\n\n\nsource\n\n\n#\n\n\nChaosTools.lambdaperms\n \n \nFunction\n.\n\n\nlambdaperms(D) -\n indperms, singperms\n\n\n\n\n\nReturn two collections that each contain all possible combinations of indices (total of \nD!\nD!\n) and signs (total of \n2^D\n2^D\n) for dimension \nD\n (see \nlambdamatrix\n).\n\n\nsource\n\n\n\n\n\n\nStandard Map example\n\n\nFor example, let's find the fixed points of the \nStandard Map\n of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the \nsigns\n but only one for the \ninds\n. We will also only use one \n\u03bb\n value, and a 21\u00d721 density of initial conditions:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\nxs\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \n21\n);\n \nys\n \n=\n \ncopy\n(\nxs\n)\n\n\nics\n \n=\n \n[\nSVector\n{\n2\n}(\nx\n,\ny\n)\n \nfor\n \nx\n \nin\n \nxs\n \nfor\n \ny\n \nin\n \nys\n]\n\n\n\n# All permutations of [\u00b11, \u00b11]:\n\n\nsingss\n \n=\n \nlambdaperms\n(\n2\n)[\n2\n]\n \n# second entry are the signs\n\n\n\n# I know from personal research I only need this `inds`:\n\n\nindss\n \n=\n \n[[\n1\n,\n2\n]]\n \n# \n- must be container of vectors!!!\n\n\n\n\u03bbs\n \n=\n \n0.005\n \n# \n- only this allowed to not be vector (could also be vector)\n\n\n\norders\n \n=\n \n[\n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n,\n \n8\n]\n\n\nALLFP\n \n=\n \nVector\n{\nSVector\n{\n2\n,\n \nFloat64\n}}[]\n\n\n\nttt\n \n=\n \ntime\n()\n\n\nfor\n \no\n \nin\n \norders\n\n    \nFP\n \n=\n \nperiodicorbits\n(\nds\n,\n \no\n,\n \nics\n,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n)\n\n    \npush!\n(\nALLFP\n,\n \nFP\n)\n\n\nend\n\n\nprintln\n(\nTotal time: \n$\n((\ntime\n()\n \n-\n \nttt\n)\n/\n60\n)\n mins.\n)\n\n\n# It takes a good 3-5 minutes to do all computations!\n\n\n\n\n# Create phase-space plot:\n\n\niters\n \n=\n \n1000\n\n\ndataset\n \n=\n \ntrajectory\n(\nds\n,\n \niters\n)\n\n\nfor\n \nx\n \nin\n \nxs\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\nx\n,\n \ny\n)\n\n        \nappend!\n(\ndataset\n,\n \ntrajectory\n(\nds\n,\n \niters\n))\n\n    \nend\n\n\nend\n\n\nm\n \n=\n \nMatrix\n(\ndataset\n)\n\n\nPyPlot\n.\nscatter\n(\nview\n(\nm\n,\n \n:\n,\n \n1\n),\n \nview\n(\nm\n,\n \n:\n,\n \n2\n),\n \ns\n=\n \n1\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nPyPlot\n.\nxlim\n(\nxs\n[\n1\n],\n \nxs\n[\nend\n])\n\n\nPyPlot\n.\nylim\n(\nys\n[\n1\n],\n \nys\n[\nend\n])\n\n\n\n# Plot fixed points:\n\n\nmarkers\n \n=\n \n[\nD\n,\n \n^\n,\n \ns\n,\n \np\n,\n \nh\n,\n \n8\n]\n\n\ncolors\n \n=\n \n[\nb\n,\n \ng\n,\n \nr\n,\n \nc\n,\n \nm\n,\n \ngrey\n]\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n6\n\n    \nFP\n \n=\n \nALLFP\n[\ni\n]\n\n    \no\n \n=\n \norders\n[\ni\n]\n\n    \nPyPlot\n.\nplot\n([\ns\n[\n1\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n \n[\ns\n[\n2\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n\n    \nmarker\n=\nmarkers\n[\ni\n],\n \ncolor\n \n=\n \ncolors\n[\ni\n],\n \nmarkersize\n=\n10.0\n \n+\n \n(\n8\n-\no\n),\n \nlinewidth\n=\n0.0\n,\n\n    \nlabel\n \n=\n \norder \n$o\n,\n \nmarkeredgecolor\n \n=\n \nyellow\n,\n \nmarkeredgewidth\n \n=\n \n0.5\n)\n\n\nend\n\n\nlegend\n(\nloc\n=\nupper right\n,\n \nframealpha\n=\n0.9\n)\n\n\nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n\nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\nAfter 3 to 5 minutes, you will get this plot: \n\n\nYou can confirm for yourself that this is correct, for many reasons:\n\n\n\n\nIt is the same \nfig. 12 of this publication\n.\n\n\nFixed points of order \nn\nn\n are also fixed points of order \n2n, 3n, 4n, ...\n2n, 3n, 4n, ...\n\n\nBesides fixed points of previous orders, \noriginal\n fixed points of order \nn\nn\n come in (possible multiples of) \n2n\n2n\n-sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/periodicity/#detecting-stable-and-unstable-periodic-orbits-of-maps", 
            "text": "Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the  periodic orbits  existing in the chaotic sea.  Finding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher   Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at  unstable  ones.  The functions  periodicorbits  and  lambdamatrix  implement the algorithm:  #  ChaosTools.periodicorbits     Function .  periodicorbits ( ds :: DiscreteDS ,   o ,   ics   [ ,   \u03bb s ,   indss ,   singss ]   ;   kwargs ...)   -   FP   Find stable and unstable fixed points  FP  of order  o  for the map  ds  using the algorithm due to Schmelcher   Diakonos [1].  ics  is a collection of initial conditions (container of  SVector s) to be evolved.  Optional Arguments  The optional arguments  \u03bbs, indss, singss   must be containers  of appropriate values, besides  \u03bbs  which can also be a number. The elements of those containers are passed to:  lambdamatrix(\u03bb, inds, sings) , which creates the appropriate  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrix (see  lambdamatrix  for more). If these arguments are not given, a random permutation will be chosen for them, with  \u03bb=0.001 .  Keyword Arguments   maxiters::Int = 100000  : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.  disttol = 1e-10  : Distance tolerance. If the 2-norm of a previous state with  the next one is  \u2264 disttol  then it has converged to a fixed point.  inftol = 10.0  : If a state reaches  norm(state) \u2265 inftol  it is assumed that  it has escaped to infinity (and is thus abandoned).  roundtol::Int = 4  : The found fixed points are rounded  to  roundtol  digits before pushed into the list of returned fixed points  FP ,   if  they are not already contained in  FP .  This is done so that  FP  doesn't contain duplicate fixed points (notice  that this has nothing to do with  disttol ). Turn this to  typemax(Int)   to get the full precision of the algorithm.   Description  The algorithm used can detect stable/unstable periodic orbits by turning stable/unstable fixed points of the original map  ds  to dissipatively stable ones, through the transformation   \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)  \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)   with  f f  =  ds.eom . The index  k k  counts the various possible  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k .  Note that algorithm is intented for  unstable  orbits, and thus there are cases where it may not work for stable orbits.  Performance Notes  All  initial conditions are evolved for  all   \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  which can very quickly lead to long computation times.  References  [1] : P. Schmelcher   F. K. Diakonos, Phys. Rev. Lett.  78 , pp 4733 (1997)  source  #  ChaosTools.lambdamatrix     Function .  lambdamatrix(\u03bb, inds::Vector{Int}, sings) -  \u039bk  Return the matrix  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  used to create a new dynamical system with some unstable fixed points turned to stable in the function  periodicorbits .  Arguments   \u03bb :Real  : the multiplier of the  C_k C_k  matrix, with  0 \u03bb 1 .  inds::Vector{Int}  : The  i th entry of this vector gives the  row  of the nonzero element of the  i th column of  C_k C_k .  sings::Vector{ :Real}  : The element of the  i th column of  C_k C_k  is +1 if  signs[i]   0  and -1 otherwise ( sings  can also be  Bool  vector).   Calling  lambdamatrix(\u03bb, D::Int)  creates a random  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  by randomly generating an  inds  and a  signs  from all possible combinations. The  collections  of all these combinations can be obtained from the function  lambdaperms .  Description  Each element of  inds   must be unique  such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.  Deciding the appropriate values for  \u03bb, inds, sings  is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for  \u03bb , one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.  References  [2] : D. Pingel  et al. , Phys. Rev. E  62 , pp 2119 (2000)  [3] : F. K. Diakonos  et al. , Phys. Rev. Lett.  81 , pp 4349 (1998)  source  #  ChaosTools.lambdaperms     Function .  lambdaperms(D) -  indperms, singperms  Return two collections that each contain all possible combinations of indices (total of  D! D! ) and signs (total of  2^D 2^D ) for dimension  D  (see  lambdamatrix ).  source", 
            "title": "Detecting Stable and Unstable Periodic Orbits of Maps"
        }, 
        {
            "location": "/chaos/periodicity/#standard-map-example", 
            "text": "For example, let's find the fixed points of the  Standard Map  of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the  signs  but only one for the  inds . We will also only use one  \u03bb  value, and a 21\u00d721 density of initial conditions:  using   DynamicalSystems ,   PyPlot ,   StaticArrays  ds   =   Systems . standardmap ()  xs   =   linspace ( 0 ,   2 \u03c0 ,   21 );   ys   =   copy ( xs )  ics   =   [ SVector { 2 }( x , y )   for   x   in   xs   for   y   in   ys ]  # All permutations of [\u00b11, \u00b11]:  singss   =   lambdaperms ( 2 )[ 2 ]   # second entry are the signs  # I know from personal research I only need this `inds`:  indss   =   [[ 1 , 2 ]]   #  - must be container of vectors!!!  \u03bbs   =   0.005   #  - only this allowed to not be vector (could also be vector)  orders   =   [ 2 ,   3 ,   4 ,   5 ,   6 ,   8 ]  ALLFP   =   Vector { SVector { 2 ,   Float64 }}[]  ttt   =   time ()  for   o   in   orders \n     FP   =   periodicorbits ( ds ,   o ,   ics ,   \u03bbs ,   indss ,   singss ) \n     push! ( ALLFP ,   FP )  end  println ( Total time:  $ (( time ()   -   ttt ) / 60 )  mins. )  # It takes a good 3-5 minutes to do all computations!  # Create phase-space plot:  iters   =   1000  dataset   =   trajectory ( ds ,   iters )  for   x   in   xs \n     for   y   in   ys \n         ds . state   =   SVector { 2 }( x ,   y ) \n         append! ( dataset ,   trajectory ( ds ,   iters )) \n     end  end  m   =   Matrix ( dataset )  PyPlot . scatter ( view ( m ,   : ,   1 ),   view ( m ,   : ,   2 ),   s =   1 ,   color   =   black )  PyPlot . xlim ( xs [ 1 ],   xs [ end ])  PyPlot . ylim ( ys [ 1 ],   ys [ end ])  # Plot fixed points:  markers   =   [ D ,   ^ ,   s ,   p ,   h ,   8 ]  colors   =   [ b ,   g ,   r ,   c ,   m ,   grey ]  for   i   in   1 : 6 \n     FP   =   ALLFP [ i ] \n     o   =   orders [ i ] \n     PyPlot . plot ([ s [ 1 ]   for   s   in   FP ],   [ s [ 2 ]   for   s   in   FP ], \n     marker = markers [ i ],   color   =   colors [ i ],   markersize = 10.0   +   ( 8 - o ),   linewidth = 0.0 , \n     label   =   order  $o ,   markeredgecolor   =   yellow ,   markeredgewidth   =   0.5 )  end  legend ( loc = upper right ,   framealpha = 0.9 )  xlabel ( \\$\\\\ theta \\$ )  ylabel ( \\$ p \\$ )   After 3 to 5 minutes, you will get this plot:   You can confirm for yourself that this is correct, for many reasons:   It is the same  fig. 12 of this publication .  Fixed points of order  n n  are also fixed points of order  2n, 3n, 4n, ... 2n, 3n, 4n, ...  Besides fixed points of previous orders,  original  fixed points of order  n n  come in (possible multiples of)  2n 2n -sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Standard Map example"
        }, 
        {
            "location": "/chaos/chaos_detection/", 
            "text": "Chaos Detection\n\n\nBeing able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum \nlyapunov\n exponent and a bounded system indicate chaos.\n\n\nHowever, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in DynamicalSystems.jl.\n\n\n\n\nGeneralized Alignment Index\n\n\n\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis \n Antonopoulos.\n\n\n#\n\n\nChaosTools.gali\n \n \nFunction\n.\n\n\ngali\n(\nds\n::\nDynamicalSystem\n,\n \nk\n::\nInt\n,\n \ntmax\n \n[\n,\n \nws\n]\n;\n \nkwargs\n...)\n \n-\n \nGALI_k\n,\n \nt\n\n\n\n\n\n\nCompute \n\\text{GALI}_k\n\\text{GALI}_k\n [1] for a given \nk\n up to time \ntmax\n. Return \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n and time vector \nt\nt\n.\n\n\nws\n is an optional argument containing the deviation vectors \nw_i\nw_i\n for \ni \\in [1,k]\ni \\in [1,k]\n, expected either as a matrix with each column a deviation vector, or as a vector of vectors. If not given, random orthonormal vectors are chosen.\n\n\nKeyword Arguments\n\n\n\n\nthreshold\n : If \nGALI_k\n falls below the \nthreshold\n iteration is terminated. Default value is \n1e-12\n.\n\n\ndt=1.0\n : Time step between variational vector normalizations for continuous systems.\n\n\ndiff_eq_kwargs\n : See \ntrajectory\n.\n\n\n\n\nDescription\n\n\nThe Generalized Alignment Index, \n\\text{GALI}_k\n\\text{GALI}_k\n, is an efficient (and very fast) indicator of chaotic or regular behavior type in \nD\nD\n-dimensional Hamiltonian systems (\nD\nD\n is number of variables). The \nasymptotic\n behavior of \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n depends critically of the type of orbit resulting from the initial condition \nstate(ds)\n. If it is a chaotic orbit, then\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\nwith \n\\lambda_1\n\\lambda_1\n being the maximum \nlyapunov\n exponent. If on the other hand the orbit is regular, corresponding to movement in \nd\nd\n-dimensional torus with \n1 \\le d \\le D/2\n1 \\le d \\le D/2\n then it holds\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, \n \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d \n 1 \\\\\n      t^{-(k - d)}, \n \\text{if} \\;\\;  d \n k \\le D - d \\\\\n      t^{-(2k - D)}, \n \\text{if} \\;\\;  D - d \n k \\le D\n    \\end{cases}\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}\n\n\n\n\n\nTraditionally, if \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n does not become less than the \nthreshold\n until \ntmax\n the given orbit is said to be chaotic, otherwise it is regular.\n\n\nThe entirety of our implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of \nA\nA\n, a matrix that has as \ncolumns\n the deviation vectors.\n\n\nPerformance Notes\n\n\nIf you want to do repeated evaluations of \ngali\n for many initial conditions and for continuous systems, you can take advantage of the function:\n\n\ngali(integrator, k, W, tmax, dt, threshold)\n\n\n\n\n\nin conjuction with \nreinit!(integrator, W)\n for various \nW=cat(2, state, ws)\n. See the source code on how to set-up the \nintegrator\n and \nW\n for the first time.\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, Physica D \n231\n, pp 30\u201354 (2007)\n\n\n[2] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\nsource\n\n\n\n\n\n\nDiscrete Example\n\n\nWe will use 3 coupled standard maps as an example for a discrete system:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n;\n \nfigure\n()\n\n\nM\n \n=\n \n3\n;\n \nks\n \n=\n \n3\nones\n(\nM\n);\n \n\u0393\n \n=\n \n0.1\n;\n\n\nstable\n \n=\n \n[\n\u03c0\n,\n \n\u03c0\n,\n \n\u03c0\n,\n \n0.01\n,\n \n0\n,\n \n0\n]\n \n.+\n \n0.1\n\n\nchaotic\n \n=\n \nrand\n(\n2\nM\n)\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nstable\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\n\nsubplot\n(\n2\n,\n2\n,\n1\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nstable\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n#\n\n\nsubplot\n(\n2\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n,\n \n5\n,\n \n6\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1e5\n;\n \nthreshold\n=\n1e-12\n)\n\n    \nlt\n \n=\n \nlog10\n.\n(\nt\n);\n \nlg\n \n=\n \nlog10\n.\n(\ng\n)\n\n\n    \nplot\n(\nlt\n,\n \nlg\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlt\n \n=\n \n2\n:\n0.5\n:\n5.5\n\n\nplot\n(\nlt\n,\n \nzeros\n(\nlt\n),\n \nlabel\n=\nconst\n)\n\n\nplot\n(\nlt\n,\n \n-\n2\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -2\n)\n\n\nplot\n(\nlt\n,\n \n-\n4\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -4\n)\n\n\nplot\n(\nlt\n,\n \n-\n6\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -6\n)\n\n\n\nxlim\n(\n2\n,\n \n5.5\n)\n\n\nylim\n(\n-\n12\n,\n \n1\n)\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nchaotic\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nsubplot\n(\n2\n,\n2\n,\n3\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nchaotic\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\n\nsubplot\n(\n2\n,\n2\n,\n4\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n100000\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n,\n5\n \n,\n6\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1000\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\nxlim\n(\n0\n,\n50\n)\n\n\nylim\n(\n1e-12\n,\n \n1\n)\n\n\n\n\n\n\n\n\n\n\nContinuous Example\n\n\nAs an example of a continuous system, let's see the \nhenonhelies\n:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\nfigure\n(\nfigsize\n=\n(\n10\n,\n \n12\n))\n\n\nsp\n \n=\n \n[\n0\n,\n \n.\n295456\n,\n \n.\n407308431\n,\n \n0\n]\n \n#stable periodic orbit: 1D torus\n\n\nqp\n \n=\n \n[\n0\n,\n \n.\n483000\n,\n \n.\n278980390\n,\n \n0\n]\n \n#quasiperiodic orbit: 2D torus\n\n\nch\n \n=\n \n[\n0\n,\n \n-\n0.25\n,\n \n0.42081\n,\n \n0\n]\n \n# chaotic orbit\n\n\ndt\n \n=\n \n1.0\n\n\n\nsubplot\n(\n3\n,\n2\n,\n1\n)\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n(\nsp\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nsp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n50000.0\n;\n \ndt\n \n=\n \ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n    \nif\n \nk\n \n \n4\n\n        \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\nk\n-\n1\n),\n \nlabel\n=\nslope -\n$\n(\nk\n-\n1\n)\n)\n\n    \nelse\n\n        \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nend\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\n\nsubplot\n(\n3\n,\n2\n,\n3\n)\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n(\nqp\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nqp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n4\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n10000.0\n;\n \ndt\n \n=\n \ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n    \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\nds\n \n=\n \nSystems\n.\nhenonhelies\n(\nch\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-6\n,\n \n:\nreltol\n=\n1e-6\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n50000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nsubplot\n(\n3\n,\n2\n,\n5\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nch\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n6\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n5000.0\n,\n \ndt\n=\ndt\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1000\n;\n \ndt\n \n=\n \ndt\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n As you can see, the results of both discrete and continuous match very well the theory described in \ngali\n.\n\n\n\n\nUsing GALI\n\n\nNo-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations.\n\n\nThe most common usage of \n\\text{GALI}_k\n\\text{GALI}_k\n is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether \n\\text{GALI}_k\n\\text{GALI}_k\n stays below it, for a (sufficiently) big \nk\nk\n.\n\n\nFor example one could do\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\n\nchaoticness\n(\nds\n)\n \n=\n \ngali\n(\nds\n,\n \n2\n,\n \n500.0\n)[\n2\n][\nend\n]\n\n\n\nfunction\n \nmain\n(\nk\n)\n\n\n    \ndens\n \n=\n \n201\n\n    \nchaoticity\n \n=\n \nzeros\n(\ndens\n,\ndens\n)\n\n    \n\u03b8s\n \n=\n \nps\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \ndens\n+\n1\n)\n\n    \nds\n \n=\n \nSystems\n.\nstandardmap\n(\nk\n \n=\n \nk\n)\n\n\n    \nfor\n \n(\ni\n,\n \n\u03b8\n)\n \n\u2208\n \nenumerate\n(\n\u03b8s\n[\n1\n:\ndens\n])\n\n        \nfor\n \n(\nj\n,\n \np\n)\n \n\u2208\n \nenumerate\n(\nps\n[\n1\n:\ndens\n])\n\n            \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\n\u03b8\n,\n \np\n)\n\n            \nchaoticity\n[\ni\n,\n \nj\n]\n \n=\n \nchaoticness\n(\nds\n)\n\n        \nend\n\n    \nend\n\n\n    \npcolormesh\n(\n\u03b8s\n \n.-\n \n(\n\u03b8s\n[\n2\n]\n \n-\n \n\u03b8s\n[\n1\n])\n/\n2\n,\n \nps\n \n.-\n \n(\nps\n[\n2\n]\n \n-\n \nps\n[\n1\n])\n/\n2\n,\n\n    \nchaoticity\n)\n\n    \ncolorbar\n()\n\n\n\nend\n\n\n\nmain\n(\n0.9\n)\n\n\n\n\n\n\nand after about two minutes you will get:", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#chaos-detection", 
            "text": "Being able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum  lyapunov  exponent and a bounded system indicate chaos.  However, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in DynamicalSystems.jl.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#generalized-alignment-index", 
            "text": "\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis   Antonopoulos.  #  ChaosTools.gali     Function .  gali ( ds :: DynamicalSystem ,   k :: Int ,   tmax   [ ,   ws ] ;   kwargs ...)   -   GALI_k ,   t   Compute  \\text{GALI}_k \\text{GALI}_k  [1] for a given  k  up to time  tmax . Return  \\text{GALI}_k(t) \\text{GALI}_k(t)  and time vector  t t .  ws  is an optional argument containing the deviation vectors  w_i w_i  for  i \\in [1,k] i \\in [1,k] , expected either as a matrix with each column a deviation vector, or as a vector of vectors. If not given, random orthonormal vectors are chosen.  Keyword Arguments   threshold  : If  GALI_k  falls below the  threshold  iteration is terminated. Default value is  1e-12 .  dt=1.0  : Time step between variational vector normalizations for continuous systems.  diff_eq_kwargs  : See  trajectory .   Description  The Generalized Alignment Index,  \\text{GALI}_k \\text{GALI}_k , is an efficient (and very fast) indicator of chaotic or regular behavior type in  D D -dimensional Hamiltonian systems ( D D  is number of variables). The  asymptotic  behavior of  \\text{GALI}_k(t) \\text{GALI}_k(t)  depends critically of the type of orbit resulting from the initial condition  state(ds) . If it is a chaotic orbit, then   \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]  \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]   with  \\lambda_1 \\lambda_1  being the maximum  lyapunov  exponent. If on the other hand the orbit is regular, corresponding to movement in  d d -dimensional torus with  1 \\le d \\le D/2 1 \\le d \\le D/2  then it holds   \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.},   \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d   1 \\\\\n      t^{-(k - d)},   \\text{if} \\;\\;  d   k \\le D - d \\\\\n      t^{-(2k - D)},   \\text{if} \\;\\;  D - d   k \\le D\n    \\end{cases}  \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}   Traditionally, if  \\text{GALI}_k(t) \\text{GALI}_k(t)  does not become less than the  threshold  until  tmax  the given orbit is said to be chaotic, otherwise it is regular.  The entirety of our implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of  A A , a matrix that has as  columns  the deviation vectors.  Performance Notes  If you want to do repeated evaluations of  gali  for many initial conditions and for continuous systems, you can take advantage of the function:  gali(integrator, k, W, tmax, dt, threshold)  in conjuction with  reinit!(integrator, W)  for various  W=cat(2, state, ws) . See the source code on how to set-up the  integrator  and  W  for the first time.  References  [1] : Skokos, C. H.  et al. , Physica D  231 , pp 30\u201354 (2007)  [2] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics  915 , Springer (2016)  source", 
            "title": "Generalized Alignment Index"
        }, 
        {
            "location": "/chaos/chaos_detection/#discrete-example", 
            "text": "We will use 3 coupled standard maps as an example for a discrete system:  using   DynamicalSystems  using   PyPlot ;   figure ()  M   =   3 ;   ks   =   3 ones ( M );   \u0393   =   0.1 ;  stable   =   [ \u03c0 ,   \u03c0 ,   \u03c0 ,   0.01 ,   0 ,   0 ]   .+   0.1  chaotic   =   rand ( 2 M )  ds   =   Systems . coupledstandardmaps ( M ,   stable ;   ks = ks ,   \u0393   =   \u0393 )  tr   =   trajectory ( ds ,   100000 )  subplot ( 2 , 2 , 1 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = stable , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  #  subplot ( 2 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ,   5 ,   6 ] \n     g ,   t   =   gali ( ds ,   k ,   1e5 ;   threshold = 1e-12 ) \n     lt   =   log10 . ( t );   lg   =   log10 . ( g ) \n\n     plot ( lt ,   lg ,   label = GALI_ $ ( k ) )  end  lt   =   2 : 0.5 : 5.5  plot ( lt ,   zeros ( lt ),   label = const )  plot ( lt ,   - 2 ( lt   -   3 ),   label = slope -2 )  plot ( lt ,   - 4 ( lt   -   3 ),   label = slope -4 )  plot ( lt ,   - 6 ( lt   -   3 ),   label = slope -6 )  xlim ( 2 ,   5.5 )  ylim ( - 12 ,   1 )  legend ( fontsize = 12 )  tight_layout ()  ds   =   Systems . coupledstandardmaps ( M ,   chaotic ;   ks = ks ,   \u0393   =   \u0393 )  tr   =   trajectory ( ds ,   100000 )  subplot ( 2 , 2 , 3 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = chaotic , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  subplot ( 2 , 2 , 4 )  ls   =   lyapunovs ( ds ,   100000 )  for   k   in   [ 2 , 3 , 4 , 5   , 6 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   k ,   1000 ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  xlim ( 0 , 50 )  ylim ( 1e-12 ,   1 )", 
            "title": "Discrete Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#continuous-example", 
            "text": "As an example of a continuous system, let's see the  henonhelies :  using   DynamicalSystems  using   PyPlot  figure ( figsize = ( 10 ,   12 ))  sp   =   [ 0 ,   . 295456 ,   . 407308431 ,   0 ]   #stable periodic orbit: 1D torus  qp   =   [ 0 ,   . 483000 ,   . 278980390 ,   0 ]   #quasiperiodic orbit: 2D torus  ch   =   [ 0 ,   - 0.25 ,   0.42081 ,   0 ]   # chaotic orbit  dt   =   1.0  subplot ( 3 , 2 , 1 )  ds   =   Systems . henonhelies ( sp )  diffeq   =   Dict ( : abstol = 1e-9 ,   : reltol = 1e-9 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   10000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = sp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   k ,   50000.0 ;   dt   =   dt ,   diff_eq_kwargs   =   diffeq ) \n     if   k     4 \n         loglog ( t ,   1. / t .^ ( k - 1 ),   label = slope - $ ( k - 1 ) ) \n     else \n         loglog ( t ,   1. / t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     end \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  subplot ( 3 , 2 , 3 )  ds   =   Systems . henonhelies ( qp )  diffeq   =   Dict ( : abstol = 1e-9 ,   : reltol = 1e-9 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   10000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = qp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 4 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   k ,   10000.0 ;   dt   =   dt ,   diff_eq_kwargs   =   diffeq ) \n     loglog ( t ,   1. / t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  tight_layout ()  ds   =   Systems . henonhelies ( ch )  diffeq   =   Dict ( : abstol = 1e-6 ,   : reltol = 1e-6 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   50000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  subplot ( 3 , 2 , 5 )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = ch , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 6 )  ls   =   lyapunovs ( ds ,   5000.0 ,   dt = dt )  for   k   in   [ 2 , 3 , 4 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   k ,   1000 ;   dt   =   dt ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  tight_layout ()    As you can see, the results of both discrete and continuous match very well the theory described in  gali .", 
            "title": "Continuous Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#using-gali", 
            "text": "No-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations.  The most common usage of  \\text{GALI}_k \\text{GALI}_k  is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether  \\text{GALI}_k \\text{GALI}_k  stays below it, for a (sufficiently) big  k k .  For example one could do  using   DynamicalSystems  using   PyPlot  chaoticness ( ds )   =   gali ( ds ,   2 ,   500.0 )[ 2 ][ end ]  function   main ( k ) \n\n     dens   =   201 \n     chaoticity   =   zeros ( dens , dens ) \n     \u03b8s   =   ps   =   linspace ( 0 ,   2 \u03c0 ,   dens + 1 ) \n     ds   =   Systems . standardmap ( k   =   k ) \n\n     for   ( i ,   \u03b8 )   \u2208   enumerate ( \u03b8s [ 1 : dens ]) \n         for   ( j ,   p )   \u2208   enumerate ( ps [ 1 : dens ]) \n             ds . state   =   SVector { 2 }( \u03b8 ,   p ) \n             chaoticity [ i ,   j ]   =   chaoticness ( ds ) \n         end \n     end \n\n     pcolormesh ( \u03b8s   .-   ( \u03b8s [ 2 ]   -   \u03b8s [ 1 ]) / 2 ,   ps   .-   ( ps [ 2 ]   -   ps [ 1 ]) / 2 , \n     chaoticity ) \n     colorbar ()  end  main ( 0.9 )   and after about two minutes you will get:", 
            "title": "Using GALI"
        }, 
        {
            "location": "/chaos/visualization/", 
            "text": "DynamicalSystems.jl\n offers some basic methods for visualizing chaotic systems in the form of the functions described in this documentation page.\n\n\nAll plotting is done through the \nPyPlot.jl\n package. However, this is not a dependency of DynamicalSystems.jl. Instead, all functions described here are brought into scope as soon as the user executes \nusing PyPlot\n, which works regardless if \nPyPlot\n module was loaded before or after \nDynamicalSystems\n. This is possible through the \nRequires.jl\n package.\n\n\nUse the help mode (press \n?\n and then the function name) to access the documentation strings for e.g. using keyword arguments.\n\n\n\n\nVisualization Library\n\n\n\n\nphasespace\n : Plots the phasespace of a 2D \nDiscreteDS\n.\n\n\nplot_linear_regions\n : Plots the results of \nlnear_regions\n.", 
            "title": "Visualization"
        }, 
        {
            "location": "/chaos/visualization/#visualization-library", 
            "text": "phasespace  : Plots the phasespace of a 2D  DiscreteDS .  plot_linear_regions  : Plots the results of  lnear_regions .", 
            "title": "Visualization Library"
        }, 
        {
            "location": "/contributors_guide/", 
            "text": "Contributor Guide\n\n\nYou can contribute to this package even if you not are very good with coding with Julia.\n\n\n\n\nReporting Bugs and other Issues\n\n\nThe easiest and most common way to improve this package is simply by \nusing it\n and reporting any unexpected behavior! You can use the \nDynamicalSystems.jl Issues\n page or, if you think it is something minor not worth opening an issue, just come over to our \ngitter chatroom\n and let us know what the problem is.\n\n\n\n\nContributing New Methods and Algorithms\n\n\nThe ultimate goal for DynamicalSystems.jl is to be a useful tool for scientists working on chaos, nonlinear dynamics and in general dynamical systems.\n\n\nFor such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!\n\n\nFor a something to be implemented in this package, the following steps have to happen:\n\n\n\n\nA suggestion that a method should be included\n has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.\n\n\nAn algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.\n\n\nThe source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the \nreliability of the implementation\n.\n\n\n\n\nIt is clear that one can contribute to \nDynamicalSystems.jl\n by contributing in steps (1) and (2). Neither of those require any hardcore coding knowledge with Julia.\n\n\nFor step (1), you can open a new issue at the \nDynamicalSystems.jl Issues\n page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features \nhere\n and see for yourself if you can contribute to some of them!\n\n\nIf you have any idea about how to improve this package please do not hesitate to \njoin our chatroom\n and share your ideas!\n\n\n\n\nExamples of new things you could contribute\n\n\n\n\nAny method that calculates a quantity that has been used in at least one scientific (and peer-reviewed) journal.\n\n\nAny kind of new \nType\n of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of \nDynamicalSystem\n. I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.\n\n\nAny kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the \nfamous_systems.jl\n file).\n\n\n\n\nNotice that the above are not conclusive, but only examples!\n\n\n\n\nHow you should contribute \ncode\n\n\nCode should be contributed to the appropriate repository, e.g. \nDynamicalSystemsBase.jl\n, \nChaosTools.jl\n etc.. Recall that the repository of DynamicalSystems.jl is mainly a documentation host.\n\n\n\n\nFor new methods and systems please follow the convention of the documentation strings (do e.g. \n?lyapunov\n to see how they are structured).\n\n\nHave enough comments in your code so that somebody that knows the method, can also understand the code immediately.\n\n\nAlways have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.\n\n\n\n\nWhen enhancing already existing code, make sure to:\n\n\n\n\nHave enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributor-guide", 
            "text": "You can contribute to this package even if you not are very good with coding with Julia.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#reporting-bugs-and-other-issues", 
            "text": "The easiest and most common way to improve this package is simply by  using it  and reporting any unexpected behavior! You can use the  DynamicalSystems.jl Issues  page or, if you think it is something minor not worth opening an issue, just come over to our  gitter chatroom  and let us know what the problem is.", 
            "title": "Reporting Bugs and other Issues"
        }, 
        {
            "location": "/contributors_guide/#contributing-new-methods-and-algorithms", 
            "text": "The ultimate goal for DynamicalSystems.jl is to be a useful tool for scientists working on chaos, nonlinear dynamics and in general dynamical systems.  For such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!  For a something to be implemented in this package, the following steps have to happen:   A suggestion that a method should be included  has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.  An algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.  The source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the  reliability of the implementation .   It is clear that one can contribute to  DynamicalSystems.jl  by contributing in steps (1) and (2). Neither of those require any hardcore coding knowledge with Julia.  For step (1), you can open a new issue at the  DynamicalSystems.jl Issues  page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features  here  and see for yourself if you can contribute to some of them!  If you have any idea about how to improve this package please do not hesitate to  join our chatroom  and share your ideas!", 
            "title": "Contributing New Methods and Algorithms"
        }, 
        {
            "location": "/contributors_guide/#examples-of-new-things-you-could-contribute", 
            "text": "Any method that calculates a quantity that has been used in at least one scientific (and peer-reviewed) journal.  Any kind of new  Type  of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of  DynamicalSystem . I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.  Any kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the  famous_systems.jl  file).   Notice that the above are not conclusive, but only examples!", 
            "title": "Examples of new things you could contribute"
        }, 
        {
            "location": "/contributors_guide/#how-you-should-contribute-code", 
            "text": "Code should be contributed to the appropriate repository, e.g.  DynamicalSystemsBase.jl ,  ChaosTools.jl  etc.. Recall that the repository of DynamicalSystems.jl is mainly a documentation host.   For new methods and systems please follow the convention of the documentation strings (do e.g.  ?lyapunov  to see how they are structured).  Have enough comments in your code so that somebody that knows the method, can also understand the code immediately.  Always have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.   When enhancing already existing code, make sure to:   Have enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "How you should contribute code"
        }
    ]
}