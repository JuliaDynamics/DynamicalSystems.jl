{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nDynamicalSystems.jl\n is a Julia software library for the exploration of chaos and nonlinear dynamics.\n\n\n\n\nJuliaDynamics\n\n\nDynamicalSystems.jl\n is part of \nJuliaDynamics\n, check out our \nwebsite\n for more cool stuff!\n\n\n\n\nThe documentation you are reading now was built with the following stable versions:\n\n\n * DelayEmbeddings ........... 1.0.3\n * RecurrenceAnalysis ........ 1.0.2\n * DynamicalSystemsBase ...... 1.2.5\n * ChaosTools ................ 1.5.0\n * InteractiveChaos .......... 0.3.2\n\n\n\n\n\nSee the \nNews\n page for recent updates!\n\n\n\n\nIntroductory textbooks\n\n\nOur library assumes some basic knowledge of nonlinear dynamics and complex systems.\n\n\nIf you are new to the field but want to learn more, we can suggest the following textbooks as introductions:\n\n\n\n\nNonlinear Dynamics And Chaos - S. Strogatz\n\n\nAn Exploration of Dynamical Systems and Chaos - J. Argyris \net al.\n\n\nChaos in Dynamical Systems - E. Ott\n\n\n\n\n\n\n\n\nJupyter Notebooks / Tutorials\n\n\nIn this repository\n you can find various Jupyter notebooks that have been used as introductory tutorials for \nDynamicalSystems.jl\n!\n\n\n\n\n\n\nYouTube tutorial\n\n\nYou can find a tutorial on \nDynamicalSystems.jl\n hosted on the official YouTube channel of the Julia language:\n\n\n\n\n\n\n\nContents\n\n\nThe \nmodule\n \nDynamicalSystems\n re-exports all following functionality, grouped into different packages.\n\n\n\n\nDynamicalSystemsBase\n\n\n\n\n\n\nIntuitive, consistent APIs for the definition of general \ndynamical systems\n, under a unified struct \nDynamicalSystem\n. The following combinations are possible:\n\n\n\n\nContinuous or Discrete systems. Continuous systems use \nDifferentialEquations.jl\n for solving the ODE problem.\n\n\nIn-place or out-of-place (large versus small systems).\n\n\nAuto-differentiated or not (for the Jacobian function).\n\n\n\n\n\n\n\n\nAutomatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\n\n\n\n\nRobust implementations of all kinds of integrators, that evolve the system, many states of the system, or even deviation vectors. See the \nadvanced documentation\n for this.\n\n\nLibrary of \npredefined well-known dynamical systems\n that have been used extensively in scientific research.\n\n\n\n\n\n\nDelayEmbeddings\n\n\nIs a package for performing delay coordinate embeddings and finding optimal parameters for doing so.\n\n\n\n\nUnified \n dedicated interface for \nnumerical data\n: \nDataset\n.\n\n\nSimple and extendable \nneighborhood\n estimation by interfacing \nNearestNeighbors\n.\n\n\n\n\nFlexible and abstracted \nreconstruct\n interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.\n\n\n\n\nSupports multiple dimensions and multiple timescales.\n\n\nMethods that estimate optimal embedding parameters: the delay time (\nestimate_delay\n) and the number of temporal neighbors  (\nestimate_dimension\n).\n\n\nFast calculation of mutual information: \nmutualinformation\n.\n\n\n\n\n\n\n\n\n\n\nChaosTools\n\n\nIs a package that has many algorithms for chaotic dynamical systems. All algorithms are independent of each other but they are also not expansive enough to be a standalone package.\n\n\nPlease see the \noverview section\n for a full list of features. Here is a quick summary:\n\n\n\n\nPoincare S.O.S. and orbit diagrams\n\n\nLyapunov Exponents\n\n\nEntropies and Dimensions\n\n\nLyapunov exponent of a timeseries (numerical data)\n\n\nFinding Fixed Points of Maps\n\n\nGALI (Generalized Alignment Index) for distinguishing chaotic and regular behavior\n\n\nNonlinear timeseries analysis\n\n\n\n\n\n\nRecurrenceAnalysis\n\n\nRecurrenceAnalysis\n offers tools to compute and analyze \nRecurrence Plots\n, a field called \nRecurrence Quantification Analysis\n.\n\n\n\n\nRecurrence, cross-recurrence and joint-recurrence \"plots\" (they are matrices)\n.\n\n\n\n\nRecurrence quantification analysis\n (RQA):\n\n\n\n\nRecurrence rate, determinism, average/maximum diagonal length, divergence, laminarity, trend, entropy, trapping time, average/maximum vertical length.\n\n\nFine-tuning of the algorithms that compute the above (e.g. Theiler window and many more)\n\n\nWindowed versions\n of the above\n\n\n\n\n\n\n\n\n\n\nInteractiveChaos\n\n\nInteractiveChaos\n is a package that provides applications for interactively exploring dynamical systems. It is an \nextension\n of \nDynamicalSystems.jl\n and builds upon existing code by hooking up to the \nDynamicalSystem\n structure.\n\n\nInteractiveChaos\n \nis not installed with DynamicalSystems.jl\n. To install it do \n]add InteractiveChaos Makie\n. \nMakie\n is necessary for providing a plotting backend, since \nInteractiveChaos\n does not install one by default.\n\n\nThe functionality of \nInteractiveChaos\n is contained within individual functions, all of which launch a dedicated interactive application. Here is their list:\n\n\n\n\ninteractive_orbitdiagram\n\n\ninteractive_poincaresos\n\n\ntrajectory_highlighter\n\n\n\n\n\n\nVideos \n Animations\n\n\nBesides the documentation strings, each interactive function is accompanied with an animation (\n.gif\n or \n.mp4\n file) displayed after the docstring, as well as a video tutorial demonstrating its use. See the individual pages for the video links (by clicking the documentation string links)!\n\n\n\n\n\n\nOur Goals\n\n\nThe ultimate goal for \nDynamicalSystems.jl\n is to be a useful \nsoftware library\n for students and scientists working on chaos, nonlinear dynamics and in general dynamical systems. The word \"library\" is intended in the literal sense: a place where people go to learn things.\n\n\nWith \nDynamicalSystems.jl\n we try to\n\n\n\n\nBe concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the \nLorenz attractor\n, or a high dimensional discrete map like \ncoupled standard maps\n.\n\n\nBe accurate, reliable and performant.\n\n\nBe transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.\n\n\n\n\n\n\nInstallation\n\n\nSimply use \n]add DynamicalSystems\n to install everything. Alternatively you can also do \nusing Pkg; Pkg.add(\"DynamicalSystems\")\n.\n\n\n\n\nFor more advanced users, you can choose which packages to install and use at a high level. The \npackage\n \nDynamicalSystems\n serves two purposes: it re-exports everything under a single module \nDynamicalSystems\n and it also builds the documentation.\n\n\nAll packages depend on \nDelayEmbeddings\n which defines core numeric data structures and methods. For example \nRecurrenceAnalysis\n and \nTimeseriesPrediction\n depend only on \nDelayEmbeddings\n. Packages that require equations of motion also depend on \nDynamicalSystemsBase\n, like for example \nChaosTools\n.\n\n\nIf you only need functionality of a specific package you can install only that one, e.g. \n]add RecurrenceAnalysis\n and only the minimum amount of requirements will be installed.\n\n\n\n\nCiting\n\n\nThere is a (very small) paper associated with \nDynamicalSystems.jl\n. If we have helped you in research that led to a publication, please be kind enough to cite it, using the DOI \n10.21105/joss.00598\n or the following BiBTeX entry:\n\n\n@article{Datseris2018,\n  doi = {10.21105/joss.00598},\n  url = {https://doi.org/10.21105/joss.00598},\n  year  = {2018},\n  month = {mar},\n  volume = {3},\n  number = {23},\n  pages = {598},\n  author = {George Datseris},\n  title = {DynamicalSystems.jl: A Julia software library for chaos and nonlinear dynamics},\n  journal = {Journal of Open Source Software}\n}\n\n\n\n\n\n\n\nIssues with Bounties\n\n\nMoney that \nDynamicalSystems.jl\n obtains from awards, sponsors or donators are converted into bounties for GitHub issues. The full list of issues that have a bounty is \navailable here\n.\n\n\nBy solving these issues you not only contribute to open source, but you also get some pocket money to boot :)\n\n\n\n\nContacting\n\n\nYou can \njoin our chatroom\n for discussions and/or questions about the packages of the JuliaDynamics organization! If you are using the Julia Slack workplace, please join the channel \n#dynamics-bridged\n.\n\n\n\n\nContributing \n Donating\n\n\nBe sure to visit the \nContributor Guide\n page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on \nGitHub\n! This gives us an accurate lower bound of users that this package has already helped!\n\n\nFinally, you can donate for the development of \nDynamicalSystems.jl\n. You can do that by adding bounties to existing issues on the GitHub repositories (you can open new issues as well). Every issue has an automatic way to create a bounty using \nBountysource\n, see the first comment of each issue.", 
            "title": "Introduction & Contents"
        }, 
        {
            "location": "/#introduction", 
            "text": "DynamicalSystems.jl  is a Julia software library for the exploration of chaos and nonlinear dynamics.   JuliaDynamics  DynamicalSystems.jl  is part of  JuliaDynamics , check out our  website  for more cool stuff!   The documentation you are reading now was built with the following stable versions:   * DelayEmbeddings ........... 1.0.3\n * RecurrenceAnalysis ........ 1.0.2\n * DynamicalSystemsBase ...... 1.2.5\n * ChaosTools ................ 1.5.0\n * InteractiveChaos .......... 0.3.2  See the  News  page for recent updates!   Introductory textbooks  Our library assumes some basic knowledge of nonlinear dynamics and complex systems.  If you are new to the field but want to learn more, we can suggest the following textbooks as introductions:   Nonlinear Dynamics And Chaos - S. Strogatz  An Exploration of Dynamical Systems and Chaos - J. Argyris  et al.  Chaos in Dynamical Systems - E. Ott     Jupyter Notebooks / Tutorials  In this repository  you can find various Jupyter notebooks that have been used as introductory tutorials for  DynamicalSystems.jl !", 
            "title": "Introduction"
        }, 
        {
            "location": "/#youtube-tutorial", 
            "text": "You can find a tutorial on  DynamicalSystems.jl  hosted on the official YouTube channel of the Julia language:", 
            "title": "YouTube tutorial"
        }, 
        {
            "location": "/#contents", 
            "text": "The  module   DynamicalSystems  re-exports all following functionality, grouped into different packages.", 
            "title": "Contents"
        }, 
        {
            "location": "/#dynamicalsystemsbase", 
            "text": "Intuitive, consistent APIs for the definition of general  dynamical systems , under a unified struct  DynamicalSystem . The following combinations are possible:   Continuous or Discrete systems. Continuous systems use  DifferentialEquations.jl  for solving the ODE problem.  In-place or out-of-place (large versus small systems).  Auto-differentiated or not (for the Jacobian function).     Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.   Robust implementations of all kinds of integrators, that evolve the system, many states of the system, or even deviation vectors. See the  advanced documentation  for this.  Library of  predefined well-known dynamical systems  that have been used extensively in scientific research.", 
            "title": "DynamicalSystemsBase"
        }, 
        {
            "location": "/#delayembeddings", 
            "text": "Is a package for performing delay coordinate embeddings and finding optimal parameters for doing so.   Unified   dedicated interface for  numerical data :  Dataset .  Simple and extendable  neighborhood  estimation by interfacing  NearestNeighbors .   Flexible and abstracted  reconstruct  interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.   Supports multiple dimensions and multiple timescales.  Methods that estimate optimal embedding parameters: the delay time ( estimate_delay ) and the number of temporal neighbors  ( estimate_dimension ).  Fast calculation of mutual information:  mutualinformation .", 
            "title": "DelayEmbeddings"
        }, 
        {
            "location": "/#chaostools", 
            "text": "Is a package that has many algorithms for chaotic dynamical systems. All algorithms are independent of each other but they are also not expansive enough to be a standalone package.  Please see the  overview section  for a full list of features. Here is a quick summary:   Poincare S.O.S. and orbit diagrams  Lyapunov Exponents  Entropies and Dimensions  Lyapunov exponent of a timeseries (numerical data)  Finding Fixed Points of Maps  GALI (Generalized Alignment Index) for distinguishing chaotic and regular behavior  Nonlinear timeseries analysis", 
            "title": "ChaosTools"
        }, 
        {
            "location": "/#recurrenceanalysis", 
            "text": "RecurrenceAnalysis  offers tools to compute and analyze  Recurrence Plots , a field called  Recurrence Quantification Analysis .   Recurrence, cross-recurrence and joint-recurrence \"plots\" (they are matrices) .   Recurrence quantification analysis  (RQA):   Recurrence rate, determinism, average/maximum diagonal length, divergence, laminarity, trend, entropy, trapping time, average/maximum vertical length.  Fine-tuning of the algorithms that compute the above (e.g. Theiler window and many more)  Windowed versions  of the above", 
            "title": "RecurrenceAnalysis"
        }, 
        {
            "location": "/#interactivechaos", 
            "text": "InteractiveChaos  is a package that provides applications for interactively exploring dynamical systems. It is an  extension  of  DynamicalSystems.jl  and builds upon existing code by hooking up to the  DynamicalSystem  structure.  InteractiveChaos   is not installed with DynamicalSystems.jl . To install it do  ]add InteractiveChaos Makie .  Makie  is necessary for providing a plotting backend, since  InteractiveChaos  does not install one by default.  The functionality of  InteractiveChaos  is contained within individual functions, all of which launch a dedicated interactive application. Here is their list:   interactive_orbitdiagram  interactive_poincaresos  trajectory_highlighter    Videos   Animations  Besides the documentation strings, each interactive function is accompanied with an animation ( .gif  or  .mp4  file) displayed after the docstring, as well as a video tutorial demonstrating its use. See the individual pages for the video links (by clicking the documentation string links)!", 
            "title": "InteractiveChaos"
        }, 
        {
            "location": "/#our-goals", 
            "text": "The ultimate goal for  DynamicalSystems.jl  is to be a useful  software library  for students and scientists working on chaos, nonlinear dynamics and in general dynamical systems. The word \"library\" is intended in the literal sense: a place where people go to learn things.  With  DynamicalSystems.jl  we try to   Be concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the  Lorenz attractor , or a high dimensional discrete map like  coupled standard maps .  Be accurate, reliable and performant.  Be transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.", 
            "title": "Our Goals"
        }, 
        {
            "location": "/#installation", 
            "text": "Simply use  ]add DynamicalSystems  to install everything. Alternatively you can also do  using Pkg; Pkg.add(\"DynamicalSystems\") .   For more advanced users, you can choose which packages to install and use at a high level. The  package   DynamicalSystems  serves two purposes: it re-exports everything under a single module  DynamicalSystems  and it also builds the documentation.  All packages depend on  DelayEmbeddings  which defines core numeric data structures and methods. For example  RecurrenceAnalysis  and  TimeseriesPrediction  depend only on  DelayEmbeddings . Packages that require equations of motion also depend on  DynamicalSystemsBase , like for example  ChaosTools .  If you only need functionality of a specific package you can install only that one, e.g.  ]add RecurrenceAnalysis  and only the minimum amount of requirements will be installed.", 
            "title": "Installation"
        }, 
        {
            "location": "/#citing", 
            "text": "There is a (very small) paper associated with  DynamicalSystems.jl . If we have helped you in research that led to a publication, please be kind enough to cite it, using the DOI  10.21105/joss.00598  or the following BiBTeX entry:  @article{Datseris2018,\n  doi = {10.21105/joss.00598},\n  url = {https://doi.org/10.21105/joss.00598},\n  year  = {2018},\n  month = {mar},\n  volume = {3},\n  number = {23},\n  pages = {598},\n  author = {George Datseris},\n  title = {DynamicalSystems.jl: A Julia software library for chaos and nonlinear dynamics},\n  journal = {Journal of Open Source Software}\n}", 
            "title": "Citing"
        }, 
        {
            "location": "/#issues-with-bounties", 
            "text": "Money that  DynamicalSystems.jl  obtains from awards, sponsors or donators are converted into bounties for GitHub issues. The full list of issues that have a bounty is  available here .  By solving these issues you not only contribute to open source, but you also get some pocket money to boot :)", 
            "title": "Issues with Bounties"
        }, 
        {
            "location": "/#contacting", 
            "text": "You can  join our chatroom  for discussions and/or questions about the packages of the JuliaDynamics organization! If you are using the Julia Slack workplace, please join the channel  #dynamics-bridged .", 
            "title": "Contacting"
        }, 
        {
            "location": "/#contributing-donating", 
            "text": "Be sure to visit the  Contributor Guide  page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on  GitHub ! This gives us an accurate lower bound of users that this package has already helped!  Finally, you can donate for the development of  DynamicalSystems.jl . You can do that by adding bounties to existing issues on the GitHub repositories (you can open new issues as well). Every issue has an automatic way to create a bounty using  Bountysource , see the first comment of each issue.", 
            "title": "Contributing &amp; Donating"
        }, 
        {
            "location": "/ds/general/", 
            "text": "Dynamical Systems\n\n\nCurrently a system in \nDynamicalSystems.jl\n can be either continuous\n\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, p, t),\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, p, t),\n\n\n\n\n\nor discrete\n\n\n\n\n\n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, p, n)\n\n\n\n\n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, p, n)\n\n\n\n\n\nwhere \np\np\n contains the parameters of the system. In addition to the above equations of motion, information about the Jacobian of the system is also part of a \"dynamical system\".\n\n\nKeep in mind that almost all functions of \nDynamicalSystems.jl\n assume that \n\\vec{f}\n\\vec{f}\n is differentiable!\n\n\n\n\nCreating a Dynamical System\n\n\n#\n\n\nDynamicalSystemsBase.DynamicalSystem\n \n \nType\n.\n\n\nDynamicalSystem\n\n\n\n\n\n\nThe central structure of \nDynamicalSystems.jl\n. All functions of the suite that can use known equations of motion expect an instance of this type.\n\n\nConstructing a \nDynamicalSystem\n\n\nDiscreteDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n::\nInt\n \n=\n \n0\n)\n\n\nContinuousDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n \n=\n \n0.0\n)\n\n\n\n\n\n\nwith \neom\n the equations of motion function (see below). \np\n is a parameter container, which we highly suggest to use a mutable object like \nArray\n, \nLMArray\n or a dictionary. Pass \nnothing\n in the place of \np\n if your system does not have parameters.\n\n\nt0\n, \nJ0\n allow you to choose the initial time and provide an initialized Jacobian matrix. See \nCDS_KWARGS\n for the default options used to evolve continuous systems (through \nOrdinaryDiffEq\n).\n\n\nEquations of motion\n\n\nThe are two \"versions\" for \nDynamicalSystem\n, depending on whether the equations of motion (\neom\n) are in-place (iip) or out-of-place (oop). Here is how to define them:\n\n\n\n\noop\n : The \neom\n \nmust\n be in the form \neom(x, p, t) -\n SVector\n which means that given a state \nx::SVector\n and some parameter container \np\n it returns an \nSVector\n (from the \nStaticArrays\n module) containing the next state.\n\n\niip\n : The \neom\n \nmust\n be in the form \neom!(xnew, x, p, t)\n which means that given a state \nx::Vector\n and some parameter container \np\n, it writes in-place the new state in \nxnew\n.\n\n\n\n\nt\n stands for time (integer for discrete systems). iip is suggested for big systems, whereas oop is suggested for small systems. The break-even point at around 100 dimensions, and for using functions that use the tangent space (like e.g. \nlyapunovs\n or \ngali\n), the break-even point is at around 10 dimensions.\n\n\nThe constructor deduces automatically whether \neom\n is iip or oop. It is not possible however to deduce whether the system is continuous or discrete just from the equations of motion, hence the 2 constructors.\n\n\nJacobian\n\n\nThe optional argument \njacobian\n for the constructors is a \nfunction\n and (if given) must also be of the same form as the \neom\n, \njacobian(x, p, n) -\n SMatrix\n for the out-of-place version and \njacobian!(xnew, x, p, n)\n for the in-place version.\n\n\nIf \njacobian\n is not given, it is constructed automatically using the module \nForwardDiff\n. It is \nheavily\n advised to provide a Jacobian function, as it gives \nmultiple\n orders of magnitude speedup.\n\n\nInterface to DifferentialEquations.jl\n\n\nContinuous systems are solved using \nDifferentialEquations.jl\n. The following two interfaces are provided:\n\n\nContinuousDynamicalSystem(prob::ODEProblem [, jacobian [, J0]])\nODEProblem(continuous_dynamical_system, tspan, args...)\n\n\n\n\n\nwhere in the second case \nargs\n stands for the \nstandard extra arguments\n of \nODEProblem\n: \ncallback, mass_matrix\n.\n\n\nIf you want to use callbacks with \ntangent_integrator\n or \nparallel_integrator\n, then invoke them with extra arguments as shown in the \nAdvanced Documentation\n.\n\n\nRelevant Functions\n\n\ntrajectory\n, \nset_parameter!\n.\n\n\n\n\n\n\nDefinition Table\n\n\nHere is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:\n\n\n\n\n\n\n\n\nSystem Type\n\n\nequations of motion\n\n\nJacobian\n\n\n\n\n\n\n\n\n\n\nin-place (big systems)\n\n\neom!(du, u, p, t)\n\n\njacobian!(J, u, p, t)\n\n\n\n\n\n\nout-of-place (small systems)\n\n\neom(u, p, t) -\n SVector\n\n\njacobian(u, p, t) -\n SMatrix\n\n\n\n\n\n\n\n\n\n\nUse mutable containers for the parameters\n\n\nIt is highly suggested to use a subtype of \nArray\n,  \nLMArray\n or a dictionary for the container of the model's parameters. Some functions offered by \nDynamicalSystems.jl\n, like e.g. \norbitdiagram\n, assume that the parameters can be first accessed by \np[x]\n with \nx\n some qualifier as well as that this value can be set by \np[x] = newvalue\n.\n\n\nThe \nLabelled Arrays\n package offers \nArray\n implementations that can be accessed both by index as well as by some name.\n\n\n\n\n\n\nGeneral Functions\n\n\nThe following functions are defined for convenience for any dynamical system:\n\n\n#\n\n\nDynamicalSystemsBase.dimension\n \n \nFunction\n.\n\n\ndimension\n(\nthing\n)\n \n-\n \nD\n\n\n\n\n\n\nReturn the dimension of the \nthing\n, in the sense of state-space dimensionality.\n\n\n#\n\n\nDynamicalSystemsBase.jacobian\n \n \nFunction\n.\n\n\njacobian\n(\nds\n::\nDynamicalSystem\n,\n \nu\n \n=\n \nds\n.\nu0\n,\n \nt\n \n=\n \nds\n.\nt0\n)\n\n\n\n\n\n\nReturn the jacobian of the system at \nu\n, at \nt\n.\n\n\n#\n\n\nDynamicalSystemsBase.set_parameter!\n \n \nFunction\n.\n\n\nset_parameter!\n(\nds\n::\nDynamicalSystem\n,\n \nindex\n,\n \nvalue\n)\n\n\nset_parameter!\n(\nds\n::\nDynamicalSystem\n,\n \nvalues\n)\n\n\n\n\n\n\nChange one or many parameters of the system by setting \np[index] = value\n in the first case and \np .= values\n in the second.\n\n\nThe same function also works for any integrator.\n\n\n\n\nExamples\n\n\n\n\nContinuous, out-of-place\n\n\nLet's see an example for a small system, which is a case where out-of-place equations of motion are preferred.\n\n\nusing\n \nDynamicalSystems\n \n# also exports relevant StaticArrays names\n\n\n# Lorenz system\n\n\n# Equations of motion:\n\n\n@inline\n \n@inbounds\n \nfunction\n \nloop\n(\nu\n,\n \np\n,\n \nt\n)\n\n    \n\u03c3\n \n=\n \np\n[\n1\n];\n \n\u03c1\n \n=\n \np\n[\n2\n];\n \n\u03b2\n \n=\n \np\n[\n3\n]\n\n    \ndu1\n \n=\n \n\u03c3\n*\n(\nu\n[\n2\n]\n-\nu\n[\n1\n])\n\n    \ndu2\n \n=\n \nu\n[\n1\n]\n*\n(\n\u03c1\n-\nu\n[\n3\n])\n \n-\n \nu\n[\n2\n]\n\n    \ndu3\n \n=\n \nu\n[\n1\n]\n*\nu\n[\n2\n]\n \n-\n \n\u03b2\n*\nu\n[\n3\n]\n\n    \nreturn\n \nSVector\n{\n3\n}(\ndu1\n,\n \ndu2\n,\n \ndu3\n)\n\n\nend\n\n\n# Jacobian:\n\n\n@inline\n \n@inbounds\n \nfunction\n \nloop_jac\n(\nu\n,\n \np\n,\n \nt\n)\n\n    \n\u03c3\n,\n \n\u03c1\n,\n \n\u03b2\n \n=\n \np\n\n    \nJ\n \n=\n \n@SMatrix\n \n[\n-\n\u03c3\n  \n\u03c3\n  \n0\n;\n\n    \n\u03c1\n \n-\n \nu\n[\n3\n]\n  \n(\n-\n1\n)\n  \n(\n-\nu\n[\n1\n]);\n\n    \nu\n[\n2\n]\n   \nu\n[\n1\n]\n  \n-\n\u03b2\n]\n\n    \nreturn\n \nJ\n\n\nend\n\n\n\nds\n \n=\n \nContinuousDynamicalSystem\n(\nloop\n,\n \nrand\n(\n3\n),\n \n[\n10.0\n,\n \n28.0\n,\n \n8\n/\n3\n],\n \nloop_jac\n)\n\n\n\n\n\n\n3-dimensional continuous dynamical system\n state:     [0.068248, 0.828095, 0.0743729]\n e.o.m.:    loop\n in-place?  false\n jacobian:  loop_jac\n\n\n\n\n\n\n\nDiscrete, in-place\n\n\nThe following example is only 2-dimensional, and thus once again it is \"correct\" to use out-of-place version with \nSVector\n. For the sake of example though, we use the in-place version.\n\n\n# Henon map.\n\n\n# equations of motion:\n\n\nfunction\n \nhiip\n(\ndx\n,\n \nx\n,\n \np\n,\n \nn\n)\n\n    \ndx\n[\n1\n]\n \n=\n \n1.0\n \n-\n \np\n[\n1\n]\n*\nx\n[\n1\n]\n^\n2\n \n+\n \nx\n[\n2\n]\n\n    \ndx\n[\n2\n]\n \n=\n \np\n[\n2\n]\n*\nx\n[\n1\n]\n\n    \nreturn\n\n\nend\n\n\n# Jacobian:\n\n\nfunction\n \nhiip_jac\n(\nJ\n,\n \nx\n,\n \np\n,\n \nn\n)\n\n    \nJ\n[\n1\n,\n1\n]\n \n=\n \n-\n2\n*\np\n[\n1\n]\n*\nx\n[\n1\n]\n\n    \nJ\n[\n1\n,\n2\n]\n \n=\n \n1.0\n\n    \nJ\n[\n2\n,\n1\n]\n \n=\n \np\n[\n2\n]\n\n    \nJ\n[\n2\n,\n2\n]\n \n=\n \n0.0\n\n    \nreturn\n\n\nend\n\n\nds\n \n=\n \nDiscreteDynamicalSystem\n(\nhiip\n,\n \nzeros\n(\n2\n),\n \n[\n1.4\n,\n \n0.3\n],\n \nhiip_jac\n)\n\n\n\n\n\n\n2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  hiip_jac\n\n\n\n\n\nOr, if you don't want to write a Jacobian and want to use the auto-differentiation capabilities of \nDynamicalSystems.jl\n, which use the module \nForwardDiff\n:\n\n\nds\n \n=\n \nDiscreteDynamicalSystem\n(\nhiip\n,\n \nzeros\n(\n2\n),\n \n[\n1.4\n,\n \n0.3\n])\n\n\n\n\n\n\n2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  ForwardDiff\n\n\n\n\n\n\n\nComplex Example\n\n\nIn this example we will go through the implementation of the coupled standard maps from our \nPredefined Systems\n. It is the most complex implementation and takes full advantage of the flexibility of the constructors. The example will use a Functor as equations of motion, as well as a sparse matrix for the Jacobian.\n\n\nCoupled standard maps is a big mapping that can have arbitrary number of equations of motion, since you can couple \nN\n \nstandard maps\n which are 2D maps, like:\n\n\n\n\n\n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]\n\n\n\n\n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]\n\n\n\n\n\nTo model this, we will make a dedicated \nstruct\n, which is parameterized on the number of coupled maps:\n\n\nstruct\n \nCoupledStandardMaps\n{\nN\n}\n\n    \nidxs\n::\nSVector\n{\nN\n,\n \nInt\n}\n\n    \nidxsm1\n::\nSVector\n{\nN\n,\n \nInt\n}\n\n    \nidxsp1\n::\nSVector\n{\nN\n,\n \nInt\n}\n\n\nend\n\n\n\n\n\n\n(what these fields are will become apparent later)\n\n\nWe initialize the struct with the amount of standard maps we want to couple, and we also define appropriate parameters:\n\n\nM\n \n=\n \n5\n  \n# couple number\n\n\nu0\n \n=\n \n0.001\nrand\n(\n2\nM\n)\n \n#initial state\n\n\nks\n \n=\n \n0.9\nones\n(\nM\n)\n \n# nonlinearity parameters\n\n\n\u0393\n \n=\n \n1.0\n \n# coupling strength\n\n\np\n \n=\n \n(\nks\n,\n \n\u0393\n)\n \n# parameter container\n\n\n\n# Create struct:\n\n\nSV\n \n=\n \nSVector\n{\nM\n,\n \nInt\n}\n\n\nidxs\n \n=\n \nSV\n(\n1\n:\nM\n...\n)\n \n# indexes of thetas\n\n\nidxsm1\n \n=\n \nSV\n(\ncircshift\n(\nidxs\n,\n \n+\n1\n)\n...\n)\n  \n#indexes of thetas - 1\n\n\nidxsp1\n \n=\n \nSV\n(\ncircshift\n(\nidxs\n,\n \n-\n1\n)\n...\n)\n  \n#indexes of thetas + 1\n\n\n# So that:\n\n\n# x[i] \u2261 \u03b8\u1d62\n\n\n# x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081\n\n\n# x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081\n\n\ncsm\n \n=\n \nCoupledStandardMaps\n{\nM\n}(\nidxs\n,\n \nidxsm1\n,\n \nidxsp1\n);\n\n\n\n\n\n\nWe will now use this struct to define a \nfunctor\n, a Type that also acts as a function.\n\n\nfunction\n \n(\nf\n::\nCoupledStandardMaps\n{\nN\n})(\nxnew\n::\nAbstractVector\n,\n \nx\n,\n \np\n,\n \nn\n)\n \nwhere\n \n{\nN\n}\n\n    \nks\n,\n \n\u0393\n \n=\n \np\n\n    \n@inbounds\n \nfor\n \ni\n \nin\n \nf\n.\nidxs\n\n\n        \nxnew\n[\ni\n+\nN\n]\n \n=\n \nmod2pi\n(\n\n            \nx\n[\ni\n+\nN\n]\n \n+\n \nks\n[\ni\n]\n*\nsin\n(\nx\n[\ni\n])\n \n-\n\n            \n\u0393\n*\n(\nsin\n(\nx\n[\nf\n.\nidxsp1\n[\ni\n]]\n \n-\n \nx\n[\ni\n])\n \n+\n \nsin\n(\nx\n[\nf\n.\nidxsm1\n[\ni\n]]\n \n-\n \nx\n[\ni\n]))\n\n        \n)\n\n\n        \nxnew\n[\ni\n]\n \n=\n \nmod2pi\n(\nx\n[\ni\n]\n \n+\n \nxnew\n[\ni\n+\nN\n])\n\n    \nend\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nWe will use \nthe same\n \nstruct\n to create a function for the Jacobian:\n\n\nfunction\n \n(\nf\n::\nCoupledStandardMaps\n{\nM\n})(\n\n    \nJ\n::\nAbstractMatrix\n,\n \nx\n,\n \np\n,\n \nn\n)\n \nwhere\n \n{\nM\n}\n\n\n    \nks\n,\n \n\u0393\n \n=\n \np\n\n    \n# x[i] \u2261 \u03b8\u1d62\n\n    \n# x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081\n\n    \n# x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081\n\n    \n@inbounds\n \nfor\n \ni\n \nin\n \nf\n.\nidxs\n\n        \ncos\u03b8\n \n=\n \ncos\n(\nx\n[\ni\n])\n\n        \ncos\u03b8p\n=\n \ncos\n(\nx\n[\nf\n.\nidxsp1\n[\ni\n]]\n \n-\n \nx\n[\ni\n])\n\n        \ncos\u03b8m\n=\n \ncos\n(\nx\n[\nf\n.\nidxsm1\n[\ni\n]]\n \n-\n \nx\n[\ni\n])\n\n        \nJ\n[\ni\n+\nM\n,\n \ni\n]\n \n=\n \nks\n[\ni\n]\n*\ncos\u03b8\n \n+\n \n\u0393\n*\n(\ncos\u03b8p\n \n+\n \ncos\u03b8m\n)\n\n        \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsm1\n[\ni\n]]\n \n=\n \n-\n \n\u0393\n*\ncos\u03b8m\n\n        \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsp1\n[\ni\n]]\n \n=\n \n-\n \n\u0393\n*\ncos\u03b8p\n\n        \nJ\n[\ni\n,\n \ni\n]\n \n=\n \n1\n \n+\n \nJ\n[\ni\n+\nM\n,\n \ni\n]\n\n        \nJ\n[\ni\n,\n \nf\n.\nidxsm1\n[\ni\n]]\n \n=\n \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsm1\n[\ni\n]]\n\n        \nJ\n[\ni\n,\n \nf\n.\nidxsp1\n[\ni\n]]\n \n=\n \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsp1\n[\ni\n]]\n\n    \nend\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nThe only reason that this is possible, is because the \neom\n always takes a \nAbstractVector\n as first argument, while the Jacobian always takes an \nAbstractMatrix\n. Therefore we can take advantage of multiple dispatch!\n\n\nNotice in addition, that the Jacobian function accesses \nonly half the elements of the matrix\n. This is intentional, and takes advantage of the fact that the other half is constant. We can leverage this further, by making the Jacobian a sparse matrix. Because the \nDynamicalSystem\n constructors allow us to give in a pre-initialized Jacobian matrix, we take advantage of that and create:\n\n\nJ\n \n=\n \nzeros\n(\neltype\n(\nu0\n),\n \n2\nM\n,\n \n2\nM\n)\n\n\n# Set \u2202/\u2202p entries (they are eye(M,M))\n\n\n# And they dont change they are constants\n\n\nfor\n \ni\n \nin\n \nidxs\n\n    \nJ\n[\ni\n,\n \ni\n+\nM\n]\n \n=\n \n1\n\n    \nJ\n[\ni\n+\nM\n,\n \ni\n+\nM\n]\n \n=\n \n1\n\n\nend\n\n\nsparseJ\n \n=\n \nsparse\n(\nJ\n)\n\n\n\ncsm\n(\nsparseJ\n,\n \nu0\n,\n \np\n,\n \n0\n)\n \n# apply Jacobian to initial state\n\n\n\n\n\n\nAnd finally, we are ready to create our dynamical system:\n\n\nds\n \n=\n \nDiscreteDynamicalSystem\n(\ncsm\n,\n \nu0\n,\n \np\n,\n \ncsm\n,\n \nsparseJ\n)\n\n\n\n\n\n\n10-dimensional discrete dynamical system\n state:       [0.000803001, 0.00092095, 0.000313022, \u2026, 3.07769e-5, 0.000670152]\n e.o.m.:      CoupledStandardMaps\n in-place?    true\n jacobian:    CoupledStandardMaps\n parameters:  Tuple", 
            "title": "Dynamical System Definition"
        }, 
        {
            "location": "/ds/general/#dynamical-systems", 
            "text": "Currently a system in  DynamicalSystems.jl  can be either continuous   \n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, p, t),  \n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, p, t),   or discrete   \n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, p, n)  \n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, p, n)   where  p p  contains the parameters of the system. In addition to the above equations of motion, information about the Jacobian of the system is also part of a \"dynamical system\".  Keep in mind that almost all functions of  DynamicalSystems.jl  assume that  \\vec{f} \\vec{f}  is differentiable!", 
            "title": "Dynamical Systems"
        }, 
        {
            "location": "/ds/general/#creating-a-dynamical-system", 
            "text": "#  DynamicalSystemsBase.DynamicalSystem     Type .  DynamicalSystem   The central structure of  DynamicalSystems.jl . All functions of the suite that can use known equations of motion expect an instance of this type.  Constructing a  DynamicalSystem  DiscreteDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0 :: Int   =   0 )  ContinuousDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0   =   0.0 )   with  eom  the equations of motion function (see below).  p  is a parameter container, which we highly suggest to use a mutable object like  Array ,  LMArray  or a dictionary. Pass  nothing  in the place of  p  if your system does not have parameters.  t0 ,  J0  allow you to choose the initial time and provide an initialized Jacobian matrix. See  CDS_KWARGS  for the default options used to evolve continuous systems (through  OrdinaryDiffEq ).  Equations of motion  The are two \"versions\" for  DynamicalSystem , depending on whether the equations of motion ( eom ) are in-place (iip) or out-of-place (oop). Here is how to define them:   oop  : The  eom   must  be in the form  eom(x, p, t) -  SVector  which means that given a state  x::SVector  and some parameter container  p  it returns an  SVector  (from the  StaticArrays  module) containing the next state.  iip  : The  eom   must  be in the form  eom!(xnew, x, p, t)  which means that given a state  x::Vector  and some parameter container  p , it writes in-place the new state in  xnew .   t  stands for time (integer for discrete systems). iip is suggested for big systems, whereas oop is suggested for small systems. The break-even point at around 100 dimensions, and for using functions that use the tangent space (like e.g.  lyapunovs  or  gali ), the break-even point is at around 10 dimensions.  The constructor deduces automatically whether  eom  is iip or oop. It is not possible however to deduce whether the system is continuous or discrete just from the equations of motion, hence the 2 constructors.  Jacobian  The optional argument  jacobian  for the constructors is a  function  and (if given) must also be of the same form as the  eom ,  jacobian(x, p, n) -  SMatrix  for the out-of-place version and  jacobian!(xnew, x, p, n)  for the in-place version.  If  jacobian  is not given, it is constructed automatically using the module  ForwardDiff . It is  heavily  advised to provide a Jacobian function, as it gives  multiple  orders of magnitude speedup.  Interface to DifferentialEquations.jl  Continuous systems are solved using  DifferentialEquations.jl . The following two interfaces are provided:  ContinuousDynamicalSystem(prob::ODEProblem [, jacobian [, J0]])\nODEProblem(continuous_dynamical_system, tspan, args...)  where in the second case  args  stands for the  standard extra arguments  of  ODEProblem :  callback, mass_matrix .  If you want to use callbacks with  tangent_integrator  or  parallel_integrator , then invoke them with extra arguments as shown in the  Advanced Documentation .  Relevant Functions  trajectory ,  set_parameter! .", 
            "title": "Creating a Dynamical System"
        }, 
        {
            "location": "/ds/general/#definition-table", 
            "text": "Here is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:     System Type  equations of motion  Jacobian      in-place (big systems)  eom!(du, u, p, t)  jacobian!(J, u, p, t)    out-of-place (small systems)  eom(u, p, t) -  SVector  jacobian(u, p, t) -  SMatrix      Use mutable containers for the parameters  It is highly suggested to use a subtype of  Array ,   LMArray  or a dictionary for the container of the model's parameters. Some functions offered by  DynamicalSystems.jl , like e.g.  orbitdiagram , assume that the parameters can be first accessed by  p[x]  with  x  some qualifier as well as that this value can be set by  p[x] = newvalue .  The  Labelled Arrays  package offers  Array  implementations that can be accessed both by index as well as by some name.", 
            "title": "Definition Table"
        }, 
        {
            "location": "/ds/general/#general-functions", 
            "text": "The following functions are defined for convenience for any dynamical system:  #  DynamicalSystemsBase.dimension     Function .  dimension ( thing )   -   D   Return the dimension of the  thing , in the sense of state-space dimensionality.  #  DynamicalSystemsBase.jacobian     Function .  jacobian ( ds :: DynamicalSystem ,   u   =   ds . u0 ,   t   =   ds . t0 )   Return the jacobian of the system at  u , at  t .  #  DynamicalSystemsBase.set_parameter!     Function .  set_parameter! ( ds :: DynamicalSystem ,   index ,   value )  set_parameter! ( ds :: DynamicalSystem ,   values )   Change one or many parameters of the system by setting  p[index] = value  in the first case and  p .= values  in the second.  The same function also works for any integrator.", 
            "title": "General Functions"
        }, 
        {
            "location": "/ds/general/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/ds/general/#continuous-out-of-place", 
            "text": "Let's see an example for a small system, which is a case where out-of-place equations of motion are preferred.  using   DynamicalSystems   # also exports relevant StaticArrays names  # Lorenz system  # Equations of motion:  @inline   @inbounds   function   loop ( u ,   p ,   t ) \n     \u03c3   =   p [ 1 ];   \u03c1   =   p [ 2 ];   \u03b2   =   p [ 3 ] \n     du1   =   \u03c3 * ( u [ 2 ] - u [ 1 ]) \n     du2   =   u [ 1 ] * ( \u03c1 - u [ 3 ])   -   u [ 2 ] \n     du3   =   u [ 1 ] * u [ 2 ]   -   \u03b2 * u [ 3 ] \n     return   SVector { 3 }( du1 ,   du2 ,   du3 )  end  # Jacobian:  @inline   @inbounds   function   loop_jac ( u ,   p ,   t ) \n     \u03c3 ,   \u03c1 ,   \u03b2   =   p \n     J   =   @SMatrix   [ - \u03c3    \u03c3    0 ; \n     \u03c1   -   u [ 3 ]    ( - 1 )    ( - u [ 1 ]); \n     u [ 2 ]     u [ 1 ]    - \u03b2 ] \n     return   J  end  ds   =   ContinuousDynamicalSystem ( loop ,   rand ( 3 ),   [ 10.0 ,   28.0 ,   8 / 3 ],   loop_jac )   3-dimensional continuous dynamical system\n state:     [0.068248, 0.828095, 0.0743729]\n e.o.m.:    loop\n in-place?  false\n jacobian:  loop_jac", 
            "title": "Continuous, out-of-place"
        }, 
        {
            "location": "/ds/general/#discrete-in-place", 
            "text": "The following example is only 2-dimensional, and thus once again it is \"correct\" to use out-of-place version with  SVector . For the sake of example though, we use the in-place version.  # Henon map.  # equations of motion:  function   hiip ( dx ,   x ,   p ,   n ) \n     dx [ 1 ]   =   1.0   -   p [ 1 ] * x [ 1 ] ^ 2   +   x [ 2 ] \n     dx [ 2 ]   =   p [ 2 ] * x [ 1 ] \n     return  end  # Jacobian:  function   hiip_jac ( J ,   x ,   p ,   n ) \n     J [ 1 , 1 ]   =   - 2 * p [ 1 ] * x [ 1 ] \n     J [ 1 , 2 ]   =   1.0 \n     J [ 2 , 1 ]   =   p [ 2 ] \n     J [ 2 , 2 ]   =   0.0 \n     return  end  ds   =   DiscreteDynamicalSystem ( hiip ,   zeros ( 2 ),   [ 1.4 ,   0.3 ],   hiip_jac )   2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  hiip_jac  Or, if you don't want to write a Jacobian and want to use the auto-differentiation capabilities of  DynamicalSystems.jl , which use the module  ForwardDiff :  ds   =   DiscreteDynamicalSystem ( hiip ,   zeros ( 2 ),   [ 1.4 ,   0.3 ])   2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  ForwardDiff", 
            "title": "Discrete, in-place"
        }, 
        {
            "location": "/ds/general/#complex-example", 
            "text": "In this example we will go through the implementation of the coupled standard maps from our  Predefined Systems . It is the most complex implementation and takes full advantage of the flexibility of the constructors. The example will use a Functor as equations of motion, as well as a sparse matrix for the Jacobian.  Coupled standard maps is a big mapping that can have arbitrary number of equations of motion, since you can couple  N   standard maps  which are 2D maps, like:   \n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]  \n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]   To model this, we will make a dedicated  struct , which is parameterized on the number of coupled maps:  struct   CoupledStandardMaps { N } \n     idxs :: SVector { N ,   Int } \n     idxsm1 :: SVector { N ,   Int } \n     idxsp1 :: SVector { N ,   Int }  end   (what these fields are will become apparent later)  We initialize the struct with the amount of standard maps we want to couple, and we also define appropriate parameters:  M   =   5    # couple number  u0   =   0.001 rand ( 2 M )   #initial state  ks   =   0.9 ones ( M )   # nonlinearity parameters  \u0393   =   1.0   # coupling strength  p   =   ( ks ,   \u0393 )   # parameter container  # Create struct:  SV   =   SVector { M ,   Int }  idxs   =   SV ( 1 : M ... )   # indexes of thetas  idxsm1   =   SV ( circshift ( idxs ,   + 1 ) ... )    #indexes of thetas - 1  idxsp1   =   SV ( circshift ( idxs ,   - 1 ) ... )    #indexes of thetas + 1  # So that:  # x[i] \u2261 \u03b8\u1d62  # x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081  # x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081  csm   =   CoupledStandardMaps { M }( idxs ,   idxsm1 ,   idxsp1 );   We will now use this struct to define a  functor , a Type that also acts as a function.  function   ( f :: CoupledStandardMaps { N })( xnew :: AbstractVector ,   x ,   p ,   n )   where   { N } \n     ks ,   \u0393   =   p \n     @inbounds   for   i   in   f . idxs \n\n         xnew [ i + N ]   =   mod2pi ( \n             x [ i + N ]   +   ks [ i ] * sin ( x [ i ])   - \n             \u0393 * ( sin ( x [ f . idxsp1 [ i ]]   -   x [ i ])   +   sin ( x [ f . idxsm1 [ i ]]   -   x [ i ])) \n         ) \n\n         xnew [ i ]   =   mod2pi ( x [ i ]   +   xnew [ i + N ]) \n     end \n     return   nothing  end   We will use  the same   struct  to create a function for the Jacobian:  function   ( f :: CoupledStandardMaps { M })( \n     J :: AbstractMatrix ,   x ,   p ,   n )   where   { M } \n\n     ks ,   \u0393   =   p \n     # x[i] \u2261 \u03b8\u1d62 \n     # x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081 \n     # x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081 \n     @inbounds   for   i   in   f . idxs \n         cos\u03b8   =   cos ( x [ i ]) \n         cos\u03b8p =   cos ( x [ f . idxsp1 [ i ]]   -   x [ i ]) \n         cos\u03b8m =   cos ( x [ f . idxsm1 [ i ]]   -   x [ i ]) \n         J [ i + M ,   i ]   =   ks [ i ] * cos\u03b8   +   \u0393 * ( cos\u03b8p   +   cos\u03b8m ) \n         J [ i + M ,   f . idxsm1 [ i ]]   =   -   \u0393 * cos\u03b8m \n         J [ i + M ,   f . idxsp1 [ i ]]   =   -   \u0393 * cos\u03b8p \n         J [ i ,   i ]   =   1   +   J [ i + M ,   i ] \n         J [ i ,   f . idxsm1 [ i ]]   =   J [ i + M ,   f . idxsm1 [ i ]] \n         J [ i ,   f . idxsp1 [ i ]]   =   J [ i + M ,   f . idxsp1 [ i ]] \n     end \n     return   nothing  end   The only reason that this is possible, is because the  eom  always takes a  AbstractVector  as first argument, while the Jacobian always takes an  AbstractMatrix . Therefore we can take advantage of multiple dispatch!  Notice in addition, that the Jacobian function accesses  only half the elements of the matrix . This is intentional, and takes advantage of the fact that the other half is constant. We can leverage this further, by making the Jacobian a sparse matrix. Because the  DynamicalSystem  constructors allow us to give in a pre-initialized Jacobian matrix, we take advantage of that and create:  J   =   zeros ( eltype ( u0 ),   2 M ,   2 M )  # Set \u2202/\u2202p entries (they are eye(M,M))  # And they dont change they are constants  for   i   in   idxs \n     J [ i ,   i + M ]   =   1 \n     J [ i + M ,   i + M ]   =   1  end  sparseJ   =   sparse ( J )  csm ( sparseJ ,   u0 ,   p ,   0 )   # apply Jacobian to initial state   And finally, we are ready to create our dynamical system:  ds   =   DiscreteDynamicalSystem ( csm ,   u0 ,   p ,   csm ,   sparseJ )   10-dimensional discrete dynamical system\n state:       [0.000803001, 0.00092095, 0.000313022, \u2026, 3.07769e-5, 0.000670152]\n e.o.m.:      CoupledStandardMaps\n in-place?    true\n jacobian:    CoupledStandardMaps\n parameters:  Tuple", 
            "title": "Complex Example"
        }, 
        {
            "location": "/ds/evolve/", 
            "text": "Time Evolution of Systems\n\n\n\n\nTrajectory and Timeseries\n\n\nThe word \"timeseries\" can be confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in \nDynamicalSystems.jl\n we have the following convention: \n\"timeseries\"\n always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word \n\"trajectory\"\n is used to refer to a \nmulti-dimensional\n timeseries, which is of course simply a group/set of one-dimensional timeseries.\n\n\nNote that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a \nDataset\n, which is a \nVector\n of \nSVector\ns, and each \nSVector\n represents a data-point (the values of the variables at a given time-point).\n\n\n\n\nDynamicalSystems.jl\n provides a convenient function for getting a trajectory of a system at equally spaced time points:\n\n\n#\n\n\nDynamicalSystemsBase.trajectory\n \n \nFunction\n.\n\n\ntrajectory\n(\nds\n::\nDynamicalSystem\n,\n \nT\n \n[,\n \nu\n];\n \nkwargs\n...\n)\n \n-\n \ndataset\n\n\n\n\n\n\nReturn a dataset that will contain the trajectory of the system, after evolving it for total time \nT\n, optionally starting from state \nu\n. See \nDataset\n for info on how to use this object.\n\n\nA \nW\u00d7D\n dataset is returned, with \nW = length(t0:dt:T)\n with \nt0:dt:T\n representing the time vector (\nnot\n returned) and \nD\n the system dimension. For discrete systems both \nT\n and \ndt\n must be integers.\n\n\nKeyword Arguments\n\n\n\n\ndt\n :  Time step of value output during the solving of the continuous system. For discrete systems it must be an integer. Defaults to \n0.01\n for continuous and \n1\n for discrete.\n\n\nTtr\n : Transient time to evolve the initial state before starting saving states.\n\n\ndiffeq...\n : Keyword arguments propagated into \ninit\n of DifferentialEquations.jl. For example \nabstol = 1e-9\n.  Only valid for continuous systems. If you want to specify a solver, do so by using the name \nalg\n, e.g.: \nalg = Tsit5(), maxiters = 1000\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers. See \nDynamicalSystemsBase.CDS_KWARGS\n for default values. These keywords can also include \ncallback\n for \nevent handling\n. Using a \nSavingCallback\n with \ntrajectory\n will lead to unexpected behavior!\n\n\n\n\n\n\nNotice that if you want to do repeated evolutions of different states of a continuous system, you should use the \nintegrator\n interface instead.\n\n\n\n\nSolution precision for continuous systems\n\n\nA numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.\n\n\nDifferentialEquations.jl offers a tool, called \nUncertainty Quantification\n, which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of \nDynamicalSystems.jl\n, the Lorenz system is accurate up to time \nt = 50.0\n.\n\n\nHowever, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the \nshadowing theorem\n (or \nshadowing lemma\n):\n\n\n\n\nShadowing Theorem\n\n\nAlthough a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.\n\n\n\n\nThis simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book \nChaos in Dynamical Systems\n by E. Ott, or the \nscholarpedia\n entry.", 
            "title": "Time Evolution"
        }, 
        {
            "location": "/ds/evolve/#time-evolution-of-systems", 
            "text": "Trajectory and Timeseries  The word \"timeseries\" can be confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in  DynamicalSystems.jl  we have the following convention:  \"timeseries\"  always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word  \"trajectory\"  is used to refer to a  multi-dimensional  timeseries, which is of course simply a group/set of one-dimensional timeseries.  Note that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a  Dataset , which is a  Vector  of  SVector s, and each  SVector  represents a data-point (the values of the variables at a given time-point).   DynamicalSystems.jl  provides a convenient function for getting a trajectory of a system at equally spaced time points:  #  DynamicalSystemsBase.trajectory     Function .  trajectory ( ds :: DynamicalSystem ,   T   [,   u ];   kwargs ... )   -   dataset   Return a dataset that will contain the trajectory of the system, after evolving it for total time  T , optionally starting from state  u . See  Dataset  for info on how to use this object.  A  W\u00d7D  dataset is returned, with  W = length(t0:dt:T)  with  t0:dt:T  representing the time vector ( not  returned) and  D  the system dimension. For discrete systems both  T  and  dt  must be integers.  Keyword Arguments   dt  :  Time step of value output during the solving of the continuous system. For discrete systems it must be an integer. Defaults to  0.01  for continuous and  1  for discrete.  Ttr  : Transient time to evolve the initial state before starting saving states.  diffeq...  : Keyword arguments propagated into  init  of DifferentialEquations.jl. For example  abstol = 1e-9 .  Only valid for continuous systems. If you want to specify a solver, do so by using the name  alg , e.g.:  alg = Tsit5(), maxiters = 1000 . This requires you to have been first  using OrdinaryDiffEq  to access the solvers. See  DynamicalSystemsBase.CDS_KWARGS  for default values. These keywords can also include  callback  for  event handling . Using a  SavingCallback  with  trajectory  will lead to unexpected behavior!    Notice that if you want to do repeated evolutions of different states of a continuous system, you should use the  integrator  interface instead.", 
            "title": "Time Evolution of Systems"
        }, 
        {
            "location": "/ds/evolve/#solution-precision-for-continuous-systems", 
            "text": "A numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.  DifferentialEquations.jl offers a tool, called  Uncertainty Quantification , which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of  DynamicalSystems.jl , the Lorenz system is accurate up to time  t = 50.0 .  However, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the  shadowing theorem  (or  shadowing lemma ):   Shadowing Theorem  Although a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.   This simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book  Chaos in Dynamical Systems  by E. Ott, or the  scholarpedia  entry.", 
            "title": "Solution precision for continuous systems"
        }, 
        {
            "location": "/ds/predefined/", 
            "text": "Predefined Systems\n\n\nPredefined systems exist in the \nSystems\n submodule in the form of functions that return a \nDynamicalSystem\n. They are accessed like:\n\n\nusing\n \nDynamicalSystems\n \n# or DynamicalSystemsBase\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n\n\n\n\n\n\nSo far, the predefined systems that exist in the \nSystems\n sub-module are:\n\n\n#\n\n\nDynamicalSystemsBase.Systems.antidots\n \n \nFunction\n.\n\n\nantidots\n(\nu\n;\n \nB\n \n=\n \n1.0\n,\n \nd0\n \n=\n \n0.3\n,\n \nc\n \n=\n \n0.2\n)\n\n\n\n\n\n\nAn antidot \"superlattice\" is a Hamiltonian system that corresponds to a smoothened periodic Sinai billiard with disk diameter \nd0\n and smooth factor \nc\n [1].\n\n\nThis version is the two dimensional classical form of the system, with quadratic equations of motion and a perpendicular magnetic field. Notice that the equations of motion are with respect to the velocity instead of momentum, i.e.:\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= v_x \\\\\n\\dot{y} \n= v_y \\\\\n\\dot{v_x} \n= B*v_y - U_x \\\\\n\\dot{v_y} \n= -B*v_x - U_X \\\\\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= v_x \\\\\n\\dot{y} &= v_y \\\\\n\\dot{v_x} &= B*v_y - U_x \\\\\n\\dot{v_y} &= -B*v_x - U_X \\\\\n\\end{aligned}\n\n\n\n\n\nwith \nU\nU\n the potential energy:\n\n\n\n\n\nU = \\left(\\tfrac{1}{c^4}\\right) \\left[\\tfrac{d_0}{2} + c - r_a\\right]^4\n\n\n\n\nU = \\left(\\tfrac{1}{c^4}\\right) \\left[\\tfrac{d_0}{2} + c - r_a\\right]^4\n\n\n\n\n\nif \nr_a = \\sqrt{(x%1)^2 + (y%1)^2} \n \\frac{d_0}{2} + c\nr_a = \\sqrt{(x%1)^2 + (y%1)^2} < \\frac{d_0}{2} + c\n and 0 otherwise. I.e. the potential is periodic with period 1 in both \nx, y\nx, y\n and normalized such that for energy value of 1 it is a circle of diameter \nd0\nd0\n. The magnetic field is also normalized such that for value \nB=1\n the cyclotron diameter is 1.\n\n\nFo more details see [1].\n\n\n[1] : G. Datseris \net al\n, \narXiv:1711.05833v3\n\n\n#\n\n\nDynamicalSystemsBase.Systems.coupledstandardmaps\n \n \nFunction\n.\n\n\ncoupledstandardmaps\n(\nM\n::\nInt\n,\n \nu0\n \n=\n \n0.001\nrand\n(\n2\nM\n);\n \nks\n \n=\n \nones\n(\nM\n),\n \n\u0393\n \n=\n \n1.0\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' \n= \\theta_i + p_{i}' \\\\\np_{i}' \n= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\nA discrete system of \nM\n nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The \ntotal\n dimension of the system is \n2M\n. The maps are coupled through \n\u0393\n and the \ni\n-th map has a nonlinear parameter \nks[i]\n.\n\n\nThe first \nM\n entries of the state are the angles, the last \nM\n are the momenta.\n\n\n[1] : H. Kantz \n P. Grassberger, J. Phys. A \n21\n, pp 127\u2013133 (1988)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.double_pendulum\n \n \nFunction\n.\n\n\ndouble_pendulum\n(\nu0\n \n=\n \n[\n\u03c0\n/\n2\n,\n \n0\n,\n \n0\n,\n \nrand\n()];\n\n                \nG\n=\n10.0\n,\n \nL1\n \n=\n \n1.0\n,\n \nL2\n \n=\n \n1.0\n,\n \nM1\n \n=\n \n1.0\n,\n \nM2\n \n=\n \n1.0\n)\n\n\n\n\n\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\n\nThe variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].\n\n\nJacobian is created automatically (thus methods that use the Jacobian will be slower)!\n\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n#\n\n\nDynamicalSystemsBase.Systems.duffing\n \n \nFunction\n.\n\n\nduffing\n(\nu0\n \n=\n \n[\nrand\n(),\n \nrand\n(),\n \n0\n];\n \n\u03c9\n \n=\n \n2.2\n,\n \nf\n \n=\n \n27.0\n,\n \nd\n \n=\n \n0.2\n,\n \n\u03b2\n \n=\n \n1\n)\n\n\n\n\n\n\nThe (forced) duffing oscillator, that satisfies the equation\n\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\nwith \nf, \u03c9\n the forcing strength and frequency and \nd\n the dampening.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n#\n\n\nDynamicalSystemsBase.Systems.gissinger\n \n \nFunction\n.\n\n\ngissinger\n(\nu0\n \n=\n \n3\nrand\n(\n3\n);\n \n\u03bc\n \n=\n \n0.119\n,\n \n\u03bd\n \n=\n \n0.1\n,\n \n\u0393\n \n=\n \n0.9\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{Q} \n= \\mu Q - VD \\\\\n\\dot{D} \n= -\\nu D + VQ \\\\\n\\dot{V} \n= \\Gamma -V + QD\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{Q} &= \\mu Q - VD \\\\\n\\dot{D} &= -\\nu D + VQ \\\\\n\\dot{V} &= \\Gamma -V + QD\n\\end{aligned}\n\n\n\n\n\nA continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : C. Gissinger, Eur. Phys. J. B \n85\n, 4, pp 1-12 (2012)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henon\n \n \nFunction\n.\n\n\nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= 1 - ax^2_n+y_n \\\\\ny_{n+1} \n = bx_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : M. H\u00e9non, Commun.Math. Phys. \n50\n, pp 69 (1976)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henonheiles\n \n \nFunction\n.\n\n\nhenonheiles\n(\nu0\n=\n[\n0\n,\n \n-\n0.25\n,\n \n0.42081\n,\n0\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= p_x \\\\\n\\dot{y} \n= p_y \\\\\n\\dot{p}_x \n= -x -2 xy \\\\\n\\dot{p}_y \n= -y - (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2 xy \\\\\n\\dot{p}_y &= -y - (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.\n\n\nThe default initial condition is a typical chaotic orbit.\n\n\n[1] : H\u00e9non, M. \n Heiles, C., The Astronomical Journal \n69\n, pp 73\u201379 (1964)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.labyrinth\n \n \nFunction\n.\n\n\nlabyrinth\n(\nu0\n \n=\n \n[\n1.0\n,\n \n0\n,\n \n0\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= \\sin(y) \\\\\n\\dot{y} \n= \\sin(z) \\\\\n\\dot{V} \n= \\sin(x)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= \\sin(y) \\\\\n\\dot{y} &= \\sin(z) \\\\\n\\dot{V} &= \\sin(x)\n\\end{aligned}\n\n\n\n\n\nThree dimensional conservative continuous system, whose evolution in 3D space looks like a speudo-random walk, the orbit moving around like in a labyrinth. Taken from the book \"Elegant Chaos\" by J. C. Sprott.\n\n\n#\n\n\nDynamicalSystemsBase.Systems.logistic\n \n \nFunction\n.\n\n\nlogistic\n(\nx0\n \n=\n \nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n\n\n\n\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\n\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : R. M. May, Nature \n261\n, pp 459 (1976)\n\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. \n19\n, pp 25 (1978)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz\n \n \nFunction\n.\n\n\nlorenz\n(\nu0\n=\n[\n0.0\n,\n \n10.0\n,\n \n0.0\n];\n \n\u03c3\n \n=\n \n10.0\n,\n \n\u03c1\n \n=\n \n28.0\n,\n \n\u03b2\n \n=\n \n8\n/\n3\n)\n \n-\n \nds\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{X} \n= \\sigma(Y-X) \\\\\n\\dot{Y} \n= -XZ + \\rho X -Y \\\\\n\\dot{Z} \n= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : E. N. Lorenz, J. atmos. Sci. \n20\n, pp 130 (1963)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz96\n \n \nFunction\n.\n\n\nlorenz96\n(\nN\n::\nInt\n,\n \nu0\n \n=\n \nrand\n(\nM\n);\n \nF\n=\n0.01\n)\n\n\n\n\n\n\n\n\n\n\\frac{dx_i}{dt} = (x_{i+1}-x_{i-2})x_{i-1} - x_i + F\n\n\n\n\n\\frac{dx_i}{dt} = (x_{i+1}-x_{i-2})x_{i-1} - x_i + F\n\n\n\n\n\nN\n is the chain length, \nF\n the forcing. Jacobian is created automatically. (parameter container only contains \nF\n)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.nosehoover\n \n \nFunction\n.\n\n\nnosehoover\n(\nu0\n \n=\n \n[\n0\n,\n \n0.1\n,\n \n0\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= y \\\\\n\\dot{y} \n= yz - x \\\\\n\\dot{z} \n= 1 - y^2\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= y \\\\\n\\dot{y} &= yz - x \\\\\n\\dot{z} &= 1 - y^2\n\\end{aligned}\n\n\n\n\n\nThree dimensional conservative continuous system, taken from the book \"Elegant Chaos\" by J. C. Sprott.\n\n\n#\n\n\nDynamicalSystemsBase.Systems.qbh\n \n \nFunction\n.\n\n\nqbh\n([\nu0\n];\n \nA\n=\n1.0\n,\n \nB\n=\n0.55\n,\n \nD\n=\n0.4\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{q}_0 \n= A p_0 \\\\\n\\dot{q}_2 \n= A p_2 \\\\\n\\dot{p}_0 \n= -A q_0 -3 \\frac{B}{\\sqrt{2}} (q_2^2 - q_1^2) - D q_1 (q_1^2 + q_2^2) \\\\\n\\dot{p}_2 \n= -q_2 (A + 3\\sqrt{2} B q_1 + D (q_1^2 + q_2^2)) (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{q}_0 &= A p_0 \\\\\n\\dot{q}_2 &= A p_2 \\\\\n\\dot{p}_0 &= -A q_0 -3 \\frac{B}{\\sqrt{2}} (q_2^2 - q_1^2) - D q_1 (q_1^2 + q_2^2) \\\\\n\\dot{p}_2 &= -q_2 (A + 3\\sqrt{2} B q_1 + D (q_1^2 + q_2^2)) (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\nThese equations of motion correspond to a Hamiltonian used in nuclear physics to study the quadrupole vibrations of the nuclear surface [1,2].\n\n\n\n\n\nH(p_0, p_2, q_0, q_2) = \\frac{A}{2}\\left(p_0^2+p_2^2\\right)+\\frac{A}{2}\\left(q_0^2+q_2^2\\right)\n             +\\frac{B}{\\sqrt{2}}q_0\\left(3q_2^2-q_0^2\\right) +\\frac{D}{4}\\left(q_0^2+q_2^2\\right)^2\n\n\n\n\nH(p_0, p_2, q_0, q_2) = \\frac{A}{2}\\left(p_0^2+p_2^2\\right)+\\frac{A}{2}\\left(q_0^2+q_2^2\\right)\n             +\\frac{B}{\\sqrt{2}}q_0\\left(3q_2^2-q_0^2\\right) +\\frac{D}{4}\\left(q_0^2+q_2^2\\right)^2\n\n\n\n\n\nThe Hamiltonian has a similar structure with the Henon-Heiles one, but it has an added fourth order term and presents a nontrivial dependence of chaoticity with the increase of energy [3]. The default initial condition is chaotic.\n\n\n[1]: Eisenberg, J.M., \n Greiner, W., Nuclear theory 2 rev ed. Netherlands: North-Holland pp 80 (1975)\n\n\n[2]: Baran V. and Raduta A. A., International Journal of Modern Physics E, \n7\n, pp 527\u2013551 (1998)\n\n\n[3]: Micluta-Campeanu S., Raportaru M.C., Nicolin A.I., Baran V., Rom. Rep. Phys. \n70\n, pp 105 (2018)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.rikitake\n \n \nFunction\n.\n\n\nrikitake\n(\nu0\n \n=\n \n[\n1\n,\n \n0\n,\n \n0.6\n];\n \n\u03bc\n \n=\n \n1.0\n,\n \n\u03b1\n \n=\n \n1.0\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= -\\mu x +yz \\\\\n\\dot{y} \n= -\\mu y +x(z-\\alpha) \\\\\n\\dot{V} \n= 1 - xz\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= -\\mu x +yz \\\\\n\\dot{y} &= -\\mu y +x(z-\\alpha) \\\\\n\\dot{V} &= 1 - xz\n\\end{aligned}\n\n\n\n\n\nRikitake's dynamo is a system that tries to model the magnetic reversal events by means of a double-disk dynamo system.\n\n\n[1] : T. Rikitake Math. Proc. Camb. Phil. Soc. \n54\n, pp 89\u2013105, (1958)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.roessler\n \n \nFunction\n.\n\n\nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= -y-z \\\\\n\\dot{y} \n= x+ay \\\\\n\\dot{z} \n= b + z(x-c)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= b + z(x-c)\n\\end{aligned}\n\n\n\n\n\nThis three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the \nlorenz\n system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n57A\n, pp 397 (1976)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.shinriki\n \n \nFunction\n.\n\n\nshinriki\n(\nu0\n \n=\n \n[\n-\n2\n,\n \n0\n,\n \n0.2\n];\n \nR1\n \n=\n \n22.0\n)\n\n\n\n\n\n\nShinriki oscillator with all other parameters (besides \nR1\n) set to constants. \nThis is a stiff problem, be careful when choosing solvers and tolerances\n.\n\n\n#\n\n\nDynamicalSystemsBase.Systems.standardmap\n \n \nFunction\n.\n\n\nstandardmap\n(\nu0\n=\n0.001\nrand\n(\n2\n);\n \nk\n \n=\n \n0.971635\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} \n= \\theta_n + p_{n+1} \\\\\np_{n+1} \n= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\n\nThe map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter \nk\n transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\n\nThe default parameter \nk\n is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable \n\u03b8\n to be the first, and the angular momentum \np\n to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : B. V. Chirikov, Preprint N. \n267\n, Institute of Nuclear Physics, Novosibirsk (1969)\n\n\n[2] : J. M. Greene, J. Math. Phys. \n20\n, pp 1183 (1979)\n\n\n#\n\n\nDynamicalSystemsBase.Systems.towel\n \n \nFunction\n.\n\n\ntowel\n(\nu0\n \n=\n \n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} \n= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} \n= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\nThe folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n71A\n, pp 155 (1979)", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/ds/predefined/#predefined-systems", 
            "text": "Predefined systems exist in the  Systems  submodule in the form of functions that return a  DynamicalSystem . They are accessed like:  using   DynamicalSystems   # or DynamicalSystemsBase  ds   =   Systems . lorenz ( \u03c1   =   32.0 )   So far, the predefined systems that exist in the  Systems  sub-module are:  #  DynamicalSystemsBase.Systems.antidots     Function .  antidots ( u ;   B   =   1.0 ,   d0   =   0.3 ,   c   =   0.2 )   An antidot \"superlattice\" is a Hamiltonian system that corresponds to a smoothened periodic Sinai billiard with disk diameter  d0  and smooth factor  c  [1].  This version is the two dimensional classical form of the system, with quadratic equations of motion and a perpendicular magnetic field. Notice that the equations of motion are with respect to the velocity instead of momentum, i.e.:   \n\\begin{aligned}\n\\dot{x}  = v_x \\\\\n\\dot{y}  = v_y \\\\\n\\dot{v_x}  = B*v_y - U_x \\\\\n\\dot{v_y}  = -B*v_x - U_X \\\\\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= v_x \\\\\n\\dot{y} &= v_y \\\\\n\\dot{v_x} &= B*v_y - U_x \\\\\n\\dot{v_y} &= -B*v_x - U_X \\\\\n\\end{aligned}   with  U U  the potential energy:   \nU = \\left(\\tfrac{1}{c^4}\\right) \\left[\\tfrac{d_0}{2} + c - r_a\\right]^4  \nU = \\left(\\tfrac{1}{c^4}\\right) \\left[\\tfrac{d_0}{2} + c - r_a\\right]^4   if  r_a = \\sqrt{(x%1)^2 + (y%1)^2}   \\frac{d_0}{2} + c r_a = \\sqrt{(x%1)^2 + (y%1)^2} < \\frac{d_0}{2} + c  and 0 otherwise. I.e. the potential is periodic with period 1 in both  x, y x, y  and normalized such that for energy value of 1 it is a circle of diameter  d0 d0 . The magnetic field is also normalized such that for value  B=1  the cyclotron diameter is 1.  Fo more details see [1].  [1] : G. Datseris  et al ,  arXiv:1711.05833v3  #  DynamicalSystemsBase.Systems.coupledstandardmaps     Function .  coupledstandardmaps ( M :: Int ,   u0   =   0.001 rand ( 2 M );   ks   =   ones ( M ),   \u0393   =   1.0 )    \n\\begin{aligned}\n\\theta_{i}'  = \\theta_i + p_{i}' \\\\\np_{i}'  = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}   A discrete system of  M  nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The  total  dimension of the system is  2M . The maps are coupled through  \u0393  and the  i -th map has a nonlinear parameter  ks[i] .  The first  M  entries of the state are the angles, the last  M  are the momenta.  [1] : H. Kantz   P. Grassberger, J. Phys. A  21 , pp 127\u2013133 (1988)  #  DynamicalSystemsBase.Systems.double_pendulum     Function .  double_pendulum ( u0   =   [ \u03c0 / 2 ,   0 ,   0 ,   rand ()]; \n                 G = 10.0 ,   L1   =   1.0 ,   L2   =   1.0 ,   M1   =   1.0 ,   M2   =   1.0 )   Famous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).  The variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].  Jacobian is created automatically (thus methods that use the Jacobian will be slower)!  (please contribute the Jacobian and the e.o.m. in LaTeX :smile:)  The parameter container has the parameters in the same order as stated in this function's documentation string.  #  DynamicalSystemsBase.Systems.duffing     Function .  duffing ( u0   =   [ rand (),   rand (),   0 ];   \u03c9   =   2.2 ,   f   =   27.0 ,   d   =   0.2 ,   \u03b2   =   1 )   The (forced) duffing oscillator, that satisfies the equation   \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)  \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)   with  f, \u03c9  the forcing strength and frequency and  d  the dampening.  The parameter container has the parameters in the same order as stated in this function's documentation string.  #  DynamicalSystemsBase.Systems.gissinger     Function .  gissinger ( u0   =   3 rand ( 3 );   \u03bc   =   0.119 ,   \u03bd   =   0.1 ,   \u0393   =   0.9 )    \n\\begin{aligned}\n\\dot{Q}  = \\mu Q - VD \\\\\n\\dot{D}  = -\\nu D + VQ \\\\\n\\dot{V}  = \\Gamma -V + QD\n\\end{aligned}  \n\\begin{aligned}\n\\dot{Q} &= \\mu Q - VD \\\\\n\\dot{D} &= -\\nu D + VQ \\\\\n\\dot{V} &= \\Gamma -V + QD\n\\end{aligned}   A continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : C. Gissinger, Eur. Phys. J. B  85 , 4, pp 1-12 (2012)  #  DynamicalSystemsBase.Systems.henon     Function .  henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 )    \n\\begin{aligned}\nx_{n+1}  = 1 - ax^2_n+y_n \\\\\ny_{n+1}   = bx_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}   The H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.  According to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : M. H\u00e9non, Commun.Math. Phys.  50 , pp 69 (1976)  #  DynamicalSystemsBase.Systems.henonheiles     Function .  henonheiles ( u0 = [ 0 ,   - 0.25 ,   0.42081 , 0 ])    \n\\begin{aligned}\n\\dot{x}  = p_x \\\\\n\\dot{y}  = p_y \\\\\n\\dot{p}_x  = -x -2 xy \\\\\n\\dot{p}_y  = -y - (x^2 - y^2)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2 xy \\\\\n\\dot{p}_y &= -y - (x^2 - y^2)\n\\end{aligned}   The H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.  The default initial condition is a typical chaotic orbit.  [1] : H\u00e9non, M.   Heiles, C., The Astronomical Journal  69 , pp 73\u201379 (1964)  #  DynamicalSystemsBase.Systems.labyrinth     Function .  labyrinth ( u0   =   [ 1.0 ,   0 ,   0 ])    \n\\begin{aligned}\n\\dot{x}  = \\sin(y) \\\\\n\\dot{y}  = \\sin(z) \\\\\n\\dot{V}  = \\sin(x)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= \\sin(y) \\\\\n\\dot{y} &= \\sin(z) \\\\\n\\dot{V} &= \\sin(x)\n\\end{aligned}   Three dimensional conservative continuous system, whose evolution in 3D space looks like a speudo-random walk, the orbit moving around like in a labyrinth. Taken from the book \"Elegant Chaos\" by J. C. Sprott.  #  DynamicalSystemsBase.Systems.logistic     Function .  logistic ( x0   =   rand ();   r   =   4.0 )    \nx_{n+1} = rx_n(1-x_n)  \nx_{n+1} = rx_n(1-x_n)   The logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.  Originally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : R. M. May, Nature  261 , pp 459 (1976)  [2] : M. J. Feigenbaum, J. Stat. Phys.  19 , pp 25 (1978)  #  DynamicalSystemsBase.Systems.lorenz     Function .  lorenz ( u0 = [ 0.0 ,   10.0 ,   0.0 ];   \u03c3   =   10.0 ,   \u03c1   =   28.0 ,   \u03b2   =   8 / 3 )   -   ds    \n\\begin{aligned}\n\\dot{X}  = \\sigma(Y-X) \\\\\n\\dot{Y}  = -XZ + \\rho X -Y \\\\\n\\dot{Z}  = XY - \\beta Z\n\\end{aligned}  \n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}   The famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.  Currently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : E. N. Lorenz, J. atmos. Sci.  20 , pp 130 (1963)  #  DynamicalSystemsBase.Systems.lorenz96     Function .  lorenz96 ( N :: Int ,   u0   =   rand ( M );   F = 0.01 )    \n\\frac{dx_i}{dt} = (x_{i+1}-x_{i-2})x_{i-1} - x_i + F  \n\\frac{dx_i}{dt} = (x_{i+1}-x_{i-2})x_{i-1} - x_i + F   N  is the chain length,  F  the forcing. Jacobian is created automatically. (parameter container only contains  F )  #  DynamicalSystemsBase.Systems.nosehoover     Function .  nosehoover ( u0   =   [ 0 ,   0.1 ,   0 ])    \n\\begin{aligned}\n\\dot{x}  = y \\\\\n\\dot{y}  = yz - x \\\\\n\\dot{z}  = 1 - y^2\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= y \\\\\n\\dot{y} &= yz - x \\\\\n\\dot{z} &= 1 - y^2\n\\end{aligned}   Three dimensional conservative continuous system, taken from the book \"Elegant Chaos\" by J. C. Sprott.  #  DynamicalSystemsBase.Systems.qbh     Function .  qbh ([ u0 ];   A = 1.0 ,   B = 0.55 ,   D = 0.4 )    \n\\begin{aligned}\n\\dot{q}_0  = A p_0 \\\\\n\\dot{q}_2  = A p_2 \\\\\n\\dot{p}_0  = -A q_0 -3 \\frac{B}{\\sqrt{2}} (q_2^2 - q_1^2) - D q_1 (q_1^2 + q_2^2) \\\\\n\\dot{p}_2  = -q_2 (A + 3\\sqrt{2} B q_1 + D (q_1^2 + q_2^2)) (x^2 - y^2)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{q}_0 &= A p_0 \\\\\n\\dot{q}_2 &= A p_2 \\\\\n\\dot{p}_0 &= -A q_0 -3 \\frac{B}{\\sqrt{2}} (q_2^2 - q_1^2) - D q_1 (q_1^2 + q_2^2) \\\\\n\\dot{p}_2 &= -q_2 (A + 3\\sqrt{2} B q_1 + D (q_1^2 + q_2^2)) (x^2 - y^2)\n\\end{aligned}   These equations of motion correspond to a Hamiltonian used in nuclear physics to study the quadrupole vibrations of the nuclear surface [1,2].   \nH(p_0, p_2, q_0, q_2) = \\frac{A}{2}\\left(p_0^2+p_2^2\\right)+\\frac{A}{2}\\left(q_0^2+q_2^2\\right)\n             +\\frac{B}{\\sqrt{2}}q_0\\left(3q_2^2-q_0^2\\right) +\\frac{D}{4}\\left(q_0^2+q_2^2\\right)^2  \nH(p_0, p_2, q_0, q_2) = \\frac{A}{2}\\left(p_0^2+p_2^2\\right)+\\frac{A}{2}\\left(q_0^2+q_2^2\\right)\n             +\\frac{B}{\\sqrt{2}}q_0\\left(3q_2^2-q_0^2\\right) +\\frac{D}{4}\\left(q_0^2+q_2^2\\right)^2   The Hamiltonian has a similar structure with the Henon-Heiles one, but it has an added fourth order term and presents a nontrivial dependence of chaoticity with the increase of energy [3]. The default initial condition is chaotic.  [1]: Eisenberg, J.M.,   Greiner, W., Nuclear theory 2 rev ed. Netherlands: North-Holland pp 80 (1975)  [2]: Baran V. and Raduta A. A., International Journal of Modern Physics E,  7 , pp 527\u2013551 (1998)  [3]: Micluta-Campeanu S., Raportaru M.C., Nicolin A.I., Baran V., Rom. Rep. Phys.  70 , pp 105 (2018)  #  DynamicalSystemsBase.Systems.rikitake     Function .  rikitake ( u0   =   [ 1 ,   0 ,   0.6 ];   \u03bc   =   1.0 ,   \u03b1   =   1.0 )    \n\\begin{aligned}\n\\dot{x}  = -\\mu x +yz \\\\\n\\dot{y}  = -\\mu y +x(z-\\alpha) \\\\\n\\dot{V}  = 1 - xz\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= -\\mu x +yz \\\\\n\\dot{y} &= -\\mu y +x(z-\\alpha) \\\\\n\\dot{V} &= 1 - xz\n\\end{aligned}   Rikitake's dynamo is a system that tries to model the magnetic reversal events by means of a double-disk dynamo system.  [1] : T. Rikitake Math. Proc. Camb. Phil. Soc.  54 , pp 89\u2013105, (1958)  #  DynamicalSystemsBase.Systems.roessler     Function .  roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 )    \n\\begin{aligned}\n\\dot{x}  = -y-z \\\\\n\\dot{y}  = x+ay \\\\\n\\dot{z}  = b + z(x-c)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= b + z(x-c)\n\\end{aligned}   This three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the  lorenz  system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : O. E. R\u00f6ssler, Phys. Lett.  57A , pp 397 (1976)  #  DynamicalSystemsBase.Systems.shinriki     Function .  shinriki ( u0   =   [ - 2 ,   0 ,   0.2 ];   R1   =   22.0 )   Shinriki oscillator with all other parameters (besides  R1 ) set to constants.  This is a stiff problem, be careful when choosing solvers and tolerances .  #  DynamicalSystemsBase.Systems.standardmap     Function .  standardmap ( u0 = 0.001 rand ( 2 );   k   =   0.971635 )    \n\\begin{aligned}\n\\theta_{n+1}  = \\theta_n + p_{n+1} \\\\\np_{n+1}  = p_n + k\\sin(\\theta_n)\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}   The standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.  The map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter  k  transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.  The default parameter  k  is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable  \u03b8  to be the first, and the angular momentum  p  to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : B. V. Chirikov, Preprint N.  267 , Institute of Nuclear Physics, Novosibirsk (1969)  [2] : J. M. Greene, J. Math. Phys.  20 , pp 1183 (1979)  #  DynamicalSystemsBase.Systems.towel     Function .  towel ( u0   =   [ 0.085 ,   - 0.121 ,   0.075 ])    \n\\begin{aligned}\nx_{n+1}  = a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1}  = 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1}  = 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}   The folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.  Default values are the ones used in the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  71A , pp 155 (1979)", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/embedding/dataset/", 
            "text": "Numerical Data\n\n\nNumerical data in \nDynamicalSystems.jl\n is most often represented by a structure called \nDataset\n\n\n#\n\n\nDelayEmbeddings.Dataset\n \n \nType\n.\n\n\nDataset\n{\nD\n,\n \nT\n}\n \n:\n \nAbstractDataset\n{\nD\n,\nT\n}\n\n\n\n\n\n\nA dedicated interface for datasets. It contains \nequally-sized datapoints\n of length \nD\n, represented by \nSVector{D, T}\n.\n\n\nWhen indexed with 1 index, a \ndataset\n is like a vector of datapoints.\n\n\nWhen indexed with 2 indices it behaves like a matrix that has each of the columns be the timeseries of each of the dynamic variables.\n\n\nDescription of indexing\n\n\nIn the following let \ni, j\n be integers,  \ntypeof(data) \n: AbstractDataset\n and \nv1, v2\n be \n: AbstractVector{Int}\n (\nv1, v2\n could also be ranges).\n\n\n\n\ndata[i]\n gives the \ni\nth datapoint (returns an \nSVector\n)\n\n\ndata[v1]\n will return a vector of datapoints\n\n\ndata[v1, :]\n using a \nColon\n as a second index will return a \nDataset\n of these points\n\n\ndata[:, j]\n gives the \nj\nth variable timeseries, as \nVector\n\n\ndata[v1, v2]\n returns a \nDataset\n with the appropriate entries (first indices being \"time\"/point index, while second being dynamic variables)\n\n\ndata[i, j]\n value of the \nj\nth variable, at the \ni\nth timepoint\n\n\n\n\nUse \nMatrix(dataset)\n or \nDataset(matrix)\n to convert. It is assumed that each \ncolumn\n of the \nmatrix\n is one dynamic variable. If you have various timeseries vectors \nx, y, z, ...\n pass them like \nDataset(x, y, z, ...)\n. You can use \ncolumns(dataset)\n to obtain the reverse, i.e. all columns of the dataset in a tuple.\n\n\n\n\nIn essence a \nDataset\n is simply a container for a \nVector\n of \nSVector\ns. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the \ncolumn\n direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nhen\n,\n \n10000\n)\n \n# this returns a dataset\n\n\nfor\n \npoint\n \nin\n \ndata\n\n\n# do stuff with each datapoint\n\n\n# (vector with as many elements as system dimension)\n\n\nend\n\n\n\n\n\n\nMost functions from \nDynamicalSystems.jl\n that manipulate and use data are expecting an \nAbstractDataset\n subtype. This allows us to define efficient methods that coordinate well with each other, like e.g. \nneighborhood\n.\n\n\nIf given a matrix, we first convert to \nDataset\n. This means that you should \nfirst convert\n your data to a \nDataset\n if you want to call functions more than once, to avoid constantly converting.\n\n\n\n\nDataset Functions\n\n\nFunctions that operate on datasets.\n\n\n#\n\n\nDelayEmbeddings.minima\n \n \nFunction\n.\n\n\nminima\n(\ndataset\n)\n\n\n\n\n\n\nReturn an \nSVector\n that contains the minimum elements of each timeseries of the dataset.\n\n\n#\n\n\nDelayEmbeddings.maxima\n \n \nFunction\n.\n\n\nmaxima\n(\ndataset\n)\n\n\n\n\n\n\nReturn an \nSVector\n that contains the maximum elements of each timeseries of the dataset.\n\n\n#\n\n\nDelayEmbeddings.minmaxima\n \n \nFunction\n.\n\n\nminmaxima\n(\ndataset\n)\n\n\n\n\n\n\nReturn \nminima(dataset), maxima(dataset)\n without doing the computation twice.\n\n\n#\n\n\nDelayEmbeddings.columns\n \n \nFunction\n.\n\n\ncolumns\n(\ndataset\n)\n \n-\n \nx\n,\n \ny\n,\n \nz\n,\n \n...\n\n\n\n\n\n\nReturn the individual columns of the dataset.\n\n\n\n\n\n\nDataset I/O\n\n\nInput/output functionality for an \nAbstractDataset\n is already achieved using base Julia, specifically \nwritedlm\n and \nreaddlm\n.\n\n\nThe thing to note is that all data of an \nAbstractDataset\n is contained within its field \ndata\n.\n\n\nTo write and read a dataset, simply do:\n\n\nusing\n \nDelimitedFiles\n\n\n\ndata\n \n=\n \nDataset\n(\nrand\n(\n1000\n,\n \n2\n))\n\n\n\n# I will write and read using delimiter \n,\n\n\nwritedlm\n(\ndata.txt\n,\n \ndata\n.\ndata\n,\n \n,\n)\n\n\n\n# Don\nt forget to convert the matrix to a Dataset when reading\n\n\ndata\n \n=\n \nDataset\n(\nreaddlm\n(\ndata.txt\n,\n \n,\n,\n \nFloat64\n))\n\n\n\n\n\n\n\n\n\n\nNeighborhoods in a dataset\n\n\nCombining the excellent performance of \nNearestNeighbors.jl\n with the \nAbstractDataset\n allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of \nAbstractNeighborhood\n.\n\n\n#\n\n\nDelayEmbeddings.neighborhood\n \n \nFunction\n.\n\n\nneighborhood\n(\npoint\n,\n \ntree\n,\n \nntype\n)\n\n\nneighborhood\n(\npoint\n,\n \ntree\n,\n \nntype\n,\n \nn\n::\nInt\n,\n \nw\n::\nInt\n \n=\n \n1\n)\n\n\n\n\n\n\nReturn a vector of indices which are the neighborhood of \npoint\n in some \ndata\n, where the \ntree\n was created using \ntree = KDTree(data [, metric])\n. The \nntype\n is the type of neighborhood and can be any subtype of \nAbstractNeighborhood\n.\n\n\nUse the second method when the \npoint\n belongs in the data, i.e. \npoint = data[n]\n. Then \nw\n stands for the Theiler window (positive integer). Only points that have index \nabs(i - n) \u2265 w\n are returned as a neighborhood, to exclude close temporal neighbors. The default \nw=1\n is the case of excluding the \npoint\n itself.\n\n\nReferences\n\n\nneighborhood\n simply interfaces the functions \nknn\n and \ninrange\n from \nNearestNeighbors.jl\n by using the argument \nntype\n.\n\n\n#\n\n\nDelayEmbeddings.AbstractNeighborhood\n \n \nType\n.\n\n\nAbstractNeighborhood\n\n\n\n\n\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\n\nConcrete subtypes:\n\n\n\n\nFixedMassNeighborhood(K::Int)\n : The neighborhood of a point consists of the \nK\n nearest neighbors of the point.\n\n\nFixedSizeNeighborhood(\u03b5::Real)\n : The neighborhood of a point consists of all neighbors that have distance \n \n\u03b5\n from the point.\n\n\n\n\nSee \nneighborhood\n for more.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/embedding/dataset/#numerical-data", 
            "text": "Numerical data in  DynamicalSystems.jl  is most often represented by a structure called  Dataset  #  DelayEmbeddings.Dataset     Type .  Dataset { D ,   T }   :   AbstractDataset { D , T }   A dedicated interface for datasets. It contains  equally-sized datapoints  of length  D , represented by  SVector{D, T} .  When indexed with 1 index, a  dataset  is like a vector of datapoints.  When indexed with 2 indices it behaves like a matrix that has each of the columns be the timeseries of each of the dynamic variables.  Description of indexing  In the following let  i, j  be integers,   typeof(data)  : AbstractDataset  and  v1, v2  be  : AbstractVector{Int}  ( v1, v2  could also be ranges).   data[i]  gives the  i th datapoint (returns an  SVector )  data[v1]  will return a vector of datapoints  data[v1, :]  using a  Colon  as a second index will return a  Dataset  of these points  data[:, j]  gives the  j th variable timeseries, as  Vector  data[v1, v2]  returns a  Dataset  with the appropriate entries (first indices being \"time\"/point index, while second being dynamic variables)  data[i, j]  value of the  j th variable, at the  i th timepoint   Use  Matrix(dataset)  or  Dataset(matrix)  to convert. It is assumed that each  column  of the  matrix  is one dynamic variable. If you have various timeseries vectors  x, y, z, ...  pass them like  Dataset(x, y, z, ...) . You can use  columns(dataset)  to obtain the reverse, i.e. all columns of the dataset in a tuple.   In essence a  Dataset  is simply a container for a  Vector  of  SVector s. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the  column  direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:  using   DynamicalSystems  hen   =   Systems . henon ()  data   =   trajectory ( hen ,   10000 )   # this returns a dataset  for   point   in   data  # do stuff with each datapoint  # (vector with as many elements as system dimension)  end   Most functions from  DynamicalSystems.jl  that manipulate and use data are expecting an  AbstractDataset  subtype. This allows us to define efficient methods that coordinate well with each other, like e.g.  neighborhood .  If given a matrix, we first convert to  Dataset . This means that you should  first convert  your data to a  Dataset  if you want to call functions more than once, to avoid constantly converting.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/embedding/dataset/#dataset-functions", 
            "text": "Functions that operate on datasets.  #  DelayEmbeddings.minima     Function .  minima ( dataset )   Return an  SVector  that contains the minimum elements of each timeseries of the dataset.  #  DelayEmbeddings.maxima     Function .  maxima ( dataset )   Return an  SVector  that contains the maximum elements of each timeseries of the dataset.  #  DelayEmbeddings.minmaxima     Function .  minmaxima ( dataset )   Return  minima(dataset), maxima(dataset)  without doing the computation twice.  #  DelayEmbeddings.columns     Function .  columns ( dataset )   -   x ,   y ,   z ,   ...   Return the individual columns of the dataset.", 
            "title": "Dataset Functions"
        }, 
        {
            "location": "/embedding/dataset/#dataset-io", 
            "text": "Input/output functionality for an  AbstractDataset  is already achieved using base Julia, specifically  writedlm  and  readdlm .  The thing to note is that all data of an  AbstractDataset  is contained within its field  data .  To write and read a dataset, simply do:  using   DelimitedFiles  data   =   Dataset ( rand ( 1000 ,   2 ))  # I will write and read using delimiter  ,  writedlm ( data.txt ,   data . data ,   , )  # Don t forget to convert the matrix to a Dataset when reading  data   =   Dataset ( readdlm ( data.txt ,   , ,   Float64 ))", 
            "title": "Dataset I/O"
        }, 
        {
            "location": "/embedding/dataset/#neighborhoods-in-a-dataset", 
            "text": "Combining the excellent performance of  NearestNeighbors.jl  with the  AbstractDataset  allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of  AbstractNeighborhood .  #  DelayEmbeddings.neighborhood     Function .  neighborhood ( point ,   tree ,   ntype )  neighborhood ( point ,   tree ,   ntype ,   n :: Int ,   w :: Int   =   1 )   Return a vector of indices which are the neighborhood of  point  in some  data , where the  tree  was created using  tree = KDTree(data [, metric]) . The  ntype  is the type of neighborhood and can be any subtype of  AbstractNeighborhood .  Use the second method when the  point  belongs in the data, i.e.  point = data[n] . Then  w  stands for the Theiler window (positive integer). Only points that have index  abs(i - n) \u2265 w  are returned as a neighborhood, to exclude close temporal neighbors. The default  w=1  is the case of excluding the  point  itself.  References  neighborhood  simply interfaces the functions  knn  and  inrange  from  NearestNeighbors.jl  by using the argument  ntype .  #  DelayEmbeddings.AbstractNeighborhood     Type .  AbstractNeighborhood   Supertype of methods for deciding the neighborhood of points for a given point.  Concrete subtypes:   FixedMassNeighborhood(K::Int)  : The neighborhood of a point consists of the  K  nearest neighbors of the point.  FixedSizeNeighborhood(\u03b5::Real)  : The neighborhood of a point consists of all neighbors that have distance    \u03b5  from the point.   See  neighborhood  for more.", 
            "title": "Neighborhoods in a dataset"
        }, 
        {
            "location": "/embedding/reconstruction/", 
            "text": "A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as \ndelay coordinates embedding\n or delay coordinates \nreconstruction\n.\n\n\n\n\nReconstruct/Embed\n\n\nDelay embedding reconstructions are done through \nreconstruct\n or \nembed\n:\n\n\n#\n\n\nDelayEmbeddings.reconstruct\n \n \nFunction\n.\n\n\nreconstruct\n(\ns\n,\n \n\u03b3\n,\n \n\u03c4\n)\n\n\n\n\n\n\nReconstruct \ns\n using the delay coordinates embedding with \n\u03b3\n temporal neighbors and delay \n\u03c4\n and return the result as a \nDataset\n.\n\n\nSee \nembed\n for the version that accepts the embedding dimension \nD = \u03b3+1\n directly.\n\n\nDescription\n\n\nSingle Timeseries\n\n\nIf \n\u03c4\n is an integer, then the \nn\nn\n-th entry of the embedded space is\n\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+\u03b3\\tau))\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+\u03b3\\tau))\n\n\n\n\n\nIf instead \n\u03c4\n is a vector of integers, so that \nlength(\u03c4) == \u03b3\n, then the \nn\nn\n-th entry is\n\n\n\n\n\n(s(n), s(n+\\tau[1]), s(n+\\tau[2]), \\dots, s(n+\\tau[\u03b3]))\n\n\n\n\n(s(n), s(n+\\tau[1]), s(n+\\tau[2]), \\dots, s(n+\\tau[\u03b3]))\n\n\n\n\n\nThe reconstructed dataset can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper \n\u03b3\n and \n\u03c4\n. This is known as the Takens embedding theorem [1, 2]. The case of different delay times allows reconstructing systems with many time scales, see [3].\n\n\nNotice\n - The dimension of the returned dataset (i.e. embedding dimension) is \n\u03b3+1\n!\n\n\nMultiple Timeseries\n\n\nTo make a reconstruction out of a multiple timeseries (i.e. trajectory) the number of timeseries must be known by type, so \ns\n can be either:\n\n\n\n\ns::AbstractDataset{B}\n\n\ns::SizedAray{A, B}\n\n\n\n\nIf the trajectory is for example \n(x, y)\n(x, y)\n and \n\u03c4\n is integer, then the \nn\nn\n-th entry of the embedded space is\n\n\n\n\n\n(x(n), y(n), x(n+\\tau), y(n+\\tau), \\dots, x(n+\u03b3\\tau), y(n+\u03b3\\tau))\n\n\n\n\n(x(n), y(n), x(n+\\tau), y(n+\\tau), \\dots, x(n+\u03b3\\tau), y(n+\u03b3\\tau))\n\n\n\n\n\nIf \n\u03c4\n is an \nAbstractMatrix{Int}\n, so that \nsize(\u03c4) == (\u03b3, B)\n, then we have\n\n\n\n\n\n(x(n), y(n), x(n+\\tau[1, 1]), y(n+\\tau[1, 2]), \\dots, x(n+\\tau[\u03b3, 1]), y(n+\\tau[\u03b3, 2]))\n\n\n\n\n(x(n), y(n), x(n+\\tau[1, 1]), y(n+\\tau[1, 2]), \\dots, x(n+\\tau[\u03b3, 1]), y(n+\\tau[\u03b3, 2]))\n\n\n\n\n\nNotice\n - The dimension of the returned dataset is \n(\u03b3+1)*B\n!\n\n\nReferences\n\n\n[1] : F. Takens, \nDetecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence\n, Lecture Notes in Mathematics \n366\n, Springer (1981)\n\n\n[2] : T. Sauer \net al.\n, J. Stat. Phys. \n65\n, pp 579 (1991)\n\n\n[3] : K. Judd \n A. Mees, \nPhysica D \n120\n, pp 273 (1998)\n\n\n#\n\n\nDelayEmbeddings.embed\n \n \nFunction\n.\n\n\nembed\n(\ns\n,\n \nD\n,\n \n\u03c4\n)\n\n\n\n\n\n\nPerform a delay coordinates embedding on signal \ns\n with embedding dimension \nD\n and delay time \n\u03c4\n. The result is returned as a \nDataset\n, which is a vector of static vectors.\n\n\nSee \nreconstruct\n for an advanced version that supports multiple delay times and can reconstruct multiple timeseries efficiently.\n\n\n\n\nHere are some examples of \nreconstruct\ning a 3D continuous chaotic system:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\ngissinger\n(\nones\n(\n3\n))\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n,\n \ndt\n \n=\n \n0.05\n)\n\n\n\nxyz\n \n=\n \ncolumns\n(\ndata\n)\n\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n12\n,\n10\n))\n\n\nk\n \n=\n \n1\n\n\nfor\n \ni\n \nin\n \n1\n:\n3\n\n    \nfor\n \n\u03c4\n \nin\n \n[\n5\n,\n \n30\n,\n \n100\n]\n\n        \nR\n \n=\n \nreconstruct\n(\nxyz\n[\ni\n],\n \n1\n,\n \n\u03c4\n)\n\n        \nax\n \n=\n \nsubplot\n(\n3\n,\n3\n,\nk\n)\n\n        \nplot\n(\nR\n[\n:\n,\n \n1\n],\n \nR\n[\n:\n,\n \n2\n],\n \ncolor\n \n=\n \nC\n$\n(\nk\n-\n1\n)\n,\n \nlw\n \n=\n \n0.8\n)\n\n        \ntitle\n(\nvar = \n$i\n, \u03c4 = \n$\u03c4\n)\n\n        \nglobal\n \nk\n+=\n1\n\n    \nend\n\n\nend\n\n\n\ntight_layout\n()\n\n\nsuptitle\n(\n2D reconstructed space\n)\n\n\nsubplots_adjust\n(\ntop\n=\n0.9\n)\n\n\n\n\n\n\n\n\n\n\n\u03c4\n and \ndt\n\n\nKeep in mind that whether a value of \n\u03c4\n is \"reasonable\" for continuous systems depends on \ndt\n. In the above example the value \n\u03c4=30\n is good, \nonly\n for the case of using \ndt = 0.05\n. For shorter/longer \ndt\n one has to adjust properly \n\u03c4\n so that their product \n\u03c4*dt\n is the same.\n\n\n\n\nYou can also \nreconstruct\n multidimensional timeseries. For this to be possible, the number of timeseries must be known by Type:\n\n\nusing\n \nStaticArrays\n:\n \nSize\n\n\na\n \n=\n \nrand\n(\n1000\n,\n \n3\n)\n \n# my trajectory\n\n\n\nA\n \n=\n \nSize\n(\n1000\n,\n \n3\n)(\na\n)\n \n# create array with the size as Type information\n\n\nR\n \n=\n \nreconstruct\n(\nA\n,\n \n2\n,\n \n2\n)\n \n#aaaall good\n\n\n\n\n\n\n9-dimensional Dataset{Float64} with 996 points\n 0.579701  0.583423  0.339023   0.387958  \u2026  0.458677  0.540187  0.15168  \n 0.154014  0.638022  0.775553   0.876439     0.660742  0.703415  0.722352 \n 0.387958  0.801119  0.670552   0.458677     0.534543  0.19187   0.781235 \n 0.876439  0.028197  0.435636   0.660742     0.73391   0.770822  0.101162 \n 0.458677  0.540187  0.15168    0.534543     0.132827  0.631728  0.97861  \n 0.660742  0.703415  0.722352   0.73391   \u2026  0.475827  0.921796  0.0842604\n 0.534543  0.19187   0.781235   0.132827     0.425608  0.294068  0.28675  \n 0.73391   0.770822  0.101162   0.475827     0.817156  0.848518  0.481871 \n 0.132827  0.631728  0.97861    0.425608     0.254286  0.133701  0.577632 \n 0.475827  0.921796  0.0842604  0.817156     0.218876  0.560254  0.0557962\n \u22ee                                        \u22f1                               \n 0.248187  0.986588  0.0440588  0.879716     0.578812  0.25225   0.314532 \n 0.442136  0.472563  0.598415   0.640914     0.319494  0.250638  0.438317 \n 0.879716  0.612561  0.745464   0.578812     0.561302  0.25014   0.19985  \n 0.640914  0.9293    0.441654   0.319494     0.650796  0.904613  0.902537 \n 0.578812  0.25225   0.314532   0.561302  \u2026  0.602465  0.715249  0.394259 \n 0.319494  0.250638  0.438317   0.650796     0.67249   0.533966  0.885619 \n 0.561302  0.25014   0.19985    0.602465     0.300294  0.662834  0.907772 \n 0.650796  0.904613  0.902537   0.67249      0.554132  0.589441  0.539833 \n 0.602465  0.715249  0.394259   0.300294     0.637452  0.845935  0.169613 \n\n\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n();\n \ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000\n)\n\n\nR\n \n=\n \nreconstruct\n(\ntr\n,\n \n2\n,\n \n2\n)\n \n# Dataset size is also known by Type!\n\n\n\n\n\n\n9-dimensional Dataset{Float64} with 9997 points\n 0.085     -0.121       0.075     \u2026  0.837347   0.0372633   0.555269\n 0.285813  -0.0675286   0.238038     0.51969    0.0616256   0.940906\n 0.76827   -0.038933    0.672094     0.966676  -0.00171595  0.2225  \n 0.681871   0.0508933   0.825263     0.112748   0.0674955   0.653573\n 0.837347   0.0372633   0.555269     0.386547  -0.0886542   0.869349\n 0.51969    0.0616256   0.940906  \u2026  0.910741  -0.0316828   0.411607\n 0.966676  -0.00171595  0.2225       0.306095   0.0689305   0.909129\n 0.112748   0.0674955   0.653573     0.824263  -0.056185    0.326064\n 0.386547  -0.0886542   0.869349     0.545332   0.0508239   0.819404\n 0.910741  -0.0316828   0.411607     0.954994   0.00453815  0.569534\n \u22ee                                \u22f1                                 \n 0.914702  -0.0315439   0.294266     0.90246    0.0242141   0.539502\n 0.289932   0.0641239   0.778698     0.335976   0.0735803   0.943945\n 0.793854  -0.0552801   0.664223     0.86657   -0.0497658   0.214728\n 0.62671    0.0557527   0.832001     0.430816   0.0535742   0.62743 \n 0.90246    0.0242141   0.539502  \u2026  0.936955  -0.0200112   0.894333\n 0.335976   0.0735803   0.943945     0.237481   0.0983265   0.353212\n 0.86657   -0.0497658   0.214728     0.681538  -0.0476555   0.883219\n 0.430816   0.0535742   0.62743      0.836353   0.0363264   0.380351\n 0.936955  -0.0200112   0.894333     0.515471   0.0534613   0.898152\n\n\n\n\n\n\n\nEmbedding Functors\n\n\nThe high level functions \nembed\n, \nreconstruct\n utilize a low-level interface for creating embedded vectors on-the-fly. The high level interface simply loops over the low level interface. The low level interface is composed of the following two structures:\n\n\n#\n\n\nDelayEmbeddings.DelayEmbedding\n \n \nType\n.\n\n\nDelayEmbedding\n(\n\u03b3\n,\n \n\u03c4\n)\n \n-\n \n`embedding`\n\n\n\n\n\n\nReturn a delay coordinates embedding structure to be used as a functor, given a timeseries and some index. Calling\n\n\nembedding\n(\ns\n,\n \nn\n)\n\n\n\n\n\n\nwill create the \nn\n-th reconstructed vector of the embedded space, which has \n\u03b3\n temporal neighbors with delay(s) \n\u03c4\n. See \nreconstruct\n for more.\n\n\nBe very careful when choosing \nn\n, because \n@inbounds\n is used internally.\n\n\n#\n\n\nDelayEmbeddings.MTDelayEmbedding\n \n \nType\n.\n\n\nMTDelayEmbedding\n(\n\u03b3\n,\n \n\u03c4\n,\n \nB\n)\n \n-\n \n`embedding`\n\n\n\n\n\n\nReturn a delay coordinates embedding structure to be used as a functor, given multiple timeseries (\nB\n in total), either as a \nDataset\n or a \nSizedArray\n), and some index. Calling\n\n\nembedding\n(\ns\n,\n \nn\n)\n\n\n\n\n\n\nwill create the \nn\n-th reconstructed vector of the embedded space, which has \n\u03b3\n temporal neighbors with delay(s) \n\u03c4\n. See \nreconstruct\n for more.\n\n\nBe very careful when choosing \nn\n, because \n@inbounds\n is used internally.", 
            "title": "Delay Coordinates"
        }, 
        {
            "location": "/embedding/reconstruction/#reconstructembed", 
            "text": "Delay embedding reconstructions are done through  reconstruct  or  embed :  #  DelayEmbeddings.reconstruct     Function .  reconstruct ( s ,   \u03b3 ,   \u03c4 )   Reconstruct  s  using the delay coordinates embedding with  \u03b3  temporal neighbors and delay  \u03c4  and return the result as a  Dataset .  See  embed  for the version that accepts the embedding dimension  D = \u03b3+1  directly.  Description  Single Timeseries  If  \u03c4  is an integer, then the  n n -th entry of the embedded space is   \n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+\u03b3\\tau))  \n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+\u03b3\\tau))   If instead  \u03c4  is a vector of integers, so that  length(\u03c4) == \u03b3 , then the  n n -th entry is   \n(s(n), s(n+\\tau[1]), s(n+\\tau[2]), \\dots, s(n+\\tau[\u03b3]))  \n(s(n), s(n+\\tau[1]), s(n+\\tau[2]), \\dots, s(n+\\tau[\u03b3]))   The reconstructed dataset can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper  \u03b3  and  \u03c4 . This is known as the Takens embedding theorem [1, 2]. The case of different delay times allows reconstructing systems with many time scales, see [3].  Notice  - The dimension of the returned dataset (i.e. embedding dimension) is  \u03b3+1 !  Multiple Timeseries  To make a reconstruction out of a multiple timeseries (i.e. trajectory) the number of timeseries must be known by type, so  s  can be either:   s::AbstractDataset{B}  s::SizedAray{A, B}   If the trajectory is for example  (x, y) (x, y)  and  \u03c4  is integer, then the  n n -th entry of the embedded space is   \n(x(n), y(n), x(n+\\tau), y(n+\\tau), \\dots, x(n+\u03b3\\tau), y(n+\u03b3\\tau))  \n(x(n), y(n), x(n+\\tau), y(n+\\tau), \\dots, x(n+\u03b3\\tau), y(n+\u03b3\\tau))   If  \u03c4  is an  AbstractMatrix{Int} , so that  size(\u03c4) == (\u03b3, B) , then we have   \n(x(n), y(n), x(n+\\tau[1, 1]), y(n+\\tau[1, 2]), \\dots, x(n+\\tau[\u03b3, 1]), y(n+\\tau[\u03b3, 2]))  \n(x(n), y(n), x(n+\\tau[1, 1]), y(n+\\tau[1, 2]), \\dots, x(n+\\tau[\u03b3, 1]), y(n+\\tau[\u03b3, 2]))   Notice  - The dimension of the returned dataset is  (\u03b3+1)*B !  References  [1] : F. Takens,  Detecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence , Lecture Notes in Mathematics  366 , Springer (1981)  [2] : T. Sauer  et al. , J. Stat. Phys.  65 , pp 579 (1991)  [3] : K. Judd   A. Mees,  Physica D  120 , pp 273 (1998)  #  DelayEmbeddings.embed     Function .  embed ( s ,   D ,   \u03c4 )   Perform a delay coordinates embedding on signal  s  with embedding dimension  D  and delay time  \u03c4 . The result is returned as a  Dataset , which is a vector of static vectors.  See  reconstruct  for an advanced version that supports multiple delay times and can reconstruct multiple timeseries efficiently.   Here are some examples of  reconstruct ing a 3D continuous chaotic system:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . gissinger ( ones ( 3 ))  data   =   trajectory ( ds ,   1000.0 ,   dt   =   0.05 )  xyz   =   columns ( data )  figure ( figsize   =   ( 12 , 10 ))  k   =   1  for   i   in   1 : 3 \n     for   \u03c4   in   [ 5 ,   30 ,   100 ] \n         R   =   reconstruct ( xyz [ i ],   1 ,   \u03c4 ) \n         ax   =   subplot ( 3 , 3 , k ) \n         plot ( R [ : ,   1 ],   R [ : ,   2 ],   color   =   C $ ( k - 1 ) ,   lw   =   0.8 ) \n         title ( var =  $i , \u03c4 =  $\u03c4 ) \n         global   k += 1 \n     end  end  tight_layout ()  suptitle ( 2D reconstructed space )  subplots_adjust ( top = 0.9 )     \u03c4  and  dt  Keep in mind that whether a value of  \u03c4  is \"reasonable\" for continuous systems depends on  dt . In the above example the value  \u03c4=30  is good,  only  for the case of using  dt = 0.05 . For shorter/longer  dt  one has to adjust properly  \u03c4  so that their product  \u03c4*dt  is the same.   You can also  reconstruct  multidimensional timeseries. For this to be possible, the number of timeseries must be known by Type:  using   StaticArrays :   Size  a   =   rand ( 1000 ,   3 )   # my trajectory  A   =   Size ( 1000 ,   3 )( a )   # create array with the size as Type information  R   =   reconstruct ( A ,   2 ,   2 )   #aaaall good   9-dimensional Dataset{Float64} with 996 points\n 0.579701  0.583423  0.339023   0.387958  \u2026  0.458677  0.540187  0.15168  \n 0.154014  0.638022  0.775553   0.876439     0.660742  0.703415  0.722352 \n 0.387958  0.801119  0.670552   0.458677     0.534543  0.19187   0.781235 \n 0.876439  0.028197  0.435636   0.660742     0.73391   0.770822  0.101162 \n 0.458677  0.540187  0.15168    0.534543     0.132827  0.631728  0.97861  \n 0.660742  0.703415  0.722352   0.73391   \u2026  0.475827  0.921796  0.0842604\n 0.534543  0.19187   0.781235   0.132827     0.425608  0.294068  0.28675  \n 0.73391   0.770822  0.101162   0.475827     0.817156  0.848518  0.481871 \n 0.132827  0.631728  0.97861    0.425608     0.254286  0.133701  0.577632 \n 0.475827  0.921796  0.0842604  0.817156     0.218876  0.560254  0.0557962\n \u22ee                                        \u22f1                               \n 0.248187  0.986588  0.0440588  0.879716     0.578812  0.25225   0.314532 \n 0.442136  0.472563  0.598415   0.640914     0.319494  0.250638  0.438317 \n 0.879716  0.612561  0.745464   0.578812     0.561302  0.25014   0.19985  \n 0.640914  0.9293    0.441654   0.319494     0.650796  0.904613  0.902537 \n 0.578812  0.25225   0.314532   0.561302  \u2026  0.602465  0.715249  0.394259 \n 0.319494  0.250638  0.438317   0.650796     0.67249   0.533966  0.885619 \n 0.561302  0.25014   0.19985    0.602465     0.300294  0.662834  0.907772 \n 0.650796  0.904613  0.902537   0.67249      0.554132  0.589441  0.539833 \n 0.602465  0.715249  0.394259   0.300294     0.637452  0.845935  0.169613   ds   =   Systems . towel ();   tr   =   trajectory ( ds ,   10000 )  R   =   reconstruct ( tr ,   2 ,   2 )   # Dataset size is also known by Type!   9-dimensional Dataset{Float64} with 9997 points\n 0.085     -0.121       0.075     \u2026  0.837347   0.0372633   0.555269\n 0.285813  -0.0675286   0.238038     0.51969    0.0616256   0.940906\n 0.76827   -0.038933    0.672094     0.966676  -0.00171595  0.2225  \n 0.681871   0.0508933   0.825263     0.112748   0.0674955   0.653573\n 0.837347   0.0372633   0.555269     0.386547  -0.0886542   0.869349\n 0.51969    0.0616256   0.940906  \u2026  0.910741  -0.0316828   0.411607\n 0.966676  -0.00171595  0.2225       0.306095   0.0689305   0.909129\n 0.112748   0.0674955   0.653573     0.824263  -0.056185    0.326064\n 0.386547  -0.0886542   0.869349     0.545332   0.0508239   0.819404\n 0.910741  -0.0316828   0.411607     0.954994   0.00453815  0.569534\n \u22ee                                \u22f1                                 \n 0.914702  -0.0315439   0.294266     0.90246    0.0242141   0.539502\n 0.289932   0.0641239   0.778698     0.335976   0.0735803   0.943945\n 0.793854  -0.0552801   0.664223     0.86657   -0.0497658   0.214728\n 0.62671    0.0557527   0.832001     0.430816   0.0535742   0.62743 \n 0.90246    0.0242141   0.539502  \u2026  0.936955  -0.0200112   0.894333\n 0.335976   0.0735803   0.943945     0.237481   0.0983265   0.353212\n 0.86657   -0.0497658   0.214728     0.681538  -0.0476555   0.883219\n 0.430816   0.0535742   0.62743      0.836353   0.0363264   0.380351\n 0.936955  -0.0200112   0.894333     0.515471   0.0534613   0.898152", 
            "title": "Reconstruct/Embed"
        }, 
        {
            "location": "/embedding/reconstruction/#embedding-functors", 
            "text": "The high level functions  embed ,  reconstruct  utilize a low-level interface for creating embedded vectors on-the-fly. The high level interface simply loops over the low level interface. The low level interface is composed of the following two structures:  #  DelayEmbeddings.DelayEmbedding     Type .  DelayEmbedding ( \u03b3 ,   \u03c4 )   -   `embedding`   Return a delay coordinates embedding structure to be used as a functor, given a timeseries and some index. Calling  embedding ( s ,   n )   will create the  n -th reconstructed vector of the embedded space, which has  \u03b3  temporal neighbors with delay(s)  \u03c4 . See  reconstruct  for more.  Be very careful when choosing  n , because  @inbounds  is used internally.  #  DelayEmbeddings.MTDelayEmbedding     Type .  MTDelayEmbedding ( \u03b3 ,   \u03c4 ,   B )   -   `embedding`   Return a delay coordinates embedding structure to be used as a functor, given multiple timeseries ( B  in total), either as a  Dataset  or a  SizedArray ), and some index. Calling  embedding ( s ,   n )   will create the  n -th reconstructed vector of the embedded space, which has  \u03b3  temporal neighbors with delay(s)  \u03c4 . See  reconstruct  for more.  Be very careful when choosing  n , because  @inbounds  is used internally.", 
            "title": "Embedding Functors"
        }, 
        {
            "location": "/embedding/estimate/", 
            "text": "Estimating Delay Embedding Parameters\n\n\nThe following functions can estimate good values that can be used in \nreconstruct\n for either the delay time or the number of temporal neighbors.\n\n\n\n\nDelay Time\n\n\n#\n\n\nDelayEmbeddings.estimate_delay\n \n \nFunction\n.\n\n\nestimate_delay\n(\ns\n,\n \nmethod\n::\nString\n \n[,\n \n\u03c4s\n \n=\n \n1\n:\n2\n:\n100\n];\n \nkwargs\n...\n)\n \n-\n \n\u03c4\n\n\n\n\n\n\nEstimate an optimal delay to be used in \nreconstruct\n or \nembed\n. The \nmethod\n can be one of the following:\n\n\n\n\n\"ac_zero\"\n : first delay at which the auto-correlation function becomes \n0.\n\n\n\"ac_min\"\n : delay of first minimum of the auto-correlation function.\n\n\n\"mi_min\"\n : delay of first minimum of mutual information of \ns\n with itself (shifted for various \n\u03c4s\n). Keywords \nnbins, binwidth\n are propagated into \nmutualinformation\n.\n\n\n\"exp_decay\"\n : \nexponential_decay_fit\n of the correlation function rounded  to an integer (uses least squares on \nc(t) = exp(-t/\u03c4)\n to find \n\u03c4\n).\n\n\n\"exp_extrema\"\n : same as above but the exponential fit is done to the absolute value of the local extrema of the correlation function.\n\n\n\n\nBoth the mutual information and correlation function (\nautocor\n) are computed \nonly\n for delays \n\u03c4s\n. This means that the \nmin\n methods can never return the first value of \n\u03c4s\n!\n\n\nThe method \nmi_min\n is significantly more accurate than the others and also returns good results for most timeseries. It is however the slowest method (but still quite fast!).\n\n\n#\n\n\nDelayEmbeddings.exponential_decay_fit\n \n \nFunction\n.\n\n\nexponential_decay_fit\n(\nx\n,\n \ny\n,\n \nweight\n \n=\n \n:\nequal\n)\n \n-\n \n\u03c4\n\n\n\n\n\n\nPerform a least square fit of the form \ny = exp(-x/\u03c4)\n and return \n\u03c4\n. Taken from:  http://mathworld.wolfram.com/LeastSquaresFittingExponential.html. Assumes equal lengths of \nx, y\n and that \ny \u2265 0\n.\n\n\nTo use the method that gives more weight to small values of \ny\n, use \nweight = :small\n.\n\n\n\n\nMutual Information\n\n\n#\n\n\nDelayEmbeddings.mutualinformation\n \n \nFunction\n.\n\n\nmutualinformation\n(\ns\n,\n \n\u03c4s\n[;\n \nnbins\n,\n \nbinwidth\n])\n\n\n\n\n\n\nCalculate the mutual information between the time series \ns\n and its images delayed by \n\u03c4\n points for \n\u03c4\n \u2208 \n\u03c4s\n, using an \nimprovement\n of the method outlined by Fraser \n Swinney in [1].\n\n\nDescription\n\n\nThe joint space of \ns\n and its \n\u03c4\n-delayed image (\ns\u03c4\n) is partitioned as a rectangular grid, and the mutual information is computed from the joint and marginal frequencies of \ns\n and \ns\u03c4\n in the grid as defined in [1]. The mutual information values are returned in a vector of the same length as \n\u03c4s\n.\n\n\nIf any of the optional keyword parameters is given, the grid will be a homogeneous partition of the space where \ns\n and \ns\u03c4\n are defined. The margins of that partition will be divided in a number of bins equal to \nnbins\n, such that the width of each bin will be \nbinwidth\n, and the range of nonzero values of \ns\n will be in the centre. If only of those two parameters is given, the other will be automatically calculated to adjust the size of the grid to the area where \ns\n and \ns\u03c4\n are nonzero.\n\n\nIf no parameter is given, the space will be partitioned by a recursive bisection algorithm based on the method given in [1].\n\n\nNotice that the recursive method of [1] evaluates the joint frequencies of \ns\n and \ns\u03c4\n in each cell resulting from a partition, and stops when the data points are uniformly distributed across the sub-partitions of the following levels. For performance and stability reasons, the automatic partition method implemented in this function is only used to divide the axes of the grid, using the marginal frequencies of \ns\n.\n\n\nReferences\n\n\n[1]: Fraser A.M. \n Swinney H.L. \"Independent coordinates for strange attractors from mutual information\" \nPhys. Rev. A 33\n(2), 1986, 1134:1140.\n\n\n\n\nBesides the above method, there also exists code that computes mutual information in two other ways. Both ways are in the file \nDelayEmbedding\\src\\old_mutual_info.jl\n. The first way is the original algorithm of Fraser, while the second is the algorithm of Kraskov. Both of these implementations are inferior to the one exposed here (performance-wise).\n\n\n\n\nEmbedding Dimension\n\n\n#\n\n\nDelayEmbeddings.estimate_dimension\n \n \nFunction\n.\n\n\nestimate_dimension\n(\ns\n::\nAbstractVector\n,\n \n\u03c4\n::\nInt\n,\n \n\u03b3s\n \n=\n \n1\n:\n5\n,\n \nmethod\n \n=\n \nafnn\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCompute a quantity that can estimate an optimal amount of temporal neighbors \n\u03b3\n to be used in \nreconstruct\n or \nembed\n.\n\n\nDescription\n\n\nGiven the scalar timeseries \ns\n and the embedding delay \n\u03c4\n compute a quantity for each \n\u03b3 \u2208 \u03b3s\n based on the \"nearest neighbors\" in the embedded time series.\n\n\nThe quantity that is calculated depends on the algorithm defined by the string \nmethod\n:\n\n\n\n\n\"afnn\"\n (default) is Cao's \"Averaged False Nearest Neighbors\" method [1], which   gives a ratio of distances between nearest neighbors. This ratio saturates   around \n1.0\n near the optimal value of \n\u03b3\n (see \nafnn\n).\n\n\n\"fnn\"\n is Kennel's \"False Nearest Neighbors\" method [2], which gives the   number of points that cease to be \"nearest neighbors\" when the dimension   increases. This number drops down to zero near the optimal value of \n\u03b3\n.   This method accepts the keyword arguments \nrtol\n and \natol\n, which stand   for the \"tolerances\" required by Kennel's algorithm (see \nfnn\n).\n\n\n\"f1nn\"\n is Krakovsk\u00e1's \"False First Nearest Neighbors\" method [3], which   gives the ratio of pairs of points that cease to be \"nearest neighbors\"   when the dimension increases. This number drops down to zero near the   optimal value of \n\u03b3\n (see \nf1nn\n).\n\n\n\n\n\"afnn\"\n and \n\"f1nn\"\n also support the \nmetric\n keyword, which can be any of \nCityblock(), Euclidean(), Chebyshev()\n. This metric is used both for computing the nearest neighbors (\nKDTree\ns) as well as the distances necessary for Cao's method (eqs. (2, 3) of [1]). Defaults to \nEuclidean()\n (note that [1] used \nChebyshev\n).\n\n\nPlease be aware that in \nDynamicalSystems.jl\n \n\u03b3\n stands for the amount of temporal neighbors and not the embedding dimension (\nD = \u03b3 + 1\n, see also \nembed\n).\n\n\nReferences\n\n\n[1] : Liangyue Cao, \nPhysica D, pp. 43-50 (1997)\n\n\n[2] : M. Kennel \net al.\n, \nPhys. Review A \n45\n(6), 3403-3411\n (1992).\n\n\n[3] : Anna Krakovsk\u00e1 \net al.\n, \nJ. Complex Sys. 932750 (2015)\n\n\n\n\nExample\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nroessler\n()\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n;\n \ndt\n \n=\n \n0.05\n)\n\n\n\n\u03c4\n \n=\n \nestimate_delay\n(\ntr\n[\n:\n,\n \n1\n],\n \nmi_min\n)\n \n# first minimum of mutual information\n\n\n\nfigure\n();\n\n\nfor\n \nmethod\n \nin\n \n[\nafnn\n,\n \nfnn\n,\n \nf1nn\n]\n\n    \nDs\n \n=\n \nestimate_dimension\n(\ntr\n[\n:\n,\n \n1\n],\n \n\u03c4\n,\n \n1\n:\n6\n,\n \nmethod\n)\n\n    \nplot\n(\n1\n:\n6\n,\n \nDs\n \n./\n \nmaximum\n(\nDs\n),\n \nlabel\n \n=\n \nmethod\n,\n \nmarker\n \n=\n \no\n)\n\n\nend\n\n\nlegend\n();\n \nxlabel\n(\n\\$\\\\\ngamma\n\\$\n (temporal neighbors)\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\n\n\nFunctions\n\n\n#\n\n\nDelayEmbeddings.fnn\n \n \nFunction\n.\n\n\nfnn\n(\ns\n::\nAbstractVector\n,\n \n\u03c4\n:\nInt\n,\n \n\u03b3s\n \n=\n \n1\n:\n5\n;\n \nrtol\n=\n10.0\n,\n \natol\n=\n2.0\n)\n\n\n\n\n\n\nCalculate the number of \"false nearest neighbors\" (FNN) of the datasets created from \ns\n with a sequence of \n\u03c4\n-delayed temporal neighbors.\n\n\nDescription\n\n\nGiven a dataset made by embedding \ns\n with \n\u03b3\n temporal neighbors and delay \n\u03c4\n, the \"false nearest neighbors\" (FNN) are the pairs of points that are nearest to each other at dimension \n\u03b3\n, but are separated at dimension \n\u03b3+1\n. Kennel's criteria for detecting FNN are based on a threshold for the relative increment of the distance between the nearest neighbors (\nrtol\n, eq. 4 in [1]), and another threshold for the ratio between the increased distance and the \"size of the attractor\" (\natol\n, eq. 5 in [1]). These thresholds are given as keyword arguments.\n\n\nThe returned value is a vector with the number of FNN for each \n\u03b3 \u2208 \u03b3s\n. The optimal value for \n\u03b3\n is found at the point where the number of FNN approaches zero.\n\n\nSee also: \nestimate_dimension\n, \nafnn\n, \nf1nn\n.\n\n\nReferences\n\n\n[1] : M. Kennel \net al.\n, \"Determining embedding dimension for phase-space reconstruction using a geometrical construction\", \nPhys. Review A 45\n(6), 3403-3411 (1992).\n\n\n#\n\n\nDelayEmbeddings.afnn\n \n \nFunction\n.\n\n\nafnn\n(\ns\n::\nAbstractVector\n,\n \n\u03c4\n:\nInt\n,\n \n\u03b3s\n \n=\n \n1\n:\n5\n,\n \nmetric\n=\nEuclidean\n())\n\n\n\n\n\n\nCompute the parameter E\u2081 of Cao's \"averaged false nearest neighbors\" method for determining the minimum embedding dimension of the time series \ns\n, with a sequence of \n\u03c4\n-delayed temporal neighbors [1].\n\n\nDescription\n\n\nGiven the scalar timeseries \ns\n and the embedding delay \n\u03c4\n compute the values of \nE\u2081\n for each \n\u03b3 \u2208 \u03b3s\n, according to Cao's Method (eq. 3 of [1]).\n\n\nThis quantity is a ratio of the averaged distances between the nearest neighbors of the reconstructed time series, which quantifies the increment of those distances when the number of temporal neighbors changes from \n\u03b3\n to \n\u03b3+1\n.\n\n\nReturn the vector of all computed \nE\u2081\ns. To estimate a good value for \n\u03b3\n from this, find \n\u03b3\n for which the value \nE\u2081\n saturates at some value around 1.\n\n\nNote: This method does not work for datasets with perfectly periodic signals.\n\n\nSee also: \nestimate_dimension\n, \nfnn\n, \nf1nn\n.\n\n\nReferences\n\n\n[1] : Liangyue Cao, \nPhysica D, pp. 43-50 (1997)\n\n\n#\n\n\nDelayEmbeddings.f1nn\n \n \nFunction\n.\n\n\nf1nn\n(\ns\n::\nAbstractVector\n,\n \n\u03c4\n:\nInt\n,\n \n\u03b3s\n \n=\n \n1\n:\n5\n,\n \nmetric\n \n=\n \nEuclidean\n())\n\n\n\n\n\n\nCalculate the ratio of \"false first nearest neighbors\" (FFNN) of the datasets created from \ns\n with a sequence of \n\u03c4\n-delayed temporal neighbors.\n\n\nDescription\n\n\nGiven a dataset made by embedding \ns\n with \n\u03b3\n temporal neighbors and delay \n\u03c4\n, the \"first nearest neighbors\" (FFNN) are the pairs of points that are nearest to each other at dimension \n\u03b3\n that cease to be nearest neighbors at dimension \n\u03b3+1\n [1].\n\n\nThe returned value is a vector with the ratio between the number of FFNN and the number of points in the dataset for each \n\u03b3 \u2208 \u03b3s\n. The optimal value for \n\u03b3\n is found at the point where this ratio approaches zero.\n\n\nSee also: \nestimate_dimension\n, \nafnn\n, \nfnn\n.\n\n\nReferences\n\n\n[1] : Anna Krakovsk\u00e1 \net al.\n, \"Use of false nearest neighbours for selecting variables and embedding parameters for state space reconstruction\", \nJ Complex Sys\n 932750 (2015), DOI: 10.1155/2015/932750\n\n\n#\n\n\nDelayEmbeddings.stochastic_indicator\n \n \nFunction\n.\n\n\nstochastic_indicator\n(\ns\n::\nAbstractVector\n,\n \n\u03c4\n:\nInt\n,\n \n\u03b3s\n \n=\n \n1\n:\n4\n)\n \n-\n \nE\u2082s\n\n\n\n\n\n\nCompute an estimator for apparent randomness in a reconstruction with \n\u03b3s\n temporal neighbors.\n\n\nDescription\n\n\nGiven the scalar timeseries \ns\n and the embedding delay \n\u03c4\n compute the values of \nE\u2082\n for each \n\u03b3 \u2208 \u03b3s\n, according to Cao's Method (eq. 5 of [1]).\n\n\nUse this function to confirm that the input signal is not random and validate the results of \nestimate_dimension\n. In the case of random signals, it should be \nE\u2082 \u2248 1 \u2200 \u03b3\n.\n\n\nReferences\n\n\n[1] : Liangyue Cao, \nPhysica D, pp. 43-50 (1997)", 
            "title": "Estimating Delay Embedding Parameters"
        }, 
        {
            "location": "/embedding/estimate/#estimating-delay-embedding-parameters", 
            "text": "The following functions can estimate good values that can be used in  reconstruct  for either the delay time or the number of temporal neighbors.", 
            "title": "Estimating Delay Embedding Parameters"
        }, 
        {
            "location": "/embedding/estimate/#delay-time", 
            "text": "#  DelayEmbeddings.estimate_delay     Function .  estimate_delay ( s ,   method :: String   [,   \u03c4s   =   1 : 2 : 100 ];   kwargs ... )   -   \u03c4   Estimate an optimal delay to be used in  reconstruct  or  embed . The  method  can be one of the following:   \"ac_zero\"  : first delay at which the auto-correlation function becomes  0.  \"ac_min\"  : delay of first minimum of the auto-correlation function.  \"mi_min\"  : delay of first minimum of mutual information of  s  with itself (shifted for various  \u03c4s ). Keywords  nbins, binwidth  are propagated into  mutualinformation .  \"exp_decay\"  :  exponential_decay_fit  of the correlation function rounded  to an integer (uses least squares on  c(t) = exp(-t/\u03c4)  to find  \u03c4 ).  \"exp_extrema\"  : same as above but the exponential fit is done to the absolute value of the local extrema of the correlation function.   Both the mutual information and correlation function ( autocor ) are computed  only  for delays  \u03c4s . This means that the  min  methods can never return the first value of  \u03c4s !  The method  mi_min  is significantly more accurate than the others and also returns good results for most timeseries. It is however the slowest method (but still quite fast!).  #  DelayEmbeddings.exponential_decay_fit     Function .  exponential_decay_fit ( x ,   y ,   weight   =   : equal )   -   \u03c4   Perform a least square fit of the form  y = exp(-x/\u03c4)  and return  \u03c4 . Taken from:  http://mathworld.wolfram.com/LeastSquaresFittingExponential.html. Assumes equal lengths of  x, y  and that  y \u2265 0 .  To use the method that gives more weight to small values of  y , use  weight = :small .", 
            "title": "Delay Time"
        }, 
        {
            "location": "/embedding/estimate/#mutual-information", 
            "text": "#  DelayEmbeddings.mutualinformation     Function .  mutualinformation ( s ,   \u03c4s [;   nbins ,   binwidth ])   Calculate the mutual information between the time series  s  and its images delayed by  \u03c4  points for  \u03c4  \u2208  \u03c4s , using an  improvement  of the method outlined by Fraser   Swinney in [1].  Description  The joint space of  s  and its  \u03c4 -delayed image ( s\u03c4 ) is partitioned as a rectangular grid, and the mutual information is computed from the joint and marginal frequencies of  s  and  s\u03c4  in the grid as defined in [1]. The mutual information values are returned in a vector of the same length as  \u03c4s .  If any of the optional keyword parameters is given, the grid will be a homogeneous partition of the space where  s  and  s\u03c4  are defined. The margins of that partition will be divided in a number of bins equal to  nbins , such that the width of each bin will be  binwidth , and the range of nonzero values of  s  will be in the centre. If only of those two parameters is given, the other will be automatically calculated to adjust the size of the grid to the area where  s  and  s\u03c4  are nonzero.  If no parameter is given, the space will be partitioned by a recursive bisection algorithm based on the method given in [1].  Notice that the recursive method of [1] evaluates the joint frequencies of  s  and  s\u03c4  in each cell resulting from a partition, and stops when the data points are uniformly distributed across the sub-partitions of the following levels. For performance and stability reasons, the automatic partition method implemented in this function is only used to divide the axes of the grid, using the marginal frequencies of  s .  References  [1]: Fraser A.M.   Swinney H.L. \"Independent coordinates for strange attractors from mutual information\"  Phys. Rev. A 33 (2), 1986, 1134:1140.   Besides the above method, there also exists code that computes mutual information in two other ways. Both ways are in the file  DelayEmbedding\\src\\old_mutual_info.jl . The first way is the original algorithm of Fraser, while the second is the algorithm of Kraskov. Both of these implementations are inferior to the one exposed here (performance-wise).", 
            "title": "Mutual Information"
        }, 
        {
            "location": "/embedding/estimate/#embedding-dimension", 
            "text": "#  DelayEmbeddings.estimate_dimension     Function .  estimate_dimension ( s :: AbstractVector ,   \u03c4 :: Int ,   \u03b3s   =   1 : 5 ,   method   =   afnn ;   kwargs ... )   Compute a quantity that can estimate an optimal amount of temporal neighbors  \u03b3  to be used in  reconstruct  or  embed .  Description  Given the scalar timeseries  s  and the embedding delay  \u03c4  compute a quantity for each  \u03b3 \u2208 \u03b3s  based on the \"nearest neighbors\" in the embedded time series.  The quantity that is calculated depends on the algorithm defined by the string  method :   \"afnn\"  (default) is Cao's \"Averaged False Nearest Neighbors\" method [1], which   gives a ratio of distances between nearest neighbors. This ratio saturates   around  1.0  near the optimal value of  \u03b3  (see  afnn ).  \"fnn\"  is Kennel's \"False Nearest Neighbors\" method [2], which gives the   number of points that cease to be \"nearest neighbors\" when the dimension   increases. This number drops down to zero near the optimal value of  \u03b3 .   This method accepts the keyword arguments  rtol  and  atol , which stand   for the \"tolerances\" required by Kennel's algorithm (see  fnn ).  \"f1nn\"  is Krakovsk\u00e1's \"False First Nearest Neighbors\" method [3], which   gives the ratio of pairs of points that cease to be \"nearest neighbors\"   when the dimension increases. This number drops down to zero near the   optimal value of  \u03b3  (see  f1nn ).   \"afnn\"  and  \"f1nn\"  also support the  metric  keyword, which can be any of  Cityblock(), Euclidean(), Chebyshev() . This metric is used both for computing the nearest neighbors ( KDTree s) as well as the distances necessary for Cao's method (eqs. (2, 3) of [1]). Defaults to  Euclidean()  (note that [1] used  Chebyshev ).  Please be aware that in  DynamicalSystems.jl   \u03b3  stands for the amount of temporal neighbors and not the embedding dimension ( D = \u03b3 + 1 , see also  embed ).  References  [1] : Liangyue Cao,  Physica D, pp. 43-50 (1997)  [2] : M. Kennel  et al. ,  Phys. Review A  45 (6), 3403-3411  (1992).  [3] : Anna Krakovsk\u00e1  et al. ,  J. Complex Sys. 932750 (2015)", 
            "title": "Embedding Dimension"
        }, 
        {
            "location": "/embedding/estimate/#example", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . roessler ()  tr   =   trajectory ( ds ,   1000.0 ;   dt   =   0.05 )  \u03c4   =   estimate_delay ( tr [ : ,   1 ],   mi_min )   # first minimum of mutual information  figure ();  for   method   in   [ afnn ,   fnn ,   f1nn ] \n     Ds   =   estimate_dimension ( tr [ : ,   1 ],   \u03c4 ,   1 : 6 ,   method ) \n     plot ( 1 : 6 ,   Ds   ./   maximum ( Ds ),   label   =   method ,   marker   =   o )  end  legend ();   xlabel ( \\$\\\\ gamma \\$  (temporal neighbors) )  tight_layout ()", 
            "title": "Example"
        }, 
        {
            "location": "/embedding/estimate/#functions", 
            "text": "#  DelayEmbeddings.fnn     Function .  fnn ( s :: AbstractVector ,   \u03c4 : Int ,   \u03b3s   =   1 : 5 ;   rtol = 10.0 ,   atol = 2.0 )   Calculate the number of \"false nearest neighbors\" (FNN) of the datasets created from  s  with a sequence of  \u03c4 -delayed temporal neighbors.  Description  Given a dataset made by embedding  s  with  \u03b3  temporal neighbors and delay  \u03c4 , the \"false nearest neighbors\" (FNN) are the pairs of points that are nearest to each other at dimension  \u03b3 , but are separated at dimension  \u03b3+1 . Kennel's criteria for detecting FNN are based on a threshold for the relative increment of the distance between the nearest neighbors ( rtol , eq. 4 in [1]), and another threshold for the ratio between the increased distance and the \"size of the attractor\" ( atol , eq. 5 in [1]). These thresholds are given as keyword arguments.  The returned value is a vector with the number of FNN for each  \u03b3 \u2208 \u03b3s . The optimal value for  \u03b3  is found at the point where the number of FNN approaches zero.  See also:  estimate_dimension ,  afnn ,  f1nn .  References  [1] : M. Kennel  et al. , \"Determining embedding dimension for phase-space reconstruction using a geometrical construction\",  Phys. Review A 45 (6), 3403-3411 (1992).  #  DelayEmbeddings.afnn     Function .  afnn ( s :: AbstractVector ,   \u03c4 : Int ,   \u03b3s   =   1 : 5 ,   metric = Euclidean ())   Compute the parameter E\u2081 of Cao's \"averaged false nearest neighbors\" method for determining the minimum embedding dimension of the time series  s , with a sequence of  \u03c4 -delayed temporal neighbors [1].  Description  Given the scalar timeseries  s  and the embedding delay  \u03c4  compute the values of  E\u2081  for each  \u03b3 \u2208 \u03b3s , according to Cao's Method (eq. 3 of [1]).  This quantity is a ratio of the averaged distances between the nearest neighbors of the reconstructed time series, which quantifies the increment of those distances when the number of temporal neighbors changes from  \u03b3  to  \u03b3+1 .  Return the vector of all computed  E\u2081 s. To estimate a good value for  \u03b3  from this, find  \u03b3  for which the value  E\u2081  saturates at some value around 1.  Note: This method does not work for datasets with perfectly periodic signals.  See also:  estimate_dimension ,  fnn ,  f1nn .  References  [1] : Liangyue Cao,  Physica D, pp. 43-50 (1997)  #  DelayEmbeddings.f1nn     Function .  f1nn ( s :: AbstractVector ,   \u03c4 : Int ,   \u03b3s   =   1 : 5 ,   metric   =   Euclidean ())   Calculate the ratio of \"false first nearest neighbors\" (FFNN) of the datasets created from  s  with a sequence of  \u03c4 -delayed temporal neighbors.  Description  Given a dataset made by embedding  s  with  \u03b3  temporal neighbors and delay  \u03c4 , the \"first nearest neighbors\" (FFNN) are the pairs of points that are nearest to each other at dimension  \u03b3  that cease to be nearest neighbors at dimension  \u03b3+1  [1].  The returned value is a vector with the ratio between the number of FFNN and the number of points in the dataset for each  \u03b3 \u2208 \u03b3s . The optimal value for  \u03b3  is found at the point where this ratio approaches zero.  See also:  estimate_dimension ,  afnn ,  fnn .  References  [1] : Anna Krakovsk\u00e1  et al. , \"Use of false nearest neighbours for selecting variables and embedding parameters for state space reconstruction\",  J Complex Sys  932750 (2015), DOI: 10.1155/2015/932750  #  DelayEmbeddings.stochastic_indicator     Function .  stochastic_indicator ( s :: AbstractVector ,   \u03c4 : Int ,   \u03b3s   =   1 : 4 )   -   E\u2082s   Compute an estimator for apparent randomness in a reconstruction with  \u03b3s  temporal neighbors.  Description  Given the scalar timeseries  s  and the embedding delay  \u03c4  compute the values of  E\u2082  for each  \u03b3 \u2208 \u03b3s , according to Cao's Method (eq. 5 of [1]).  Use this function to confirm that the input signal is not random and validate the results of  estimate_dimension . In the case of random signals, it should be  E\u2082 \u2248 1 \u2200 \u03b3 .  References  [1] : Liangyue Cao,  Physica D, pp. 43-50 (1997)", 
            "title": "Functions"
        }, 
        {
            "location": "/chaos/overview/", 
            "text": "Features Overview\n\n\nThe features offered in this documentation section come from the package \nChaosTools.jl\n. If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.\n\n\n\n\nOrbit Diagrams\n\n\n\n\nOrbit diagrams (aka bifurcation diagrams) of maps: \norbitdiagram\n.\n\n\nPoincar\u00e9 surfaces of section for continuous systems: \npoincaresos\n.\n\n\nAutomated production of orbit diagrams for continuous systems: \nproduce_orbitdiagram\n.\n\n\n\n\n\n\nLyapunov Exponents\n\n\nThe following treat systems where the equations of motion are known:\n\n\n\n\nMaximum Lyapunov exponent for both discrete and continuous systems: \nlyapunov\n.\n\n\nLyapunov \nspectrum\n for both discrete and continuous systems: \nlyapunovs\n.\n\n\n\n\n\n\nChaos Detection\n\n\n\n\n\n\nThe Generalized Alignment Index: \n\\text{GALI}_k\n\\text{GALI}_k\n : \ngali\n.\n\n\n\n\nImplemented for both discrete and continuous systems.\n\n\n\n\n\n\n\n\n\n\nEntropies and Dimensions\n\n\n\n\nGeneralized (Renyi) entropy: \ngenentropy\n.\n\n\nPermutation entropy: \npermentropy\n.\n\n\nFast and cheap (memory-wise) method for computing entropies of large datasets.\n\n\nGeneralized dimensions (e.g. capacity dimension, information dimension, etc.): \ngeneralized_dim\n.\n\n\nKaplan-Yorke dimension: \nkaplanyorke_dim\n.\n\n\nAutomated detection of best algorithmic parameters for calculating attractor dimensions.\n\n\n\n\nAnd, in order to automatically deduce dimensions, we also offer methods for:\n\n\n\n\nPartitioning a function \ny(x)\ny(x)\n vs. \nx\nx\n into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See \nlinear_regions\n.\n\n\nDetection of largest linear region of a function \ny(x)\ny(x)\n vs. \nx\nx\n and extraction of the slope of this region.\n\n\n\n\n\n\nNonlinear Timeseries Analysis\n\n\n\n\nBroomhead-King coordinates: \nbroomhead_king\n.\n\n\nNumerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries: \nnumericallyapunov\n.\n\n\n\n\n\n\nPeriodicity\n\n\n\n\n\n\nNumerical method to find unstable and stable fixed points of \nany order\n \nn\nn\n of a discrete map (of any dimensionality): \nperiodicorbits\n.\n\n\n\n\nConvenience functions for defining and realizing all possible combinations of \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrices required in the above method.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#features-overview", 
            "text": "The features offered in this documentation section come from the package  ChaosTools.jl . If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#orbit-diagrams", 
            "text": "Orbit diagrams (aka bifurcation diagrams) of maps:  orbitdiagram .  Poincar\u00e9 surfaces of section for continuous systems:  poincaresos .  Automated production of orbit diagrams for continuous systems:  produce_orbitdiagram .", 
            "title": "Orbit Diagrams"
        }, 
        {
            "location": "/chaos/overview/#lyapunov-exponents", 
            "text": "The following treat systems where the equations of motion are known:   Maximum Lyapunov exponent for both discrete and continuous systems:  lyapunov .  Lyapunov  spectrum  for both discrete and continuous systems:  lyapunovs .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/overview/#chaos-detection", 
            "text": "The Generalized Alignment Index:  \\text{GALI}_k \\text{GALI}_k  :  gali .   Implemented for both discrete and continuous systems.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/overview/#entropies-and-dimensions", 
            "text": "Generalized (Renyi) entropy:  genentropy .  Permutation entropy:  permentropy .  Fast and cheap (memory-wise) method for computing entropies of large datasets.  Generalized dimensions (e.g. capacity dimension, information dimension, etc.):  generalized_dim .  Kaplan-Yorke dimension:  kaplanyorke_dim .  Automated detection of best algorithmic parameters for calculating attractor dimensions.   And, in order to automatically deduce dimensions, we also offer methods for:   Partitioning a function  y(x) y(x)  vs.  x x  into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See  linear_regions .  Detection of largest linear region of a function  y(x) y(x)  vs.  x x  and extraction of the slope of this region.", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/overview/#nonlinear-timeseries-analysis", 
            "text": "Broomhead-King coordinates:  broomhead_king .  Numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries:  numericallyapunov .", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/overview/#periodicity", 
            "text": "Numerical method to find unstable and stable fixed points of  any order   n n  of a discrete map (of any dimensionality):  periodicorbits .   Convenience functions for defining and realizing all possible combinations of  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrices required in the above method.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/orbitdiagram/", 
            "text": "Orbit Diagrams of Maps\n\n\nAn orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed\n\n\n#\n\n\nChaosTools.orbitdiagram\n \n \nFunction\n.\n\n\norbitdiagram\n(\nds\n::\nDiscreteDynamicalSystem\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCompute the orbit diagram (also called bifurcation diagram) of the given system, saving the \ni\n variable(s) for parameter values \npvalues\n. The \np_index\n specifies which parameter of the equations of motion is to be changed.\n\n\ni\n can be \nInt\n or \nAbstractVector{Int}\n. If \ni\n is \nInt\n, returns a vector of vectors. Else it returns vectors of vectors of vectors. Each entry are the points at each parameter value.\n\n\nKeyword Arguments\n\n\n\n\nTtr::Int = 1000\n : Transient steps; each orbit is evolved for \nTtr\n first before saving output.\n\n\nn::Int = 100\n : Amount of points to save for each initial condition.\n\n\ndt = 1\n : Stepping time. Changing this will give you the orbit diagram of the \ndt\n order map.\n\n\nu0 = get_state(ds)\n : Initial condition. Besides a vector you can also give a vector of vectors such that \nlength(u0) == length(pvalues)\n. Then each parameter has a different initial condition.\n\n\n\n\nSee also \npoincaresos\n and \nproduce_orbitdiagram\n.\n\n\n\n\nFor example, let's compute the famous orbit diagram of the logistic map:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\ni\n \n=\n \n1\n\n\npvalues\n \n=\n \n3\n:\n0.001\n:\n4\n\n\nics\n \n=\n \n[\nrand\n()\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n2000\n\n\nTtr\n \n=\n \n2000\n\n\np_index\n \n=\n \n1\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n)\n\n\n\nL\n \n=\n \nlength\n(\npvalues\n)\n\n\nx\n \n=\n \nVector\n{\nFloat64\n}(\nundef\n,\n \nn\n*\nL\n)\n\n\ny\n \n=\n \ncopy\n(\nx\n)\n\n\nfor\n \nj\n \nin\n \n1\n:\nL\n\n    \nx\n[(\n1\n \n+\n \n(\nj\n-\n1\n)\n*\nn\n)\n:\nj\n*\nn\n]\n \n.=\n \npvalues\n[\nj\n]\n\n    \ny\n[(\n1\n \n+\n \n(\nj\n-\n1\n)\n*\nn\n)\n:\nj\n*\nn\n]\n \n.=\n \noutput\n[\nj\n]\n\n\nend\n\n\n\nfigure\n()\n\n\nPyPlot\n.\ntitle\n(\ntotal points: \n$\n(\nL\n*\nn\n)\n)\n\n\nplot\n(\nx\n,\n \ny\n,\n \nls\n \n=\n \nNone\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n,\n \nmarker\n \n=\n \no\n,\n \nalpha\n \n=\n \n0.05\n)\n\n\nxlim\n(\npvalues\n[\n1\n],\n \npvalues\n[\nend\n]);\n \nylim\n(\n0\n,\n1\n)\n\n\nxlabel\n(\n\\$\nr\n\\$\n);\n \nylabel\n(\n\\$\nx\n\\$\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nNotice that if you are using \nPyPlot\n, the plotting process will be slow, since it is slow at plotting big numbers of points.\n\n\nThe function is not limited to 1D maps, and can be applied just as well to any discrete system.\n\n\n\n\nPoincar\u00e9 Surface of Section\n\n\nAlso called \nPoincar\u00e9 map\n is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:\n\n\n#\n\n\nChaosTools.poincaresos\n \n \nFunction\n.\n\n\npoincaresos\n(\nds\n::\nContinuousDynamicalSystem\n,\n \nplane\n,\n \ntfinal\n \n=\n \n1000.0\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCalculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1, 2] of the given system with the given \nplane\n. The system is evolved for total time of \ntfinal\n.\n\n\nIf the state of the system is \n\\mathbf{u} = (u_1, \\ldots, u_D)\n\\mathbf{u} = (u_1, \\ldots, u_D)\n then the equation defining a hyperplane is\n\n\n\n\n\na_1u_1 + \\dots + a_Du_D = \\mathbf{a}\\cdot\\mathbf{u}=b\n\n\n\n\na_1u_1 + \\dots + a_Du_D = \\mathbf{a}\\cdot\\mathbf{u}=b\n\n\n\n\n\nwhere \n\\mathbf{a}, b\n\\mathbf{a}, b\n are the parameters of the hyperplane.\n\n\nIn code, \nplane\n can be either:\n\n\n\n\nA \nTuple{Int, \n: Number}\n, like \n(j, r)\n : the plane is defined as when the \nj\n variable of the system equals the value \nr\n.\n\n\nA vector of length \nD+1\n. The first \nD\n elements of the vector correspond to \n\\mathbf{a}\n\\mathbf{a}\n while the last element is \nb\nb\n.\n\n\n\n\nReturns a \nDataset\n of the points that are on the surface of section.\n\n\nKeyword Arguments\n\n\n\n\ndirection = -1\n : Only crossings with \nsign(direction)\n are considered to belong to the surface of section. Positive direction means going from less than \nb\nb\n to greater than \nb\nb\n.\n\n\nidxs = 1:dimension(ds)\n : Optionally you can choose which variables to save. Defaults to the entire state.\n\n\nTtr = 0.0\n : Transient time to evolve the system before starting to compute the PSOS.\n\n\nu0 = get_state(ds)\n : Specify an initial state.\n\n\nwarning = true\n : Throw a warning if the Poincar\u00e9 section was empty.\n\n\nrootkw = (xrtol = 1e-6, atol = 1e-6)\n : A \nNamedTuple\n of keyword arguments passed to \nfind_zero\n from \nRoots.jl\n.\n\n\ndiffeq...\n : All other extra keyword arguments are propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples.\n\n\n\n\nPerformance Notes\n\n\nThis function uses a standard \nintegrator\n. For loops over initial conditions and/or parameters you should use the low level method that accepts an integrator and \nreinit!\n to new initial conditions. See the \"advanced documentation\" for more.\n\n\nThe low level call signature is:\n\n\npoincaresos\n(\ninteg\n,\n \nplanecrossing\n,\n \ntfinal\n,\n \nTtr\n,\n \nidxs\n,\n \nrootkw\n)\n\n\n\n\n\n\nwhere\n\n\nplanecrossing\n \n=\n \nPlaneCrossing\n(\nplane\n,\n \ndirection\n \n \n0\n)\n\n\n\n\n\n\nand \nidxs\n must be \nInt\n or \nSVector{Int}\n.\n\n\nReferences\n\n\n[1] : H. Poincar\u00e9, \nLes Methods Nouvelles de la M\u00e9canique Celeste\n, Paris: Gauthier-Villars (1892)\n\n\n[2] : M. Tabor, \nChaos and Integrability in Nonlinear Dynamics: An Introduction\n, \u00a74.1, in pp. 118-126, New York: Wiley (1989)\n\n\nSee also \norbitdiagram\n, \nproduce_orbitdiagram\n.\n\n\n\n\nHere is an example of the \nHenon-Heiles\n system showing the mixed nature of the phase space\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nhh\n \n=\n \nSystems\n.\nhenonheiles\n()\n\n\n\nplane\n \n=\n \n(\n1\n,\n \n0.0\n)\n\n\nu0s\n \n=\n \n[[\n0.0\n,\n \n-\n0.25\n,\n \n0.42081\n,\n \n0.0\n],\n\n\n[\n0.0\n,\n \n-\n0.31596\n,\n \n0.354461\n,\n \n0.0591255\n],\n\n\n[\n0.0\n,\n \n0.1\n,\n \n0.5\n,\n \n0.0\n],\n\n\n[\n0.0\n,\n \n-\n0.0910355\n,\n \n0.459522\n,\n \n-\n0.173339\n],\n\n\n[\n0.0\n,\n \n-\n0.205144\n,\n \n0.449328\n,\n \n-\n0.0162098\n]]\n\n\n\nfigure\n()\n\n\nfor\n \nu0\n \nin\n \nu0s\n\n    \npsos\n \n=\n \npoincaresos\n(\nhh\n,\n \nplane\n,\n \n20000.0\n;\n \nu0\n \n=\n \nu0\n)\n\n    \nscatter\n(\npsos\n[\n:\n,\n \n2\n],\n \npsos\n[\n:\n,\n \n4\n],\n \ns\n \n=\n \n2.0\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nq_2\n\\$\n);\n \nylabel\n(\n\\$\np_2\n\\$\n)\n\n\n\n\n\n\n\n\nHere the surface of section was the (hyper-) plane that \nq_1 = 0\nq_1 = 0\n. Some chaotic and regular orbits can be seen in the plot. You can tell the regular orbits apart because they look like a single connected curve. This is the result of cutting a 2-torus by a plane!\n\n\n\n\nFinally here is one more example with a more complex hyperplane:\n\n\ngis\n \n=\n \nSystems\n.\ngissinger\n([\n2.32865\n,\n \n2.02514\n,\n \n1.98312\n])\n\n\n\n# Define appropriate hyperplane for gissinger system\n\n\nconst\n \n\u03bd\n \n=\n \n0.1\n\n\nconst\n \n\u0393\n \n=\n \n0.9\n \n# default parameters of the system\n\n\n\n# I want hyperperplane defined by these two points:\n\n\nNp\n(\n\u03bc\n)\n \n=\n \nSVector\n{\n3\n}(\nsqrt\n(\n\u03bd\n \n+\n \n\u0393\n*\nsqrt\n(\n\u03bd\n/\n\u03bc\n)),\n \n-\nsqrt\n(\n\u03bc\n \n+\n \n\u0393\n*\nsqrt\n(\n\u03bc\n/\n\u03bd\n)),\n \n-\nsqrt\n(\n\u03bc\n*\n\u03bd\n))\n\n\nNm\n(\n\u03bc\n)\n \n=\n \nSVector\n{\n3\n}(\n-\nsqrt\n(\n\u03bd\n \n+\n \n\u0393\n*\nsqrt\n(\n\u03bd\n/\n\u03bc\n)),\n \nsqrt\n(\n\u03bc\n \n+\n \n\u0393\n*\nsqrt\n(\n\u03bc\n/\n\u03bd\n)),\n \n-\nsqrt\n(\n\u03bc\n*\n\u03bd\n))\n\n\n\n# Create hyperplane passing through Np, Nm and 0:\n\n\nusing\n \nLinearAlgebra\n\n\ngis_plane\n(\n\u03bc\n)\n \n=\n \n[\ncross\n(\nNp\n(\n\u03bc\n),\n \nNm\n(\n\u03bc\n))\n...\n,\n \n0\n]\n\n\n\n\u03bc\n \n=\n \n0.119\n\n\nset_parameter!\n(\ngis\n,\n \n1\n,\n \n\u03bc\n)\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n8\n,\n6\n))\n\n\npsos\n \n=\n \npoincaresos\n(\ngis\n,\n \ngis_plane\n(\n\u03bc\n),\n \n10000.0\n,\n \nTtr\n \n=\n \n200.0\n,)\n\n\nplot3D\n(\ncolumns\n(\npsos\n)\n...\n,\n \nmarker\n \n=\n \no\n,\n \nls\n \n=\n \nNone\n,\n \nms\n \n=\n \n2.0\n);\n\n\nxlabel\n(\nQ\n);\n \nylabel\n(\nD\n);\n \nzlabel\n(\nV\n);\n\n\n\n\n\n\n\n\n\n\nStroboscopic Map\n\n\nA special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the \nDuffing oscillator\n.\n\n\nA \"cut\" through the phase-space can be produced at every period \nT = 2\\pi/\\omega\nT = 2\\pi/\\omega\n. There is no reason to use \npoincaresos\n for this though, because you can simply use \ntrajectory\n and get the solution with a certain time sampling rate:\n\n\nds\n \n=\n \nSystems\n.\nduffing\n(\n\u03b2\n \n=\n \n-\n1\n,\n \n\u03c9\n \n=\n \n1\n,\n \nf\n \n=\n \n0.3\n)\n \n# non-autonomous chaotic system\n\n\na\n \n=\n \ntrajectory\n(\nds\n,\n \n100000.0\n,\n \ndt\n \n=\n \n2\n\u03c0\n)\n \n# every period T = 2\u03c0/\u03c9\n\n\nfigure\n()\n\n\nplot\n(\na\n[\n:\n,\n \n1\n],\n \na\n[\n:\n,\n \n2\n],\n \nlw\n \n=\n \n0\n,\n \nmarker\n \n=\no\n,\n \nms\n \n=\n \n1\n)\n\n\nxlabel\n(\n\\$\nx\n\\$\n);\n \nylabel\n(\n\\$\\\\\ndot{x}\n\\$\n)\n\n\n\n\n\n\n\n\n\n\nProducing Orbit Diagrams for Flows\n\n\nThe \norbitdiagram\n does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for \norbitdiagram\n to have meaning one must have a map.\n\n\nIf only there was a way to turn a continuous system into a map... \nOH WAIT!\n That is what \npoincaresos\n does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.\n\n\nWe have bundled this process in the following function:\n\n\n#\n\n\nChaosTools.produce_orbitdiagram\n \n \nFunction\n.\n\n\nproduce_orbitdiagram\n(\nds\n::\nContinuousDynamicalSystem\n,\n \nplane\n,\n \ni\n::\nInt\n,\n\n                     \np_index\n,\n \npvalues\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nProduce an orbit diagram (also called bifurcation diagram) for the \ni\n variable(s) of the given continuous system by computing Poincar\u00e9 surfaces of section using \nplane\n for the given parameter values (see \npoincaresos\n).\n\n\ni\n can be \nInt\n or \nAbstractVector{Int}\n. If \ni\n is \nInt\n, returns a vector of vectors. Else it returns a vector of vectors of vectors. Each entry are the points at each parameter value.\n\n\nKeyword Arguments\n\n\n\n\nprintparams::Bool = false\n : Whether to print the parameter used during computation in order to keep track of running time.\n\n\ndirection, warning, Ttr, rootkw, diffeq...\n : Propagated into \npoincaresos\n.\n\n\nu0 = get_state(ds)\n : Initial condition. Besides a vector you can also give a vector of vectors such that \nlength(u0) == length(pvalues)\n. Then each parameter has a different initial condition.\n\n\n\n\nDescription\n\n\nFor each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for the \ni\n variable of the system, just like it is done in \norbitdiagram\n.\n\n\nThe parameter change is done as \np[p_index] = value\n taking values from \npvalues\n and thus you must use a parameter container that supports this (either \nArray\n, \nLMArray\n, dictionary or other).\n\n\nSee also \npoincaresos\n, \norbitdiagram\n.\n\n\n\n\nFor example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!\n\n\nds\n \n=\n \nSystems\n.\nshinriki\n([\n-\n2\n,\n \n0\n,\n \n0.2\n])\n\n\n\npvalues\n \n=\n \nrange\n(\n19\n,\n \nstop\n \n=\n \n22\n,\n \nlength\n \n=\n \n401\n)\n\n\ni\n \n=\n \n1\n\n\nplane\n \n=\n \n(\n2\n,\n \n0.0\n)\n\n\ntf\n \n=\n \n200.0\n\n\np_index\n \n=\n \n1\n\n\n\noutput\n \n=\n \nproduce_orbitdiagram\n(\nds\n,\n \nplane\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n\n                              \ntfinal\n \n=\n \ntf\n,\n \nTtr\n \n=\n \n200.0\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\nfill\n(\np\n,\n \nlength\n(\noutput\n[\nj\n])),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.2\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nR_1\n\\$\n);\n \nylabel\n(\n\\$\nV_1\n\\$\n)\n\n\ntight_layout\n()", 
            "title": "Orbit Diagrams & PSOS"
        }, 
        {
            "location": "/chaos/orbitdiagram/#orbit-diagrams-of-maps", 
            "text": "An orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed  #  ChaosTools.orbitdiagram     Function .  orbitdiagram ( ds :: DiscreteDynamicalSystem ,   i ,   p_index ,   pvalues ;   kwargs ... )   Compute the orbit diagram (also called bifurcation diagram) of the given system, saving the  i  variable(s) for parameter values  pvalues . The  p_index  specifies which parameter of the equations of motion is to be changed.  i  can be  Int  or  AbstractVector{Int} . If  i  is  Int , returns a vector of vectors. Else it returns vectors of vectors of vectors. Each entry are the points at each parameter value.  Keyword Arguments   Ttr::Int = 1000  : Transient steps; each orbit is evolved for  Ttr  first before saving output.  n::Int = 100  : Amount of points to save for each initial condition.  dt = 1  : Stepping time. Changing this will give you the orbit diagram of the  dt  order map.  u0 = get_state(ds)  : Initial condition. Besides a vector you can also give a vector of vectors such that  length(u0) == length(pvalues) . Then each parameter has a different initial condition.   See also  poincaresos  and  produce_orbitdiagram .   For example, let's compute the famous orbit diagram of the logistic map:  using   DynamicalSystems  using   PyPlot  ds   =   Systems . logistic ()  i   =   1  pvalues   =   3 : 0.001 : 4  ics   =   [ rand ()   for   m   in   1 : 10 ]  n   =   2000  Ttr   =   2000  p_index   =   1  output   =   orbitdiagram ( ds ,   i ,   p_index ,   pvalues ;   n   =   n ,   Ttr   =   Ttr )  L   =   length ( pvalues )  x   =   Vector { Float64 }( undef ,   n * L )  y   =   copy ( x )  for   j   in   1 : L \n     x [( 1   +   ( j - 1 ) * n ) : j * n ]   .=   pvalues [ j ] \n     y [( 1   +   ( j - 1 ) * n ) : j * n ]   .=   output [ j ]  end  figure ()  PyPlot . title ( total points:  $ ( L * n ) )  plot ( x ,   y ,   ls   =   None ,   ms   =   0.5 ,   color   =   black ,   marker   =   o ,   alpha   =   0.05 )  xlim ( pvalues [ 1 ],   pvalues [ end ]);   ylim ( 0 , 1 )  xlabel ( \\$ r \\$ );   ylabel ( \\$ x \\$ )  tight_layout ()    Notice that if you are using  PyPlot , the plotting process will be slow, since it is slow at plotting big numbers of points.  The function is not limited to 1D maps, and can be applied just as well to any discrete system.", 
            "title": "Orbit Diagrams of Maps"
        }, 
        {
            "location": "/chaos/orbitdiagram/#poincare-surface-of-section", 
            "text": "Also called  Poincar\u00e9 map  is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:  #  ChaosTools.poincaresos     Function .  poincaresos ( ds :: ContinuousDynamicalSystem ,   plane ,   tfinal   =   1000.0 ;   kwargs ... )   Calculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1, 2] of the given system with the given  plane . The system is evolved for total time of  tfinal .  If the state of the system is  \\mathbf{u} = (u_1, \\ldots, u_D) \\mathbf{u} = (u_1, \\ldots, u_D)  then the equation defining a hyperplane is   \na_1u_1 + \\dots + a_Du_D = \\mathbf{a}\\cdot\\mathbf{u}=b  \na_1u_1 + \\dots + a_Du_D = \\mathbf{a}\\cdot\\mathbf{u}=b   where  \\mathbf{a}, b \\mathbf{a}, b  are the parameters of the hyperplane.  In code,  plane  can be either:   A  Tuple{Int,  : Number} , like  (j, r)  : the plane is defined as when the  j  variable of the system equals the value  r .  A vector of length  D+1 . The first  D  elements of the vector correspond to  \\mathbf{a} \\mathbf{a}  while the last element is  b b .   Returns a  Dataset  of the points that are on the surface of section.  Keyword Arguments   direction = -1  : Only crossings with  sign(direction)  are considered to belong to the surface of section. Positive direction means going from less than  b b  to greater than  b b .  idxs = 1:dimension(ds)  : Optionally you can choose which variables to save. Defaults to the entire state.  Ttr = 0.0  : Transient time to evolve the system before starting to compute the PSOS.  u0 = get_state(ds)  : Specify an initial state.  warning = true  : Throw a warning if the Poincar\u00e9 section was empty.  rootkw = (xrtol = 1e-6, atol = 1e-6)  : A  NamedTuple  of keyword arguments passed to  find_zero  from  Roots.jl .  diffeq...  : All other extra keyword arguments are propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples.   Performance Notes  This function uses a standard  integrator . For loops over initial conditions and/or parameters you should use the low level method that accepts an integrator and  reinit!  to new initial conditions. See the \"advanced documentation\" for more.  The low level call signature is:  poincaresos ( integ ,   planecrossing ,   tfinal ,   Ttr ,   idxs ,   rootkw )   where  planecrossing   =   PlaneCrossing ( plane ,   direction     0 )   and  idxs  must be  Int  or  SVector{Int} .  References  [1] : H. Poincar\u00e9,  Les Methods Nouvelles de la M\u00e9canique Celeste , Paris: Gauthier-Villars (1892)  [2] : M. Tabor,  Chaos and Integrability in Nonlinear Dynamics: An Introduction , \u00a74.1, in pp. 118-126, New York: Wiley (1989)  See also  orbitdiagram ,  produce_orbitdiagram .   Here is an example of the  Henon-Heiles  system showing the mixed nature of the phase space  using   DynamicalSystems ,   PyPlot  hh   =   Systems . henonheiles ()  plane   =   ( 1 ,   0.0 )  u0s   =   [[ 0.0 ,   - 0.25 ,   0.42081 ,   0.0 ],  [ 0.0 ,   - 0.31596 ,   0.354461 ,   0.0591255 ],  [ 0.0 ,   0.1 ,   0.5 ,   0.0 ],  [ 0.0 ,   - 0.0910355 ,   0.459522 ,   - 0.173339 ],  [ 0.0 ,   - 0.205144 ,   0.449328 ,   - 0.0162098 ]]  figure ()  for   u0   in   u0s \n     psos   =   poincaresos ( hh ,   plane ,   20000.0 ;   u0   =   u0 ) \n     scatter ( psos [ : ,   2 ],   psos [ : ,   4 ],   s   =   2.0 )  end  xlabel ( \\$ q_2 \\$ );   ylabel ( \\$ p_2 \\$ )    Here the surface of section was the (hyper-) plane that  q_1 = 0 q_1 = 0 . Some chaotic and regular orbits can be seen in the plot. You can tell the regular orbits apart because they look like a single connected curve. This is the result of cutting a 2-torus by a plane!   Finally here is one more example with a more complex hyperplane:  gis   =   Systems . gissinger ([ 2.32865 ,   2.02514 ,   1.98312 ])  # Define appropriate hyperplane for gissinger system  const   \u03bd   =   0.1  const   \u0393   =   0.9   # default parameters of the system  # I want hyperperplane defined by these two points:  Np ( \u03bc )   =   SVector { 3 }( sqrt ( \u03bd   +   \u0393 * sqrt ( \u03bd / \u03bc )),   - sqrt ( \u03bc   +   \u0393 * sqrt ( \u03bc / \u03bd )),   - sqrt ( \u03bc * \u03bd ))  Nm ( \u03bc )   =   SVector { 3 }( - sqrt ( \u03bd   +   \u0393 * sqrt ( \u03bd / \u03bc )),   sqrt ( \u03bc   +   \u0393 * sqrt ( \u03bc / \u03bd )),   - sqrt ( \u03bc * \u03bd ))  # Create hyperplane passing through Np, Nm and 0:  using   LinearAlgebra  gis_plane ( \u03bc )   =   [ cross ( Np ( \u03bc ),   Nm ( \u03bc )) ... ,   0 ]  \u03bc   =   0.119  set_parameter! ( gis ,   1 ,   \u03bc )  figure ( figsize   =   ( 8 , 6 ))  psos   =   poincaresos ( gis ,   gis_plane ( \u03bc ),   10000.0 ,   Ttr   =   200.0 ,)  plot3D ( columns ( psos ) ... ,   marker   =   o ,   ls   =   None ,   ms   =   2.0 );  xlabel ( Q );   ylabel ( D );   zlabel ( V );", 
            "title": "Poincar\u00e9 Surface of Section"
        }, 
        {
            "location": "/chaos/orbitdiagram/#stroboscopic-map", 
            "text": "A special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the  Duffing oscillator .  A \"cut\" through the phase-space can be produced at every period  T = 2\\pi/\\omega T = 2\\pi/\\omega . There is no reason to use  poincaresos  for this though, because you can simply use  trajectory  and get the solution with a certain time sampling rate:  ds   =   Systems . duffing ( \u03b2   =   - 1 ,   \u03c9   =   1 ,   f   =   0.3 )   # non-autonomous chaotic system  a   =   trajectory ( ds ,   100000.0 ,   dt   =   2 \u03c0 )   # every period T = 2\u03c0/\u03c9  figure ()  plot ( a [ : ,   1 ],   a [ : ,   2 ],   lw   =   0 ,   marker   = o ,   ms   =   1 )  xlabel ( \\$ x \\$ );   ylabel ( \\$\\\\ dot{x} \\$ )", 
            "title": "Stroboscopic Map"
        }, 
        {
            "location": "/chaos/orbitdiagram/#producing-orbit-diagrams-for-flows", 
            "text": "The  orbitdiagram  does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for  orbitdiagram  to have meaning one must have a map.  If only there was a way to turn a continuous system into a map...  OH WAIT!  That is what  poincaresos  does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.  We have bundled this process in the following function:  #  ChaosTools.produce_orbitdiagram     Function .  produce_orbitdiagram ( ds :: ContinuousDynamicalSystem ,   plane ,   i :: Int , \n                      p_index ,   pvalues ;   kwargs ... )   Produce an orbit diagram (also called bifurcation diagram) for the  i  variable(s) of the given continuous system by computing Poincar\u00e9 surfaces of section using  plane  for the given parameter values (see  poincaresos ).  i  can be  Int  or  AbstractVector{Int} . If  i  is  Int , returns a vector of vectors. Else it returns a vector of vectors of vectors. Each entry are the points at each parameter value.  Keyword Arguments   printparams::Bool = false  : Whether to print the parameter used during computation in order to keep track of running time.  direction, warning, Ttr, rootkw, diffeq...  : Propagated into  poincaresos .  u0 = get_state(ds)  : Initial condition. Besides a vector you can also give a vector of vectors such that  length(u0) == length(pvalues) . Then each parameter has a different initial condition.   Description  For each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for the  i  variable of the system, just like it is done in  orbitdiagram .  The parameter change is done as  p[p_index] = value  taking values from  pvalues  and thus you must use a parameter container that supports this (either  Array ,  LMArray , dictionary or other).  See also  poincaresos ,  orbitdiagram .   For example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!  ds   =   Systems . shinriki ([ - 2 ,   0 ,   0.2 ])  pvalues   =   range ( 19 ,   stop   =   22 ,   length   =   401 )  i   =   1  plane   =   ( 2 ,   0.0 )  tf   =   200.0  p_index   =   1  output   =   produce_orbitdiagram ( ds ,   plane ,   i ,   p_index ,   pvalues ; \n                               tfinal   =   tf ,   Ttr   =   200.0 )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( fill ( p ,   length ( output [ j ])),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.2 ,   color   =   black )  end  xlabel ( \\$ R_1 \\$ );   ylabel ( \\$ V_1 \\$ )  tight_layout ()", 
            "title": "Producing Orbit Diagrams for Flows"
        }, 
        {
            "location": "/chaos/lyapunovs/", 
            "text": "Lyapunov exponents\n\n\nLyapunov exponents measure exponential rates of separation of nearby trajectories in the flow of a dynamical system. The \nWikipedia\n and the \nScholarpedia\n entries have a lot of valuable information about the history and usage of these quantities.\n\n\nThis page treats systems where the equations of motion are known. If instead you have numerical data, see the \nnonlinear timeseries analysis page\n.\n\n\n\n\nPerformance depends on the solver\n\n\nNotice that the performance of functions that use \nContinuousDynamicalSystem\ns depend crucially on the chosen solver. Please see the documentation page on \nChoosing a solver\n for an in-depth discussion.\n\n\n\n\n\n\nLyapunov Spectrum\n\n\nThe function \nlyapunovs\n calculates the entire spectrum of the Lyapunov exponents of a system:\n\n\n#\n\n\nChaosTools.lyapunovs\n \n \nFunction\n.\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n \n[,\n \nk\n::\nInt\n \n|\n \nQ0\n];\n \nkwargs\n...\n)\n \n-\n \n\u03bbs\n\n\n\n\n\n\nCalculate the spectrum of Lyapunov exponents [1] of \nds\n by applying a QR-decomposition on the parallelepiped matrix \nN\n times. Return the spectrum sorted from maximum to minimum.\n\n\nThe third argument \nk\n is optional, and dictates how many lyapunov exponents to calculate (defaults to \ndimension(ds)\n). Instead of passing an integer \nk\n you can pass a pre-initialized matrix \nQ0\n whose columns are initial deviation vectors (then \nk = size(Q0)[2]\n).\n\n\nKeyword Arguments\n\n\n\n\nu0 = get_state(ds)\n : State to start from.\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems. Both the system and the deviation vectors are evolved for this time.\n\n\ndt = 1\n : Time of individual evolutions between successive orthonormalization steps. For continuous systems this is approximate.\n\n\ndiffeq...\n : Keyword arguments propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples. Only valid for continuous systems.\n\n\n\n\nDescription\n\n\nThe method we employ is \"H2\" of [2], originally stated in [3]. The deviation vectors defining a \nD\n-dimensional parallepiped in tangent space are evolved using the tangent dynamics of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over \nN\n successive steps, yielding the lyapunov exponent spectrum (at each step the parallepiped is re-normalized).\n\n\nPerformance Notes\n\n\nThis function uses a \ntangent_integrator\n. For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and \nreinit!\n it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is\n\n\nlyapunovs\n(\ntinteg\n,\n \nN\n,\n \ndt\n::\nReal\n,\n \nTtr\n::\nReal\n)\n\n\n\n\n\n\nIf you want to obtain the convergence timeseries of the Lyapunov spectrum, use the method\n\n\nChaosTools\n.\nlyapunovs_convergence\n(\ntinteg\n,\n \nN\n,\n \ndt\n,\n \nTtr\n)\n\n\n\n\n\n\n(not exported).\n\n\nReferences\n\n\n[1] : A. M. Lyapunov, \nThe General Problem of the Stability of Motion\n, Taylor \n Francis (1992)\n\n\n[2] : K. Geist \net al.\n, Progr. Theor. Phys. \n83\n, pp 875 (1990)\n\n\n[3] : G. Benettin \net al.\n, Meccanica \n15\n, pp 9-20 \n 21-30 (1980)\n\n\n\n\nAs you can see, the documentation string is detailed and self-contained. For example, the Lyapunov spectrum of the \nfolded towel map\n is calculated as:\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nds\n,\n \n10000\n)\n\n\n\n\n\n\n3-element Array{Float64,1}:\n  0.4324643001570437\n  0.372138249644847 \n -3.296974844093203 \n\n\n\n\n\nSimilarly, for a continuous system, e.g. the Lorenz system, you would do:\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n \n#this is not the original parameter!\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nlor\n,\n \n10000\n,\n \ndt\n \n=\n \n0.1\n)\n\n\n\n\n\n\n3-element Array{Float64,1}:\n   0.9837999200006314  \n  -0.001272173431277142\n -14.649189089612964   \n\n\n\n\n\nlyapunovs\n is also very fast:\n\n\nusing\n \nBenchmarkTools\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n@btime\n \nlyapunovs\n(\n$\nds\n,\n \n2000\n);\n\n\n\n\n\n\n  237.226 \u03bcs (45 allocations: 4.27 KiB)\n\n\n\n\n\nHere is an example of plotting the exponents of the Roessler system for various parameters:\n\n\n```@example lyap\nds = Systems.roessler()\n\n\ncs = 4:0.01:6; \u03bbs = zeros(length(cs), 3)\nfor (i, c) in enumerate(cs)\n    set_parameter!(ds, 3, c)\n    \u03bbs[i, :] .= lyapunovs(ds, 10000; Ttr = 500.0)\nend\n\n\nfigure()\nplot(cs, \u03bbs)\ntight_layout() # hide\nsavefig(\"rosl_l.png\"); nothing # hide\n\n\n![](osl_l.png)\n\n\n\na\n \nid=\nMaximum-Lyapunov-Exponent-1\n/a\n\n\n## Maximum Lyapunov Exponent\n\n\nIt is possible to get only the maximum Lyapunov exponent simply by giving `1` as the third argument of [`lyapunovs`](lyapunovs.md#ChaosTools.lyapunovs). However, there is a second algorithm that allows you to do the same thing, which is offered by the function `lyapunov`:\n\n\na\n \nid=\nChaosTools.lyapunov\n \nhref=\n#ChaosTools.lyapunov\n#\n/a\n\n**`ChaosTools.lyapunov`** \nmdash;\n *Function*.\n\n\n\n```julia\nlyapunov(ds::DynamicalSystem, \u03a4; kwargs...) -\n \u03bb\n\n\n\n\n\nCalculate the maximum Lyapunov exponent \n\u03bb\n using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one. \nT\n  denotes the total time of evolution (should be \nInt\n for discrete systems).\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the trajectories before starting to measure the expontent. Should be \nInt\n for discrete systems.\n\n\nd0 = 1e-9\n : Initial \n rescaling distance between the two neighboring trajectories.\n\n\nupper_threshold = 1e-6\n : Upper distance threshold for rescaling.\n\n\nlower_threshold = 1e-12\n : Lower distance threshold for rescaling (in order to  be able to detect negative exponents).\n\n\ndt = 1\n : Time of evolution between each check of distance exceeding the thresholds. For continuous systems this is approximate.\n\n\ninittest = (u1, d0) -\n u1 .+ d0/sqrt(D)\n : A function that given \n(u1, d0)\n initializes the test state with distance \nd0\n from the given state \nu1\n (\nD\n is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.\n\n\ndiffeq...\n : Keyword arguments propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples. Only valid for continuous systems.\n\n\n\n\nDescription\n\n\nTwo neighboring trajectories with initial distance \nd0\n are evolved in time. At time \nt_i\nt_i\n their distance \nd(t_i)\nd(t_i)\n either exceeds the \nupper_threshold\n, or is lower than \nlower_threshold\n, which initializes a rescaling of the test trajectory back to having distance \nd0\n from the given one, while the rescaling keeps the difference vector along the maximal expansion/contraction direction: \nu_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0)\nu_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0)\n.\n\n\nThe maximum Lyapunov exponent is the average of the time-local Lyapunov exponents\n\n\n\n\n\n\\lambda = \\frac{1}{t_{n} - t_0}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\\lambda = \\frac{1}{t_{n} - t_0}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\nPerformance Notes\n\n\nThis function uses a \nparallel_integrator\n. For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and \nreinit!\n it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is\n\n\nlyapunov(pinteg, T, Ttr, dt, d0, ut, lt)\n\n\n\n\n\nReferences\n\n\n[1] : G. Benettin \net al.\n, Phys. Rev. A \n14\n, pp 2338 (1976)\n\n\n\n\nFor example:\n\n\nusing\n \nDynamicalSystems\n\n\nhenon\n \n=\n \nSystems\n.\nhenon\n()\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nhenon\n,\n \n10000\n,\n \nd0\n \n=\n \n1e-7\n,\n \nupper_threshold\n \n=\n \n1e-4\n,\n \nTtr\n \n=\n \n100\n)\n\n\n\n\n\n\n0.42018736282059616\n\n\n\n\n\nThe same is done for continuous systems:\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32\n)\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nlor\n,\n \n10000.0\n,\n \ndt\n \n=\n \n10.0\n,\n \nTtr\n \n=\n \n100.0\n)\n\n\n\n\n\n\n0.9959721568028167", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-exponents", 
            "text": "Lyapunov exponents measure exponential rates of separation of nearby trajectories in the flow of a dynamical system. The  Wikipedia  and the  Scholarpedia  entries have a lot of valuable information about the history and usage of these quantities.  This page treats systems where the equations of motion are known. If instead you have numerical data, see the  nonlinear timeseries analysis page .   Performance depends on the solver  Notice that the performance of functions that use  ContinuousDynamicalSystem s depend crucially on the chosen solver. Please see the documentation page on  Choosing a solver  for an in-depth discussion.", 
            "title": "Lyapunov exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-spectrum", 
            "text": "The function  lyapunovs  calculates the entire spectrum of the Lyapunov exponents of a system:  #  ChaosTools.lyapunovs     Function .  lyapunovs ( ds :: DynamicalSystem ,   N   [,   k :: Int   |   Q0 ];   kwargs ... )   -   \u03bbs   Calculate the spectrum of Lyapunov exponents [1] of  ds  by applying a QR-decomposition on the parallelepiped matrix  N  times. Return the spectrum sorted from maximum to minimum.  The third argument  k  is optional, and dictates how many lyapunov exponents to calculate (defaults to  dimension(ds) ). Instead of passing an integer  k  you can pass a pre-initialized matrix  Q0  whose columns are initial deviation vectors (then  k = size(Q0)[2] ).  Keyword Arguments   u0 = get_state(ds)  : State to start from.  Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems. Both the system and the deviation vectors are evolved for this time.  dt = 1  : Time of individual evolutions between successive orthonormalization steps. For continuous systems this is approximate.  diffeq...  : Keyword arguments propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples. Only valid for continuous systems.   Description  The method we employ is \"H2\" of [2], originally stated in [3]. The deviation vectors defining a  D -dimensional parallepiped in tangent space are evolved using the tangent dynamics of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over  N  successive steps, yielding the lyapunov exponent spectrum (at each step the parallepiped is re-normalized).  Performance Notes  This function uses a  tangent_integrator . For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and  reinit!  it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is  lyapunovs ( tinteg ,   N ,   dt :: Real ,   Ttr :: Real )   If you want to obtain the convergence timeseries of the Lyapunov spectrum, use the method  ChaosTools . lyapunovs_convergence ( tinteg ,   N ,   dt ,   Ttr )   (not exported).  References  [1] : A. M. Lyapunov,  The General Problem of the Stability of Motion , Taylor   Francis (1992)  [2] : K. Geist  et al. , Progr. Theor. Phys.  83 , pp 875 (1990)  [3] : G. Benettin  et al. , Meccanica  15 , pp 9-20   21-30 (1980)   As you can see, the documentation string is detailed and self-contained. For example, the Lyapunov spectrum of the  folded towel map  is calculated as:  using   DynamicalSystems  ds   =   Systems . towel ()  \u03bb\u03bb   =   lyapunovs ( ds ,   10000 )   3-element Array{Float64,1}:\n  0.4324643001570437\n  0.372138249644847 \n -3.296974844093203   Similarly, for a continuous system, e.g. the Lorenz system, you would do:  lor   =   Systems . lorenz ( \u03c1   =   32.0 )   #this is not the original parameter!  \u03bb\u03bb   =   lyapunovs ( lor ,   10000 ,   dt   =   0.1 )   3-element Array{Float64,1}:\n   0.9837999200006314  \n  -0.001272173431277142\n -14.649189089612964     lyapunovs  is also very fast:  using   BenchmarkTools  ds   =   Systems . towel ()  @btime   lyapunovs ( $ ds ,   2000 );     237.226 \u03bcs (45 allocations: 4.27 KiB)  Here is an example of plotting the exponents of the Roessler system for various parameters:  ```@example lyap\nds = Systems.roessler()  cs = 4:0.01:6; \u03bbs = zeros(length(cs), 3)\nfor (i, c) in enumerate(cs)\n    set_parameter!(ds, 3, c)\n    \u03bbs[i, :] .= lyapunovs(ds, 10000; Ttr = 500.0)\nend  figure()\nplot(cs, \u03bbs)\ntight_layout() # hide\nsavefig(\"rosl_l.png\"); nothing # hide  ![](osl_l.png) a   id= Maximum-Lyapunov-Exponent-1 /a \n\n## Maximum Lyapunov Exponent\n\n\nIt is possible to get only the maximum Lyapunov exponent simply by giving `1` as the third argument of [`lyapunovs`](lyapunovs.md#ChaosTools.lyapunovs). However, there is a second algorithm that allows you to do the same thing, which is offered by the function `lyapunov`: a   id= ChaosTools.lyapunov   href= #ChaosTools.lyapunov # /a \n**`ChaosTools.lyapunov`**  mdash;  *Function*.\n\n\n\n```julia\nlyapunov(ds::DynamicalSystem, \u03a4; kwargs...) -  \u03bb  Calculate the maximum Lyapunov exponent  \u03bb  using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one.  T   denotes the total time of evolution (should be  Int  for discrete systems).  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the trajectories before starting to measure the expontent. Should be  Int  for discrete systems.  d0 = 1e-9  : Initial   rescaling distance between the two neighboring trajectories.  upper_threshold = 1e-6  : Upper distance threshold for rescaling.  lower_threshold = 1e-12  : Lower distance threshold for rescaling (in order to  be able to detect negative exponents).  dt = 1  : Time of evolution between each check of distance exceeding the thresholds. For continuous systems this is approximate.  inittest = (u1, d0) -  u1 .+ d0/sqrt(D)  : A function that given  (u1, d0)  initializes the test state with distance  d0  from the given state  u1  ( D  is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.  diffeq...  : Keyword arguments propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples. Only valid for continuous systems.   Description  Two neighboring trajectories with initial distance  d0  are evolved in time. At time  t_i t_i  their distance  d(t_i) d(t_i)  either exceeds the  upper_threshold , or is lower than  lower_threshold , which initializes a rescaling of the test trajectory back to having distance  d0  from the given one, while the rescaling keeps the difference vector along the maximal expansion/contraction direction:  u_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0) u_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0) .  The maximum Lyapunov exponent is the average of the time-local Lyapunov exponents   \n\\lambda = \\frac{1}{t_{n} - t_0}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.  \n\\lambda = \\frac{1}{t_{n} - t_0}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.   Performance Notes  This function uses a  parallel_integrator . For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and  reinit!  it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is  lyapunov(pinteg, T, Ttr, dt, d0, ut, lt)  References  [1] : G. Benettin  et al. , Phys. Rev. A  14 , pp 2338 (1976)   For example:  using   DynamicalSystems  henon   =   Systems . henon ()  \u03bb   =   lyapunov ( henon ,   10000 ,   d0   =   1e-7 ,   upper_threshold   =   1e-4 ,   Ttr   =   100 )   0.42018736282059616  The same is done for continuous systems:  lor   =   Systems . lorenz ( \u03c1   =   32 )  \u03bb   =   lyapunov ( lor ,   10000.0 ,   dt   =   10.0 ,   Ttr   =   100.0 )   0.9959721568028167", 
            "title": "Lyapunov Spectrum"
        }, 
        {
            "location": "/chaos/chaos_detection/", 
            "text": "Chaos Detection\n\n\nBeing able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum \nlyapunov\n exponent and a bounded system indicate chaos.\n\n\nHowever, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in \nDynamicalSystems.jl\n.\n\n\n\n\nPerformance depends on the solver\n\n\nNotice that the performance of functions that use \nContinuousDynamicalSystem\ns depend crucially on the chosen solver. Please see the documentation page on \nChoosing a solver\n for an in-depth discussion.\n\n\n\n\n\n\nGeneralized Alignment Index\n\n\n\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis \n Antonopoulos.\n\n\n#\n\n\nChaosTools.gali\n \n \nFunction\n.\n\n\ngali\n(\nds\n::\nDynamicalSystem\n,\n \ntmax\n,\n \nk\n::\nInt\n \n|\n \nQ0\n;\n \nkwargs\n...\n)\n \n-\n \nGALI_k\n,\n \nt\n\n\n\n\n\n\nCompute \n\\text{GALI}_k\n\\text{GALI}_k\n [1] for a given \nk\n up to time \ntmax\n. Return \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n and time vector \nt\nt\n.\n\n\nThe third argument, which sets the order of \ngali\n, can be an integer \nk\n, or a matrix with its columns being the deviation vectors (then \nk = size(Q0)[2]\n). In the first case random orthonormal vectors are chosen.\n\n\nKeyword Arguments\n\n\n\n\nthreshold = 1e-12\n : If \nGALI_k\n falls below the \nthreshold\n iteration is terminated.\n\n\ndt = 1\n : Time-step between deviation vector normalizations. For continuous systems this is approximate.\n\n\nu0\n : Initial state for the system. Defaults to \nget_state(ds)\n.\n\n\ndiffeq...\n : Keyword arguments propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples. Only valid for continuous systems.\n\n\n\n\nDescription\n\n\nThe Generalized Alignment Index, \n\\text{GALI}_k\n\\text{GALI}_k\n, is an efficient (and very fast) indicator of chaotic or regular behavior type in \nD\nD\n-dimensional Hamiltonian systems (\nD\nD\n is number of variables). The \nasymptotic\n behavior of \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n depends critically on the type of orbit resulting from the initial condition. If it is a chaotic orbit, then\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\nwith \n\\lambda_j\n\\lambda_j\n being the \nj\n-th Lyapunov exponent (see \nlyapunov\n, \nlyapunovs\n). If on the other hand the orbit is regular, corresponding to movement in \nd\nd\n-dimensional torus with \n1 \\le d \\le D/2\n1 \\le d \\le D/2\n then it holds\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, \n \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d \n 1 \\\\\n      t^{-(k - d)}, \n \\text{if} \\;\\;  d \n k \\le D - d \\\\\n      t^{-(2k - D)}, \n \\text{if} \\;\\;  D - d \n k \\le D\n    \\end{cases}\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}\n\n\n\n\n\nTraditionally, if \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n does not become less than the \nthreshold\n until \ntmax\n the given orbit is said to be chaotic, otherwise it is regular.\n\n\nOur implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of \nA\nA\n, a matrix that has as \ncolumns\n the deviation vectors.\n\n\nPerformance Notes\n\n\nThis function uses a \ntangent_integrator\n. For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and \nreinit!\n it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is\n\n\nChaosTools.gali(tinteg, tmax, dt, threshold)\n\n\n\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, Physica D \n231\n, pp 30\u201354 (2007)\n\n\n[2] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n\n\n\n\nDiscrete Example\n\n\nWe will use 3 coupled standard maps as an example for a discrete system:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\nM\n \n=\n \n3\n;\n \nks\n \n=\n \n3\nones\n(\nM\n);\n \n\u0393\n \n=\n \n0.1\n;\n\n\nstable\n \n=\n \n[\n\u03c0\n,\n \n\u03c0\n,\n \n\u03c0\n,\n \n0.01\n,\n \n0\n,\n \n0\n]\n \n.+\n \n0.1\n\n\nchaotic\n \n=\n \nrand\n(\n2\nM\n)\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nstable\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\n\n\n\n\n6-dimensional discrete dynamical system\n state:       [3.24159, 3.24159, 3.24159, 0.11, 0.1, 0.1]\n e.o.m.:      CoupledStandardMaps\n in-place?    true\n jacobian:    CoupledStandardMaps\n parameters:  Tuple\n\n\n\n\n\nFirst, let's see the behavior of GALI for a stable orbit\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n8\n,\n4\n))\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nstable\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n4\n,\n \n5\n,\n \n6\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \n1e5\n,\n \nk\n;\n \nthreshold\n=\n1e-12\n)\n\n    \nlt\n \n=\n \nlog10\n.\n(\nt\n);\n \nlg\n \n=\n \nlog10\n.\n(\ng\n)\n\n    \nplot\n(\nlt\n,\n \nlg\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlt\n \n=\n \n2\n:\n0.5\n:\n5.5\n\n\nplot\n(\nlt\n,\n \n-\n2\n(\nlt\n \n.-\n \n3\n),\n \nlabel\n=\nslope -2\n)\n\n\nplot\n(\nlt\n,\n \n-\n4\n(\nlt\n \n.-\n \n3\n),\n \nlabel\n=\nslope -4\n)\n\n\nplot\n(\nlt\n,\n \n-\n6\n(\nlt\n \n.-\n \n3\n),\n \nlabel\n=\nslope -6\n)\n\n\n\nxlim\n(\n2\n,\n \n5.5\n)\n\n\nylim\n(\n-\n12\n,\n \n2\n)\n\n\nlegend\n()\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nNow do the same for a chaotic orbit\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n8\n,\n4\n))\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n,\n \nchaotic\n)\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nchaotic\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n100000\n;\n \nu0\n \n=\n \nchaotic\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n6\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \n1000\n,\n \nk\n;\n \nu0\n \n=\n \nchaotic\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n()\n\n\nxlim\n(\n0\n,\n100\n)\n\n\nylim\n(\n1e-12\n,\n \n1\n)\n\n\n\n\n\n\n\n\n\n\nContinuous Example\n\n\nAs an example of a continuous system, let's see the \nhenonheiles\n:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n,\n \nOrdinaryDiffEq\n\n\nsp\n \n=\n \n[\n0\n,\n \n.\n295456\n,\n \n.\n407308431\n,\n \n0\n]\n \n# stable periodic orbit: 1D torus\n\n\nqp\n \n=\n \n[\n0\n,\n \n.\n483000\n,\n \n.\n278980390\n,\n \n0\n]\n \n# quasiperiodic orbit: 2D torus\n\n\nch\n \n=\n \n[\n0\n,\n \n-\n0.25\n,\n \n0.42081\n,\n \n0\n]\n      \n# chaotic orbit\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n(\nsp\n)\n\n\n\n\n\n\n4-dimensional continuous dynamical system\n state:       [0.0, 0.295456, 0.407308, 0.0]\n e.o.m.:      hheom!\n in-place?    true\n jacobian:    hhjacob!\n parameters:  nothing\n\n\n\n\n\nFirst, we see the behavior with a stable periodic orbit\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n8\n,\n4\n))\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\ndt\n \n=\n \n1.0\n\n\n\ndiffeq\n \n=\n \n(\nabstol\n=\n1e-9\n,\n \nreltol\n=\n1e-9\n,\n \nalg\n \n=\n \nTsit5\n(),\n \nmaxiters\n \n=\n \ntypemax\n(\nInt\n))\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n;\n \ndt\n=\ndt\n,\n \ndiffeq\n...\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nsp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \n10000.0\n,\n \nk\n;\n \ndt\n \n=\n \ndt\n,\n \ndiffeq\n...\n)\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n    \nif\n \nk\n \n \n4\n\n        \nloglog\n(\nt\n,\n \n100\n \n./\n \nt\n.^\n(\nk\n-\n1\n),\n \nlabel\n=\nslope -\n$\n(\nk\n-\n1\n)\n)\n\n    \nelse\n\n        \nloglog\n(\nt\n,\n \n10000\n \n./\n \nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nend\n\n\nend\n\n\nylim\n(\n1e-12\n,\n \n2\n)\n\n\nlegend\n();\n\n\n\n\n\n\n\n\nNext, let's see what happens with a quasi-periodic orbit. Don't forget to change the \nu0\n arguments!\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n8\n,\n4\n))\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \nqp\n;\n \ndt\n=\ndt\n,\n \ndiffeq\n...\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nqp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \n10000.0\n,\n \nk\n;\n \nu0\n \n=\n \nqp\n,\n \ndt\n \n=\n \ndt\n,\n \ndiffeq\n...\n)\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n    \nif\n \nk\n \n==\n \n2\n\n        \nloglog\n(\nt\n,\n \n1\n \n./\n \nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nelse\n\n        \nloglog\n(\nt\n,\n \n100\n \n./\n \nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nend\n\n\nend\n\n\nylim\n(\n1e-12\n,\n \n2\n)\n\n\nlegend\n()\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nFinally, here is GALI of a continuous system with a chaotic orbit\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n8\n,\n4\n))\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \nch\n;\n \ndt\n=\ndt\n,\n \ndiffeq\n...\n)\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nch\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n5000.0\n;\n \ndt\n=\ndt\n,\n \nu0\n \n=\n \nch\n,\n \ndiffeq\n...\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \n1000\n,\n \nk\n;\n \nu0\n \n=\n \nch\n,\n \ndt\n \n=\n \ndt\n,\n \ndiffeq\n...\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n()\n\n\nylim\n(\n1e-16\n,\n \n1\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nAs you can see, the results of both discrete and continuous systems match very well the theory described in \ngali\n.\n\n\n\n\nUsing GALI\n\n\nNo-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations and proofs that the method works as expected in all cases.\n\n\nThe most common usage of \n\\text{GALI}_k\n\\text{GALI}_k\n is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether \n\\text{GALI}_k\n\\text{GALI}_k\n stays below it, for a (sufficiently) big \nk\nk\n.\n\n\nThe following is an example of \nadvanced usage\n:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nfunction\n \nmain\n(\nk\n)\n\n\n    \n# Measure of chaoticity: final time of gali_2\n\n    \ndens\n \n=\n \n201\n\n    \nchaoticity\n \n=\n \nzeros\n(\nInt\n,\n \ndens\n,\n \ndens\n)\n\n\n    \n\u03b8s\n \n=\n \nps\n \n=\n \nrange\n(\n0\n,\n \nstop\n \n=\n \n2\n\u03c0\n,\n \nlength\n \n=\n \ndens\n+\n1\n)\n\n    \nds\n \n=\n \nSystems\n.\nstandardmap\n(\nk\n \n=\n \nk\n)\n\n\n    \ntinteg\n \n=\n \ntangent_integrator\n(\nds\n,\n \n2\n)\n\n\n    \nfor\n \n(\ni\n,\n \n\u03b8\n)\n \n\u2208\n \nenumerate\n(\n\u03b8s\n[\n1\n:\ndens\n])\n\n        \nprintln\n(\ni = \n$\n(\ni\n)\n)\n\n        \nfor\n \n(\nj\n,\n \np\n)\n \n\u2208\n \nenumerate\n(\nps\n[\n1\n:\ndens\n])\n\n\n            \n# new initial state is the system initial state\n\n            \nu0\n \n=\n \nSVector\n{\n2\n}(\n\u03b8\n,\n \np\n)\n\n            \nreinit!\n(\ntinteg\n,\n \nu0\n,\n \northonormal\n(\n2\n,\n2\n))\n\n\n            \n# Low-level call signature of gali:\n\n            \n#  gali(tinteg, tmax, dt, threshold)\n\n            \nchaoticity\n[\ni\n,\n \nj\n]\n \n=\n \ngali\n(\ntinteg\n,\n \n500\n,\n \n1\n,\n \n1e-12\n)[\n2\n][\nend\n]\n\n        \nend\n\n    \nend\n\n    \nfigure\n()\n\n    \npcolormesh\n(\n\u03b8s\n \n.-\n \n(\n\u03b8s\n[\n2\n]\n \n-\n \n\u03b8s\n[\n1\n])\n/\n2\n,\n \nps\n \n.-\n \n(\nps\n[\n2\n]\n \n-\n \nps\n[\n1\n])\n/\n2\n,\n\n    \nchaoticity\n)\n\n    \ncolorbar\n()\n\n    \nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n    \nylabel\n(\n\\$\np\n\\$\n)\n\n    \nreturn\n\n\nend\n\n\n\nmain\n(\n0.9\n);\n\n\n\n\n\n\n\n\n\n\nRegular orbits in the Henon-Heiles system\n\n\nIn this example we use the \npoincaresos\n function to produce surfaces of section of the \nhenonheiles\n system at different energies. At each energy \ngali\n is used to color-code each initial condition according to how chaotic/regular it is, i.e. how much time does it need to exceed the \nthreshold\n of \ngali\n.\n\n\n \n \n\n\n\nYou can download the video using \nthis link\n.\n\n\nYou can find the script that produced this animation in \nDynamicalSystems/docs/coolanimations/gali_psos_henonhelies.jl\n.", 
            "title": "Chaos Distinction"
        }, 
        {
            "location": "/chaos/chaos_detection/#chaos-detection", 
            "text": "Being able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum  lyapunov  exponent and a bounded system indicate chaos.  However, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in  DynamicalSystems.jl .   Performance depends on the solver  Notice that the performance of functions that use  ContinuousDynamicalSystem s depend crucially on the chosen solver. Please see the documentation page on  Choosing a solver  for an in-depth discussion.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#generalized-alignment-index", 
            "text": "\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis   Antonopoulos.  #  ChaosTools.gali     Function .  gali ( ds :: DynamicalSystem ,   tmax ,   k :: Int   |   Q0 ;   kwargs ... )   -   GALI_k ,   t   Compute  \\text{GALI}_k \\text{GALI}_k  [1] for a given  k  up to time  tmax . Return  \\text{GALI}_k(t) \\text{GALI}_k(t)  and time vector  t t .  The third argument, which sets the order of  gali , can be an integer  k , or a matrix with its columns being the deviation vectors (then  k = size(Q0)[2] ). In the first case random orthonormal vectors are chosen.  Keyword Arguments   threshold = 1e-12  : If  GALI_k  falls below the  threshold  iteration is terminated.  dt = 1  : Time-step between deviation vector normalizations. For continuous systems this is approximate.  u0  : Initial state for the system. Defaults to  get_state(ds) .  diffeq...  : Keyword arguments propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples. Only valid for continuous systems.   Description  The Generalized Alignment Index,  \\text{GALI}_k \\text{GALI}_k , is an efficient (and very fast) indicator of chaotic or regular behavior type in  D D -dimensional Hamiltonian systems ( D D  is number of variables). The  asymptotic  behavior of  \\text{GALI}_k(t) \\text{GALI}_k(t)  depends critically on the type of orbit resulting from the initial condition. If it is a chaotic orbit, then   \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]  \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]   with  \\lambda_j \\lambda_j  being the  j -th Lyapunov exponent (see  lyapunov ,  lyapunovs ). If on the other hand the orbit is regular, corresponding to movement in  d d -dimensional torus with  1 \\le d \\le D/2 1 \\le d \\le D/2  then it holds   \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.},   \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d   1 \\\\\n      t^{-(k - d)},   \\text{if} \\;\\;  d   k \\le D - d \\\\\n      t^{-(2k - D)},   \\text{if} \\;\\;  D - d   k \\le D\n    \\end{cases}  \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}   Traditionally, if  \\text{GALI}_k(t) \\text{GALI}_k(t)  does not become less than the  threshold  until  tmax  the given orbit is said to be chaotic, otherwise it is regular.  Our implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of  A A , a matrix that has as  columns  the deviation vectors.  Performance Notes  This function uses a  tangent_integrator . For loops over initial conditions and/or parameter values one should use the low level method that accepts an integrator, and  reinit!  it to new initial conditions. See the \"advanced documentation\" for info on the integrator object. The low level method is  ChaosTools.gali(tinteg, tmax, dt, threshold)  References  [1] : Skokos, C. H.  et al. , Physica D  231 , pp 30\u201354 (2007)  [2] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics  915 , Springer (2016)", 
            "title": "Generalized Alignment Index"
        }, 
        {
            "location": "/chaos/chaos_detection/#discrete-example", 
            "text": "We will use 3 coupled standard maps as an example for a discrete system:  using   DynamicalSystems  using   PyPlot  M   =   3 ;   ks   =   3 ones ( M );   \u0393   =   0.1 ;  stable   =   [ \u03c0 ,   \u03c0 ,   \u03c0 ,   0.01 ,   0 ,   0 ]   .+   0.1  chaotic   =   rand ( 2 M )  ds   =   Systems . coupledstandardmaps ( M ,   stable ;   ks = ks ,   \u0393   =   \u0393 )   6-dimensional discrete dynamical system\n state:       [3.24159, 3.24159, 3.24159, 0.11, 0.1, 0.1]\n e.o.m.:      CoupledStandardMaps\n in-place?    true\n jacobian:    CoupledStandardMaps\n parameters:  Tuple  First, let's see the behavior of GALI for a stable orbit  figure ( figsize   =   ( 8 , 4 ))  tr   =   trajectory ( ds ,   100000 )  subplot ( 1 , 2 , 1 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = stable , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  subplot ( 1 , 2 , 2 )  for   k   in   [ 4 ,   5 ,   6 ] \n     g ,   t   =   gali ( ds ,   1e5 ,   k ;   threshold = 1e-12 ) \n     lt   =   log10 . ( t );   lg   =   log10 . ( g ) \n     plot ( lt ,   lg ,   label = GALI_ $ ( k ) )  end  lt   =   2 : 0.5 : 5.5  plot ( lt ,   - 2 ( lt   .-   3 ),   label = slope -2 )  plot ( lt ,   - 4 ( lt   .-   3 ),   label = slope -4 )  plot ( lt ,   - 6 ( lt   .-   3 ),   label = slope -6 )  xlim ( 2 ,   5.5 )  ylim ( - 12 ,   2 )  legend ()  tight_layout ()    Now do the same for a chaotic orbit  figure ( figsize   =   ( 8 , 4 ))  tr   =   trajectory ( ds ,   100000 ,   chaotic )  subplot ( 1 , 2 , 1 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = chaotic , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  subplot ( 1 , 2 , 2 )  ls   =   lyapunovs ( ds ,   100000 ;   u0   =   chaotic )  for   k   in   [ 2 , 3 , 6 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   1000 ,   k ;   u0   =   chaotic ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ()  xlim ( 0 , 100 )  ylim ( 1e-12 ,   1 )", 
            "title": "Discrete Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#continuous-example", 
            "text": "As an example of a continuous system, let's see the  henonheiles :  using   DynamicalSystems  using   PyPlot ,   OrdinaryDiffEq  sp   =   [ 0 ,   . 295456 ,   . 407308431 ,   0 ]   # stable periodic orbit: 1D torus  qp   =   [ 0 ,   . 483000 ,   . 278980390 ,   0 ]   # quasiperiodic orbit: 2D torus  ch   =   [ 0 ,   - 0.25 ,   0.42081 ,   0 ]        # chaotic orbit  ds   =   Systems . henonheiles ( sp )   4-dimensional continuous dynamical system\n state:       [0.0, 0.295456, 0.407308, 0.0]\n e.o.m.:      hheom!\n in-place?    true\n jacobian:    hhjacob!\n parameters:  nothing  First, we see the behavior with a stable periodic orbit  figure ( figsize   =   ( 8 , 4 ))  subplot ( 1 , 2 , 1 )  dt   =   1.0  diffeq   =   ( abstol = 1e-9 ,   reltol = 1e-9 ,   alg   =   Tsit5 (),   maxiters   =   typemax ( Int ))  tr   =   trajectory ( ds ,   10000.0 ;   dt = dt ,   diffeq ... )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = sp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 1 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   10000.0 ,   k ;   dt   =   dt ,   diffeq ... ) \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) ) \n     if   k     4 \n         loglog ( t ,   100   ./   t .^ ( k - 1 ),   label = slope - $ ( k - 1 ) ) \n     else \n         loglog ( t ,   10000   ./   t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     end  end  ylim ( 1e-12 ,   2 )  legend ();    Next, let's see what happens with a quasi-periodic orbit. Don't forget to change the  u0  arguments!  figure ( figsize   =   ( 8 , 4 ))  subplot ( 1 , 2 , 1 )  tr   =   trajectory ( ds ,   10000.0 ,   qp ;   dt = dt ,   diffeq ... )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = qp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 1 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   10000.0 ,   k ;   u0   =   qp ,   dt   =   dt ,   diffeq ... ) \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) ) \n     if   k   ==   2 \n         loglog ( t ,   1   ./   t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     else \n         loglog ( t ,   100   ./   t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     end  end  ylim ( 1e-12 ,   2 )  legend ()  tight_layout ()    Finally, here is GALI of a continuous system with a chaotic orbit  figure ( figsize   =   ( 8 , 4 ))  tr   =   trajectory ( ds ,   10000.0 ,   ch ;   dt = dt ,   diffeq ... )  subplot ( 1 , 2 , 1 )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = ch , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 1 , 2 , 2 )  ls   =   lyapunovs ( ds ,   5000.0 ;   dt = dt ,   u0   =   ch ,   diffeq ... )  for   k   in   [ 2 , 3 , 4 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   1000 ,   k ;   u0   =   ch ,   dt   =   dt ,   diffeq ... ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ()  ylim ( 1e-16 ,   1 )  tight_layout ()    As you can see, the results of both discrete and continuous systems match very well the theory described in  gali .", 
            "title": "Continuous Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#using-gali", 
            "text": "No-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations and proofs that the method works as expected in all cases.  The most common usage of  \\text{GALI}_k \\text{GALI}_k  is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether  \\text{GALI}_k \\text{GALI}_k  stays below it, for a (sufficiently) big  k k .  The following is an example of  advanced usage :  using   DynamicalSystems  using   PyPlot ,   StaticArrays  function   main ( k ) \n\n     # Measure of chaoticity: final time of gali_2 \n     dens   =   201 \n     chaoticity   =   zeros ( Int ,   dens ,   dens ) \n\n     \u03b8s   =   ps   =   range ( 0 ,   stop   =   2 \u03c0 ,   length   =   dens + 1 ) \n     ds   =   Systems . standardmap ( k   =   k ) \n\n     tinteg   =   tangent_integrator ( ds ,   2 ) \n\n     for   ( i ,   \u03b8 )   \u2208   enumerate ( \u03b8s [ 1 : dens ]) \n         println ( i =  $ ( i ) ) \n         for   ( j ,   p )   \u2208   enumerate ( ps [ 1 : dens ]) \n\n             # new initial state is the system initial state \n             u0   =   SVector { 2 }( \u03b8 ,   p ) \n             reinit! ( tinteg ,   u0 ,   orthonormal ( 2 , 2 )) \n\n             # Low-level call signature of gali: \n             #  gali(tinteg, tmax, dt, threshold) \n             chaoticity [ i ,   j ]   =   gali ( tinteg ,   500 ,   1 ,   1e-12 )[ 2 ][ end ] \n         end \n     end \n     figure () \n     pcolormesh ( \u03b8s   .-   ( \u03b8s [ 2 ]   -   \u03b8s [ 1 ]) / 2 ,   ps   .-   ( ps [ 2 ]   -   ps [ 1 ]) / 2 , \n     chaoticity ) \n     colorbar () \n     xlabel ( \\$\\\\ theta \\$ ) \n     ylabel ( \\$ p \\$ ) \n     return  end  main ( 0.9 );", 
            "title": "Using GALI"
        }, 
        {
            "location": "/chaos/chaos_detection/#regular-orbits-in-the-henon-heiles-system", 
            "text": "In this example we use the  poincaresos  function to produce surfaces of section of the  henonheiles  system at different energies. At each energy  gali  is used to color-code each initial condition according to how chaotic/regular it is, i.e. how much time does it need to exceed the  threshold  of  gali .       You can download the video using  this link .  You can find the script that produced this animation in  DynamicalSystems/docs/coolanimations/gali_psos_henonhelies.jl .", 
            "title": "Regular orbits in the Henon-Heiles system"
        }, 
        {
            "location": "/chaos/entropies/", 
            "text": "Entropies and Dimensions\n\n\n\n\nGeneralized Entropy\n\n\nIn the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known \nthermodynamic ones\n, used in Statistical Physics. Rather, they are more like the to the entropies of \ninformation theory\n, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.\n\n\n\n\nThe main way of computing entropies in \nDynamicalSystems.jl\n is the \"generalized entropy\":\n\n\n#\n\n\nChaosTools.genentropy\n \n \nFunction\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the \n\u03b1\n order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length \n\u03b5\n using \nnon0hist\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \np\n::\nAbstractArray\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the entropy of an array \np\n directly, assuming that \np\n is sum-normalized.\n\n\nOptionally use \nbase\n for the logarithms.\n\n\nDescription\n\n\nLet \np\np\n be an array of probabilities (summing to 1). Then the R\u00e9nyi entropy is\n\n\n\n\n\nH_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)\n\n\n\n\nH_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)\n\n\n\n\n\nand generalizes other known entropies, like e.g. the information entropy (\n\\alpha = 1\n\\alpha = 1\n, see [2]), the maximum entropy (\n\\alpha=0\n\\alpha=0\n, also known as Hartley entropy), or the correlation entropy (\n\\alpha = 2\n\\alpha = 2\n, also known as collision entropy).\n\n\nReferences\n\n\n[1] : A. R\u00e9nyi, \nProceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability\n, pp 547 (1960)\n\n\n[2] : C. E. Shannon, Bell Systems Technical Journal \n27\n, pp 379 (1948)\n\n\n\n\nBasically, given a \ndataset\n you can partition it into boxes to calculate an entropy. See below for a detailed example.\n\n\n\n\nWorried about memory overflow? Don't be!\n\n\nPartitioning the dataset (i.e. doing a \nhistogram\n) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size \n\u03b5\n.\n\n\nHowever, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!\n\n\n\n\nThe function used internally by \ngenentropy\n is \nnon0hist\n:\n\n\n#\n\n\nChaosTools.non0hist\n \n \nFunction\n.\n\n\nnon0hist\n(\n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n)\n\n\n\n\n\n\nPartition a dataset into tabulated intervals (boxes) of size \n\u03b5\n and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements and bin edge information.\n\n\nPerformances Notes\n\n\nThis method has a linearithmic time complexity (\nn log(n)\n for \nn = length(data)\n) and a linear space complexity (\nl\n for \nl = dimension(data)\n). This allows computation of entropies of high-dimensional datasets and with small box sizes \n\u03b5\n without memory overflow.\n\n\nUse e.g. \nfit(Histogram, ...)\n from \nStatsBase\n if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\n\n\n\n\nAttractor Dimension Estimation\n\n\nThere are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the \nFractal dimension\n. This real number can offer a lot of information about the object that the dataset represents.\n\n\nBased on the definition of the \ngeneralized entropy\n, one can calculate an appropriate dimension, called \ngeneralized dimension\n:\n\n\n#\n\n\nChaosTools.generalized_dim\n \n \nFunction\n.\n\n\ngeneralized_dim\n(\n\u03b1\n,\n \ndataset\n \n[,\n \nsizes\n])\n \n-\n \nD_\u03b1\n\n\n\n\n\n\nReturn the \n\u03b1\n order generalized dimension of the \ndataset\n, by calculating the \ngenentropy\n for each \n\u03b5 \u2208 sizes\n.\n\n\nDescription\n\n\nThe returned dimension is approximated by the (inverse) power law exponent of the scaling of the \ngenentropy\n versus the box size \n\u03b5\n, where \n\u03b5 \u2208 sizes\n.\n\n\nCalling this function performs a lot of automated steps:\n\n\n\n\nA vector of box sizes is decided by calling \nsizes = estimate_boxsizes(dataset)\n, if \nsizes\n is not given.\n\n\nFor each element of \nsizes\n the appropriate entropy is calculated, through \nd = genentropy.(\u03b1, sizes, dataset)\n. Let \nx = -log.(sizes)\n.\n\n\nThe curve \nd(x)\n is decomposed into linear regions, using \nlinear_regions\n(x, d)\n.\n\n\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the function \nlinear_region\n. This slope is the return value of \ngeneralized_dim\n.\n\n\n\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\n\nThe following aliases are provided:\n\n\n\n\n\u03b1 = 0 : \nboxcounting_dim\n, \ncapacity_dim\n\n\n\u03b1 = 1 : \ninformation_dim\n\n\n\n\n\n\n\n\nBe wary when using \ngeneralized_dim\n\n\nAs stated clearly by the documentation string, calling \ngeneralized_dim\n performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.\n\n\n\n\n#\n\n\nChaosTools.estimate_boxsizes\n \n \nFunction\n.\n\n\nestimate_boxsizes\n(\ndataset\n::\nAbstractDataset\n;\n \nk\n::\nInt\n \n=\n \n12\n,\n \nz\n \n=\n \n-\n1\n,\n \nw\n \n=\n \n1\n)\n\n\n\n\n\n\nReturn \nk\n exponentially spaced values: \n10 .^ range(lower+w, upper+z, length = k)\n.\n\n\nlower\n is the magnitude of the minimum pair-wise distance between datapoints while \nupper\n is the magnitude of the maximum difference between greatest and smallest number among each timeseries.\n\n\n\"Magnitude\" here stands for order of magnitude, i.e. \nround(log10(x))\n.\n\n\n#\n\n\nChaosTools.linear_regions\n \n \nFunction\n.\n\n\nlinear_regions\n(\nx\n,\n \ny\n;\n \ndxi\n::\nInt\n \n=\n \n1\n,\n \ntol\n \n=\n \n0.2\n)\n \n-\n \n(\nlrs\n,\n \ntangents\n)\n\n\n\n\n\n\nIdentify regions where the curve \ny(x)\n is linear, by scanning the \nx\n-axis every \ndxi\n indices (e.g. at \nx[1] to x[5], x[5] to x[10], x[10] to x[15]\n and so on if \ndxi=5\n).\n\n\nIf the slope (calculated using \nLsqFit\n) of a region of width \ndxi\n is approximatelly equal to that of the previous region, within tolerance \ntol\n, then these two regions belong to the same linear region.\n\n\nReturn the indices of \nx\n that correspond to linear regions, \nlrs\n, and the approximated \ntangents\n at each region. \nlrs\n is a vector of \nInt\n. Notice that \ntangents\n is \nnot\n accurate: it is not recomputed at every step, but only when its error exceeds the tolerance \ntol\n! Use \nlinear_region\n to obtain a correct estimate for the slope of the largest linear region.\n\n\n#\n\n\nChaosTools.linear_region\n \n \nFunction\n.\n\n\nlinear_region\n(\nx\n,\n \ny\n;\n \ndxi\n::\nInt\n \n=\n \n1\n,\n \ntol\n \n=\n \n0.2\n)\n \n-\n \n([\nind1\n,\n \nind2\n],\n \nslope\n)\n\n\n\n\n\n\nCall \nlinear_regions\n, identify the largest linear region and approximate the slope of the entire region using \nlinreg\n. Return the indices where the region starts and stops (\nx[ind1:ind2]\n) as well as the approximated slope.\n\n\n\n\n\n\nExample\n\n\nFor an example of using entropies to compute the dimension of an attractor let's use everyone's favorite system:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n()\n\n\n\n\n\n\n3-dimensional continuous dynamical system\n state:       [0.0, 10.0, 0.0]\n e.o.m.:      loop\n in-place?    false\n jacobian:    loop_jac\n parameters:  [10.0, 28.0, 2.66667]\n\n\n\n\n\nOur goal is to compute entropies for many different partition sizes \n\u03b5\n, so let's get down to it:\n\n\ntr\n \n=\n \ntrajectory\n(\nlor\n,\n \n100.0\n;\n \nTtr\n \n=\n \n10.0\n)\n\n\n\n\u03b5\u03c2\n \n=\n \n\u212f\n \n.^\n \n(\n-\n3.5\n:\n0.5\n:\n3.5\n)\n \n# semi-random guess\n\n\nHs\n \n=\n \ngenentropy\n.\n(\n1\n,\n \n\u03b5\u03c2\n,\n \nRef\n(\ntr\n))\n\n\n\n\n\n\n15-element Array{Float64,1}:\n 9.203093741524961 \n 9.192836189007936 \n 9.175263277513562 \n 9.11505930200447  \n 8.96800482792302  \n 8.650506643435117 \n 8.093472893003044 \n 7.329635456822501 \n 6.440181060621013 \n 5.520699459712151 \n 4.5223766061173905\n 3.5423893065177388\n 2.688046235608927 \n 1.9474099557575748\n 0.8398578086498265\n\n\n\n\n\nxs\n \n=\n \n@\n.\n \n-\nlog\n(\n\u03b5\u03c2\n)\n\n\nfigure\n()\n\n\nplot\n(\nxs\n,\n \nHs\n)\n\n\nylabel\n(\n\\$\nH_1\n\\$\n)\n\n\nxlabel\n(\n\\$\n-\n\\\\\nlog (\n\\\\\nepsilon)\n\\$\n);\n\n\n\n\n\n\n\n\nThe slope of the linear scaling region of the above plot is the generalized dimension (of order \u03b1 = 2) for the attractor of the Lorenz system.\n\n\nGiven that we \nsee\n the plot, we can estimate where the linear scaling region starts and ends. However, we can use the function \nlinear_region\n to get an estimate of the result as well. First let's visualize what it does:\n\n\nlrs\n,\n \nslopes\n \n=\n \nlinear_regions\n(\nxs\n,\n \nHs\n,\n \ntol\n \n=\n \n0.25\n)\n\n\n\nfigure\n()\n\n\nfor\n \ni\n \nin\n \n1\n:\nlength\n(\nlrs\n)\n-\n1\n\n    \nplot\n(\nxs\n[\nlrs\n[\ni\n]\n:\nlrs\n[\ni\n+\n1\n]],\n \nHs\n[\nlrs\n[\ni\n]\n:\nlrs\n[\ni\n+\n1\n]],\n \nmarker\n \n=\n \no\n)\n\n\nend\n\n\nylabel\n(\n\\$\nH_1\n\\$\n)\n\n\nxlabel\n(\n\\$\n-\n\\\\\nlog (\n\\\\\nepsilon)\n\\$\n);\n\n\n\n\n\n\n\n\nThe \nlinear_region\n function  computes the slope of the largest region:\n\n\nlinear_region\n(\nxs\n,\n \nHs\n)[\n2\n]\n\n\n\n\n\n\n1.721554939214834\n\n\n\n\n\nThis result is an approximation of the information dimension (because we used \n\u03b1 = 1\n) of the Lorenz attractor.\n\n\n\n\nThe above pipeline is bundled in \ngeneralized_dim\n. For example, the dimension of the strange attractor of the \nH\u00e9non map\n, following the above approach but taking automated steps, is:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nts\n \n=\n \ntrajectory\n(\nhen\n,\n \n200000\n)\n\n\nD_hen\n \n=\n \ngeneralized_dim\n(\n1\n,\n \nts\n)\n\n\n\n\n\n\n1.215884931528749\n\n\n\n\n\nAs a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D \n56\n, pp 185-187 (1992)).\n\n\n\n\n\n\nOther Entropies and Dimensions\n\n\n\n\nPermutation Entropy\n\n\nThe permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.\n\n\n#\n\n\nChaosTools.permentropy\n \n \nFunction\n.\n\n\npermentropy\n(\nx\n::\nAbstractVector\n,\n \norder\n \n[,\n \ninterval\n=\n1\n];\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the permutation entropy [1] of given \norder\n from the \nx\n timeseries.\n\n\nOptionally, \ninterval\n can be specified to use \nx[t0:interval:t1]\n when calculating permutation of the sliding windows between \nt0\n and \nt1 = t0 + interval * (order - 1)\n.\n\n\nOptionally use \nbase\n for the logarithms.\n\n\nReferences\n\n\n[1] : C. Bandt, \n B. Pompe, \nPhys. Rev. Lett. \n88\n (17), pp 174102 (2002)\n\n\nFor example, we will compute and compare the \nlyapunov\n exponent of the logistic map with the order-6 permutation entropy, like in the original paper.\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\nrs\n \n=\n \n3.5\n:\n0.001\n:\n4\n\n\nls\n \n=\n \nFloat64\n[];\n \nhs\n \n=\n \nFloat64\n[]\n\n\nfor\n \nr\n \nin\n \nrs\n\n    \nds\n.\np\n[\n1\n]\n \n=\n \nr\n\n    \npush!\n(\nls\n,\n \nlyapunov\n(\nds\n,\n \n100000\n))\n\n    \n# For 1D systems `trajectory` returns a vector\n\n    \npush!\n(\nhs\n,\n \npermentropy\n(\ntrajectory\n(\nds\n,\n \n10000\n),\n \n6\n))\n\n\nend\n\n\n\nf\n \n=\n \nfigure\n(\nfigsize\n \n=\n \n(\n10\n,\n6\n))\n\n\na1\n \n=\n \nsubplot\n(\n211\n)\n\n\nplot\n(\nrs\n,\n \nls\n);\n \nylim\n(\n-\n2\n,\n \nlog\n(\n2\n));\n \nylabel\n(\n\\$\\\\\nlambda\n\\$\n)\n\n\na1\n.\naxes\n.\nget_xaxis\n()\n.\nset_ticklabels\n([])\n\n\nxlim\n(\nrs\n[\n1\n],\n \nrs\n[\nend\n]);\n\n\n\na2\n \n=\n \nsubplot\n(\n212\n)\n\n\nplot\n(\nrs\n,\n \nhs\n;\n \ncolor\n \n=\n \nC1\n);\n \nylabel\n(\n\\$\nh_6\n\\$\n)\n\n\nxlim\n(\nrs\n[\n1\n],\n \nrs\n[\nend\n]);\n \nxlabel\n(\n\\$\nr\n\\$\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\n\n\nPermutation Entropy performance\n\n\nEven though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue \nChaosTools.jl#22\n keeps track of this, and contains information on how to improve performance.\n\n\n\n\n\n\nKaplan-Yorke Dimension\n\n\n#\n\n\nChaosTools.kaplanyorke_dim\n \n \nFunction\n.\n\n\nkaplanyorke_dim\n(\nlyapunovs\n::\nAbstractVector\n)\n\n\n\n\n\n\nCalculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].\n\n\nDescription\n\n\nThe Kaplan-Yorke dimension is simply the point where \ncumsum(lyapunovs)\n becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.\n\n\nUseful in combination with \nlyapunovs\n.\n\n\nReferences\n\n\n[1] :  J. Kaplan \n J. Yorke, \nChaotic behavior of multidimensional difference equations\n, Lecture Notes in Mathematics vol. \n730\n, Springer (1979)\n\n\n\n\nNotice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nD_kp\n \n=\n \nkaplanyorke_dim\n(\nlyapunovs\n(\nhen\n,\n \n100000\n))\n\n\n\n\n\n\n1.2586975135042189", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies-and-dimensions", 
            "text": "", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#generalized-entropy", 
            "text": "In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known  thermodynamic ones , used in Statistical Physics. Rather, they are more like the to the entropies of  information theory , which represents information contained within a dataset, or information about the dimensional scaling of a dataset.   The main way of computing entropies in  DynamicalSystems.jl  is the \"generalized entropy\":  #  ChaosTools.genentropy     Function .  genentropy ( \u03b1 ,   \u03b5 ,   dataset :: AbstractDataset ;   base   =   e )   Compute the  \u03b1  order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length  \u03b5  using  non0hist .  genentropy ( \u03b1 ,   p :: AbstractArray ;   base   =   e )   Compute the entropy of an array  p  directly, assuming that  p  is sum-normalized.  Optionally use  base  for the logarithms.  Description  Let  p p  be an array of probabilities (summing to 1). Then the R\u00e9nyi entropy is   \nH_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)  \nH_\\alpha(p) = \\frac{1}{1-\\alpha} \\log \\left(\\sum_i p[i]^\\alpha\\right)   and generalizes other known entropies, like e.g. the information entropy ( \\alpha = 1 \\alpha = 1 , see [2]), the maximum entropy ( \\alpha=0 \\alpha=0 , also known as Hartley entropy), or the correlation entropy ( \\alpha = 2 \\alpha = 2 , also known as collision entropy).  References  [1] : A. R\u00e9nyi,  Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability , pp 547 (1960)  [2] : C. E. Shannon, Bell Systems Technical Journal  27 , pp 379 (1948)   Basically, given a  dataset  you can partition it into boxes to calculate an entropy. See below for a detailed example.   Worried about memory overflow? Don't be!  Partitioning the dataset (i.e. doing a  histogram ) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size  \u03b5 .  However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!   The function used internally by  genentropy  is  non0hist :  #  ChaosTools.non0hist     Function .  non0hist ( \u03b5 ,   dataset :: AbstractDataset )   Partition a dataset into tabulated intervals (boxes) of size  \u03b5  and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements and bin edge information.  Performances Notes  This method has a linearithmic time complexity ( n log(n)  for  n = length(data) ) and a linear space complexity ( l  for  l = dimension(data) ). This allows computation of entropies of high-dimensional datasets and with small box sizes  \u03b5  without memory overflow.  Use e.g.  fit(Histogram, ...)  from  StatsBase  if you wish to keep information about the edges of the binning as well as the zero elements.", 
            "title": "Generalized Entropy"
        }, 
        {
            "location": "/chaos/entropies/#attractor-dimension-estimation", 
            "text": "There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the  Fractal dimension . This real number can offer a lot of information about the object that the dataset represents.  Based on the definition of the  generalized entropy , one can calculate an appropriate dimension, called  generalized dimension :  #  ChaosTools.generalized_dim     Function .  generalized_dim ( \u03b1 ,   dataset   [,   sizes ])   -   D_\u03b1   Return the  \u03b1  order generalized dimension of the  dataset , by calculating the  genentropy  for each  \u03b5 \u2208 sizes .  Description  The returned dimension is approximated by the (inverse) power law exponent of the scaling of the  genentropy  versus the box size  \u03b5 , where  \u03b5 \u2208 sizes .  Calling this function performs a lot of automated steps:   A vector of box sizes is decided by calling  sizes = estimate_boxsizes(dataset) , if  sizes  is not given.  For each element of  sizes  the appropriate entropy is calculated, through  d = genentropy.(\u03b1, sizes, dataset) . Let  x = -log.(sizes) .  The curve  d(x)  is decomposed into linear regions, using  linear_regions (x, d) .  The biggest linear region is chosen, and a fit for the slope of that region is performed using the function  linear_region . This slope is the return value of  generalized_dim .   By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.  The following aliases are provided:   \u03b1 = 0 :  boxcounting_dim ,  capacity_dim  \u03b1 = 1 :  information_dim     Be wary when using  generalized_dim  As stated clearly by the documentation string, calling  generalized_dim  performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.   #  ChaosTools.estimate_boxsizes     Function .  estimate_boxsizes ( dataset :: AbstractDataset ;   k :: Int   =   12 ,   z   =   - 1 ,   w   =   1 )   Return  k  exponentially spaced values:  10 .^ range(lower+w, upper+z, length = k) .  lower  is the magnitude of the minimum pair-wise distance between datapoints while  upper  is the magnitude of the maximum difference between greatest and smallest number among each timeseries.  \"Magnitude\" here stands for order of magnitude, i.e.  round(log10(x)) .  #  ChaosTools.linear_regions     Function .  linear_regions ( x ,   y ;   dxi :: Int   =   1 ,   tol   =   0.2 )   -   ( lrs ,   tangents )   Identify regions where the curve  y(x)  is linear, by scanning the  x -axis every  dxi  indices (e.g. at  x[1] to x[5], x[5] to x[10], x[10] to x[15]  and so on if  dxi=5 ).  If the slope (calculated using  LsqFit ) of a region of width  dxi  is approximatelly equal to that of the previous region, within tolerance  tol , then these two regions belong to the same linear region.  Return the indices of  x  that correspond to linear regions,  lrs , and the approximated  tangents  at each region.  lrs  is a vector of  Int . Notice that  tangents  is  not  accurate: it is not recomputed at every step, but only when its error exceeds the tolerance  tol ! Use  linear_region  to obtain a correct estimate for the slope of the largest linear region.  #  ChaosTools.linear_region     Function .  linear_region ( x ,   y ;   dxi :: Int   =   1 ,   tol   =   0.2 )   -   ([ ind1 ,   ind2 ],   slope )   Call  linear_regions , identify the largest linear region and approximate the slope of the entire region using  linreg . Return the indices where the region starts and stops ( x[ind1:ind2] ) as well as the approximated slope.", 
            "title": "Attractor Dimension Estimation"
        }, 
        {
            "location": "/chaos/entropies/#example", 
            "text": "For an example of using entropies to compute the dimension of an attractor let's use everyone's favorite system:  using   DynamicalSystems ,   PyPlot  lor   =   Systems . lorenz ()   3-dimensional continuous dynamical system\n state:       [0.0, 10.0, 0.0]\n e.o.m.:      loop\n in-place?    false\n jacobian:    loop_jac\n parameters:  [10.0, 28.0, 2.66667]  Our goal is to compute entropies for many different partition sizes  \u03b5 , so let's get down to it:  tr   =   trajectory ( lor ,   100.0 ;   Ttr   =   10.0 )  \u03b5\u03c2   =   \u212f   .^   ( - 3.5 : 0.5 : 3.5 )   # semi-random guess  Hs   =   genentropy . ( 1 ,   \u03b5\u03c2 ,   Ref ( tr ))   15-element Array{Float64,1}:\n 9.203093741524961 \n 9.192836189007936 \n 9.175263277513562 \n 9.11505930200447  \n 8.96800482792302  \n 8.650506643435117 \n 8.093472893003044 \n 7.329635456822501 \n 6.440181060621013 \n 5.520699459712151 \n 4.5223766061173905\n 3.5423893065177388\n 2.688046235608927 \n 1.9474099557575748\n 0.8398578086498265  xs   =   @ .   - log ( \u03b5\u03c2 )  figure ()  plot ( xs ,   Hs )  ylabel ( \\$ H_1 \\$ )  xlabel ( \\$ - \\\\ log ( \\\\ epsilon) \\$ );    The slope of the linear scaling region of the above plot is the generalized dimension (of order \u03b1 = 2) for the attractor of the Lorenz system.  Given that we  see  the plot, we can estimate where the linear scaling region starts and ends. However, we can use the function  linear_region  to get an estimate of the result as well. First let's visualize what it does:  lrs ,   slopes   =   linear_regions ( xs ,   Hs ,   tol   =   0.25 )  figure ()  for   i   in   1 : length ( lrs ) - 1 \n     plot ( xs [ lrs [ i ] : lrs [ i + 1 ]],   Hs [ lrs [ i ] : lrs [ i + 1 ]],   marker   =   o )  end  ylabel ( \\$ H_1 \\$ )  xlabel ( \\$ - \\\\ log ( \\\\ epsilon) \\$ );    The  linear_region  function  computes the slope of the largest region:  linear_region ( xs ,   Hs )[ 2 ]   1.721554939214834  This result is an approximation of the information dimension (because we used  \u03b1 = 1 ) of the Lorenz attractor.   The above pipeline is bundled in  generalized_dim . For example, the dimension of the strange attractor of the  H\u00e9non map , following the above approach but taking automated steps, is:  using   DynamicalSystems  hen   =   Systems . henon ()  ts   =   trajectory ( hen ,   200000 )  D_hen   =   generalized_dim ( 1 ,   ts )   1.215884931528749  As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D  56 , pp 185-187 (1992)).", 
            "title": "Example"
        }, 
        {
            "location": "/chaos/entropies/#other-entropies-and-dimensions", 
            "text": "", 
            "title": "Other Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#permutation-entropy", 
            "text": "The permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.  #  ChaosTools.permentropy     Function .  permentropy ( x :: AbstractVector ,   order   [,   interval = 1 ];   base   =   e )   Compute the permutation entropy [1] of given  order  from the  x  timeseries.  Optionally,  interval  can be specified to use  x[t0:interval:t1]  when calculating permutation of the sliding windows between  t0  and  t1 = t0 + interval * (order - 1) .  Optionally use  base  for the logarithms.  References  [1] : C. Bandt,   B. Pompe,  Phys. Rev. Lett.  88  (17), pp 174102 (2002)  For example, we will compute and compare the  lyapunov  exponent of the logistic map with the order-6 permutation entropy, like in the original paper.  using   DynamicalSystems ,   PyPlot  ds   =   Systems . logistic ()  rs   =   3.5 : 0.001 : 4  ls   =   Float64 [];   hs   =   Float64 []  for   r   in   rs \n     ds . p [ 1 ]   =   r \n     push! ( ls ,   lyapunov ( ds ,   100000 )) \n     # For 1D systems `trajectory` returns a vector \n     push! ( hs ,   permentropy ( trajectory ( ds ,   10000 ),   6 ))  end  f   =   figure ( figsize   =   ( 10 , 6 ))  a1   =   subplot ( 211 )  plot ( rs ,   ls );   ylim ( - 2 ,   log ( 2 ));   ylabel ( \\$\\\\ lambda \\$ )  a1 . axes . get_xaxis () . set_ticklabels ([])  xlim ( rs [ 1 ],   rs [ end ]);  a2   =   subplot ( 212 )  plot ( rs ,   hs ;   color   =   C1 );   ylabel ( \\$ h_6 \\$ )  xlim ( rs [ 1 ],   rs [ end ]);   xlabel ( \\$ r \\$ )  tight_layout ()     Permutation Entropy performance  Even though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue  ChaosTools.jl#22  keeps track of this, and contains information on how to improve performance.", 
            "title": "Permutation Entropy"
        }, 
        {
            "location": "/chaos/entropies/#kaplan-yorke-dimension", 
            "text": "#  ChaosTools.kaplanyorke_dim     Function .  kaplanyorke_dim ( lyapunovs :: AbstractVector )   Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].  Description  The Kaplan-Yorke dimension is simply the point where  cumsum(lyapunovs)  becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.  Useful in combination with  lyapunovs .  References  [1] :  J. Kaplan   J. Yorke,  Chaotic behavior of multidimensional difference equations , Lecture Notes in Mathematics vol.  730 , Springer (1979)   Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:  using   DynamicalSystems  hen   =   Systems . henon ()  D_kp   =   kaplanyorke_dim ( lyapunovs ( hen ,   100000 ))   1.2586975135042189", 
            "title": "Kaplan-Yorke Dimension"
        }, 
        {
            "location": "/chaos/nlts/", 
            "text": "Nonlinear Timeseries Analysis\n\n\n\n\nNumerical Lyapunov Exponent\n\n\nGiven any timeseries, one can first \nreconstruct\n it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with\n\n\n#\n\n\nChaosTools.numericallyapunov\n \n \nFunction\n.\n\n\nnumericallyapunov\n(\nR\n::\nDataset\n,\n \nks\n;\n  \nrefstates\n,\n \nw\n,\n \ndistance\n,\n \nntype\n)\n\n\n\n\n\n\nReturn \nE = [E(k) for k \u2208 ks]\n, where \nE(k)\n is the average logarithmic distance between states of a \nneighborhood\n that are evolved in time for \nk\n steps (\nk\n must be integer).\n\n\nKeyword Arguments\n\n\n\n\nrefstates = 1:(length(R) - ks[end])\n : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in \nrefstates\n.\n\n\nw::Int = 1\n : The Theiler window, which determines whether points are separated enough in time to be considered separate trajectories (see [1] and \nneighborhood\n).\n\n\nntype::AbstractNeighborhood = FixedMassNeighborhood(1)\n : The method to be used when evaluating the neighborhood of each reference state. See \nAbstractNeighborhood\n or \nneighborhood\n for more info.\n\n\ndistance::Metric = Cityblock()\n : The distance function used in the logarithmic distance of nearby states. The allowed distances are \nCityblock()\n and \nEuclidean()\n. See below for more info.\n\n\n\n\nDescription\n\n\nIf the dataset/reconstruction exhibits exponential divergence of nearby states, then it should clearly hold\n\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\n\nfor a \nwell defined region\n in the \nk\n axis, where \n\\lambda\n\\lambda\n is the approximated maximum Lyapunov exponent. \n\\Delta t\n\\Delta t\n is the time between samples in the original timeseries. You can use \nlinear_region\n with arguments \n(ks .* \u0394t, E)\n to identify the slope (= \n\\lambda\n\\lambda\n) immediatelly, assuming you have choosen sufficiently good \nks\n such that the linear scaling region is bigger than the saturated region.\n\n\nThe algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index \nk\n increases. The average of the above over all neighborhood states over all reference states is the returned result.\n\n\nIf the \nMetric\n is \nEuclidean()\n then use the Euclidean distance of the full \nD\n-dimensional points (distance \nd_E\nd_E\n in ref. [1]). If however the \nMetric\n is \nCityblock()\n, calculate the absolute distance of \nonly the first elements\n of the \nm+k\n and \nn+k\n points of the reconstruction \nR\n (distance \nd_F\nd_F\n in ref. [1]).\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 1 (section 1.3.2), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n[2] : Kantz, H., Phys. Lett. A \n185\n, pp 77\u201387 (1994)\n\n\n\n\nThe function \nnumericallyapunov\n has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.\n\n\n\n\nExample of Numerical Lyapunov computation\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n \n#fake measurements for the win!\n\n\n\nks\n \n=\n \n1\n:\n20\n\n\n\u211c\n \n=\n \n1\n:\n10000\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n6\n))\n\n\n\nfor\n \n(\ni\n,\n \ndi\n)\n \nin\n \nenumerate\n([\nEuclidean\n(),\n \nCityblock\n()])\n\n    \nsubplot\n(\n1\n,\n \n2\n,\n \ni\n)\n\n    \nntype\n \n=\n \nFixedMassNeighborhood\n(\n2\n)\n\n    \ntitle\n(\nDistance: \n$\n(\ndi\n)\n,\n \nsize\n \n=\n \n18\n)\n\n    \nfor\n \nD\n \nin\n \n[\n1\n,\n \n3\n,\n \n6\n]\n\n        \nR\n \n=\n \nreconstruct\n(\nx\n,\n \nD\n,\n \n1\n)\n\n        \nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n;\n\n        \nrefstates\n \n=\n \n\u211c\n,\n \ndistance\n \n=\n \ndi\n,\n \nntype\n \n=\n \nntype\n)\n\n        \n\u0394t\n \n=\n \n1\n\n        \n\u03bb\n \n=\n \nlinear_region\n(\nks\n.*\n\u0394t\n,\n \nE\n)[\n2\n]\n\n        \n# gives the linear slope, i.e. the Lyapunov exponent\n\n        \nplot\n(\nks\n \n.-\n \n1\n,\n \nE\n \n.-\n \nE\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$D\n, \u03bb=\n$\n(\nround\n(\n\u03bb\n,\n \ndigits\n \n=\n \n3\n))\n)\n\n        \nlegend\n()\n\n        \ntight_layout\n()\n\n    \nend\n\n\nend\n\n\n\n\n\n\n\n\n\n\nBad Time-axis (\nks\n) length\n\n\n\n\nLarge \nks\n\n\nThis simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!\n\n\n\n\nLet's revisit the example of the previous section:\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\nlength\n(\nx\n)\n\n\n\n\n\n\n100001\n\n\n\n\n\nThe timeseries of such length could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following\n\n\nks\n \n=\n \n1\n:\n100\n\n\nR\n \n=\n \nreconstruct\n(\nx\n,\n \n1\n,\n \n1\n)\n\n\nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n,\n \nntype\n \n=\n \nFixedMassNeighborhood\n(\n2\n))\n\n\nfigure\n()\n\n\nplot\n(\nks\n \n.-\n \n1\n,\n \nE\n \n.-\n \nE\n[\n1\n])\n\n\ntitle\n(\nLyappunov: \n$\n(\nlinear_region\n(\nks\n,\n \nE\n)[\n2\n])\n)\n\n\n\n\n\n\n\n\nNotice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function \nlinear_region\n would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)\n\n\n\n\nCase of a Continuous system\n\n\nThe process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example helps the users get familiar with the process:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nntype\n \n=\n \nFixedMassNeighborhood\n(\n5\n)\n \n#5 nearest neighbors of each state\n\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n\n\n# create a timeseries of 1 dimension\n\n\ndt\n \n=\n \n0.05\n\n\nx\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n;\n \ndt\n \n=\n \ndt\n)[\n:\n,\n \n1\n]\n\n\n\n\n\n\n20001-element Array{Float64,1}:\n  0.0               \n  4.285178117517708 \n  8.924780522479637 \n 15.012203311102235 \n 20.05533894475613  \n 18.062350952804728 \n  9.898343637398332 \n  2.199113375749754 \n -2.6729722259323863\n -5.33812377718313  \n  \u22ee                 \n  8.982259166809083 \n 10.670302924424051 \n 11.842660338013772 \n 11.87017960987118  \n 10.618810328221139 \n  8.656181145701055 \n  6.751870416569524 \n  5.371698729920532 \n  4.63198025969704  \n\n\n\n\n\nWe know that we have to use much bigger \nks\n than \n1:20\n, because this is a continuous case! (See reference given in \nnumericallyapunovs\n)\n\n\nks1\n \n=\n \n0\n:\n200\n\n\n\n\n\n\n0\n:\n200\n\n\n\n\n\n\nand in fact it is even better to not increment the \nks\n one by one but instead do\n\n\nks2\n \n=\n \n0\n:\n4\n:\n200\n\n\n\n\n\n\n0\n:\n4\n:\n200\n\n\n\n\n\n\nNow we plot some example computations\n\n\nfigure\n()\n\n\nfor\n \nD\n \nin\n \n[\n3\n,\n \n7\n],\n \n\u03c4\n \nin\n \n[\n7\n,\n \n15\n]\n\n    \nr\n \n=\n \nreconstruct\n(\nx\n,\n \nD\n,\n \n\u03c4\n)\n\n\n    \n# E1 = numericallyapunov(r, ks1; ntype = ntype)\n\n    \n# \u03bb1 = linear_region(ks1 .* dt, E1)[2]\n\n    \nE2\n \n=\n \nnumericallyapunov\n(\nr\n,\n \nks2\n;\n \nntype\n \n=\n \nntype\n)\n\n    \n\u03bb2\n \n=\n \nlinear_region\n(\nks2\n \n.*\n \ndt\n,\n \nE2\n)[\n2\n]\n\n\n    \n# plot(ks1,E1.-E1[1], label = \ndense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3))\n)\n\n    \nplot\n(\nks2\n,\nE2\n.-\nE2\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$\n(\nD\n)\n, \u03c4=\n$\n(\n\u03c4\n)\n, \u03bb=\n$\n(\nround\n(\n\u03bb2\n,\n \ndigits\n \n=\n \n3\n))\n)\n\n\nend\n\n\n\nlegend\n()\n\n\nxlabel\n(\nk (0.05\u00d7t)\n)\n\n\nylabel\n(\nE - E(0)\n)\n\n\ntitle\n(\nContinuous Reconstruction Lyapunov\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nAs you can see, using \n\u03c4 = 15\n is not a great choice! The estimates with \n\u03c4 = 7\n though are very good (the actual value is around \n\u03bb \u2248 0.89...\n).\n\n\n\n\nBroomhead-King Coordinates\n\n\n#\n\n\nChaosTools.broomhead_king\n \n \nFunction\n.\n\n\nbroomhead_king\n(\ns\n::\nAbstractVector\n,\n \nd\n::\nInt\n)\n \n-\n \nU\n,\n \nS\n,\n \nVtr\n\n\n\n\n\n\nReturn the Broomhead-King coordinates of a timeseries \ns\n by performing \nsvd\n on the so-called trajectory matrix with dimension \nd\n.\n\n\nDescription\n\n\nBroomhead and King coordinates is an approach proposed in [1] that applies the Karhunen\u2013Lo\u00e8ve theorem to delay coordinates embedding with smallest possible delay.\n\n\nThe function performs singular value decomposition on the \nd\n-dimensional trajectory matrix \nX\nX\n of \ns\ns\n,\n\n\n\n\n\nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 \n x_2 \n \\ldots \n x_d \\\\\nx_2 \n x_3 \n \\ldots \n x_{d+1}\\\\\n\\vdots \n \\vdots \n \\vdots \n \\vdots \\\\\nx_{N-d+1} \n x_{N-d+2} \n\\ldots \n x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.\n\n\n\n\nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 & x_2 & \\ldots & x_d \\\\\nx_2 & x_3 & \\ldots & x_{d+1}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nx_{N-d+1} & x_{N-d+2} &\\ldots & x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.\n\n\n\n\n\nwhere \nx := s - \\bar{s}\nx := s - \\bar{s}\n. The columns of \nU\nU\n can then be used as a new coordinate system, and by considering the values of the singular values \nS\nS\n you can decide how many columns of \nU\nU\n are \"important\". See the documentation page for example application.\n\n\nReferences\n\n\n[1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A \n20\n, 9, pp L563 (1987)\n\n\n\n\nThis alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.\n\n\nTake the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\ngissinger\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n,\n \ndt\n \n=\n \n0.05\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\nL\n \n=\n \nlength\n(\nx\n)\n\n\ns\n \n=\n \nx\n \n.+\n \n0.5\nrand\n(\nL\n)\n \n#add noise\n\n\n\nU\n,\n \nS\n \n=\n \nbroomhead_king\n(\ns\n,\n \n40\n)\n\n\nsummary\n(\nU\n)\n\n\n\n\n\n\n19962\u00d740 Array{Float64,2}\n\n\n\n\n\n\nNow let's simply compare the above result with the one you get from doing a \"standard\" call to \nreconstruct\n:\n\n\nfigure\n(\nfigsize\n=\n \n(\n10\n,\n6\n))\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\nplot\n(\nU\n[\n:\n,\n \n1\n],\n \nU\n[\n:\n,\n \n2\n])\n\n\ntitle\n(\nBroomhead-King of s\n)\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nR\n \n=\n \nreconstruct\n(\ns\n,\n \n1\n,\n \n30\n)\n\n\nplot\n(\ncolumns\n(\nR\n)\n...\n;\n \ncolor\n \n=\n \nC3\n)\n\n\ntitle\n(\n2D reconstruction of s\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nwe have used the same system as in the \ndelay coordinates reconstruction\n example, and picked the optimal delay time of \n\u03c4 = 30\n (for same \ndt = 0.05\n). Regardless, the vanilla delay coordinates is much worse than the Broomhead-King coordinates.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#nonlinear-timeseries-analysis", 
            "text": "", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#numerical-lyapunov-exponent", 
            "text": "Given any timeseries, one can first  reconstruct  it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with  #  ChaosTools.numericallyapunov     Function .  numericallyapunov ( R :: Dataset ,   ks ;    refstates ,   w ,   distance ,   ntype )   Return  E = [E(k) for k \u2208 ks] , where  E(k)  is the average logarithmic distance between states of a  neighborhood  that are evolved in time for  k  steps ( k  must be integer).  Keyword Arguments   refstates = 1:(length(R) - ks[end])  : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in  refstates .  w::Int = 1  : The Theiler window, which determines whether points are separated enough in time to be considered separate trajectories (see [1] and  neighborhood ).  ntype::AbstractNeighborhood = FixedMassNeighborhood(1)  : The method to be used when evaluating the neighborhood of each reference state. See  AbstractNeighborhood  or  neighborhood  for more info.  distance::Metric = Cityblock()  : The distance function used in the logarithmic distance of nearby states. The allowed distances are  Cityblock()  and  Euclidean() . See below for more info.   Description  If the dataset/reconstruction exhibits exponential divergence of nearby states, then it should clearly hold   \nE(k) \\approx \\lambda\\Delta t k + E(0)  \nE(k) \\approx \\lambda\\Delta t k + E(0)   for a  well defined region  in the  k  axis, where  \\lambda \\lambda  is the approximated maximum Lyapunov exponent.  \\Delta t \\Delta t  is the time between samples in the original timeseries. You can use  linear_region  with arguments  (ks .* \u0394t, E)  to identify the slope (=  \\lambda \\lambda ) immediatelly, assuming you have choosen sufficiently good  ks  such that the linear scaling region is bigger than the saturated region.  The algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index  k  increases. The average of the above over all neighborhood states over all reference states is the returned result.  If the  Metric  is  Euclidean()  then use the Euclidean distance of the full  D -dimensional points (distance  d_E d_E  in ref. [1]). If however the  Metric  is  Cityblock() , calculate the absolute distance of  only the first elements  of the  m+k  and  n+k  points of the reconstruction  R  (distance  d_F d_F  in ref. [1]).  References  [1] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 1 (section 1.3.2), Lecture Notes in Physics  915 , Springer (2016)  [2] : Kantz, H., Phys. Lett. A  185 , pp 77\u201387 (1994)   The function  numericallyapunov  has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.", 
            "title": "Numerical Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/nlts/#example-of-numerical-lyapunov-computation", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   #fake measurements for the win!  ks   =   1 : 20  \u211c   =   1 : 10000  fig   =   figure ( figsize = ( 10 , 6 ))  for   ( i ,   di )   in   enumerate ([ Euclidean (),   Cityblock ()]) \n     subplot ( 1 ,   2 ,   i ) \n     ntype   =   FixedMassNeighborhood ( 2 ) \n     title ( Distance:  $ ( di ) ,   size   =   18 ) \n     for   D   in   [ 1 ,   3 ,   6 ] \n         R   =   reconstruct ( x ,   D ,   1 ) \n         E   =   numericallyapunov ( R ,   ks ; \n         refstates   =   \u211c ,   distance   =   di ,   ntype   =   ntype ) \n         \u0394t   =   1 \n         \u03bb   =   linear_region ( ks .* \u0394t ,   E )[ 2 ] \n         # gives the linear slope, i.e. the Lyapunov exponent \n         plot ( ks   .-   1 ,   E   .-   E [ 1 ],   label   =   D= $D , \u03bb= $ ( round ( \u03bb ,   digits   =   3 )) ) \n         legend () \n         tight_layout () \n     end  end", 
            "title": "Example of Numerical Lyapunov computation"
        }, 
        {
            "location": "/chaos/nlts/#bad-time-axis-ks-length", 
            "text": "Large  ks  This simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!   Let's revisit the example of the previous section:  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]  length ( x )   100001  The timeseries of such length could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following  ks   =   1 : 100  R   =   reconstruct ( x ,   1 ,   1 )  E   =   numericallyapunov ( R ,   ks ,   ntype   =   FixedMassNeighborhood ( 2 ))  figure ()  plot ( ks   .-   1 ,   E   .-   E [ 1 ])  title ( Lyappunov:  $ ( linear_region ( ks ,   E )[ 2 ]) )    Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function  linear_region  would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)", 
            "title": "Bad Time-axis (ks) length"
        }, 
        {
            "location": "/chaos/nlts/#case-of-a-continuous-system", 
            "text": "The process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example helps the users get familiar with the process:  using   DynamicalSystems ,   PyPlot  ntype   =   FixedMassNeighborhood ( 5 )   #5 nearest neighbors of each state  ds   =   Systems . lorenz ()  # create a timeseries of 1 dimension  dt   =   0.05  x   =   trajectory ( ds ,   1000.0 ;   dt   =   dt )[ : ,   1 ]   20001-element Array{Float64,1}:\n  0.0               \n  4.285178117517708 \n  8.924780522479637 \n 15.012203311102235 \n 20.05533894475613  \n 18.062350952804728 \n  9.898343637398332 \n  2.199113375749754 \n -2.6729722259323863\n -5.33812377718313  \n  \u22ee                 \n  8.982259166809083 \n 10.670302924424051 \n 11.842660338013772 \n 11.87017960987118  \n 10.618810328221139 \n  8.656181145701055 \n  6.751870416569524 \n  5.371698729920532 \n  4.63198025969704    We know that we have to use much bigger  ks  than  1:20 , because this is a continuous case! (See reference given in  numericallyapunovs )  ks1   =   0 : 200   0 : 200   and in fact it is even better to not increment the  ks  one by one but instead do  ks2   =   0 : 4 : 200   0 : 4 : 200   Now we plot some example computations  figure ()  for   D   in   [ 3 ,   7 ],   \u03c4   in   [ 7 ,   15 ] \n     r   =   reconstruct ( x ,   D ,   \u03c4 ) \n\n     # E1 = numericallyapunov(r, ks1; ntype = ntype) \n     # \u03bb1 = linear_region(ks1 .* dt, E1)[2] \n     E2   =   numericallyapunov ( r ,   ks2 ;   ntype   =   ntype ) \n     \u03bb2   =   linear_region ( ks2   .*   dt ,   E2 )[ 2 ] \n\n     # plot(ks1,E1.-E1[1], label =  dense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3)) ) \n     plot ( ks2 , E2 .- E2 [ 1 ],   label   =   D= $ ( D ) , \u03c4= $ ( \u03c4 ) , \u03bb= $ ( round ( \u03bb2 ,   digits   =   3 )) )  end  legend ()  xlabel ( k (0.05\u00d7t) )  ylabel ( E - E(0) )  title ( Continuous Reconstruction Lyapunov )  tight_layout ()    As you can see, using  \u03c4 = 15  is not a great choice! The estimates with  \u03c4 = 7  though are very good (the actual value is around  \u03bb \u2248 0.89... ).", 
            "title": "Case of a Continuous system"
        }, 
        {
            "location": "/chaos/nlts/#broomhead-king-coordinates", 
            "text": "#  ChaosTools.broomhead_king     Function .  broomhead_king ( s :: AbstractVector ,   d :: Int )   -   U ,   S ,   Vtr   Return the Broomhead-King coordinates of a timeseries  s  by performing  svd  on the so-called trajectory matrix with dimension  d .  Description  Broomhead and King coordinates is an approach proposed in [1] that applies the Karhunen\u2013Lo\u00e8ve theorem to delay coordinates embedding with smallest possible delay.  The function performs singular value decomposition on the  d -dimensional trajectory matrix  X X  of  s s ,   \nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1   x_2   \\ldots   x_d \\\\\nx_2   x_3   \\ldots   x_{d+1}\\\\\n\\vdots   \\vdots   \\vdots   \\vdots \\\\\nx_{N-d+1}   x_{N-d+2}  \\ldots   x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.  \nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 & x_2 & \\ldots & x_d \\\\\nx_2 & x_3 & \\ldots & x_{d+1}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nx_{N-d+1} & x_{N-d+2} &\\ldots & x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.   where  x := s - \\bar{s} x := s - \\bar{s} . The columns of  U U  can then be used as a new coordinate system, and by considering the values of the singular values  S S  you can decide how many columns of  U U  are \"important\". See the documentation page for example application.  References  [1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A  20 , 9, pp L563 (1987)   This alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.  Take the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . gissinger ()  data   =   trajectory ( ds ,   1000.0 ,   dt   =   0.05 )  x   =   data [ : ,   1 ]  L   =   length ( x )  s   =   x   .+   0.5 rand ( L )   #add noise  U ,   S   =   broomhead_king ( s ,   40 )  summary ( U )   19962\u00d740 Array{Float64,2}   Now let's simply compare the above result with the one you get from doing a \"standard\" call to  reconstruct :  figure ( figsize =   ( 10 , 6 ))  subplot ( 1 , 2 , 1 )  plot ( U [ : ,   1 ],   U [ : ,   2 ])  title ( Broomhead-King of s )  subplot ( 1 , 2 , 2 )  R   =   reconstruct ( s ,   1 ,   30 )  plot ( columns ( R ) ... ;   color   =   C3 )  title ( 2D reconstruction of s )  tight_layout ()    we have used the same system as in the  delay coordinates reconstruction  example, and picked the optimal delay time of  \u03c4 = 30  (for same  dt = 0.05 ). Regardless, the vanilla delay coordinates is much worse than the Broomhead-King coordinates.", 
            "title": "Broomhead-King Coordinates"
        }, 
        {
            "location": "/chaos/periodicity/", 
            "text": "Detecting Stable and Unstable Periodic Orbits of Maps\n\n\nChaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the \nperiodic orbits\n existing in the chaotic sea.\n\n\nFinding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher \n Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at \nunstable\n ones.\n\n\nThe functions \nperiodicorbits\n and \nlambdamatrix\n implement the algorithm:\n\n\n#\n\n\nChaosTools.periodicorbits\n \n \nFunction\n.\n\n\nperiodicorbits\n(\nds\n::\nDiscreteDynamicalSystem\n,\n\n               \no\n,\n \nics\n \n[,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n];\n \nkwargs\n...\n)\n \n-\n \nFP\n\n\n\n\n\n\nFind fixed points \nFP\n of order \no\n for the map \nds\n using the algorithm due to Schmelcher \n Diakonos [1]. \nics\n is a collection of initial conditions (container of vectors) to be evolved.\n\n\nOptional Arguments\n\n\nThe optional arguments \n\u03bbs, indss, singss\n \nmust be containers\n of appropriate values, besides \n\u03bbs\n which can also be a number. The elements of those containers are passed to: \nlambdamatrix(\u03bb, inds, sings)\n, which creates the appropriate \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrix. If these arguments are not given, a random permutation will be chosen for them, with \n\u03bb=0.001\n.\n\n\nKeyword Arguments\n\n\n\n\nmaxiters::Int = 100000\n : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\n\n\ndisttol = 1e-10\n : Distance tolerance. If the 2-norm of a previous state with  the next one is \n\u2264 disttol\n then it has converged to a fixed point.\n\n\ninftol = 10.0\n : If a state reaches \nnorm(state) \u2265 inftol\n it is assumed that  it has escaped to infinity (and is thus abandoned).\n\n\nroundtol::Int = 4\n : The found fixed points are rounded  to \nroundtol\n digits before pushed into the list of returned fixed points \nFP\n,  \nif\n they are not already contained in \nFP\n.  This is done so that \nFP\n doesn't contain duplicate fixed points (notice  that this has nothing to do with \ndisttol\n). Turn this to \ntypemax(Int)\n  to get the full precision of the algorithm.\n\n\n\n\nDescription\n\n\nThe algorithm used can detect periodic orbits by turning fixed points of the original map \nds\n to stable ones, through the transformation\n\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\nwith \nf\nf\n = \neom\n. The index \nk\nk\n counts the various possible \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n.\n\n\nPerformance Notes\n\n\nAll\n initial conditions are evolved for \nall\n \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n which can very quickly lead to long computation times.\n\n\nReferences\n\n\n[1] : P. Schmelcher \n F. K. Diakonos, Phys. Rev. Lett. \n78\n, pp 4733 (1997)\n\n\n#\n\n\nChaosTools.lambdamatrix\n \n \nFunction\n.\n\n\nlambdamatrix\n(\n\u03bb\n,\n \ninds\n::\nVector\n{\nInt\n},\n \nsings\n)\n \n-\n \n\u039bk\n\n\n\n\n\n\nReturn the matrix \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n used to create a new dynamical system with some unstable fixed points turned to stable in the function \nperiodicorbits\n.\n\n\nArguments\n\n\n\n\n\u03bb\n:Real\n : the multiplier of the \nC_k\nC_k\n matrix, with \n0\n\u03bb\n1\n.\n\n\ninds::Vector{Int}\n : The \ni\nth entry of this vector gives the \nrow\n of the nonzero element of the \ni\nth column of \nC_k\nC_k\n.\n\n\nsings::Vector{\n:Real}\n : The element of the \ni\nth column of \nC_k\nC_k\n is +1 if \nsigns[i] \n 0\n and -1 otherwise (\nsings\n can also be \nBool\n vector).\n\n\n\n\nCalling \nlambdamatrix(\u03bb, D::Int)\n creates a random \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n by randomly generating an \ninds\n and a \nsigns\n from all possible combinations. The \ncollections\n of all these combinations can be obtained from the function \nlambdaperms\n.\n\n\nDescription\n\n\nEach element of \ninds\n \nmust be unique\n such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.\n\n\nDeciding the appropriate values for \n\u03bb, inds, sings\n is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for \n\u03bb\n, one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.\n\n\nReferences\n\n\n[2] : D. Pingel \net al.\n, Phys. Rev. E \n62\n, pp 2119 (2000)\n\n\n[3] : F. K. Diakonos \net al.\n, Phys. Rev. Lett. \n81\n, pp 4349 (1998)\n\n\n#\n\n\nChaosTools.lambdaperms\n \n \nFunction\n.\n\n\nlambdaperms\n(\nD\n)\n \n-\n \nindperms\n,\n \nsingperms\n\n\n\n\n\n\nReturn two collections that each contain all possible combinations of indices (total of \nD!\nD!\n) and signs (total of \n2^D\n2^D\n) for dimension \nD\n (see \nlambdamatrix\n).\n\n\n\n\n\n\nStandard Map example\n\n\nFor example, let's find the fixed points of the \nStandard Map\n of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the \nsigns\n but only one for the \ninds\n. We will also only use one \n\u03bb\n value, and a 21\u00d721 density of initial conditions.\n\n\nFirst, initialize everything\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\nxs\n \n=\n \nrange\n(\n0\n,\n \nstop\n \n=\n \n2\n\u03c0\n,\n \nlength\n \n=\n \n21\n);\n \nys\n \n=\n \ncopy\n(\nxs\n)\n\n\nics\n \n=\n \n[\nSVector\n{\n2\n}(\nx\n,\ny\n)\n \nfor\n \nx\n \nin\n \nxs\n \nfor\n \ny\n \nin\n \nys\n]\n\n\n\n# All permutations of [\u00b11, \u00b11]:\n\n\nsingss\n \n=\n \nlambdaperms\n(\n2\n)[\n2\n]\n \n# second entry are the signs\n\n\n\n# I know from personal research I only need this `inds`:\n\n\nindss\n \n=\n \n[[\n1\n,\n2\n]]\n \n# \n- must be container of vectors!!!\n\n\n\n\u03bbs\n \n=\n \n0.005\n \n# \n- only this allowed to not be vector (could also be vector)\n\n\n\norders\n \n=\n \n[\n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n,\n \n8\n]\n\n\nALLFP\n \n=\n \nDataset\n{\n2\n,\n \nFloat64\n}[];\n\n\n\n\n\n\n0-element Array{Dataset{2,Float64},1}\n\n\n\n\n\nThen, do the necessary computations for all orders\n\n\nfor\n \no\n \nin\n \norders\n\n    \nFP\n \n=\n \nperiodicorbits\n(\nds\n,\n \no\n,\n \nics\n,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n)\n\n    \npush!\n(\nALLFP\n,\n \nFP\n)\n\n\nend\n\n\n\n\n\n\nPlot the phase space of the standard map\n\n\niters\n \n=\n \n1000\n\n\ndataset\n \n=\n \ntrajectory\n(\nds\n,\n \niters\n)\n\n\nfor\n \nx\n \nin\n \nxs\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nappend!\n(\ndataset\n,\n \ntrajectory\n(\nds\n,\n \niters\n,\n \nSVector\n{\n2\n}(\nx\n,\n \ny\n)))\n\n    \nend\n\n\nend\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n12\n,\n12\n))\n\n\nm\n \n=\n \nMatrix\n(\ndataset\n)\n\n\nPyPlot\n.\nscatter\n(\nview\n(\nm\n,\n \n:\n,\n \n1\n),\n \nview\n(\nm\n,\n \n:\n,\n \n2\n),\n \ns\n=\n \n1\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nPyPlot\n.\nxlim\n(\nxs\n[\n1\n],\n \nxs\n[\nend\n])\n\n\nPyPlot\n.\nylim\n(\nys\n[\n1\n],\n \nys\n[\nend\n]);\n\n\n\n\n\n\n(0.0, 6.283185307179586)\n\n\n\n\n\nand finally, plot the fixed points\n\n\nmarkers\n \n=\n \n[\nD\n,\n \n^\n,\n \ns\n,\n \np\n,\n \nh\n,\n \n8\n]\n\n\ncolors\n \n=\n \n[\nb\n,\n \ng\n,\n \nr\n,\n \nc\n,\n \nm\n,\n \ngrey\n]\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n6\n\n    \nFP\n \n=\n \nALLFP\n[\ni\n]\n\n    \no\n \n=\n \norders\n[\ni\n]\n\n    \nPyPlot\n.\nplot\n(\ncolumns\n(\nFP\n)\n...\n,\n\n    \nmarker\n=\nmarkers\n[\ni\n],\n \ncolor\n \n=\n \ncolors\n[\ni\n],\n \nmarkersize\n=\n10.0\n \n+\n \n(\n8\n-\no\n),\n \nlinewidth\n=\n0.0\n,\n\n    \nlabel\n \n=\n \norder \n$o\n,\n \nmarkeredgecolor\n \n=\n \nyellow\n,\n \nmarkeredgewidth\n \n=\n \n0.5\n)\n\n\nend\n\n\nlegend\n(\nloc\n=\nupper right\n,\n \nframealpha\n=\n0.9\n)\n\n\nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n\nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\n\n\nYou can confirm for yourself that this is correct, for many reasons:\n\n\n\n\nIt is the same \nfig. 12 of this publication\n.\n\n\nFixed points of order \nn\nn\n are also fixed points of order \n2n, 3n, 4n, ...\n2n, 3n, 4n, ...\n\n\nBesides fixed points of previous orders, \noriginal\n fixed points of order \nn\nn\n come in (possible multiples of) \n2n\n2n\n-sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/periodicity/#detecting-stable-and-unstable-periodic-orbits-of-maps", 
            "text": "Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the  periodic orbits  existing in the chaotic sea.  Finding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher   Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at  unstable  ones.  The functions  periodicorbits  and  lambdamatrix  implement the algorithm:  #  ChaosTools.periodicorbits     Function .  periodicorbits ( ds :: DiscreteDynamicalSystem , \n                o ,   ics   [,   \u03bbs ,   indss ,   singss ];   kwargs ... )   -   FP   Find fixed points  FP  of order  o  for the map  ds  using the algorithm due to Schmelcher   Diakonos [1].  ics  is a collection of initial conditions (container of vectors) to be evolved.  Optional Arguments  The optional arguments  \u03bbs, indss, singss   must be containers  of appropriate values, besides  \u03bbs  which can also be a number. The elements of those containers are passed to:  lambdamatrix(\u03bb, inds, sings) , which creates the appropriate  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrix. If these arguments are not given, a random permutation will be chosen for them, with  \u03bb=0.001 .  Keyword Arguments   maxiters::Int = 100000  : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.  disttol = 1e-10  : Distance tolerance. If the 2-norm of a previous state with  the next one is  \u2264 disttol  then it has converged to a fixed point.  inftol = 10.0  : If a state reaches  norm(state) \u2265 inftol  it is assumed that  it has escaped to infinity (and is thus abandoned).  roundtol::Int = 4  : The found fixed points are rounded  to  roundtol  digits before pushed into the list of returned fixed points  FP ,   if  they are not already contained in  FP .  This is done so that  FP  doesn't contain duplicate fixed points (notice  that this has nothing to do with  disttol ). Turn this to  typemax(Int)   to get the full precision of the algorithm.   Description  The algorithm used can detect periodic orbits by turning fixed points of the original map  ds  to stable ones, through the transformation   \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)  \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)   with  f f  =  eom . The index  k k  counts the various possible  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k .  Performance Notes  All  initial conditions are evolved for  all   \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  which can very quickly lead to long computation times.  References  [1] : P. Schmelcher   F. K. Diakonos, Phys. Rev. Lett.  78 , pp 4733 (1997)  #  ChaosTools.lambdamatrix     Function .  lambdamatrix ( \u03bb ,   inds :: Vector { Int },   sings )   -   \u039bk   Return the matrix  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  used to create a new dynamical system with some unstable fixed points turned to stable in the function  periodicorbits .  Arguments   \u03bb :Real  : the multiplier of the  C_k C_k  matrix, with  0 \u03bb 1 .  inds::Vector{Int}  : The  i th entry of this vector gives the  row  of the nonzero element of the  i th column of  C_k C_k .  sings::Vector{ :Real}  : The element of the  i th column of  C_k C_k  is +1 if  signs[i]   0  and -1 otherwise ( sings  can also be  Bool  vector).   Calling  lambdamatrix(\u03bb, D::Int)  creates a random  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  by randomly generating an  inds  and a  signs  from all possible combinations. The  collections  of all these combinations can be obtained from the function  lambdaperms .  Description  Each element of  inds   must be unique  such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.  Deciding the appropriate values for  \u03bb, inds, sings  is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for  \u03bb , one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.  References  [2] : D. Pingel  et al. , Phys. Rev. E  62 , pp 2119 (2000)  [3] : F. K. Diakonos  et al. , Phys. Rev. Lett.  81 , pp 4349 (1998)  #  ChaosTools.lambdaperms     Function .  lambdaperms ( D )   -   indperms ,   singperms   Return two collections that each contain all possible combinations of indices (total of  D! D! ) and signs (total of  2^D 2^D ) for dimension  D  (see  lambdamatrix ).", 
            "title": "Detecting Stable and Unstable Periodic Orbits of Maps"
        }, 
        {
            "location": "/chaos/periodicity/#standard-map-example", 
            "text": "For example, let's find the fixed points of the  Standard Map  of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the  signs  but only one for the  inds . We will also only use one  \u03bb  value, and a 21\u00d721 density of initial conditions.  First, initialize everything  using   DynamicalSystems ,   PyPlot ,   StaticArrays  ds   =   Systems . standardmap ()  xs   =   range ( 0 ,   stop   =   2 \u03c0 ,   length   =   21 );   ys   =   copy ( xs )  ics   =   [ SVector { 2 }( x , y )   for   x   in   xs   for   y   in   ys ]  # All permutations of [\u00b11, \u00b11]:  singss   =   lambdaperms ( 2 )[ 2 ]   # second entry are the signs  # I know from personal research I only need this `inds`:  indss   =   [[ 1 , 2 ]]   #  - must be container of vectors!!!  \u03bbs   =   0.005   #  - only this allowed to not be vector (could also be vector)  orders   =   [ 2 ,   3 ,   4 ,   5 ,   6 ,   8 ]  ALLFP   =   Dataset { 2 ,   Float64 }[];   0-element Array{Dataset{2,Float64},1}  Then, do the necessary computations for all orders  for   o   in   orders \n     FP   =   periodicorbits ( ds ,   o ,   ics ,   \u03bbs ,   indss ,   singss ) \n     push! ( ALLFP ,   FP )  end   Plot the phase space of the standard map  iters   =   1000  dataset   =   trajectory ( ds ,   iters )  for   x   in   xs \n     for   y   in   ys \n         append! ( dataset ,   trajectory ( ds ,   iters ,   SVector { 2 }( x ,   y ))) \n     end  end  figure ( figsize   =   ( 12 , 12 ))  m   =   Matrix ( dataset )  PyPlot . scatter ( view ( m ,   : ,   1 ),   view ( m ,   : ,   2 ),   s =   1 ,   color   =   black )  PyPlot . xlim ( xs [ 1 ],   xs [ end ])  PyPlot . ylim ( ys [ 1 ],   ys [ end ]);   (0.0, 6.283185307179586)  and finally, plot the fixed points  markers   =   [ D ,   ^ ,   s ,   p ,   h ,   8 ]  colors   =   [ b ,   g ,   r ,   c ,   m ,   grey ]  for   i   in   1 : 6 \n     FP   =   ALLFP [ i ] \n     o   =   orders [ i ] \n     PyPlot . plot ( columns ( FP ) ... , \n     marker = markers [ i ],   color   =   colors [ i ],   markersize = 10.0   +   ( 8 - o ),   linewidth = 0.0 , \n     label   =   order  $o ,   markeredgecolor   =   yellow ,   markeredgewidth   =   0.5 )  end  legend ( loc = upper right ,   framealpha = 0.9 )  xlabel ( \\$\\\\ theta \\$ )  ylabel ( \\$ p \\$ )    You can confirm for yourself that this is correct, for many reasons:   It is the same  fig. 12 of this publication .  Fixed points of order  n n  are also fixed points of order  2n, 3n, 4n, ... 2n, 3n, 4n, ...  Besides fixed points of previous orders,  original  fixed points of order  n n  come in (possible multiples of)  2n 2n -sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Standard Map example"
        }, 
        {
            "location": "/chaos/choosing/", 
            "text": "Choosing a solver\n\n\nContinuousDynamicalSystem\ns are evolved using solvers from \nDifferentialEquations.jl\n. In this page we discuss the importance of which solver to choose.\n\n\n\n\nDefault Solver\n\n\nThe default solver is:\n\n\nusing\n \nDynamicalSystems\n\n\nDynamicalSystemsBase\n.\nDEFAULT_SOLVER\n\n\n\n\n\n\nSimpleDiffEq.SimpleATsit5()\n\n\n\n\n\nwhich is a Runge-Kutta-like solver. The number in the solver's name is the \"order\" of the solver.\n\n\n\n\nSpeed of a solver\n\n\nEstimating a given solver's performance for a particular problem is not trivial. The following are general rules of thumb:\n\n\n\n\nHigher order solvers call the equations of motion function more times per step.\n\n\nHigher order solvers can cover larger timespans per step.\n\n\nHigher order solvers do better at small tolerances.\n\n\n\n\nThis means that there is a delicate balance between how expensive is your function and how large of a step a solver can take while it is still efficient. In general you want to strike a point of taking large steps but also not calling the function exceedingly often.\n\n\n\n\nHow do I pick?\n\n\nThe answer to this question is easy: \nbenchmarks!\n\n\nHere is a simple case: let's compute the Lyapunov spectrum of the Lorenz system using \nlyapunovs\n:\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n\n\ntols\n \n=\n \n(\nabstol\n \n=\n \n1e-6\n,\n \nreltol\n \n=\n \n1e-6\n)\n\n\nlyapunovs\n(\nds\n,\n \n2000\n;\n \nTtr\n \n=\n \n100.0\n,\n \ntols\n...\n)\n\n\n\n\n\n\n3-element Array{Float64,1}:\n   0.903181336132451    \n   0.0007789400795075135\n -14.570603587032299    \n\n\n\n\n\nThe above uses the default solver. Let's now benchmark using two different solvers, \nSimpleATsit5\n and \nVern9\n. Since the \nSimpleATsit5\n case is of lower order, naively one might think it is faster because it makes less function calls. This argument is not necessarily true though.\n\n\nIt is important to understand that when calling \nlyapunovs(ds, 2000)\n you want the system (and the tangent space) to be evolved so that it reaches a total time of \n2000*dt\n, which by default is \n2000.0\n units of time. Even though \nSimpleATsit5\n requires less function calls per step, \nVern9\n can cover larger timespans per step.\n\n\nHere are the numbers:\n\n\nusing\n \nBenchmarkTools\n,\n \nOrdinaryDiffEq\n,\n \nSimpleDiffEq\n,\n \nStatistics\n\n\nb1\n \n=\n \n@benchmark\n \nlyapunovs\n(\nds\n,\n \n2000\n;\n \nalg\n \n=\n \nSimpleATsit5\n(),\n \nTtr\n \n=\n \n100.0\n,\n \ntols\n...\n);\n\n\nb2\n \n=\n \n@benchmark\n \nlyapunovs\n(\nds\n,\n \n2000\n;\n \nalg\n \n=\n \nVern9\n(),\n        \nTtr\n \n=\n \n100.0\n,\n \ntols\n...\n);\n\n\nprintln\n(\nTiming for SimpleATsit5:\n)\n\n\ndisplay\n(\nmean\n(\nb1\n))\n\n\nprintln\n(\nTiming for Vern9:\n)\n\n\ndisplay\n(\nmean\n(\nb2\n))\n\n\n\n\n\n\nTiming for SimpleATsit5:\nTiming for Vern9:\n\n\n\n\n\nAs you can see \nVern9\n is faster in doing the \nentire\n computation! Of course this does not have to be universally true. It is true for the Lorenz system, but for your specific system you should do dedicated benchmarks!\n\n\n\n\nDifferentialEquations.jl\n\n\nFor more info about the possible solvers be sure to head over to the documentation of \nDifferentialEquations.jl\n!", 
            "title": "Choosing a solver"
        }, 
        {
            "location": "/chaos/choosing/#choosing-a-solver", 
            "text": "ContinuousDynamicalSystem s are evolved using solvers from  DifferentialEquations.jl . In this page we discuss the importance of which solver to choose.", 
            "title": "Choosing a solver"
        }, 
        {
            "location": "/chaos/choosing/#default-solver", 
            "text": "The default solver is:  using   DynamicalSystems  DynamicalSystemsBase . DEFAULT_SOLVER   SimpleDiffEq.SimpleATsit5()  which is a Runge-Kutta-like solver. The number in the solver's name is the \"order\" of the solver.", 
            "title": "Default Solver"
        }, 
        {
            "location": "/chaos/choosing/#speed-of-a-solver", 
            "text": "Estimating a given solver's performance for a particular problem is not trivial. The following are general rules of thumb:   Higher order solvers call the equations of motion function more times per step.  Higher order solvers can cover larger timespans per step.  Higher order solvers do better at small tolerances.   This means that there is a delicate balance between how expensive is your function and how large of a step a solver can take while it is still efficient. In general you want to strike a point of taking large steps but also not calling the function exceedingly often.", 
            "title": "Speed of a solver"
        }, 
        {
            "location": "/chaos/choosing/#how-do-i-pick", 
            "text": "The answer to this question is easy:  benchmarks!  Here is a simple case: let's compute the Lyapunov spectrum of the Lorenz system using  lyapunovs :  ds   =   Systems . lorenz ()  tols   =   ( abstol   =   1e-6 ,   reltol   =   1e-6 )  lyapunovs ( ds ,   2000 ;   Ttr   =   100.0 ,   tols ... )   3-element Array{Float64,1}:\n   0.903181336132451    \n   0.0007789400795075135\n -14.570603587032299      The above uses the default solver. Let's now benchmark using two different solvers,  SimpleATsit5  and  Vern9 . Since the  SimpleATsit5  case is of lower order, naively one might think it is faster because it makes less function calls. This argument is not necessarily true though.  It is important to understand that when calling  lyapunovs(ds, 2000)  you want the system (and the tangent space) to be evolved so that it reaches a total time of  2000*dt , which by default is  2000.0  units of time. Even though  SimpleATsit5  requires less function calls per step,  Vern9  can cover larger timespans per step.  Here are the numbers:  using   BenchmarkTools ,   OrdinaryDiffEq ,   SimpleDiffEq ,   Statistics  b1   =   @benchmark   lyapunovs ( ds ,   2000 ;   alg   =   SimpleATsit5 (),   Ttr   =   100.0 ,   tols ... );  b2   =   @benchmark   lyapunovs ( ds ,   2000 ;   alg   =   Vern9 (),          Ttr   =   100.0 ,   tols ... );  println ( Timing for SimpleATsit5: )  display ( mean ( b1 ))  println ( Timing for Vern9: )  display ( mean ( b2 ))   Timing for SimpleATsit5:\nTiming for Vern9:  As you can see  Vern9  is faster in doing the  entire  computation! Of course this does not have to be universally true. It is true for the Lorenz system, but for your specific system you should do dedicated benchmarks!", 
            "title": "How do I pick?"
        }, 
        {
            "location": "/chaos/choosing/#differentialequationsjl", 
            "text": "For more info about the possible solvers be sure to head over to the documentation of  DifferentialEquations.jl !", 
            "title": "DifferentialEquations.jl"
        }, 
        {
            "location": "/rqa/rplots/", 
            "text": "Recurrence Plots\n\n\n\n\nRecurrence Matrices\n\n\nA \nRecurrence plot\n (which refers to the plot of a matrix) is a way to quantify \nrecurrences\n that occur in a trajectory. A recurrence happens when a trajectory visits the same neighborhood on the phase space that it was at some previous time.\n\n\nThe central structure used in these recurrences is the (cross-) recurrence matrix:\n\n\n\n\n\nR[i, j] = \\begin{cases}\n1 \\quad \\text{if}\\quad d(x[i], y[j]) \\le \\varepsilon\\\\\n0 \\quad \\text{else}\n\\end{cases}\n\n\n\n\nR[i, j] = \\begin{cases}\n1 \\quad \\text{if}\\quad d(x[i], y[j]) \\le \\varepsilon\\\\\n0 \\quad \\text{else}\n\\end{cases}\n\n\n\n\n\nwhere \nd(x[i], y[j])\nd(x[i], y[j])\n stands for the \ndistance\n between trajectory \nx\nx\n at point \ni\ni\n and trajectory \ny\ny\n at point \nj\nj\n. Both \nx, y\nx, y\n can be single timeseries, full trajectories or embedded timeseries (which are also trajectories).\n\n\nIf \nx\\equiv y\nx\\equiv y\n then \nR\nR\n is called recurrence matrix, otherwise it is called cross-recurrence matrix. There is also the joint-recurrence variant, see below. With \nRecurrenceAnalysis\n you can use the following functions to access these matrices\n\n\n#\n\n\nRecurrenceAnalysis.RecurrenceMatrix\n \n \nType\n.\n\n\nRecurrenceMatrix\n(\nx\n,\n \n\u03b5\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCreate a recurrence matrix from trajectory \nx\n. Objects of type \n:AbstractRecurrenceMatrix\n are displayed as a \nrecurrenceplot\n.\n\n\nDescription\n\n\nThe recurrence matrix is a numeric representation of a \"recurrence plot\" [1, 2], in the form of a sparse square matrix of Boolean values.\n\n\nx\n must be a \nVector\n or a \nDataset\n or a \nMatrix\n with data points in rows (possibly representing and embedded phase space; see \nembed\n). If \nd(x[i], x[j]) \u2264 \u03b5\n (with \nd\n the distance function), then the cell \n(i, j)\n of the matrix will have a \ntrue\n value. The criteria to evaluate distances between data points are defined by the following keyword arguments:\n\n\n\n\nscale=1\n : a function of the distance matrix (see \ndistancematrix\n), or a fixed number, used to scale the value of \n\u03b5\n. Typical choices are \nmaximum\n or \nmean\n, such that the threshold \n\u03b5\n is defined as a ratio of the maximum or the mean distance between data points, respectively (using \nmean\n or \nmaximum\n calls specialized versions that are faster than the naive approach).  Use \n1\n to keep the distances unscaled (default).\n\n\nfixedrate::Bool=false\n : a flag that indicates if \n\u03b5\n should be taken as a target fixed recurrence rate (see \nrecurrencerate\n). If \nfixedrate\n is set to \ntrue\n, \n\u03b5\n must be a value between 0 and 1, and \nscale\n is ignored.\n\n\nmetric=\"euclidean\"\n : metric of the distances, either \nMetric\n or a string,  as in \ndistancematrix\n.\n\n\n\n\nSee also: \nCrossRecurrenceMatrix\n, \nJointRecurrenceMatrix\n and use \nrecurrenceplot\n to turn the result of these functions into a plottable format.\n\n\nReferences\n\n\n[1] : N. Marwan \net al.\n, \"Recurrence plots for the analysis of complex systems\", \nPhys. Reports 438\n(5-6), 237-329 (2007).\n\n\n[2] : N. Marwan \n C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. \n N. Marwan (eds.), \nRecurrence Quantification Analysis. Theory and Best Practices\n, Springer, pp. 3-43 (2015).\n\n\n#\n\n\nRecurrenceAnalysis.CrossRecurrenceMatrix\n \n \nType\n.\n\n\nCrossRecurrenceMatrix\n(\nx\n,\n \ny\n,\n \n\u03b5\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCreate a cross recurrence matrix from trajectories \nx\n and \ny\n.\n\n\nThe cross recurrence matrix is a bivariate extension of the recurrence matrix. For the time series \nx\n, \ny\n, of length \nn\n and \nm\n, respectively, it is a sparse \nn\u00d7m\n matrix of Boolean values, such that if \nd(x[i], y[j]) \u2264 \u03b5\n, then the cell \n(i, j)\n of the matrix will have a \ntrue\n value.\n\n\nSee \nRecurrenceMatrix\n for details, references and keywords. See also: \nJointRecurrenceMatrix\n.\n\n\n#\n\n\nRecurrenceAnalysis.JointRecurrenceMatrix\n \n \nType\n.\n\n\nJointRecurrenceMatrix\n(\nx\n,\n \ny\n,\n \n\u03b5\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCreate a joint recurrence matrix from \nx\n and \ny\n.\n\n\nThe joint recurrence matrix considers the recurrences of the trajectories of \nx\n and \ny\n separately, and looks for points where both recur simultaneously. It is calculated by the element-wise multiplication of the recurrence matrices of \nx\n and \ny\n. If \nx\n and \ny\n are of different length, the recurrences are only calculated until the length of the shortest one.\n\n\nSee \nRecurrenceMatrix\n for details, references and keywords. See also: \nCrossRecurrenceMatrix\n.\n\n\n\n\nSimple Recurrence Plots\n\n\nThe recurrence matrices are internally stored as sparse matrices with boolean values. Typically in the literature one does not \"see\" the matrices themselves but instead a plot of them (hence \"Recurrence Plots\"). By default, when a Recurrence Matrix is created we \"show\" a mini plot of it which is a text-based scatterplot.\n\n\nHere is an example recurrence plot/matrix of a full trajectory of the Roessler system:\n\n\nusing\n \nDynamicalSystems\n\n\nro\n \n=\n \nSystems\n.\nroessler\n(\nones\n(\n3\n),\n \na\n=\n0.15\n,\n \nb\n=\n0.20\n,\n \nc\n=\n10.0\n)\n\n\nN\n \n=\n \n2000\n;\n \ndt\n \n=\n \n0.05\n\n\ntr\n \n=\n \ntrajectory\n(\nro\n,\n \nN\n*\ndt\n;\n \ndt\n \n=\n \ndt\n,\n \nTtr\n \n=\n \n10.0\n)\n\n\n\nR\n \n=\n \nRecurrenceMatrix\n(\ntr\n,\n \n5.0\n;\n \nmetric\n \n=\n \neuclidean\n)\n\n\nrecurrenceplot\n(\nR\n;\n \nascii\n \n=\n \ntrue\n)\n\n\n\n\n\n\n      RecurrenceMatrix of size (2001, 2001) with 383597 entries\n    +------------------------------------------------------------+ \n    |         ..:\n.::\n       .::\n.:\n..:\n       ..:\n.::    ..  .:\n|\n    |   ..  .::\n.:\n   .:\n .:\n..\n.::\n   .   .::\n.:\n    .:\n..:\n  |\n    | .:\n:.:\n:::\n .  .:\n.::\n.::\n.:\n    .:\n.::\n.::\n..  ::\n.::\n.:\n |\n    |:\n.::\n.::\n      :.:::.:\n    ..    \n.::\n.::\n      :.:::.:\n   |\n    | \n \n \n ..  .:\n   ..:\n..  .:\n  \n .. ..:\n \n   ..|\n    |         .:\n.::\n       .::\n.:\n.::\n       .::\n.::\n    .  .:\n|\n    |      .:\n .:\n..:    ..:\n..:\n.:\n.:\n    .:\n..:\n..:    ..:\n.::|\n    |   ..:\n.::\n.::\n   .::\n.::\n :\n.::\n   .::\n.::\n.:\n \n .::\n.:\n |\n    |\n.::\n.::\n.:\n    .:::.:\n..  .:\n   .:::.:::.:\n    .:\n:::\n    |\n    |:::::\n:::\n      \n.::\n.:\n  \n      \n:::\n.::\n      \n.::\n..    |\n    |\n::\n ::\n   ..  .::\n::\n    .. .   .::\n.::\n   ..  .::\n::\n    .|\n    |         .:\n.::\n       .::\n.:\n .:\n       ..:\n.::\n       .::\n|\n    |      .::\n.::\n.:     .:\n.:\n.::\n..     .::\n.:\n.: .   .:\n:.:|\n    |     :\n :\n.::\n.:  ::\n ::\n.:\n:.:\n..   :\n ::\n.::\n.:\n ::\n.::\n.|\n    |     .   .:\n..:\n    .:\n.::\n.:\n.:\n    .  ..:\n.::\n   ..:\n.::\n|\n    |  ..:\n.::\n.::\n   .::\n.::\n..\n.::\n   ..:\n.::\n.:\n   .::\n.:\n  |\n    |.::\n.:::.:\n     :::.:\n.::\n ::\n    :::.:::.:\n     :\n:::\n.::  |\n    |::::\n:::\n       .::\n.::\n   .      .::\n.::\n       .::\n.:\n   |\n    | \n  \n  \n.:\n .:\n \n    .:\n..: .:\n \n   .:\n .:\n \n    .:|\n    |        .:\n..:\n.      .::\n.:\n.:\n..      .:\n.::\n.    . .::\n.|\n    |     .::\n.::\n.:\n    .:\n.:\n.::\n.:\n    .::\n.:\n:.:\n.   .:\n..:\n|\n    |.  .:\n:.:\n..:\n  \n.::\n.::\n  \n.:\n   ..:\n:::\n..\n  \n.::\n.::\n  |\n    |:::\n.::\n.:\n    :::.::\n..  ::\n    ::\n.::\n.:\n     :::.:\n    |\n    |::::::::\n       .::\n.::\n          .::::::\n       .::\n.::    |\n    |::::::\n..       ::.::\n            :::::\n.        ::.:\n      |\n    +------------------------------------------------------------+ \n\n\n\n\n\ntypeof\n(\nR\n)\n\n\n\n\n\n\nRecurrenceMatrix\n\n\n\n\n\nsummary\n(\nR\n)\n\n\n\n\n\n\nRecurrenceMatrix of size (2001, 2001) with 383597 entries\n\n\n\n\n\n\n\n\nThe above simple plotting functionality is possible through the package \nUnicodePlots\n. The following function creates the plot:\n\n\n#\n\n\nRecurrenceAnalysis.recurrenceplot\n \n \nFunction\n.\n\n\nrecurrenceplot\n([\nio\n,]\n \nR\n;\n \nminh\n \n=\n \n25\n,\n \nmaxh\n \n=\n \n0.5\n,\n \nascii\n,\n \nkwargs\n...\n)\n \n-\n \nu\n\n\n\n\n\n\nCreate a text-based scatterplot representation of a recurrence matrix \nR\n to be displayed in \nio\n (by default \nstdout\n) using \nUnicodePlots\n. The matrix spans at minimum \nminh\n rows and at maximum \nmaxh*displaysize(io)[1]\n (i.e. by default half the display). As we always try to plot in equal aspect ratio, if the width of the plot is even less, the minimum height is dictated by the width.\n\n\nThe keyword \nascii::Bool\n can ensure that all elements of the plot are ASCII characters (\ntrue\n) or Unicode (\nfalse\n).\n\n\nThe rest of the \nkwargs\n are propagated into \nUnicodePlots.scatterplot\n.\n\n\nNotice that the accuracy of this function drops drastically for matrices whose size is significantly bigger than the width and height of the display (assuming each index of the matrix is one character).\n\n\n\n\nHere is the same plot but using Unicode Braille characters\n\n\nrecurrenceplot\n(\nR\n;\n \nascii\n \n=\n \nfalse\n)\n\n\n\n\n\n\n      RecurrenceMatrix of size (2001, 2001) with 383597 entries\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28e0\u281e\u2803\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281f\u2801\u28e0\u2876\u280b\u2880\u28e4\u281e\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28e4\u281e\u2801\u28c0\u2874\u281f\u2800\u2800\u2800\u2800\u2880\u28e4\u2800\u2800\u28c0\u2874\u281b\u2502\n    \u2502\u2800\u2800\u2800\u2880\u2840\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2801\u2800\u2800\u2800\u28c0\u2874\u280b\u2800\u28e0\u287e\u280b\u2880\u28e0\u2818\u2809\u28c0\u2874\u281f\u2801\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u28e0\u2876\u281f\u2801\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u28e0\u2876\u280b\u2880\u28e0\u287e\u280b\u2800\u2800\u2502\n    \u2502\u2800\u28e0\u2876\u281b\u2881\u28e0\u287e\u280b\u2881\u28f4\u283e\u280b\u2800\u2840\u2800\u2800\u28a0\u287e\u280b\u2880\u28f4\u281f\u280b\u28c0\u2874\u281f\u2801\u28a0\u287e\u280b\u2800\u2800\u2800\u2800\u28a0\u287e\u280b\u2880\u28f4\u287e\u280b\u2880\u28f4\u281e\u2809\u2880\u2840\u2800\u2800\u28f4\u287e\u280b\u28c0\u28f4\u281f\u2809\u28c0\u2874\u280b\u2800\u2502\n    \u2502\u287f\u280b\u28e0\u28f4\u287f\u280b\u28e0\u28f6\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2888\u28e0\u28fe\u281f\u2881\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u2880\u2840\u2800\u2800\u2800\u2800\u2808\u28e0\u28f6\u281f\u280b\u28e0\u28fe\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2881\u28e4\u287e\u281f\u2881\u28e0\u287e\u280b\u2800\u2800\u2800\u2502\n    \u2502\u2800\u281a\u281b\u2801\u2800\u281a\u281b\u2801\u2800\u2812\u2800\u28e0\u2844\u2800\u2800\u28e0\u281e\u281b\u2801\u2810\u281b\u280b\u2800\u2800\u2800\u2880\u28e0\u281e\u280b\u2880\u2844\u2800\u2800\u28e0\u287c\u281b\u2801\u2810\u281b\u280b\u2800\u2800\u2812\u2800\u28e0\u2844\u2800\u2880\u28e4\u281f\u280b\u2800\u2810\u281b\u2809\u2800\u2800\u2800\u2880\u28e4\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e4\u281e\u2809\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281f\u2801\u28e0\u287e\u280b\u2880\u28f4\u281e\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28c0\u2874\u281f\u2801\u2800\u2800\u2800\u2800\u2840\u2800\u2800\u28e0\u2874\u281b\u2801\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u28c0\u2874\u2802\u2800\u28e0\u287e\u280b\u2880\u28e0\u281e\u2800\u2800\u2800\u2800\u2880\u28e0\u287e\u280b\u2880\u28e4\u281e\u2801\u28e0\u2874\u281b\u2801\u28e0\u2876\u2803\u2800\u2800\u2800\u2800\u28e0\u2874\u280b\u2880\u28e0\u287e\u280b\u2880\u28e4\u281e\u2800\u2800\u2800\u2800\u2880\u28e4\u283e\u280b\u2880\u28f4\u281e\u2502\n    \u2502\u2800\u2800\u2800\u2880\u28e4\u287e\u280b\u2880\u28f4\u281f\u280b\u2880\u2874\u281f\u2801\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2874\u281f\u2801\u2800\u2838\u280b\u2880\u28f4\u281e\u2801\u2800\u2800\u2800\u2880\u28f4\u283e\u280b\u28c0\u28f4\u281f\u2801\u28c0\u2874\u280b\u2801\u2800\u2812\u2800\u28e0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2801\u2800\u2502\n    \u2502\u2803\u28e0\u28f6\u281f\u2809\u28e0\u28fe\u281f\u2801\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u28e0\u28fe\u281f\u2881\u28e4\u287e\u280b\u2880\u2840\u2800\u2800\u28a0\u2874\u280b\u2801\u2800\u2800\u2800\u28a0\u28f6\u281f\u2881\u28e0\u287e\u281f\u2881\u28e0\u283e\u280b\u2800\u2800\u2800\u2800\u28e4\u287e\u281b\u2881\u28f4\u287e\u280b\u2800\u2800\u2800\u2800\u2502\n    \u2502\u28ff\u281f\u28c1\u28f4\u287f\u280b\u28c1\u28f4\u281f\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28e0\u28f6\u283f\u280b\u28e0\u2874\u281b\u2801\u2800\u2800\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u28e1\u28f4\u287f\u280b\u28e0\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28e0\u28fe\u281f\u2801\u28e0\u2844\u2800\u2800\u2800\u2800\u2502\n    \u2502\u2801\u283e\u283f\u280b\u2800\u283e\u281f\u2801\u2800\u2800\u2800\u2880\u2840\u2800\u2800\u28e0\u287e\u281f\u2801\u2830\u283e\u280b\u2800\u2800\u2800\u2800\u28e0\u2844\u2800\u2880\u2800\u2800\u2800\u28c0\u287c\u283f\u280b\u2820\u283e\u281f\u2801\u2800\u2800\u2800\u28c0\u2840\u2800\u2800\u28e0\u283f\u281f\u2801\u2830\u281e\u280b\u2800\u2800\u2800\u2800\u28e0\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u287e\u280b\u2880\u28f4\u281e\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28a0\u2874\u280b\u2800\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28e0\u281e\u280b\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281f\u2801\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28e0\u2874\u281f\u2801\u28e0\u2836\u2800\u2800\u2800\u2800\u2800\u28e0\u2874\u280b\u2801\u28e0\u287e\u280b\u2880\u28f4\u281f\u2801\u28c0\u2864\u2800\u2800\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2801\u28e0\u2816\u2800\u2880\u2800\u2800\u2800\u28e0\u287e\u280b\u2881\u28e0\u281e\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2836\u280b\u2801\u2800\u283e\u280b\u2880\u28f4\u281e\u2801\u28e0\u2874\u2800\u2800\u2830\u283e\u280b\u2800\u2830\u281f\u2801\u28e0\u287c\u281b\u2881\u28e4\u281e\u280b\u2880\u2844\u2800\u2800\u2800\u283e\u280b\u2800\u2830\u283e\u280b\u28c0\u2874\u281f\u2801\u28e0\u283e\u280b\u2800\u2830\u281f\u280b\u2880\u2870\u281f\u2801\u28e0\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u28e0\u287e\u280b\u2880\u28e4\u281e\u280b\u2800\u2800\u2800\u2800\u28e0\u2876\u2803\u2880\u28f4\u281e\u280b\u28a0\u2874\u281b\u2801\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u28c0\u2800\u2800\u2880\u28e0\u287e\u280b\u2880\u28f4\u281e\u2801\u2800\u2800\u2800\u2880\u28e0\u281e\u280b\u2880\u28f4\u281e\u2801\u2502\n    \u2502\u2800\u2800\u2880\u28e0\u287e\u280b\u2880\u28f4\u281f\u280b\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u28f4\u281f\u2801\u28e0\u2804\u2808\u2880\u28f4\u281e\u2809\u2800\u2800\u2800\u2880\u28e4\u281e\u2809\u28c0\u28f4\u281f\u2801\u28e0\u2874\u281b\u2801\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u281b\u2801\u2800\u2800\u2502\n    \u2502\u28e0\u28f4\u281f\u2801\u28e0\u28fe\u281f\u2881\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2838\u281f\u2881\u28e4\u287e\u280b\u2880\u28f4\u281e\u2801\u2800\u2830\u281f\u2801\u2800\u2800\u2800\u2800\u2830\u281f\u2881\u28e0\u287e\u281f\u2881\u28e4\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u283e\u280b\u2881\u28f4\u287e\u280b\u2880\u28f4\u2806\u2800\u2800\u2502\n    \u2502\u281f\u28c1\u28f4\u287f\u281b\u28c1\u28f4\u283f\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28a0\u28f6\u287f\u280b\u28e0\u28f6\u281f\u2801\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u28a0\u28f4\u287f\u280b\u28e0\u28f4\u281f\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u28f6\u281f\u2809\u28e0\u287e\u280b\u2801\u2800\u2800\u2800\u2502\n    \u2502\u2800\u2809\u2809\u2800\u2800\u2809\u2801\u2800\u2800\u2801\u2880\u2874\u2802\u2800\u28e0\u2876\u280b\u2801\u2800\u2808\u2809\u2800\u2800\u2800\u2800\u28e0\u2876\u280b\u2880\u28e4\u2806\u2800\u28c0\u2874\u280b\u2809\u2800\u2808\u2809\u2801\u2800\u2800\u2800\u28c0\u2874\u2802\u2800\u28e0\u2876\u280b\u2801\u2800\u2808\u2809\u2800\u2800\u2800\u2800\u28e0\u2836\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u283e\u280b\u2880\u28e4\u281e\u280b\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2809\u28c0\u2870\u280b\u2801\u28e0\u287e\u280b\u2880\u2840\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u283e\u280b\u2880\u28f4\u281f\u2801\u2880\u2800\u2800\u2800\u2800\u2804\u2800\u2880\u28f4\u281f\u2801\u28c0\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28e0\u2874\u281f\u2801\u28e0\u2876\u280b\u2800\u2800\u2800\u2800\u28e0\u2876\u281b\u2801\u28e0\u287e\u280b\u2880\u28f4\u281f\u2801\u28c0\u2874\u280b\u2800\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2881\u28e0\u283e\u280b\u2880\u2800\u2800\u2800\u28e0\u287e\u280b\u2880\u28e0\u283e\u280b\u2502\n    \u2502\u2864\u2800\u2800\u28e0\u287e\u281b\u2881\u28e4\u287e\u280b\u2880\u28e4\u281e\u2801\u2800\u2800\u2808\u2880\u28f4\u287e\u280b\u2880\u28f4\u281f\u2809\u2800\u2800\u2808\u2801\u28e0\u283e\u280b\u2800\u2800\u2800\u2880\u28e0\u287e\u280b\u2881\u28f4\u287e\u280b\u2880\u2864\u2808\u2801\u2800\u2800\u2809\u2880\u28f4\u283f\u280b\u28c0\u28f4\u281f\u2801\u2800\u2800\u2502\n    \u2502\u28c1\u28f4\u287f\u280b\u28e0\u28f4\u281f\u280b\u28e0\u2874\u281b\u2801\u2800\u2800\u2800\u2800\u28fc\u281f\u2889\u28e0\u287e\u281f\u2801\u28e0\u2804\u2800\u2800\u28b0\u281f\u2801\u2800\u2800\u2800\u2800\u28b0\u287f\u280b\u28e0\u28f6\u281f\u2801\u28e0\u2876\u280b\u2800\u2800\u2800\u2800\u2800\u28fe\u281f\u2881\u28e0\u287e\u280b\u2801\u2800\u2800\u2800\u2800\u2502\n    \u2502\u287f\u288b\u28f4\u28fe\u281f\u2881\u28f4\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28a0\u28f4\u287f\u280b\u28c0\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u28ff\u281f\u28c1\u28f4\u287f\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u28f4\u287f\u280b\u28c0\u28f4\u2806\u2800\u2800\u2800\u2800\u2502\n    \u2502\u28fe\u28ff\u289f\u28e1\u28fe\u287f\u280b\u28c0\u2840\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u283b\u288b\u28e4\u28fe\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2838\u288b\u28e5\u28fe\u281f\u2809\u28c0\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u281f\u288b\u28e4\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \n\n\n\n\n\nAs you can see, the Unicode based plotting doesn't display nicely everywhere. It does display perfectly in e.g. Juno, which is where it is the default printing type. Here is how it looks like in a dark background:\n\n\n\n\n\n\nAdvanced Recurrence Plots\n\n\nA text-based plot is cool, fast and simple. But often one needs the full resolution offered by the data of a recurrence matrix.\n\n\nThere are two more ways to plot a recurrence matrix using \nRecurrenceAnalysis\n:\n\n\n#\n\n\nRecurrenceAnalysis.coordinates\n \n \nFunction\n.\n\n\ncoordinates\n(\nR\n)\n \n-\n \nxs\n,\n \nys\n\n\n\n\n\n\nReturn the coordinates of the recurrence points of \nR\n (in indices).\n\n\n#\n\n\nRecurrenceAnalysis.grayscale\n \n \nFunction\n.\n\n\ngrayscale\n(\nR\n \n[,\n \nbwcode\n];\n \nwidth\n::\nInt\n,\n \nheight\n::\nInt\n,\n \nexactsize\n=\nfalse\n)\n\n\n\n\n\n\nTransform the recurrence matrix \nR\n into a full matrix suitable for plotting as a grayscale image. By default it returns a matrix with the same size as \nR\n, but switched axes, containing \"black\" values in the cells that represent recurrent points, and \"white\" values in the empty cells and interpolating in-between for cases with both recurrent and empty cells, see below.\n\n\nThe numeric codes for black and white are given in a 2-element tuple as a second optional argument. Its default value is \n(0.0, 1.0)\n, i.e. black is coded as \n0.0\n (no brightness) and white as \n1.0\n (full brightness). The type of the elements in the tuple defines the type of the returned matrix. This must be taken into account if, for instance, the image is coded as a matrix of integers corresponding to a grayscale; in such case the black and white codes must be given as numbers of the required integer type.\n\n\nThe keyword arguments \nwidth\n and \nheight\n can be given to define a custom size of the image. If only one dimension is given, the other is automatically calculated. If both dimensions are given, by default they are adjusted to keep an aspect proportional to the original matrix, such that the returned matrix fits into a matrix of the given dimensions. This automatic adjustment can be disabled by passing the keyword argument \nexactsize=true\n.\n\n\nIf the image has different dimensions than \nR\n, the cells of \nR\n are distributed in a grid with the size of the image, and a gray level between white and black is calculated for each element of the grid, proportional to the number of recurrent points contained in it. The levels of gray are coded as numbers of the same type as the black and white codes.\n\n\nIt is advised to use \nwidth, height\n arguments for large matrices otherwise plots using functions like e.g. \nimshow\n could be misleading.\n\n\n\n\nFor example, here is the representation of the above \nR\n from the Roessler system using both plotting approaches:\n\n\nusing\n \nPyPlot\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n10\n,\n5\n))\n\n\n\nax\n \n=\n \nsubplot\n(\n121\n)\n\n\nxs\n,\n \nys\n \n=\n \ncoordinates\n(\nR\n)\n\n\nscatter\n(\nxs\n,\n \nys\n,\n \ncolor\n \n=\n \nk\n,\n \ns\n \n=\n \n1\n)\n\n\nxlim\n(\n1\n,\n \nsize\n(\nR\n)[\n1\n]);\n \nylim\n(\n1\n,\n \nsize\n(\nR\n)[\n2\n]);\n\n\nax\n.\nset_aspect\n(\nequal\n)\n\n\n\nsubplot\n(\n122\n)\n\n\nRg\n \n=\n \ngrayscale\n(\nR\n)\n\n\nimshow\n(\nRg\n,\n \ncmap\n \n=\n \nbinary_r\n,\n \nextent\n \n=\n \n(\n1\n,\n \nsize\n(\nR\n)[\n1\n],\n \n1\n,\n \nsize\n(\nR\n)[\n2\n]))\n\n\n\n\n\n\n\n\nand here is exactly the same process, but using the embedded trajectory instead\n\n\ny\n \n=\n \ntr\n[\n:\n,\n \n2\n]\n\n\n\u03c4\n \n=\n \nestimate_delay\n(\ny\n,\n \nmi_min\n)\n\n\nm\n \n=\n \nreconstruct\n(\ny\n,\n \n2\n,\n \n\u03c4\n)\n\n\nR\n \n=\n \nRecurrenceMatrix\n(\nm\n,\n \n5.0\n;\n \nmetric\n \n=\n \neuclidean\n)\n\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n5\n,\n5\n))\n\n\n\nxs\n,\n \nys\n \n=\n \ncoordinates\n(\nR\n)\n\n\nscatter\n(\nxs\n,\n \nys\n,\n \ncolor\n \n=\n \nk\n,\n \ns\n \n=\n \n1\n)\n\n\nxlim\n(\n1\n,\n \nsize\n(\nR\n)[\n1\n]);\n \nylim\n(\n1\n,\n \nsize\n(\nR\n)[\n2\n]);\n\n\n\n\n\n\n\n\nwhich justifies why recurrence plots are so fitting to be used in embedded timeseries.\n\n\n\n\nCareful when using Recurrence Plots\n\n\nIt is easy when using \ngrayscale\n to not change the width/height parameters. These are however very important when the matrix size exceeds the display size! Most plotting libraries may resample arbitrarily or simply limit the displayed pixels, so one needs to be extra careful.\n\n\nBesides graphical problems there are also other potential pitfalls dealing with the conceptual understanding and use of recurrence plots. All of these are summarized in the following paper which we suggest users to take a look at:\n\n\nN. Marwan, \nHow to avoid potential pitfalls in recurrence plot based data analysis\n, Int. J. of Bifurcations and Chaos (\narXiv\n).\n\n\n\n\n\n\nExample\n\n\nIn the following we will plot recurrence plots of the Lorenz system for a periodic and chaotic regime (using scatter plot).\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n()\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n10\n,\n10\n))\n\n\n\nfor\n \n(\ni\n,\n \n\u03c1\n)\n \nin\n \nenumerate\n((\n69.75\n,\n \n28.0\n))\n\n    \nset_parameter!\n(\nlor\n,\n \n2\n,\n \n\u03c1\n)\n\n    \nt\n,\n \ndt\n \n=\n \n20.0\n,\n \n0.01\n\n    \ntr\n \n=\n \ntrajectory\n(\nlor\n,\n \nt\n;\n \ndt\n \n=\n \ndt\n,\n \nTtr\n \n=\n \n2000.0\n)\n\n    \ntvec\n \n=\n \n0\n:\ndt\n:\nt\n\n\n    \nsubplot\n(\n2\n,\n2\n,\n \ni\n)\n\n    \nplot\n(\ntr\n[\n:\n,\n \n1\n],\n \ntr\n[\n:\n,\n \n3\n],\n \ncolor\n \n=\n \nC\n$\n(\ni\n+\n1\n)\n,\n \nlabel\n \n=\n \nX vs Z\n)\n\n    \ntitle\n(\n\u03c1 = \n$\u03c1\n, \n \n*\n \n(\ni\n \n!=\n \n1\n \n?\n \nnot periodic\n \n:\n \nperiodic\n));\n \nlegend\n()\n\n\n    \n\u03b5\n \n=\n \ni\n \n==\n \n1\n \n?\n \n5.0\n \n:\n \n3.0\n\n    \nR\n \n=\n \nRecurrenceMatrix\n(\ntr\n,\n \n\u03b5\n)\n\n\n    \nsubplot\n(\n2\n,\n2\n,\ni\n+\n2\n)\n\n    \nx\n,\n \ny\n \n=\n \ncoordinates\n(\nR\n)\n\n    \nscatter\n(\ntvec\n[\nx\n],\n \ntvec\n[\ny\n],\n \ns\n \n=\n \n1\n,\n \nalpha\n \n=\n \n0.2\n,\n \ncolor\n \n=\n \nC\n$\n(\ni\n+\n1\n)\n)\n\n    \nxlim\n(\n0\n,\n \nt\n);\n \nylim\n(\n0\n,\n \nt\n);\n \ngca\n()\n.\nset_aspect\n(\nequal\n)\n\n    \nxlabel\n(\nt\n);\n \ni\n \n==\n \n1\n \n \nylabel\n(\nt\n);\n\n\nend\n\n\nPyPlot\n.\ntight_layout\n()\n\n\n\n\n\n\n\n\nOn the left we see long (infinite) diagonals repeated over and over for different times. This is the case for periodic systems as they visit exactly the same area on the phase space again and again. The distance between the offset diagonals also coincides with the periodicity of the system, which is around \nt \u2248 4\n.\n\n\nOn the right we see a structure typical of chaotic motion on a strange attractor such as the one of the Lorenz system: the orbit visits neighborhoods of previous points but then quickly diverges again. This results in many small diagonal lines.\n\n\n\n\nDistances\n\n\nThe distance function used in \nRecurrenceMatrix\n and co. can be specified either as a string or as any \nMetric\n instance from \nDistances\n. In addition, the following function returns a matrix with the cross-distances across all points in one or two trajectories:\n\n\n#\n\n\nRecurrenceAnalysis.distancematrix\n \n \nFunction\n.\n\n\ndistancematrix\n(\nx\n \n[,\n \ny\n \n=\n \nx\n],\n \nmetric\n \n=\n \neuclidean\n)\n\n\n\n\n\n\nCreate a matrix with the distances between each pair of points of the time series \nx\n and \ny\n using \nmetric\n.\n\n\nThe time series \nx\n and \ny\n can be \nDataset\ns or vectors or matrices with data points in rows. The data point dimensions (or number of columns) must be the same for \nx\n and \ny\n. The returned value is a \nn\u00d7m\n matrix, with \nn\n being the length (or number of rows) of \nx\n, and \nm\n the length of \ny\n.\n\n\nThe metric can be identified by a string, or any of the \nMetric\ns defined in the \nDistances\n package\n. The list of strings available to define the metric are:\n\n\n\n\n\"max\"\n or \n\"inf\"\n for the maximum or L\u221e norm (\nChebyshev()\n in the \nDistances\n package).\n\n\n\"euclidean\"\n for the L2 or Euclidean norm, used by default (\nEuclidean()\n in \nDistances\n).\n\n\n\"manhattan\"\n, \n\"cityblock\"\n, \n\"taxicab\"\n or \n\"min\"\n for the Manhattan or L1 norm (\nCityblock()\n in \nDistances\n).", 
            "title": "Recurrence Plots"
        }, 
        {
            "location": "/rqa/rplots/#recurrence-plots", 
            "text": "", 
            "title": "Recurrence Plots"
        }, 
        {
            "location": "/rqa/rplots/#recurrence-matrices", 
            "text": "A  Recurrence plot  (which refers to the plot of a matrix) is a way to quantify  recurrences  that occur in a trajectory. A recurrence happens when a trajectory visits the same neighborhood on the phase space that it was at some previous time.  The central structure used in these recurrences is the (cross-) recurrence matrix:   \nR[i, j] = \\begin{cases}\n1 \\quad \\text{if}\\quad d(x[i], y[j]) \\le \\varepsilon\\\\\n0 \\quad \\text{else}\n\\end{cases}  \nR[i, j] = \\begin{cases}\n1 \\quad \\text{if}\\quad d(x[i], y[j]) \\le \\varepsilon\\\\\n0 \\quad \\text{else}\n\\end{cases}   where  d(x[i], y[j]) d(x[i], y[j])  stands for the  distance  between trajectory  x x  at point  i i  and trajectory  y y  at point  j j . Both  x, y x, y  can be single timeseries, full trajectories or embedded timeseries (which are also trajectories).  If  x\\equiv y x\\equiv y  then  R R  is called recurrence matrix, otherwise it is called cross-recurrence matrix. There is also the joint-recurrence variant, see below. With  RecurrenceAnalysis  you can use the following functions to access these matrices  #  RecurrenceAnalysis.RecurrenceMatrix     Type .  RecurrenceMatrix ( x ,   \u03b5 ;   kwargs ... )   Create a recurrence matrix from trajectory  x . Objects of type  :AbstractRecurrenceMatrix  are displayed as a  recurrenceplot .  Description  The recurrence matrix is a numeric representation of a \"recurrence plot\" [1, 2], in the form of a sparse square matrix of Boolean values.  x  must be a  Vector  or a  Dataset  or a  Matrix  with data points in rows (possibly representing and embedded phase space; see  embed ). If  d(x[i], x[j]) \u2264 \u03b5  (with  d  the distance function), then the cell  (i, j)  of the matrix will have a  true  value. The criteria to evaluate distances between data points are defined by the following keyword arguments:   scale=1  : a function of the distance matrix (see  distancematrix ), or a fixed number, used to scale the value of  \u03b5 . Typical choices are  maximum  or  mean , such that the threshold  \u03b5  is defined as a ratio of the maximum or the mean distance between data points, respectively (using  mean  or  maximum  calls specialized versions that are faster than the naive approach).  Use  1  to keep the distances unscaled (default).  fixedrate::Bool=false  : a flag that indicates if  \u03b5  should be taken as a target fixed recurrence rate (see  recurrencerate ). If  fixedrate  is set to  true ,  \u03b5  must be a value between 0 and 1, and  scale  is ignored.  metric=\"euclidean\"  : metric of the distances, either  Metric  or a string,  as in  distancematrix .   See also:  CrossRecurrenceMatrix ,  JointRecurrenceMatrix  and use  recurrenceplot  to turn the result of these functions into a plottable format.  References  [1] : N. Marwan  et al. , \"Recurrence plots for the analysis of complex systems\",  Phys. Reports 438 (5-6), 237-329 (2007).  [2] : N. Marwan   C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L.   N. Marwan (eds.),  Recurrence Quantification Analysis. Theory and Best Practices , Springer, pp. 3-43 (2015).  #  RecurrenceAnalysis.CrossRecurrenceMatrix     Type .  CrossRecurrenceMatrix ( x ,   y ,   \u03b5 ;   kwargs ... )   Create a cross recurrence matrix from trajectories  x  and  y .  The cross recurrence matrix is a bivariate extension of the recurrence matrix. For the time series  x ,  y , of length  n  and  m , respectively, it is a sparse  n\u00d7m  matrix of Boolean values, such that if  d(x[i], y[j]) \u2264 \u03b5 , then the cell  (i, j)  of the matrix will have a  true  value.  See  RecurrenceMatrix  for details, references and keywords. See also:  JointRecurrenceMatrix .  #  RecurrenceAnalysis.JointRecurrenceMatrix     Type .  JointRecurrenceMatrix ( x ,   y ,   \u03b5 ;   kwargs ... )   Create a joint recurrence matrix from  x  and  y .  The joint recurrence matrix considers the recurrences of the trajectories of  x  and  y  separately, and looks for points where both recur simultaneously. It is calculated by the element-wise multiplication of the recurrence matrices of  x  and  y . If  x  and  y  are of different length, the recurrences are only calculated until the length of the shortest one.  See  RecurrenceMatrix  for details, references and keywords. See also:  CrossRecurrenceMatrix .", 
            "title": "Recurrence Matrices"
        }, 
        {
            "location": "/rqa/rplots/#simple-recurrence-plots", 
            "text": "The recurrence matrices are internally stored as sparse matrices with boolean values. Typically in the literature one does not \"see\" the matrices themselves but instead a plot of them (hence \"Recurrence Plots\"). By default, when a Recurrence Matrix is created we \"show\" a mini plot of it which is a text-based scatterplot.  Here is an example recurrence plot/matrix of a full trajectory of the Roessler system:  using   DynamicalSystems  ro   =   Systems . roessler ( ones ( 3 ),   a = 0.15 ,   b = 0.20 ,   c = 10.0 )  N   =   2000 ;   dt   =   0.05  tr   =   trajectory ( ro ,   N * dt ;   dt   =   dt ,   Ttr   =   10.0 )  R   =   RecurrenceMatrix ( tr ,   5.0 ;   metric   =   euclidean )  recurrenceplot ( R ;   ascii   =   true )         RecurrenceMatrix of size (2001, 2001) with 383597 entries\n    +------------------------------------------------------------+ \n    |         ..: .::        .:: .: ..:        ..: .::    ..  .: |\n    |   ..  .:: .:    .:  .: .. .::    .   .:: .:     .: ..:   |\n    | .: :.: :::  .  .: .:: .:: .:     .: .:: .:: ..  :: .:: .:  |\n    |: .:: .::       :.:::.:     ..     .:: .::       :.:::.:    |\n    |       ..  .:    ..: ..  .:     .. ..:      ..|\n    |         .: .::        .:: .: .::        .:: .::     .  .: |\n    |      .:  .: ..:    ..: ..: .: .:     .: ..: ..:    ..: .::|\n    |   ..: .:: .::    .:: .::  : .::    .:: .:: .:    .:: .:  |\n    | .:: .:: .:     .:::.: ..  .:    .:::.:::.:     .: :::     |\n    |::::: :::        .:: .:           ::: .::        .:: ..    |\n    | ::  ::    ..  .:: ::     .. .   .:: .::    ..  .:: ::     .|\n    |         .: .::        .:: .:  .:        ..: .::        .:: |\n    |      .:: .:: .:     .: .: .:: ..     .:: .: .: .   .: :.:|\n    |     :  : .:: .:  ::  :: .: :.: ..   :  :: .:: .:  :: .:: .|\n    |     .   .: ..:     .: .:: .: .:     .  ..: .::    ..: .:: |\n    |  ..: .:: .::    .:: .:: .. .::    ..: .:: .:    .:: .:   |\n    |.:: .:::.:      :::.: .::  ::     :::.:::.:      : ::: .::  |\n    |:::: :::        .:: .::    .      .:: .::        .:: .:    |\n    |        .:  .:       .: ..: .:      .:  .:       .:|\n    |        .: ..: .      .:: .: .: ..      .: .:: .    . .:: .|\n    |     .:: .:: .:     .: .: .:: .:     .:: .: :.: .   .: ..: |\n    |.  .: :.: ..:    .:: .::    .:    ..: ::: ..    .:: .::   |\n    |::: .:: .:     :::.:: ..  ::     :: .:: .:      :::.:     |\n    |::::::::        .:: .::           .::::::        .:: .::    |\n    |:::::: ..       ::.::             ::::: .        ::.:       |\n    +------------------------------------------------------------+   typeof ( R )   RecurrenceMatrix  summary ( R )   RecurrenceMatrix of size (2001, 2001) with 383597 entries    The above simple plotting functionality is possible through the package  UnicodePlots . The following function creates the plot:  #  RecurrenceAnalysis.recurrenceplot     Function .  recurrenceplot ([ io ,]   R ;   minh   =   25 ,   maxh   =   0.5 ,   ascii ,   kwargs ... )   -   u   Create a text-based scatterplot representation of a recurrence matrix  R  to be displayed in  io  (by default  stdout ) using  UnicodePlots . The matrix spans at minimum  minh  rows and at maximum  maxh*displaysize(io)[1]  (i.e. by default half the display). As we always try to plot in equal aspect ratio, if the width of the plot is even less, the minimum height is dictated by the width.  The keyword  ascii::Bool  can ensure that all elements of the plot are ASCII characters ( true ) or Unicode ( false ).  The rest of the  kwargs  are propagated into  UnicodePlots.scatterplot .  Notice that the accuracy of this function drops drastically for matrices whose size is significantly bigger than the width and height of the display (assuming each index of the matrix is one character).   Here is the same plot but using Unicode Braille characters  recurrenceplot ( R ;   ascii   =   false )         RecurrenceMatrix of size (2001, 2001) with 383597 entries\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28e0\u281e\u2803\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281f\u2801\u28e0\u2876\u280b\u2880\u28e4\u281e\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28e4\u281e\u2801\u28c0\u2874\u281f\u2800\u2800\u2800\u2800\u2880\u28e4\u2800\u2800\u28c0\u2874\u281b\u2502\n    \u2502\u2800\u2800\u2800\u2880\u2840\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2801\u2800\u2800\u2800\u28c0\u2874\u280b\u2800\u28e0\u287e\u280b\u2880\u28e0\u2818\u2809\u28c0\u2874\u281f\u2801\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u28e0\u2876\u281f\u2801\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u28e0\u2876\u280b\u2880\u28e0\u287e\u280b\u2800\u2800\u2502\n    \u2502\u2800\u28e0\u2876\u281b\u2881\u28e0\u287e\u280b\u2881\u28f4\u283e\u280b\u2800\u2840\u2800\u2800\u28a0\u287e\u280b\u2880\u28f4\u281f\u280b\u28c0\u2874\u281f\u2801\u28a0\u287e\u280b\u2800\u2800\u2800\u2800\u28a0\u287e\u280b\u2880\u28f4\u287e\u280b\u2880\u28f4\u281e\u2809\u2880\u2840\u2800\u2800\u28f4\u287e\u280b\u28c0\u28f4\u281f\u2809\u28c0\u2874\u280b\u2800\u2502\n    \u2502\u287f\u280b\u28e0\u28f4\u287f\u280b\u28e0\u28f6\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2888\u28e0\u28fe\u281f\u2881\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u2880\u2840\u2800\u2800\u2800\u2800\u2808\u28e0\u28f6\u281f\u280b\u28e0\u28fe\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2881\u28e4\u287e\u281f\u2881\u28e0\u287e\u280b\u2800\u2800\u2800\u2502\n    \u2502\u2800\u281a\u281b\u2801\u2800\u281a\u281b\u2801\u2800\u2812\u2800\u28e0\u2844\u2800\u2800\u28e0\u281e\u281b\u2801\u2810\u281b\u280b\u2800\u2800\u2800\u2880\u28e0\u281e\u280b\u2880\u2844\u2800\u2800\u28e0\u287c\u281b\u2801\u2810\u281b\u280b\u2800\u2800\u2812\u2800\u28e0\u2844\u2800\u2880\u28e4\u281f\u280b\u2800\u2810\u281b\u2809\u2800\u2800\u2800\u2880\u28e4\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e4\u281e\u2809\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281f\u2801\u28e0\u287e\u280b\u2880\u28f4\u281e\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28c0\u2874\u281f\u2801\u2800\u2800\u2800\u2800\u2840\u2800\u2800\u28e0\u2874\u281b\u2801\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u28c0\u2874\u2802\u2800\u28e0\u287e\u280b\u2880\u28e0\u281e\u2800\u2800\u2800\u2800\u2880\u28e0\u287e\u280b\u2880\u28e4\u281e\u2801\u28e0\u2874\u281b\u2801\u28e0\u2876\u2803\u2800\u2800\u2800\u2800\u28e0\u2874\u280b\u2880\u28e0\u287e\u280b\u2880\u28e4\u281e\u2800\u2800\u2800\u2800\u2880\u28e4\u283e\u280b\u2880\u28f4\u281e\u2502\n    \u2502\u2800\u2800\u2800\u2880\u28e4\u287e\u280b\u2880\u28f4\u281f\u280b\u2880\u2874\u281f\u2801\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2874\u281f\u2801\u2800\u2838\u280b\u2880\u28f4\u281e\u2801\u2800\u2800\u2800\u2880\u28f4\u283e\u280b\u28c0\u28f4\u281f\u2801\u28c0\u2874\u280b\u2801\u2800\u2812\u2800\u28e0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2801\u2800\u2502\n    \u2502\u2803\u28e0\u28f6\u281f\u2809\u28e0\u28fe\u281f\u2801\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u28e0\u28fe\u281f\u2881\u28e4\u287e\u280b\u2880\u2840\u2800\u2800\u28a0\u2874\u280b\u2801\u2800\u2800\u2800\u28a0\u28f6\u281f\u2881\u28e0\u287e\u281f\u2881\u28e0\u283e\u280b\u2800\u2800\u2800\u2800\u28e4\u287e\u281b\u2881\u28f4\u287e\u280b\u2800\u2800\u2800\u2800\u2502\n    \u2502\u28ff\u281f\u28c1\u28f4\u287f\u280b\u28c1\u28f4\u281f\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28e0\u28f6\u283f\u280b\u28e0\u2874\u281b\u2801\u2800\u2800\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u28e1\u28f4\u287f\u280b\u28e0\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28e0\u28fe\u281f\u2801\u28e0\u2844\u2800\u2800\u2800\u2800\u2502\n    \u2502\u2801\u283e\u283f\u280b\u2800\u283e\u281f\u2801\u2800\u2800\u2800\u2880\u2840\u2800\u2800\u28e0\u287e\u281f\u2801\u2830\u283e\u280b\u2800\u2800\u2800\u2800\u28e0\u2844\u2800\u2880\u2800\u2800\u2800\u28c0\u287c\u283f\u280b\u2820\u283e\u281f\u2801\u2800\u2800\u2800\u28c0\u2840\u2800\u2800\u28e0\u283f\u281f\u2801\u2830\u281e\u280b\u2800\u2800\u2800\u2800\u28e0\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u287e\u280b\u2880\u28f4\u281e\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28a0\u2874\u280b\u2800\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28e0\u281e\u280b\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281f\u2801\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28e0\u2874\u281f\u2801\u28e0\u2836\u2800\u2800\u2800\u2800\u2800\u28e0\u2874\u280b\u2801\u28e0\u287e\u280b\u2880\u28f4\u281f\u2801\u28c0\u2864\u2800\u2800\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2801\u28e0\u2816\u2800\u2880\u2800\u2800\u2800\u28e0\u287e\u280b\u2881\u28e0\u281e\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2836\u280b\u2801\u2800\u283e\u280b\u2880\u28f4\u281e\u2801\u28e0\u2874\u2800\u2800\u2830\u283e\u280b\u2800\u2830\u281f\u2801\u28e0\u287c\u281b\u2881\u28e4\u281e\u280b\u2880\u2844\u2800\u2800\u2800\u283e\u280b\u2800\u2830\u283e\u280b\u28c0\u2874\u281f\u2801\u28e0\u283e\u280b\u2800\u2830\u281f\u280b\u2880\u2870\u281f\u2801\u28e0\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u28e0\u287e\u280b\u2880\u28e4\u281e\u280b\u2800\u2800\u2800\u2800\u28e0\u2876\u2803\u2880\u28f4\u281e\u280b\u28a0\u2874\u281b\u2801\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u28c0\u2800\u2800\u2880\u28e0\u287e\u280b\u2880\u28f4\u281e\u2801\u2800\u2800\u2800\u2880\u28e0\u281e\u280b\u2880\u28f4\u281e\u2801\u2502\n    \u2502\u2800\u2800\u2880\u28e0\u287e\u280b\u2880\u28f4\u281f\u280b\u2880\u28f4\u281f\u2801\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u28f4\u281f\u2801\u28e0\u2804\u2808\u2880\u28f4\u281e\u2809\u2800\u2800\u2800\u2880\u28e4\u281e\u2809\u28c0\u28f4\u281f\u2801\u28e0\u2874\u281b\u2801\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u281b\u2801\u2800\u2800\u2502\n    \u2502\u28e0\u28f4\u281f\u2801\u28e0\u28fe\u281f\u2881\u28e0\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2838\u281f\u2881\u28e4\u287e\u280b\u2880\u28f4\u281e\u2801\u2800\u2830\u281f\u2801\u2800\u2800\u2800\u2800\u2830\u281f\u2881\u28e0\u287e\u281f\u2881\u28e4\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u283e\u280b\u2881\u28f4\u287e\u280b\u2880\u28f4\u2806\u2800\u2800\u2502\n    \u2502\u281f\u28c1\u28f4\u287f\u281b\u28c1\u28f4\u283f\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28a0\u28f6\u287f\u280b\u28e0\u28f6\u281f\u2801\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u28a0\u28f4\u287f\u280b\u28e0\u28f4\u281f\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u28f6\u281f\u2809\u28e0\u287e\u280b\u2801\u2800\u2800\u2800\u2502\n    \u2502\u2800\u2809\u2809\u2800\u2800\u2809\u2801\u2800\u2800\u2801\u2880\u2874\u2802\u2800\u28e0\u2876\u280b\u2801\u2800\u2808\u2809\u2800\u2800\u2800\u2800\u28e0\u2876\u280b\u2880\u28e4\u2806\u2800\u28c0\u2874\u280b\u2809\u2800\u2808\u2809\u2801\u2800\u2800\u2800\u28c0\u2874\u2802\u2800\u28e0\u2876\u280b\u2801\u2800\u2808\u2809\u2800\u2800\u2800\u2800\u28e0\u2836\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u283e\u280b\u2880\u28e4\u281e\u280b\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2809\u28c0\u2870\u280b\u2801\u28e0\u287e\u280b\u2880\u2840\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u283e\u280b\u2880\u28f4\u281f\u2801\u2880\u2800\u2800\u2800\u2800\u2804\u2800\u2880\u28f4\u281f\u2801\u28c0\u2502\n    \u2502\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u281e\u2801\u28e0\u2874\u281f\u2801\u28e0\u2876\u280b\u2800\u2800\u2800\u2800\u28e0\u2876\u281b\u2801\u28e0\u287e\u280b\u2880\u28f4\u281f\u2801\u28c0\u2874\u280b\u2800\u2800\u2800\u2800\u28c0\u28f4\u281f\u2801\u28e0\u2876\u280b\u2881\u28e0\u283e\u280b\u2880\u2800\u2800\u2800\u28e0\u287e\u280b\u2880\u28e0\u283e\u280b\u2502\n    \u2502\u2864\u2800\u2800\u28e0\u287e\u281b\u2881\u28e4\u287e\u280b\u2880\u28e4\u281e\u2801\u2800\u2800\u2808\u2880\u28f4\u287e\u280b\u2880\u28f4\u281f\u2809\u2800\u2800\u2808\u2801\u28e0\u283e\u280b\u2800\u2800\u2800\u2880\u28e0\u287e\u280b\u2881\u28f4\u287e\u280b\u2880\u2864\u2808\u2801\u2800\u2800\u2809\u2880\u28f4\u283f\u280b\u28c0\u28f4\u281f\u2801\u2800\u2800\u2502\n    \u2502\u28c1\u28f4\u287f\u280b\u28e0\u28f4\u281f\u280b\u28e0\u2874\u281b\u2801\u2800\u2800\u2800\u2800\u28fc\u281f\u2889\u28e0\u287e\u281f\u2801\u28e0\u2804\u2800\u2800\u28b0\u281f\u2801\u2800\u2800\u2800\u2800\u28b0\u287f\u280b\u28e0\u28f6\u281f\u2801\u28e0\u2876\u280b\u2800\u2800\u2800\u2800\u2800\u28fe\u281f\u2881\u28e0\u287e\u280b\u2801\u2800\u2800\u2800\u2800\u2502\n    \u2502\u287f\u288b\u28f4\u28fe\u281f\u2881\u28f4\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28a0\u28f4\u287f\u280b\u28c0\u28f4\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u28ff\u281f\u28c1\u28f4\u287f\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28e0\u28f4\u287f\u280b\u28c0\u28f4\u2806\u2800\u2800\u2800\u2800\u2502\n    \u2502\u28fe\u28ff\u289f\u28e1\u28fe\u287f\u280b\u28c0\u2840\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u283b\u288b\u28e4\u28fe\u281f\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2838\u288b\u28e5\u28fe\u281f\u2809\u28c0\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u281f\u288b\u28e4\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   As you can see, the Unicode based plotting doesn't display nicely everywhere. It does display perfectly in e.g. Juno, which is where it is the default printing type. Here is how it looks like in a dark background:", 
            "title": "Simple Recurrence Plots"
        }, 
        {
            "location": "/rqa/rplots/#advanced-recurrence-plots", 
            "text": "A text-based plot is cool, fast and simple. But often one needs the full resolution offered by the data of a recurrence matrix.  There are two more ways to plot a recurrence matrix using  RecurrenceAnalysis :  #  RecurrenceAnalysis.coordinates     Function .  coordinates ( R )   -   xs ,   ys   Return the coordinates of the recurrence points of  R  (in indices).  #  RecurrenceAnalysis.grayscale     Function .  grayscale ( R   [,   bwcode ];   width :: Int ,   height :: Int ,   exactsize = false )   Transform the recurrence matrix  R  into a full matrix suitable for plotting as a grayscale image. By default it returns a matrix with the same size as  R , but switched axes, containing \"black\" values in the cells that represent recurrent points, and \"white\" values in the empty cells and interpolating in-between for cases with both recurrent and empty cells, see below.  The numeric codes for black and white are given in a 2-element tuple as a second optional argument. Its default value is  (0.0, 1.0) , i.e. black is coded as  0.0  (no brightness) and white as  1.0  (full brightness). The type of the elements in the tuple defines the type of the returned matrix. This must be taken into account if, for instance, the image is coded as a matrix of integers corresponding to a grayscale; in such case the black and white codes must be given as numbers of the required integer type.  The keyword arguments  width  and  height  can be given to define a custom size of the image. If only one dimension is given, the other is automatically calculated. If both dimensions are given, by default they are adjusted to keep an aspect proportional to the original matrix, such that the returned matrix fits into a matrix of the given dimensions. This automatic adjustment can be disabled by passing the keyword argument  exactsize=true .  If the image has different dimensions than  R , the cells of  R  are distributed in a grid with the size of the image, and a gray level between white and black is calculated for each element of the grid, proportional to the number of recurrent points contained in it. The levels of gray are coded as numbers of the same type as the black and white codes.  It is advised to use  width, height  arguments for large matrices otherwise plots using functions like e.g.  imshow  could be misleading.   For example, here is the representation of the above  R  from the Roessler system using both plotting approaches:  using   PyPlot  figure ( figsize   =   ( 10 , 5 ))  ax   =   subplot ( 121 )  xs ,   ys   =   coordinates ( R )  scatter ( xs ,   ys ,   color   =   k ,   s   =   1 )  xlim ( 1 ,   size ( R )[ 1 ]);   ylim ( 1 ,   size ( R )[ 2 ]);  ax . set_aspect ( equal )  subplot ( 122 )  Rg   =   grayscale ( R )  imshow ( Rg ,   cmap   =   binary_r ,   extent   =   ( 1 ,   size ( R )[ 1 ],   1 ,   size ( R )[ 2 ]))    and here is exactly the same process, but using the embedded trajectory instead  y   =   tr [ : ,   2 ]  \u03c4   =   estimate_delay ( y ,   mi_min )  m   =   reconstruct ( y ,   2 ,   \u03c4 )  R   =   RecurrenceMatrix ( m ,   5.0 ;   metric   =   euclidean )  figure ( figsize   =   ( 5 , 5 ))  xs ,   ys   =   coordinates ( R )  scatter ( xs ,   ys ,   color   =   k ,   s   =   1 )  xlim ( 1 ,   size ( R )[ 1 ]);   ylim ( 1 ,   size ( R )[ 2 ]);    which justifies why recurrence plots are so fitting to be used in embedded timeseries.   Careful when using Recurrence Plots  It is easy when using  grayscale  to not change the width/height parameters. These are however very important when the matrix size exceeds the display size! Most plotting libraries may resample arbitrarily or simply limit the displayed pixels, so one needs to be extra careful.  Besides graphical problems there are also other potential pitfalls dealing with the conceptual understanding and use of recurrence plots. All of these are summarized in the following paper which we suggest users to take a look at:  N. Marwan,  How to avoid potential pitfalls in recurrence plot based data analysis , Int. J. of Bifurcations and Chaos ( arXiv ).", 
            "title": "Advanced Recurrence Plots"
        }, 
        {
            "location": "/rqa/rplots/#example", 
            "text": "In the following we will plot recurrence plots of the Lorenz system for a periodic and chaotic regime (using scatter plot).  lor   =   Systems . lorenz ()  figure ( figsize   =   ( 10 , 10 ))  for   ( i ,   \u03c1 )   in   enumerate (( 69.75 ,   28.0 )) \n     set_parameter! ( lor ,   2 ,   \u03c1 ) \n     t ,   dt   =   20.0 ,   0.01 \n     tr   =   trajectory ( lor ,   t ;   dt   =   dt ,   Ttr   =   2000.0 ) \n     tvec   =   0 : dt : t \n\n     subplot ( 2 , 2 ,   i ) \n     plot ( tr [ : ,   1 ],   tr [ : ,   3 ],   color   =   C $ ( i + 1 ) ,   label   =   X vs Z ) \n     title ( \u03c1 =  $\u03c1 ,    *   ( i   !=   1   ?   not periodic   :   periodic ));   legend () \n\n     \u03b5   =   i   ==   1   ?   5.0   :   3.0 \n     R   =   RecurrenceMatrix ( tr ,   \u03b5 ) \n\n     subplot ( 2 , 2 , i + 2 ) \n     x ,   y   =   coordinates ( R ) \n     scatter ( tvec [ x ],   tvec [ y ],   s   =   1 ,   alpha   =   0.2 ,   color   =   C $ ( i + 1 ) ) \n     xlim ( 0 ,   t );   ylim ( 0 ,   t );   gca () . set_aspect ( equal ) \n     xlabel ( t );   i   ==   1     ylabel ( t );  end  PyPlot . tight_layout ()    On the left we see long (infinite) diagonals repeated over and over for different times. This is the case for periodic systems as they visit exactly the same area on the phase space again and again. The distance between the offset diagonals also coincides with the periodicity of the system, which is around  t \u2248 4 .  On the right we see a structure typical of chaotic motion on a strange attractor such as the one of the Lorenz system: the orbit visits neighborhoods of previous points but then quickly diverges again. This results in many small diagonal lines.", 
            "title": "Example"
        }, 
        {
            "location": "/rqa/rplots/#distances", 
            "text": "The distance function used in  RecurrenceMatrix  and co. can be specified either as a string or as any  Metric  instance from  Distances . In addition, the following function returns a matrix with the cross-distances across all points in one or two trajectories:  #  RecurrenceAnalysis.distancematrix     Function .  distancematrix ( x   [,   y   =   x ],   metric   =   euclidean )   Create a matrix with the distances between each pair of points of the time series  x  and  y  using  metric .  The time series  x  and  y  can be  Dataset s or vectors or matrices with data points in rows. The data point dimensions (or number of columns) must be the same for  x  and  y . The returned value is a  n\u00d7m  matrix, with  n  being the length (or number of rows) of  x , and  m  the length of  y .  The metric can be identified by a string, or any of the  Metric s defined in the  Distances  package . The list of strings available to define the metric are:   \"max\"  or  \"inf\"  for the maximum or L\u221e norm ( Chebyshev()  in the  Distances  package).  \"euclidean\"  for the L2 or Euclidean norm, used by default ( Euclidean()  in  Distances ).  \"manhattan\" ,  \"cityblock\" ,  \"taxicab\"  or  \"min\"  for the Manhattan or L1 norm ( Cityblock()  in  Distances ).", 
            "title": "Distances"
        }, 
        {
            "location": "/rqa/quantification/", 
            "text": "Quantification \n Analysis functions\n\n\nA \nRecurrenceMatrix\n can be analyzed in several ways to yield information about the dynamics of the trajectory. All these various \nmeasures\n and functions are collectively called \"Recurrence Quantification Analysis\" (RQA).\n\n\nTo understand how each measure can be useful, we suggest to see the review articles listed in our documentation strings, namely:\n\n\n\n\nN. Marwan \net al.\n, \"Recurrence plots for the analysis of complex systems\", \nPhys. Reports 438\n(5-6), 237-329 (2007).\n\n\nN. Marwan \n C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. \n N. Marwan (eds.), \nRecurrence Quantification Analysis. Theory and Best Practices\n, Springer, pp. 3-43 (2015).\n\n\n\n\nYou can also check the wikipedia page for \nRecurrence quantification analysis\n.\n\n\nThe functions described in this page all accept a recurrence matrix (\nx\n), see the \nprevious page\n.\n\n\n\n\nRQA Measures\n\n\n\n\nAll-in-one Bundle\n\n\nIn case you need all of the RQA-related functions (see below) and you don't want to write 10 lines of code to compute them all (since they are so many) we provide an all-in-one function that computes all of them and returns a NamedTuple of the results!\n\n\n#\n\n\nRecurrenceAnalysis.rqa\n \n \nFunction\n.\n\n\nrqa\n(\nR\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nCalculate all RQA parameters of a recurrence matrix \nR\n. See the functions referred to below for the definition of the different parameters and the default values of the arguments. Using this function is much more efficient than calling all individual functions one by one.\n\n\nReturn\n\n\nThe returned value is a NamedTuple with the following entries:\n\n\n\n\nRR\n: recurrence rate (see \nrecurrencerate\n)\n\n\nDET\n: determinsm (see \ndeterminism\n)\n\n\nL\n: average length of diagonal structures (see \ndl_average\n)\n\n\nLmax\n: maximum length of diagonal structures (see \ndl_max\n)\n\n\nDIV\n: divergence (see \ndivergence\n)\n\n\nENTR\n: entropy of diagonal structures (see \ndl_entropy\n)\n\n\nTREND\n: trend of recurrences (see \ntrend\n)\n\n\nLAM\n: laminarity (see \nlaminarity\n)\n\n\nTT\n: trapping time (see \ntrappingtime\n)\n\n\nVmax\n: maximum length of vertical structures (see \nvl_max\n)\n\n\nVENTR\n: entropy of vertical structures (see \nvl_entropy\n)\n\n\nMRT\n: mean recurrence time (see \nmeanrecurrencetime\n)\n\n\nRTE\n recurrence time entropy (see \nrt_entropy\n)\n\n\nNMPRT\n: number of the most probable recurrence time (see \nnmprt\n)\n\n\n\n\nIn the case of empty histograms (e.g. no existing vertical lines less than the keyword \nlminvert\n) the average and maximum values (\nL\n, \nLmax\n, \nTT\n, \nVmax\n, \nMRT\n) are returned as \n0.0\n but their respective entropies (\nENTR\n, \nVENTR\n, \nRTE\n) are returned as \nNaN\n.\n\n\nKeyword Arguments\n\n\nStandard keyword arguments are the ones accepted by the functions listed below, i.e. \ntheiler\n, \nlmin\n, and \nborder\n:\n\n\n\n\ntheiler\n is used to define a \"Theiler window\" around the central diagonal or \"line of identity\" (LOI): a region of points that are excluded in the calculation of RQA parameters, in order to rule out self-recurrences and apparent recurrences for smooth or high resolution data. The LOI is excluded by default for matrices of the types \nRecurrenceMatrix\n or \nJointRecurrenceMatrix\n, but it is included for matrices of the type \nCrossRecurrenceMatrix\n. \ntheiler=0\n means that the whole matrix is scanned for lines. \ntheiler=1\n means that the LOI is excluded. In general, \ntheiler=n\n means that the \nn\n central diagonals are excluded (at both sides of the LOI, i.e. actually \n2n-1\n diagonals are excluded).\n\n\nlmin\n is used to define the minimum line length in the parameters that describe the distributions of diagonal or vertical lines (it is set as 2 by default).\n\n\nborder\n is used to avoid border effects in the calculation of \nTREND\n (cf. \ntrend\n).\n\n\n\n\nIn addition \ntheilerdiag\n, \nlmindiag\n may be used to declare specific values that override the values of \ntheiler\n and \nlmin\n in the calculation of parameters related to diagonal structures. Likewise, \ntheilervert\n and \nlminvert\n can be used for the calculation of parameters related to vertical structures.\n\n\nThe keyword argument \nonlydiagonal\n (\nfalse\n by default) can be set to \ntrue\n in order to restrict the analysis to the recurrence rate and the parameters related to diagonal structures (\nRR\n, \nDET\n, \nL\n, \nLmax\n, \nDIV\n and \nENTR\n), which makes this function slightly faster.\n\n\n\n\n\n\nReturn values for empty histograms\n\n\nIt may be the case that for a given recurrence matrix some structures do not exist at all. For example there are recurrence matrices that have no vertical lengths (or no vertical lengths with length less than \nlmin\n). In such cases the behavior of our RQA pipeline is the following:\n\n\n\n\nQuantities that represent maximum or average values are \n0.0\n.\n\n\nQuantities that represent entropies are \nNaN\n.\n\n\n\n\n\n\n\n\nSee also the \n@windowed\n macro for a windowed version of \nrqa\n!\n\n\n\n\nClassical RQA Measures\n\n\n#\n\n\nRecurrenceAnalysis.recurrencerate\n \n \nFunction\n.\n\n\nrecurrencerate\n(\nR\n[;\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the recurrence rate of the recurrence matrix \nR\n.\n\n\nDescription\n\n\nThe recurrence rate is calculated as:\n\n\n\n\n\nRR = \\frac{1}{S} \\sum R\n\n\n\n\nRR = \\frac{1}{S} \\sum R\n\n\n\n\n\nwhere \nS\nS\n is the size of \nR\n or the region of \nR\n with potential recurrent points. There is not a unique definition of that denominator, which is defined as the full size of the matrix in many sources (e.g. [1]), whereas in others it is adjusted to remove the points of the LOI when they are excluded from the count [2,3].\n\n\nFor matrices of type \nRecurrenceMatrix\n or \nJointRecurrenceMatrix\n, where the points around the central diagonal are usually excluded, the denominator is adjusted to the size of the matrix outside the Theiler window (by default equal to the LOI, and adjustable with the keyword argument \ntheiler\n; see \nrqa\n for details). For matrices of type \nCrossRecurrenceMatrix\n, where normally all points are analyzed, the denominator is always the full size of the matrix, regardless of the Theiler window that might be defined (none by default).\n\n\nHint\n: to reproduce the calculations done following the formulas that use the full size of the matrix in the denominator, use \nCrossRecurrenceMatrix(s,s,\u03b5)\n to define the recurrence matrix, instead of \nRecurrenceMatrix(s,\u03b5)\n, setting \ntheiler=1\n (or \ntheiler=n\n in general) to explicitly exclude the LOI or other diagonals around it.\n\n\nReferences\n\n\n[1] : N. Marwan \net al.\n, \"Recurrence plots for the analysis of complex systems\", \nPhys. Reports 438\n(5-6), 237-329 (2007).\n\n\n[2] : C.L. Webber \n J.P. Zbilut, \"Recurrence Quantification Analysis of Nonlinear Dynamical Systems\", in: Riley MA \n Van Orden GC, Tutorials in Contemporary Nonlinear Methods for the Behavioral Sciences, 26-94 (2005). URL: https://www.nsf.gov/pubs/2005/nsf05057/nmbs/nmbs.pdf\n\n\n[3] : N. Marwan \n C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. \n N. Marwan (eds.), \nRecurrence Quantification Analysis. Theory and Best Practices\n, Springer, pp. 3-43 (2015).\n\n\n#\n\n\nRecurrenceAnalysis.determinism\n \n \nFunction\n.\n\n\ndeterminism\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the determinism of the recurrence matrix \nR\n:\n\n\nDescription\n\n\nThe determinism is calculated as:\n\n\n\n\n\nDET = \\frac{\\sum_{l=lmin}{l P(l)}}{\\sum_{l=1}{l P(l)}} =\n\\frac{\\sum_{l=lmin}{l P(l)}}{\\sum R}\n\n\n\n\nDET = \\frac{\\sum_{l=lmin}{l P(l)}}{\\sum_{l=1}{l P(l)}} =\n\\frac{\\sum_{l=lmin}{l P(l)}}{\\sum R}\n\n\n\n\n\nwhere \nl\nl\n stands for the lengths of diagonal lines in the matrix, and \nP(l)\nP(l)\n is the number of lines of length equal to \nl\nl\n.\n\n\nlmin\n is set to 2 by default, and this calculation rules out all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.dl_average\n \n \nFunction\n.\n\n\ndl_average\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the average of the diagonal lines contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.dl_max\n \n \nFunction\n.\n\n\ndl_max\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the longest diagonal line contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.dl_entropy\n \n \nFunction\n.\n\n\ndl_entropy\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the Shannon entropy of the diagonal lines contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.divergence\n \n \nFunction\n.\n\n\ndivergence\n(\nR\n[;\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the divergence of the recurrence matrix \nR\n (actually the inverse of \ndl_max\n).\n\n\n#\n\n\nRecurrenceAnalysis.trend\n \n \nFunction\n.\n\n\ntrend\n(\nR\n[;\n \nborder\n=\n10\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the trend of recurrences in the recurrence matrix \nR\n.\n\n\nDescription\n\n\nThe trend is the slope of the linear regression that relates the density of recurrent points in the diagonals parallel to the LOI and the distance between those diagonals and the LOI. It quantifies the degree of system stationarity, such that in recurrence plots where points \"fade away\" from the central diagonal, the trend will have a negative value.\n\n\nIt is calculated as:\n\n\n\n\n\nTREND = 10^3\\frac{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]\\left(RR[d]-\\langle RR[d]\\rangle\\right)}{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]^2}\n\n\n\n\nTREND = 10^3\\frac{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]\\left(RR[d]-\\langle RR[d]\\rangle\\right)}{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]^2}\n\n\n\n\n\nwhere \nRR[d]\nRR[d]\n is the local recurrence rate of the diagonal \nd\nd\n, \n\\delta[d]\n\\delta[d]\n is a balanced measure of the distance between that diagonal and the LOI, \n\\tau\n\\tau\n is the Theiler window (number of central diagonals that are excluded), and \n\\tilde{N}\n\\tilde{N}\n is the number of the outmost diagonal that is included.\n\n\nThis parameter is expressed in units of variation recurrence rate every 1000 data points, hence the factor \n10^3\n10^3\n in the formula [1]. \n\n\nThe 10 outermost diagonals (counting from the corners of the matrix) are excluded by default to avoid \"border effects\". Use the keyword argument \nborder\n to define a different number of excluded lines, and \ntheiler\n to define the size of the Theiler window (see \nrqa\n for details).\n\n\nNote\n: In rectangular cross-recurrence plots (i.e. when the time series that originate them are not of the same length), the limits of the formula for TREND are not clearly defined. For the sake of consistency, this function limits the calculations to the biggest square matrix that contains the LOI.\n\n\nReferences\n\n\n[1] C.L. Webber \n J.P. Zbilut, \"Recurrence Quantification Analysis of Nonlinear Dynamical Systems\", in: Riley MA \n Van Orden GC, \nTutorials in Contemporary Nonlinear Methods for the Behavioral Sciences\n, 2005, 26-94. https://www.nsf.gov/pubs/2005/nsf05057/nmbs/nmbs.pdf\n\n\n\n\n\n\nExtended RQA Measures\n\n\n#\n\n\nRecurrenceAnalysis.laminarity\n \n \nFunction\n.\n\n\nlaminarity\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the laminarity of the recurrence matrix \nR\n.\n\n\nDescription\n\n\nThe laminarity is calculated as:\n\n\n\n\n\nLAM = \\frac{\\sum_{v=lmin}{v P(l)}}{\\sum_{v=1}{v P(v)}} =\n\\frac{\\sum_{v=lmin}{v P(l)}}{\\sum R}\n\n\n\n\nLAM = \\frac{\\sum_{v=lmin}{v P(l)}}{\\sum_{v=1}{v P(v)}} =\n\\frac{\\sum_{v=lmin}{v P(l)}}{\\sum R}\n\n\n\n\n\nwhere \nv\nv\n stands for the lengths of vertical lines in the matrix, and \nP(v)\nP(v)\n is the number of lines of length equal to \nv\nv\n.\n\n\nlmin\n is set to 2 by default, and this calculation rules out all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.trappingtime\n \n \nFunction\n.\n\n\ntrappingtime\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the trapping time of the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\nThe trapping time is the average of the vertical line structures and thus equal to \nvl_average\n.\n\n\n#\n\n\nRecurrenceAnalysis.vl_average\n \n \nFunction\n.\n\n\nvl_average\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the average of the vertical lines contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.vl_max\n \n \nFunction\n.\n\n\nvl_max\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the longest vertical line contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.vl_entropy\n \n \nFunction\n.\n\n\nvl_entropy\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the Shannon entropy of the vertical lines contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n\n\n\n\nRecurrence Time Measures\n\n\n#\n\n\nRecurrenceAnalysis.meanrecurrencetime\n \n \nFunction\n.\n\n\nmeanrecurrencetime\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the mean recurrence time of the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\nEquivalent to \nrt_average\n.\n\n\n#\n\n\nRecurrenceAnalysis.nmprt\n \n \nFunction\n.\n\n\nnmprt\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the number of the most probable recurrence time (NMPRT), ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\nThis number indicates how many times the system has recurred using the recurrence time that appears most frequently, i.e it is the maximum value of the histogram of recurrence times [1].\n\n\nReferences\n\n\n[1] : E.J. Ngamga \net al.\n \"Recurrence analysis of strange nonchaotic dynamics\", \nPhysical Review E\n, 75(3), 036222(1-8), 2007, DOI:10.1103/physreve.75.036222\n\n\n#\n\n\nRecurrenceAnalysis.rt_entropy\n \n \nFunction\n.\n\n\nrt_entropy\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the Shannon entropy of the recurrence times contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n#\n\n\nRecurrenceAnalysis.rt_average\n \n \nFunction\n.\n\n\nrt_average\n(\nR\n[;\n \nlmin\n=\n2\n,\n \ntheiler\n])\n\n\n\n\n\n\nCalculate the average of the recurrence times contained in the recurrence matrix \nR\n, ruling out the lines shorter than \nlmin\n (2 by default) and all the points inside the Theiler window (see \nrqa\n for the default values and usage of the keyword argument \ntheiler\n).\n\n\n\n\n\n\nKeyword table\n\n\nSince most of the above functions can be fined tuned with keyword arguments, here is a table summarizing them that could be of use:\n\n\n\n\n\n\n\n\nArgument\n\n\nDefault\n\n\nFunctions\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntheiler\n\n\n0 for \nCrossRecurrenceMatrix\n, 1 otherwise.\n\n\nrecurrencerate\ndeterminism\n*_average\n*_max\n*_entropy\ndivergence\ntrend\nlaminarity\ntrappingtime\n \nmeanrecurrencetime\nnmprt\n\n\nTheiler window: number of diagonals around the LOI \nexcluded\n from the analysis. The value \n0\n means that the LOI is \nincluded\n in the analysis. Use \n1\n to exclude the LOI.\n\n\n\n\n\n\nlmin\n\n\n2\n\n\ndeterminism\n*_average\n*_max\n*_entropy\ndivergence\nlaminarity\ntrappingtime\n \nmeanrecurrencetime\nnmprt\n\n\nMinimum length of the recurrent structures (diagonal or vertical) considered in the analysis.\n\n\n\n\n\n\nborder\n\n\n10\n\n\ntrend\n\n\nNumber of diagonals excluded from the analysis near the border of the matrix.\n\n\n\n\n\n\n\n\n\n\nRecurrence Structures Histograms\n\n\nThe functions that we list in this page internally compute histograms of some recurrence structures, like e.g. the vertical lengths. You can access these values directly with the following function:\n\n\n#\n\n\nRecurrenceAnalysis.recurrencestructures\n \n \nFunction\n.\n\n\nrecurrencestructures\n(\nx\n::\nAbstractRecurrenceMatrix\n;\n\n                         \ndiagonal\n=\ntrue\n,\n\n                         \nvertical\n=\ntrue\n,\n\n                         \nrecurrencetimes\n=\ntrue\n,\n\n                         \nkwargs\n...\n)\n\n\n\n\n\n\nReturn a dictionary with the histograms of the recurrence structures contained in the recurrence matrix \nx\n, with the keys \n\"diagonal\"\n, \n\"vertical\"\n or \n\"recurrencetimes\"\n, depending on what keyword arguments are given as \ntrue\n.\n\n\nDescription\n\n\nEach item of the dictionary is a vector of integers, such that the \ni\n-th element of the vector is the number of lines of length \ni\n contained in \nx\n.\n\n\n\n\n\"diagonal\"\n counts the diagonal lines, i.e. the recurrent trajectories.\n\n\n\"vertical\"\n counts the vertical lines, i.e. the laminar states.\n\n\n\"recurrencetimes\"\n counts the vertical distances between recurrent states,   i.e. the recurrence times.\n\n\n\n\nAll the points of the matrix are counted by default. The keyword argument \ntheiler\n can be passed to rule out the lines around the main diagonal. See the arguments of the function \nrqa\n for further details.\n\n\n\"Empty\" histograms are represented always as \n[0]\n.\n\n\nNotice\n: There is not a unique operational definition of \"recurrence times\". In the analysis of recurrence plots, usually the  \"second type\" of recurrence times as defined by Gao and Cai [1] are considered, i.e. the distance between consecutive (but separated) recurrent structures in the vertical direction of the matrix. But that distance is not uniquely defined when the vertical recurrent structures are longer than one point. The recurrence times calculated here are the distance between the midpoints of consecutive lines, which is a balanced estimator of the Poincar\u00e9 recurrence times [2].\n\n\nReferences\n\n\n[1] J. Gao \n H. Cai. \"On the structures and quantification of recurrence plots\". \nPhysics Letters A\n, 270(1-2), 75\u201387 (2000)\n.\n\n\n[2] N. Marwan \n C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L. \n N. Marwan (eds.), \nRecurrence Quantification Analysis. Theory and Best Practices\n, Springer, pp. 3-43 (2015).", 
            "title": "Quantification & Analysis functions"
        }, 
        {
            "location": "/rqa/quantification/#quantification-analysis-functions", 
            "text": "A  RecurrenceMatrix  can be analyzed in several ways to yield information about the dynamics of the trajectory. All these various  measures  and functions are collectively called \"Recurrence Quantification Analysis\" (RQA).  To understand how each measure can be useful, we suggest to see the review articles listed in our documentation strings, namely:   N. Marwan  et al. , \"Recurrence plots for the analysis of complex systems\",  Phys. Reports 438 (5-6), 237-329 (2007).  N. Marwan   C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L.   N. Marwan (eds.),  Recurrence Quantification Analysis. Theory and Best Practices , Springer, pp. 3-43 (2015).   You can also check the wikipedia page for  Recurrence quantification analysis .  The functions described in this page all accept a recurrence matrix ( x ), see the  previous page .", 
            "title": "Quantification &amp; Analysis functions"
        }, 
        {
            "location": "/rqa/quantification/#rqa-measures", 
            "text": "", 
            "title": "RQA Measures"
        }, 
        {
            "location": "/rqa/quantification/#all-in-one-bundle", 
            "text": "In case you need all of the RQA-related functions (see below) and you don't want to write 10 lines of code to compute them all (since they are so many) we provide an all-in-one function that computes all of them and returns a NamedTuple of the results!  #  RecurrenceAnalysis.rqa     Function .  rqa ( R ;   kwargs ... )   Calculate all RQA parameters of a recurrence matrix  R . See the functions referred to below for the definition of the different parameters and the default values of the arguments. Using this function is much more efficient than calling all individual functions one by one.  Return  The returned value is a NamedTuple with the following entries:   RR : recurrence rate (see  recurrencerate )  DET : determinsm (see  determinism )  L : average length of diagonal structures (see  dl_average )  Lmax : maximum length of diagonal structures (see  dl_max )  DIV : divergence (see  divergence )  ENTR : entropy of diagonal structures (see  dl_entropy )  TREND : trend of recurrences (see  trend )  LAM : laminarity (see  laminarity )  TT : trapping time (see  trappingtime )  Vmax : maximum length of vertical structures (see  vl_max )  VENTR : entropy of vertical structures (see  vl_entropy )  MRT : mean recurrence time (see  meanrecurrencetime )  RTE  recurrence time entropy (see  rt_entropy )  NMPRT : number of the most probable recurrence time (see  nmprt )   In the case of empty histograms (e.g. no existing vertical lines less than the keyword  lminvert ) the average and maximum values ( L ,  Lmax ,  TT ,  Vmax ,  MRT ) are returned as  0.0  but their respective entropies ( ENTR ,  VENTR ,  RTE ) are returned as  NaN .  Keyword Arguments  Standard keyword arguments are the ones accepted by the functions listed below, i.e.  theiler ,  lmin , and  border :   theiler  is used to define a \"Theiler window\" around the central diagonal or \"line of identity\" (LOI): a region of points that are excluded in the calculation of RQA parameters, in order to rule out self-recurrences and apparent recurrences for smooth or high resolution data. The LOI is excluded by default for matrices of the types  RecurrenceMatrix  or  JointRecurrenceMatrix , but it is included for matrices of the type  CrossRecurrenceMatrix .  theiler=0  means that the whole matrix is scanned for lines.  theiler=1  means that the LOI is excluded. In general,  theiler=n  means that the  n  central diagonals are excluded (at both sides of the LOI, i.e. actually  2n-1  diagonals are excluded).  lmin  is used to define the minimum line length in the parameters that describe the distributions of diagonal or vertical lines (it is set as 2 by default).  border  is used to avoid border effects in the calculation of  TREND  (cf.  trend ).   In addition  theilerdiag ,  lmindiag  may be used to declare specific values that override the values of  theiler  and  lmin  in the calculation of parameters related to diagonal structures. Likewise,  theilervert  and  lminvert  can be used for the calculation of parameters related to vertical structures.  The keyword argument  onlydiagonal  ( false  by default) can be set to  true  in order to restrict the analysis to the recurrence rate and the parameters related to diagonal structures ( RR ,  DET ,  L ,  Lmax ,  DIV  and  ENTR ), which makes this function slightly faster.    Return values for empty histograms  It may be the case that for a given recurrence matrix some structures do not exist at all. For example there are recurrence matrices that have no vertical lengths (or no vertical lengths with length less than  lmin ). In such cases the behavior of our RQA pipeline is the following:   Quantities that represent maximum or average values are  0.0 .  Quantities that represent entropies are  NaN .     See also the  @windowed  macro for a windowed version of  rqa !", 
            "title": "All-in-one Bundle"
        }, 
        {
            "location": "/rqa/quantification/#classical-rqa-measures", 
            "text": "#  RecurrenceAnalysis.recurrencerate     Function .  recurrencerate ( R [;   theiler ])   Calculate the recurrence rate of the recurrence matrix  R .  Description  The recurrence rate is calculated as:   \nRR = \\frac{1}{S} \\sum R  \nRR = \\frac{1}{S} \\sum R   where  S S  is the size of  R  or the region of  R  with potential recurrent points. There is not a unique definition of that denominator, which is defined as the full size of the matrix in many sources (e.g. [1]), whereas in others it is adjusted to remove the points of the LOI when they are excluded from the count [2,3].  For matrices of type  RecurrenceMatrix  or  JointRecurrenceMatrix , where the points around the central diagonal are usually excluded, the denominator is adjusted to the size of the matrix outside the Theiler window (by default equal to the LOI, and adjustable with the keyword argument  theiler ; see  rqa  for details). For matrices of type  CrossRecurrenceMatrix , where normally all points are analyzed, the denominator is always the full size of the matrix, regardless of the Theiler window that might be defined (none by default).  Hint : to reproduce the calculations done following the formulas that use the full size of the matrix in the denominator, use  CrossRecurrenceMatrix(s,s,\u03b5)  to define the recurrence matrix, instead of  RecurrenceMatrix(s,\u03b5) , setting  theiler=1  (or  theiler=n  in general) to explicitly exclude the LOI or other diagonals around it.  References  [1] : N. Marwan  et al. , \"Recurrence plots for the analysis of complex systems\",  Phys. Reports 438 (5-6), 237-329 (2007).  [2] : C.L. Webber   J.P. Zbilut, \"Recurrence Quantification Analysis of Nonlinear Dynamical Systems\", in: Riley MA   Van Orden GC, Tutorials in Contemporary Nonlinear Methods for the Behavioral Sciences, 26-94 (2005). URL: https://www.nsf.gov/pubs/2005/nsf05057/nmbs/nmbs.pdf  [3] : N. Marwan   C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L.   N. Marwan (eds.),  Recurrence Quantification Analysis. Theory and Best Practices , Springer, pp. 3-43 (2015).  #  RecurrenceAnalysis.determinism     Function .  determinism ( R [;   lmin = 2 ,   theiler ])   Calculate the determinism of the recurrence matrix  R :  Description  The determinism is calculated as:   \nDET = \\frac{\\sum_{l=lmin}{l P(l)}}{\\sum_{l=1}{l P(l)}} =\n\\frac{\\sum_{l=lmin}{l P(l)}}{\\sum R}  \nDET = \\frac{\\sum_{l=lmin}{l P(l)}}{\\sum_{l=1}{l P(l)}} =\n\\frac{\\sum_{l=lmin}{l P(l)}}{\\sum R}   where  l l  stands for the lengths of diagonal lines in the matrix, and  P(l) P(l)  is the number of lines of length equal to  l l .  lmin  is set to 2 by default, and this calculation rules out all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.dl_average     Function .  dl_average ( R [;   lmin = 2 ,   theiler ])   Calculate the average of the diagonal lines contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.dl_max     Function .  dl_max ( R [;   lmin = 2 ,   theiler ])   Calculate the longest diagonal line contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.dl_entropy     Function .  dl_entropy ( R [;   lmin = 2 ,   theiler ])   Calculate the Shannon entropy of the diagonal lines contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.divergence     Function .  divergence ( R [;   theiler ])   Calculate the divergence of the recurrence matrix  R  (actually the inverse of  dl_max ).  #  RecurrenceAnalysis.trend     Function .  trend ( R [;   border = 10 ,   theiler ])   Calculate the trend of recurrences in the recurrence matrix  R .  Description  The trend is the slope of the linear regression that relates the density of recurrent points in the diagonals parallel to the LOI and the distance between those diagonals and the LOI. It quantifies the degree of system stationarity, such that in recurrence plots where points \"fade away\" from the central diagonal, the trend will have a negative value.  It is calculated as:   \nTREND = 10^3\\frac{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]\\left(RR[d]-\\langle RR[d]\\rangle\\right)}{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]^2}  \nTREND = 10^3\\frac{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]\\left(RR[d]-\\langle RR[d]\\rangle\\right)}{\\sum_{d=\\tau}^{\\tilde{N}}\\delta[d]^2}   where  RR[d] RR[d]  is the local recurrence rate of the diagonal  d d ,  \\delta[d] \\delta[d]  is a balanced measure of the distance between that diagonal and the LOI,  \\tau \\tau  is the Theiler window (number of central diagonals that are excluded), and  \\tilde{N} \\tilde{N}  is the number of the outmost diagonal that is included.  This parameter is expressed in units of variation recurrence rate every 1000 data points, hence the factor  10^3 10^3  in the formula [1].   The 10 outermost diagonals (counting from the corners of the matrix) are excluded by default to avoid \"border effects\". Use the keyword argument  border  to define a different number of excluded lines, and  theiler  to define the size of the Theiler window (see  rqa  for details).  Note : In rectangular cross-recurrence plots (i.e. when the time series that originate them are not of the same length), the limits of the formula for TREND are not clearly defined. For the sake of consistency, this function limits the calculations to the biggest square matrix that contains the LOI.  References  [1] C.L. Webber   J.P. Zbilut, \"Recurrence Quantification Analysis of Nonlinear Dynamical Systems\", in: Riley MA   Van Orden GC,  Tutorials in Contemporary Nonlinear Methods for the Behavioral Sciences , 2005, 26-94. https://www.nsf.gov/pubs/2005/nsf05057/nmbs/nmbs.pdf", 
            "title": "Classical RQA Measures"
        }, 
        {
            "location": "/rqa/quantification/#extended-rqa-measures", 
            "text": "#  RecurrenceAnalysis.laminarity     Function .  laminarity ( R [;   lmin = 2 ,   theiler ])   Calculate the laminarity of the recurrence matrix  R .  Description  The laminarity is calculated as:   \nLAM = \\frac{\\sum_{v=lmin}{v P(l)}}{\\sum_{v=1}{v P(v)}} =\n\\frac{\\sum_{v=lmin}{v P(l)}}{\\sum R}  \nLAM = \\frac{\\sum_{v=lmin}{v P(l)}}{\\sum_{v=1}{v P(v)}} =\n\\frac{\\sum_{v=lmin}{v P(l)}}{\\sum R}   where  v v  stands for the lengths of vertical lines in the matrix, and  P(v) P(v)  is the number of lines of length equal to  v v .  lmin  is set to 2 by default, and this calculation rules out all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.trappingtime     Function .  trappingtime ( R [;   lmin = 2 ,   theiler ])   Calculate the trapping time of the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  The trapping time is the average of the vertical line structures and thus equal to  vl_average .  #  RecurrenceAnalysis.vl_average     Function .  vl_average ( R [;   lmin = 2 ,   theiler ])   Calculate the average of the vertical lines contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.vl_max     Function .  vl_max ( R [;   lmin = 2 ,   theiler ])   Calculate the longest vertical line contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.vl_entropy     Function .  vl_entropy ( R [;   lmin = 2 ,   theiler ])   Calculate the Shannon entropy of the vertical lines contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).", 
            "title": "Extended RQA Measures"
        }, 
        {
            "location": "/rqa/quantification/#recurrence-time-measures", 
            "text": "#  RecurrenceAnalysis.meanrecurrencetime     Function .  meanrecurrencetime ( R [;   lmin = 2 ,   theiler ])   Calculate the mean recurrence time of the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  Equivalent to  rt_average .  #  RecurrenceAnalysis.nmprt     Function .  nmprt ( R [;   lmin = 2 ,   theiler ])   Calculate the number of the most probable recurrence time (NMPRT), ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  This number indicates how many times the system has recurred using the recurrence time that appears most frequently, i.e it is the maximum value of the histogram of recurrence times [1].  References  [1] : E.J. Ngamga  et al.  \"Recurrence analysis of strange nonchaotic dynamics\",  Physical Review E , 75(3), 036222(1-8), 2007, DOI:10.1103/physreve.75.036222  #  RecurrenceAnalysis.rt_entropy     Function .  rt_entropy ( R [;   lmin = 2 ,   theiler ])   Calculate the Shannon entropy of the recurrence times contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).  #  RecurrenceAnalysis.rt_average     Function .  rt_average ( R [;   lmin = 2 ,   theiler ])   Calculate the average of the recurrence times contained in the recurrence matrix  R , ruling out the lines shorter than  lmin  (2 by default) and all the points inside the Theiler window (see  rqa  for the default values and usage of the keyword argument  theiler ).", 
            "title": "Recurrence Time Measures"
        }, 
        {
            "location": "/rqa/quantification/#keyword-table", 
            "text": "Since most of the above functions can be fined tuned with keyword arguments, here is a table summarizing them that could be of use:     Argument  Default  Functions  Description      theiler  0 for  CrossRecurrenceMatrix , 1 otherwise.  recurrencerate determinism *_average *_max *_entropy divergence trend laminarity trappingtime   meanrecurrencetime nmprt  Theiler window: number of diagonals around the LOI  excluded  from the analysis. The value  0  means that the LOI is  included  in the analysis. Use  1  to exclude the LOI.    lmin  2  determinism *_average *_max *_entropy divergence laminarity trappingtime   meanrecurrencetime nmprt  Minimum length of the recurrent structures (diagonal or vertical) considered in the analysis.    border  10  trend  Number of diagonals excluded from the analysis near the border of the matrix.", 
            "title": "Keyword table"
        }, 
        {
            "location": "/rqa/quantification/#recurrence-structures-histograms", 
            "text": "The functions that we list in this page internally compute histograms of some recurrence structures, like e.g. the vertical lengths. You can access these values directly with the following function:  #  RecurrenceAnalysis.recurrencestructures     Function .  recurrencestructures ( x :: AbstractRecurrenceMatrix ; \n                          diagonal = true , \n                          vertical = true , \n                          recurrencetimes = true , \n                          kwargs ... )   Return a dictionary with the histograms of the recurrence structures contained in the recurrence matrix  x , with the keys  \"diagonal\" ,  \"vertical\"  or  \"recurrencetimes\" , depending on what keyword arguments are given as  true .  Description  Each item of the dictionary is a vector of integers, such that the  i -th element of the vector is the number of lines of length  i  contained in  x .   \"diagonal\"  counts the diagonal lines, i.e. the recurrent trajectories.  \"vertical\"  counts the vertical lines, i.e. the laminar states.  \"recurrencetimes\"  counts the vertical distances between recurrent states,   i.e. the recurrence times.   All the points of the matrix are counted by default. The keyword argument  theiler  can be passed to rule out the lines around the main diagonal. See the arguments of the function  rqa  for further details.  \"Empty\" histograms are represented always as  [0] .  Notice : There is not a unique operational definition of \"recurrence times\". In the analysis of recurrence plots, usually the  \"second type\" of recurrence times as defined by Gao and Cai [1] are considered, i.e. the distance between consecutive (but separated) recurrent structures in the vertical direction of the matrix. But that distance is not uniquely defined when the vertical recurrent structures are longer than one point. The recurrence times calculated here are the distance between the midpoints of consecutive lines, which is a balanced estimator of the Poincar\u00e9 recurrence times [2].  References  [1] J. Gao   H. Cai. \"On the structures and quantification of recurrence plots\".  Physics Letters A , 270(1-2), 75\u201387 (2000) .  [2] N. Marwan   C.L. Webber, \"Mathematical and computational foundations of recurrence quantifications\", in: Webber, C.L.   N. Marwan (eds.),  Recurrence Quantification Analysis. Theory and Best Practices , Springer, pp. 3-43 (2015).", 
            "title": "Recurrence Structures Histograms"
        }, 
        {
            "location": "/rqa/windowed/", 
            "text": "Windowed RQA\n\n\nIn some cases, specially with very long time series, it may be suitable to perform the analysis at different points, considering only a limited \nwindow\n of data around each observation. The macro \n@windowed\n modifies the behaviour of the basic functions to calculate RQA parameters in that fashion. For instance, if \nrmat\n is a 10\n4\n10\n4\n recurrence matrix, then\n\n\n@windowed\n \ndeterminism\n(\nrmat\n,\n \ntheiler\n=\n2\n,\n \nlmin\n=\n3\n)\n \nwidth\n=\n1000\n \nstep\n=\n100\n\n\n\n\n\n\nwill return a 91-element vector, such that each value is the determinism associated to a 1000-point fragment, starting at every 100 points (i.e. at \n1\n, \n101\n, \n \n9001\n).\n\n\nThe general syntax of that macro is:\n\n\n@windowed\n \nexpr\n \nw\n                 \n#1\n\n\n@windowed\n \nexpr\n \nwidth\n=\nw\n \nstep\n=\ns\n    \n#2\n\n\n\n\n\n\nwhere:\n\n\n\n\nexpr\n is an expression used to calculate RQA parameters\n\n\nw\n is the width of the window for relevant data around each point.\n\n\ns\n is the step or distance between points where the calculations are done (starting in the first point).\n\n\n\n\nTo prevent syntax failures in the expansion of the macro, identify the RQA function (\nrqa\n, \nrecurrencerate\n, \ndeterminism\n,...) directly by its name (avoid aliases), and use simple variable names (not complex expressions) for the arguments. On the other hand, the windowing options \nwidth\n and \nstep\n can be given in any order. If \nstep\n is ommitted, the calculations are done at every point, and the keyword \nwidth\n may be ommitted. (However, using \nstep=1\n may be computationally very expensive, and that will provide just overly redundant results around each point, so it is advisable to set \nstep\n a relatively big fraction of the window \nwidth\n.)\n\n\nThe value returned by the macro will normally be a vector with the same type of numbers as expected by \nexpr\n. In the case of \n@windowed rqa(...) ...\n, it will return a NamedTuple with a similar structure as in the default \nrqa\n function, but replacing scalar values by vectors.\n\n\nThe macro \n@windowed\n can also be applied to the functions that calculate recurrence matrices (\nRecurrenceMatrix\n, \nCrossRecurrenceMatrix\n, \nJointRecurrenceMatrix\n). That creates a sparse matrix with the same size as if the macro was not used, but only containing valid values for pairs of points that belong to the \nw\n first main diagonals (i.e. the separation in time from one point to the other is \nw\n or smaller). The \nstep\n parameter \ns\n has no effect on those functions. Such \nwindowed\n matrices can be used as the input arguments to calculate windowed RQA parameters, obtaining the same results as if the complete matrix was used (under certain conditions, see below). For instance, the following calculations are equivalent:\n\n\n# Using complete matrix\n\n\nrmat\n \n=\n \nRecurrenceMatrix\n(\nx\n,\n \n1.5\n)\n\n\nd\n \n=\n \n@windowed\n \ndeterminism\n(\nrmat\n)\n \nwidth\n=\n1000\n \nstep\n=\n250\n\n\n\n# Using windowed matrix\n\n\nrmatw\n \n=\n \n@windowed\n \nRecurrenceMatrix\n(\nx\n,\n \n1.5\n)\n \n1000\n\n\nd\n \n=\n \n@windowed\n \ndeterminism\n(\nrmatw\n)\n \nwidth\n=\n1000\n \nstep\n=\n250\n\n\n\n\n\n\nThe main difference between the two alternatives is that the second one will be faster and consume less memory. To ensure the equivalence between both approaches, the window width used to create the matrix must be greater than the one used to calculate the RQA parameters. Otherwise, the computation of RQA parameters might involve data points whose value is not well defined. Besides, the threshold to identify recurrences should be referred to a fixed scale. For instance:\n\n\nrmat\n  \n=\n           \nRecurrenceMatrix\n(\nx\n,\n \n0.1\n,\n \nscale\n=\nmaximum\n)\n\n\nrmatw\n \n=\n \n@windowed\n \nRecurrenceMatrix\n(\nx\n,\n \n0.1\n,\n \nscale\n=\nmaximum\n)\n \n1000\n\n\nrmat\n[\n1\n:\n1000\n,\n1\n:\n1000\n]\n \n==\n \nrmatw\n[\n1\n:\n1000\n,\n1\n:\n1000\n]\n \n# FALSE!!!\n\n\n\n\n\n\nIn this example, the \n1000\u00d71000\n blocks of both matrices differ, because the threshold \n0.1\n is scaled with respect to the maximum distance between all points of \nx\n in \nrmat\n, but in the case of \nrmatw\n the scale changes between subsets of points. Something similar may happen if the recurrence matrix is calculated for a fixed recurrence rate (with the option \nfixedrate=true\n).\n\n\n\n\nDocstring\n\n\n#\n\n\nRecurrenceAnalysis.@windowed\n \n \nMacro\n.\n\n\n@windowed\n(\nf\n(\nx\n,\n...\n),\n \nwidth\n)\n\n\n@windowed\n(\nf\n(\nx\n,\n...\n);\n \nwidth\n,\n \nstep\n=\n1\n)\n\n\n\n\n\n\nCalculate windowed RQA parameters with a given window width.\n\n\nf(x,...)\n may be any call to RQA functions (e.g. \nrecurrencerate\n, \ndeterminism\n, etc.), with \nx\n being a named variable that designates the recurrence matrix (do not use in-place calculations of the recurrence matrix). The results are returned in a vector with one value for each position of the window. By default the window moves at one-point intervals, but a longer \nstep\n length may be specified, together with the window \nwidth\n, by declaring those options as keyword arguments.\n\n\nThis macro may be also used with recurrence matrix constructors (\nRecurrenceMatrix\n, \nCrossRecurrenceMatrix\n, \nJointRecurrenceMatrix\n), to create 'incomplete' matrices that are suitable for such windowed RQA. The values of the resulting matrix in the diagonals within the window width will be equal to those obtained without the \n@windowed\n macro, if the distances are not scaled (using the option \nscale=1\n, see \nRecurrenceMatrix\n). Outside the window width, the values of the recurrence matrix will be undefined (mostly zero).\n\n\n\n\nAlternative syntax for \n@windowed\n\n\nThe following ways of using the macro \n@windowed\n are equivalent:\n\n\ny\n \n=\n \n@windowed\n \nf\n(\nx\n,\n...\n)\n \nw\n\n\n@windowed\n \ny\n=\nf\n(\nx\n,\n...\n)\n \nw\n\n\ny\n \n=\n \n@windowed\n(\nf\n(\nx\n,\n...\n),\n \nw\n)\n\n\n@windowed\n(\ny\n=\nf\n(\nx\n,\n...\n),\n \nw\n)\n\n\n\n\n\n\nIn all four cases, the width parameter \nw\n might have been qualified with a keyword as \nwidth=w\n. If the step parameter is added, the keyword qualification is mandatory.", 
            "title": "Windowed RQA"
        }, 
        {
            "location": "/rqa/windowed/#windowed-rqa", 
            "text": "In some cases, specially with very long time series, it may be suitable to perform the analysis at different points, considering only a limited  window  of data around each observation. The macro  @windowed  modifies the behaviour of the basic functions to calculate RQA parameters in that fashion. For instance, if  rmat  is a 10 4 10 4  recurrence matrix, then  @windowed   determinism ( rmat ,   theiler = 2 ,   lmin = 3 )   width = 1000   step = 100   will return a 91-element vector, such that each value is the determinism associated to a 1000-point fragment, starting at every 100 points (i.e. at  1 ,  101 ,    9001 ).  The general syntax of that macro is:  @windowed   expr   w                   #1  @windowed   expr   width = w   step = s      #2   where:   expr  is an expression used to calculate RQA parameters  w  is the width of the window for relevant data around each point.  s  is the step or distance between points where the calculations are done (starting in the first point).   To prevent syntax failures in the expansion of the macro, identify the RQA function ( rqa ,  recurrencerate ,  determinism ,...) directly by its name (avoid aliases), and use simple variable names (not complex expressions) for the arguments. On the other hand, the windowing options  width  and  step  can be given in any order. If  step  is ommitted, the calculations are done at every point, and the keyword  width  may be ommitted. (However, using  step=1  may be computationally very expensive, and that will provide just overly redundant results around each point, so it is advisable to set  step  a relatively big fraction of the window  width .)  The value returned by the macro will normally be a vector with the same type of numbers as expected by  expr . In the case of  @windowed rqa(...) ... , it will return a NamedTuple with a similar structure as in the default  rqa  function, but replacing scalar values by vectors.  The macro  @windowed  can also be applied to the functions that calculate recurrence matrices ( RecurrenceMatrix ,  CrossRecurrenceMatrix ,  JointRecurrenceMatrix ). That creates a sparse matrix with the same size as if the macro was not used, but only containing valid values for pairs of points that belong to the  w  first main diagonals (i.e. the separation in time from one point to the other is  w  or smaller). The  step  parameter  s  has no effect on those functions. Such  windowed  matrices can be used as the input arguments to calculate windowed RQA parameters, obtaining the same results as if the complete matrix was used (under certain conditions, see below). For instance, the following calculations are equivalent:  # Using complete matrix  rmat   =   RecurrenceMatrix ( x ,   1.5 )  d   =   @windowed   determinism ( rmat )   width = 1000   step = 250  # Using windowed matrix  rmatw   =   @windowed   RecurrenceMatrix ( x ,   1.5 )   1000  d   =   @windowed   determinism ( rmatw )   width = 1000   step = 250   The main difference between the two alternatives is that the second one will be faster and consume less memory. To ensure the equivalence between both approaches, the window width used to create the matrix must be greater than the one used to calculate the RQA parameters. Otherwise, the computation of RQA parameters might involve data points whose value is not well defined. Besides, the threshold to identify recurrences should be referred to a fixed scale. For instance:  rmat    =             RecurrenceMatrix ( x ,   0.1 ,   scale = maximum )  rmatw   =   @windowed   RecurrenceMatrix ( x ,   0.1 ,   scale = maximum )   1000  rmat [ 1 : 1000 , 1 : 1000 ]   ==   rmatw [ 1 : 1000 , 1 : 1000 ]   # FALSE!!!   In this example, the  1000\u00d71000  blocks of both matrices differ, because the threshold  0.1  is scaled with respect to the maximum distance between all points of  x  in  rmat , but in the case of  rmatw  the scale changes between subsets of points. Something similar may happen if the recurrence matrix is calculated for a fixed recurrence rate (with the option  fixedrate=true ).", 
            "title": "Windowed RQA"
        }, 
        {
            "location": "/rqa/windowed/#docstring", 
            "text": "#  RecurrenceAnalysis.@windowed     Macro .  @windowed ( f ( x , ... ),   width )  @windowed ( f ( x , ... );   width ,   step = 1 )   Calculate windowed RQA parameters with a given window width.  f(x,...)  may be any call to RQA functions (e.g.  recurrencerate ,  determinism , etc.), with  x  being a named variable that designates the recurrence matrix (do not use in-place calculations of the recurrence matrix). The results are returned in a vector with one value for each position of the window. By default the window moves at one-point intervals, but a longer  step  length may be specified, together with the window  width , by declaring those options as keyword arguments.  This macro may be also used with recurrence matrix constructors ( RecurrenceMatrix ,  CrossRecurrenceMatrix ,  JointRecurrenceMatrix ), to create 'incomplete' matrices that are suitable for such windowed RQA. The values of the resulting matrix in the diagonals within the window width will be equal to those obtained without the  @windowed  macro, if the distances are not scaled (using the option  scale=1 , see  RecurrenceMatrix ). Outside the window width, the values of the recurrence matrix will be undefined (mostly zero).", 
            "title": "Docstring"
        }, 
        {
            "location": "/rqa/windowed/#alternative-syntax-for-windowed", 
            "text": "The following ways of using the macro  @windowed  are equivalent:  y   =   @windowed   f ( x , ... )   w  @windowed   y = f ( x , ... )   w  y   =   @windowed ( f ( x , ... ),   w )  @windowed ( y = f ( x , ... ),   w )   In all four cases, the width parameter  w  might have been qualified with a keyword as  width=w . If the step parameter is added, the keyword qualification is mandatory.", 
            "title": "Alternative syntax for @windowed"
        }, 
        {
            "location": "/interact/od/", 
            "text": "Interactive Orbit Diagram\n\n\n\n\nDocstrings\n\n\n#\n\n\nInteractiveChaos.interactive_orbitdiagram\n \n \nFunction\n.\n\n\ninteractive_orbitdiagram\n(\nds\n::\nDiscreteDynamicalSystem\n,\n\n    \ni\n::\nInt\n,\n \np_index\n,\n \np_min\n,\n \np_max\n;\n\n    \ndensity\n \n=\n \n500\n,\n \nu0\n \n=\n \nget_state\n(\nds\n),\n \nTtr\n \n=\n \n200\n,\n \nn\n \n=\n \n500\n,\n\n    \nparname\n \n=\n \np\n\n\n)\n\n\n\n\n\n\nOpen an interactive application for exploring orbit diagrams (ODs) of discrete systems. The functionality works for \nany\n discrete system.\n\n\nOnce initialized it opens a Makie plot window and an Electron control window.\n\n\nInteraction\n\n\nBy using the Electron window you are able to update all parameters of the OD interactively (like e.g. \nn\n or \nTtr\n). You have to press \nupdate\n after changing these parameters. You can even decide which variable to get the OD for, by choosing one of the variables from the wheel (again, press \nupdate\n afterwards).\n\n\nIn the Makie window you can interactively zoom into the OD. Click and drag with the left mouse button to select a region in the OD. This region is then \nre-computed\n at a higher resolution (i.e. we don't \"just zoom\").\n\n\nBack in the Electron window, you can press \nreset\n to bring the OD in the original state (and variable). Pressing \nback\n will go back through the history of your exploration History is stored when any change happens (besides transparency).\n\n\nAccessing the data\n\n\nWhat is plotted on the application window is a \ntrue\n orbit diagram, not a plotting shorthand. This means that all data are obtainable and usable directly. Internally we always scale the orbit diagram to [0,1]\u00b2 (to allow \nFloat64\n precision even though plotting is \nFloat32\n-based). This however means that it is necessary to transform the data in real scale. This is done through the function \nscaleod\n which accepts the 5 arguments returned from the current function:\n\n\nod, pmin, pmax, umin, umax = interactive_orbitdiagram(...)\nps, us = scaleod(od, pmin, pmax, umin, umax)\n\n\n\n\n\n#\n\n\nInteractiveChaos.scaleod\n \n \nFunction\n.\n\n\nscaleod\n(\nod\n,\n \npmin\n,\n \npmax\n,\n \numin\n,\n \numax\n)\n \n-\n \nps\n,\n \nus\n\n\n\n\n\n\nGiven the return values of \ninteractive_orbitdiagram\n, produce orbit diagram data scaled correctly in data units. Return the data as a vector of parameter values and a vector of corresponding variable values.\n\n\n\n\nFunction Video\n\n\nusing\n \nInteractiveChaos\n,\n \nMakie\n\n\n\ni\n \n=\n \n1\n\n\np_index\n \n=\n \n1\n\n\n\nsystems\n \n=\n \n[(\nSystems\n.\nlogistic\n(),\n \n3.0\n,\n \n4.0\n,\n \nr\n),\n\n           \n(\nSystems\n.\nhenon\n(),\n \n0.8\n,\n \n1.4\n,\n \na\n),\n\n           \n(\nSystems\n.\nstandardmap\n(),\n \n0.6\n,\n \n1.2\n,\n \nk\n)]\n\n\n\nds\n,\n \np_min\n,\n \np_max\n,\n \nparname\n \n=\n \nsystems\n[\n1\n]\n\n\n\noddata\n \n=\n \ninteractive_orbitdiagram\n(\n\n           \nds\n,\n \ni\n,\n \np_index\n,\n \np_min\n,\n \np_max\n;\n\n           \nparname\n \n=\n \nparname\n\n         \n)\n\n\n\n\n\n\n \n \n\n\n\n\n\nVideo Tutorial", 
            "title": "Orbit Diagram"
        }, 
        {
            "location": "/interact/od/#interactive-orbit-diagram", 
            "text": "", 
            "title": "Interactive Orbit Diagram"
        }, 
        {
            "location": "/interact/od/#docstrings", 
            "text": "#  InteractiveChaos.interactive_orbitdiagram     Function .  interactive_orbitdiagram ( ds :: DiscreteDynamicalSystem , \n     i :: Int ,   p_index ,   p_min ,   p_max ; \n     density   =   500 ,   u0   =   get_state ( ds ),   Ttr   =   200 ,   n   =   500 , \n     parname   =   p  )   Open an interactive application for exploring orbit diagrams (ODs) of discrete systems. The functionality works for  any  discrete system.  Once initialized it opens a Makie plot window and an Electron control window.  Interaction  By using the Electron window you are able to update all parameters of the OD interactively (like e.g.  n  or  Ttr ). You have to press  update  after changing these parameters. You can even decide which variable to get the OD for, by choosing one of the variables from the wheel (again, press  update  afterwards).  In the Makie window you can interactively zoom into the OD. Click and drag with the left mouse button to select a region in the OD. This region is then  re-computed  at a higher resolution (i.e. we don't \"just zoom\").  Back in the Electron window, you can press  reset  to bring the OD in the original state (and variable). Pressing  back  will go back through the history of your exploration History is stored when any change happens (besides transparency).  Accessing the data  What is plotted on the application window is a  true  orbit diagram, not a plotting shorthand. This means that all data are obtainable and usable directly. Internally we always scale the orbit diagram to [0,1]\u00b2 (to allow  Float64  precision even though plotting is  Float32 -based). This however means that it is necessary to transform the data in real scale. This is done through the function  scaleod  which accepts the 5 arguments returned from the current function:  od, pmin, pmax, umin, umax = interactive_orbitdiagram(...)\nps, us = scaleod(od, pmin, pmax, umin, umax)  #  InteractiveChaos.scaleod     Function .  scaleod ( od ,   pmin ,   pmax ,   umin ,   umax )   -   ps ,   us   Given the return values of  interactive_orbitdiagram , produce orbit diagram data scaled correctly in data units. Return the data as a vector of parameter values and a vector of corresponding variable values.", 
            "title": "Docstrings"
        }, 
        {
            "location": "/interact/od/#function-video", 
            "text": "using   InteractiveChaos ,   Makie  i   =   1  p_index   =   1  systems   =   [( Systems . logistic (),   3.0 ,   4.0 ,   r ), \n            ( Systems . henon (),   0.8 ,   1.4 ,   a ), \n            ( Systems . standardmap (),   0.6 ,   1.2 ,   k )]  ds ,   p_min ,   p_max ,   parname   =   systems [ 1 ]  oddata   =   interactive_orbitdiagram ( \n            ds ,   i ,   p_index ,   p_min ,   p_max ; \n            parname   =   parname \n          )", 
            "title": "Function Video"
        }, 
        {
            "location": "/interact/od/#video-tutorial", 
            "text": "", 
            "title": "Video Tutorial"
        }, 
        {
            "location": "/interact/psos/", 
            "text": "Interactive Poincar\u00e9 Surface of Section\n\n\n\n\nDocstrings\n\n\n#\n\n\nInteractiveChaos.interactive_poincaresos\n \n \nFunction\n.\n\n\ninteractive_poincaresos\n(\ncds\n,\n \nplane\n,\n \nidxs\n,\n \ncomplete\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nOpen an interactive application for exploring a Poincar\u00e9 surface of section (PSOS) of the continuous dynamical system \ncds\n. Return an observable containing the latest initial state created by \ncomplete\n, as well as its color.\n\n\nThe \nplane\n can only be the \nTuple\n type accepted by \npoincaresos\n, i.e. \n(i, r)\n for the \ni\nth variable crossing the value \nr\n. \nidxs\n gives the two indices of the variables to be displayed, since the PSOS plot is always a 2D scatterplot. I.e. \nidxs = (1, 2)\n will plot the 1st versus 2nd variable of the PSOS. It follows that \nplane[1] \u2209 idxs\n must be true.\n\n\ncomplete\n is a three-argument \nfunction\n that completes the new initial state during interactive use, see below.\n\n\nThe function returns: an observable containing the latest initial \nstate\n and the \nscene\n that is plotted. The scatter plot is \nscene.children[2]\n.\n\n\nKeyword Arguments\n\n\n\n\ndirection, rootkw\n : Same use as in \npoincaresos\n.\n\n\ntfinal\n : A 2-element tuple for the range of values for the total integration time (chosen interactively).\n\n\nTtr\n : A 2-element tuple for the range of values for the transient integration time (chosen interactively).\n\n\nmarkersizes = (-4, -1)\n : A 2-element tuple for the range of the marker sizes (which scale exponentially: the actual size is \n10.0^markersize\n).\n\n\ncolor\n : A \nfunction\n of the system's initial condition, that returns a color to plot the new points with. A random color is chosen by default. Notice that for type stability reasons this function must return an instance of \nRGBf0(red, green, blue)\n.\n\n\nlabels = (\"u\u2081\" , \"u\u2082\")\n : Axis labels.\n\n\ndiffeq...\n : Any extra keyword arguments are passed into \ninit\n of DiffEq.\n\n\n\n\nInteraction\n\n\nThe application is a standard AbstractPlotting scatterplot, which shows the PSOS of the system, initially using the system's \nu0\n. Two sliders control the final evolution time and the size of the marker points.\n\n\nUpon clicking within the bounds of the scatter plot your click is transformed into a new initial condition, which is further evolved and its PSOS is computed and then plotted into the scatter plot.\n\n\nYour click is transformed into a full \nD\n-dimensional initial condition through the function \ncomplete\n. The first two arguments of the function are the positions of the click on the PSOS. The third argument is the value of the variable the PSOS is defined on. To be more exact, this is how the function is called:\n\n\nx\n,\n \ny\n \n=\n \nmouseclick\n;\n \nz\n \n=\n \nplane\n[\n2\n]\n\n\nnewstate\n \n=\n \ncomplete\n(\nx\n,\n \ny\n,\n \nz\n)\n\n\n\n\n\n\nThe \ncomplete\n function can throw an error for ill-conditioned \nx, y, z\n. This will be properly handled instead of breaking the application. This \nnewstate\n is also given to the function \ncolor\n that gets a new color for the new points.\n\n\n\n\nFunction Video\n\n\nusing\n \nInteractiveChaos\n,\n \nMakie\n\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n()\n\n\n\npotential\n(\nx\n,\n \ny\n)\n \n=\n \n0.5\n(\nx\n^\n2\n \n+\n \ny\n^\n2\n)\n \n+\n \n(\nx\n^\n2\n*\ny\n \n-\n \n(\ny\n^\n3\n)\n/\n3\n)\n\n\nenergy\n(\nx\n,\ny\n,\npx\n,\npy\n)\n \n=\n \n0.5\n(\npx\n^\n2\n \n+\n \npy\n^\n2\n)\n \n+\n \npotential\n(\nx\n,\ny\n)\n\n\nconst\n \nE\n \n=\n \nenergy\n(\nget_state\n(\nds\n)\n...\n)\n\n\n\nfunction\n \ncomplete\n(\ny\n,\n \npy\n,\n \nx\n)\n\n    \nV\n \n=\n \npotential\n(\nx\n,\n \ny\n)\n\n    \nKy\n \n=\n \n0.5\n*\n(\npy\n^\n2\n)\n\n    \nKy\n \n+\n \nV\n \n\u2265\n \nE\n \n \nerror\n(\nPoint has more energy!\n)\n\n    \npx\n \n=\n \nsqrt\n(\n2\n(\nE\n \n-\n \nV\n \n-\n \nKy\n))\n\n    \nic\n \n=\n \n[\nx\n,\n \ny\n,\n \npx\n,\n \npy\n]\n\n    \nreturn\n \nic\n\n\nend\n\n\n\nchaotic\n \n=\n \nget_state\n(\nds\n)\n\n\nstable\n \n=\n \n[\n0.\n,\n \n0.1\n,\n \n0.5\n,\n \n0.\n]\n\n\n\nplane\n \n=\n \n(\n1\n,\n \n0.0\n)\n\n\n\npsos\n \n=\n \ninteractive_poincaresos\n(\nds\n,\n \nplane\n,\n \n(\n2\n,\n \n4\n),\n \ncomplete\n;\n \nmarkersizes\n \n=\n \n(\n-\n5\n,\n \n-\n1\n))\n\n\n\n\n\n\n \n \n\n\n\n\n\nVideo Tutorial", 
            "title": "Poincar\u00e9 Surface of Section"
        }, 
        {
            "location": "/interact/psos/#interactive-poincare-surface-of-section", 
            "text": "", 
            "title": "Interactive Poincar\u00e9 Surface of Section"
        }, 
        {
            "location": "/interact/psos/#docstrings", 
            "text": "#  InteractiveChaos.interactive_poincaresos     Function .  interactive_poincaresos ( cds ,   plane ,   idxs ,   complete ;   kwargs ... )   Open an interactive application for exploring a Poincar\u00e9 surface of section (PSOS) of the continuous dynamical system  cds . Return an observable containing the latest initial state created by  complete , as well as its color.  The  plane  can only be the  Tuple  type accepted by  poincaresos , i.e.  (i, r)  for the  i th variable crossing the value  r .  idxs  gives the two indices of the variables to be displayed, since the PSOS plot is always a 2D scatterplot. I.e.  idxs = (1, 2)  will plot the 1st versus 2nd variable of the PSOS. It follows that  plane[1] \u2209 idxs  must be true.  complete  is a three-argument  function  that completes the new initial state during interactive use, see below.  The function returns: an observable containing the latest initial  state  and the  scene  that is plotted. The scatter plot is  scene.children[2] .  Keyword Arguments   direction, rootkw  : Same use as in  poincaresos .  tfinal  : A 2-element tuple for the range of values for the total integration time (chosen interactively).  Ttr  : A 2-element tuple for the range of values for the transient integration time (chosen interactively).  markersizes = (-4, -1)  : A 2-element tuple for the range of the marker sizes (which scale exponentially: the actual size is  10.0^markersize ).  color  : A  function  of the system's initial condition, that returns a color to plot the new points with. A random color is chosen by default. Notice that for type stability reasons this function must return an instance of  RGBf0(red, green, blue) .  labels = (\"u\u2081\" , \"u\u2082\")  : Axis labels.  diffeq...  : Any extra keyword arguments are passed into  init  of DiffEq.   Interaction  The application is a standard AbstractPlotting scatterplot, which shows the PSOS of the system, initially using the system's  u0 . Two sliders control the final evolution time and the size of the marker points.  Upon clicking within the bounds of the scatter plot your click is transformed into a new initial condition, which is further evolved and its PSOS is computed and then plotted into the scatter plot.  Your click is transformed into a full  D -dimensional initial condition through the function  complete . The first two arguments of the function are the positions of the click on the PSOS. The third argument is the value of the variable the PSOS is defined on. To be more exact, this is how the function is called:  x ,   y   =   mouseclick ;   z   =   plane [ 2 ]  newstate   =   complete ( x ,   y ,   z )   The  complete  function can throw an error for ill-conditioned  x, y, z . This will be properly handled instead of breaking the application. This  newstate  is also given to the function  color  that gets a new color for the new points.", 
            "title": "Docstrings"
        }, 
        {
            "location": "/interact/psos/#function-video", 
            "text": "using   InteractiveChaos ,   Makie  ds   =   Systems . henonheiles ()  potential ( x ,   y )   =   0.5 ( x ^ 2   +   y ^ 2 )   +   ( x ^ 2 * y   -   ( y ^ 3 ) / 3 )  energy ( x , y , px , py )   =   0.5 ( px ^ 2   +   py ^ 2 )   +   potential ( x , y )  const   E   =   energy ( get_state ( ds ) ... )  function   complete ( y ,   py ,   x ) \n     V   =   potential ( x ,   y ) \n     Ky   =   0.5 * ( py ^ 2 ) \n     Ky   +   V   \u2265   E     error ( Point has more energy! ) \n     px   =   sqrt ( 2 ( E   -   V   -   Ky )) \n     ic   =   [ x ,   y ,   px ,   py ] \n     return   ic  end  chaotic   =   get_state ( ds )  stable   =   [ 0. ,   0.1 ,   0.5 ,   0. ]  plane   =   ( 1 ,   0.0 )  psos   =   interactive_poincaresos ( ds ,   plane ,   ( 2 ,   4 ),   complete ;   markersizes   =   ( - 5 ,   - 1 ))", 
            "title": "Function Video"
        }, 
        {
            "location": "/interact/psos/#video-tutorial", 
            "text": "", 
            "title": "Video Tutorial"
        }, 
        {
            "location": "/interact/highlight/", 
            "text": "Trajectory Highlighter\n\n\n\n\nDocstrings\n\n\n#\n\n\nInteractiveChaos.trajectory_highlighter\n \n \nFunction\n.\n\n\ntrajectory_highlighter\n(\ndatasets\n,\n \nvals\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nOpen an interactive application for highlighting specific datasets and properties of these datasets. \ndatasets\n is a vector of \nanything\n from \nDynamicalSystems.jl\n that supports \nplot_dataset\n (currently \nDataset\n or \nMatrix\n). Each dataset corresponds to a specific value from \nvals\n (a \nVector{\n:Real}\n). The value of \nvals\n gives each dataset a specific color based on a colormap.\n\n\nThe application is composed of two scenes: the left scene plots the datasets, while the right scene plots the histogram of the \nvals\n. The function returns the two scenes \ndata_scene, hist_scene\n.\n\n\nInteraction\n\n\nClicking on a bin of the histogram plot will \"highlight\" all data whose value belongs in that bin. Here highlighting actually means \"hidding\" (i.e. reducing their alpha value) all other data besides the ones you want to highlight. Clicking on empty space on the histogram plot will reset highlighting.\n\n\nClicking on a plotted series in the left window will highlight this series as well as the histogram bin that contains its value. Clicking on empty space will reset the highlighting.\n\n\nKeyword Arguments\n\n\n\n\nnbins = 10, closed = :left\n : used in producing the histogram.\n\n\n\u03b1 = 0.05\n : the alpha value of the hidden data.\n\n\nh\u03b1 = 0.2\n : the alpha value of the hidden histogram bins.\n\n\ncmap = :viridis\n : the colormap used.\n\n\nhname = \"value\"\n : name for the histogram axis.\n\n\nkwargs...\n : Anything else is propagated to \nplot_dataset\n.\n\n\n\n\n\n\nFunction Video\n\n\nusing\n \nInteractiveChaos\n,\n \nMakie\n\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n()\n\n\n\n# Grid of initial conditions at given energy:\n\n\nenergy\n(\nx\n,\ny\n,\npx\n,\npy\n)\n \n=\n \n0.5\n(\npx\n^\n2\n \n+\n \npy\n^\n2\n)\n \n+\n \npotential\n(\nx\n,\ny\n)\n\n\npotential\n(\nx\n,\n \ny\n)\n \n=\n \n0.5\n(\nx\n^\n2\n \n+\n \ny\n^\n2\n)\n \n+\n \n(\nx\n^\n2\n*\ny\n \n-\n \n(\ny\n^\n3\n)\n/\n3\n)\n\n\nfunction\n \ngenerate_ics\n(\nE\n,\n \nn\n)\n\n    \nys\n \n=\n \nrange\n(\n-\n0.4\n,\n \nstop\n \n=\n \n1.0\n,\n \nlength\n \n=\n \nn\n)\n\n    \npys\n \n=\n \nrange\n(\n-\n0.5\n,\n \nstop\n \n=\n \n0.5\n,\n \nlength\n \n=\n \nn\n)\n\n    \nics\n \n=\n \nVector\n{\nVector\n{\nFloat64\n}}()\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nV\n \n=\n \npotential\n(\n0.0\n,\n \ny\n)\n\n        \nV\n \n\u2265\n \nE\n \n \ncontinue\n\n        \nfor\n \npy\n \nin\n \npys\n\n            \nKy\n \n=\n \n0.5\n*\n(\npy\n^\n2\n)\n\n            \nKy\n \n+\n \nV\n \n\u2265\n \nE\n \n \ncontinue\n\n            \npx\n \n=\n \nsqrt\n(\n2\n(\nE\n \n-\n \nV\n \n-\n \nKy\n))\n\n            \nic\n \n=\n \n[\n0.0\n,\n \ny\n,\n \npx\n,\n \npy\n]\n\n            \npush!\n(\nics\n,\n \n[\n0.0\n,\n \ny\n,\n \npx\n,\n \npy\n])\n\n        \nend\n\n    \nend\n\n    \nreturn\n \nics\n\n\nend\n\n\n\ndensity\n \n=\n \n15\n\n\ntfinal\n \n=\n \n2000.0\n\n\ntgali\n \n=\n \n1000.0\n\n\nE\n \n=\n \n0.13\n\n\nics\n \n=\n \ngenerate_ics\n(\nE\n,\n \ndensity\n)\n\n\n\ntinteg\n \n=\n \ntangent_integrator\n(\nds\n,\n \n4\n)\n\n\n\nregularity\n \n=\n \nFloat64\n[];\n \npsos\n \n=\n \nDataset\n{\n2\n,\n \nFloat64\n}[]\n\n\ntrs\n \n=\n \nDataset\n{\n3\n,\n \nFloat64\n}[]\n\n\n@time\n \nfor\n \nu\n \nin\n \nics\n\n    \n# compute gali (using advanced usage)\n\n    \nreinit!\n(\ntinteg\n,\n \nu\n,\n \northonormal\n(\n4\n,\n4\n))\n\n    \npush!\n(\nregularity\n,\n \ngali\n(\ntinteg\n,\n \ntgali\n,\n \n1\n,\n \n1e-12\n)[\n2\n][\nend\n]\n/\ntgali\n)\n\n    \npush!\n(\npsos\n,\n \npoincaresos\n(\nds\n,\n \n(\n1\n,\n \n0.0\n),\n \n2000.0\n;\n \nu0\n \n=\n \nu\n,\n \nidxs\n \n=\n \n[\n2\n,\n \n4\n]))\n\n    \ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n200.0\n,\n \nu\n)[\n:\n,\n \n[\n1\n,\n \n2\n,\n \n4\n]]\n\n    \npush!\n(\ntrs\n,\n \ntr\n)\n\n\nend\n\n\n\n# %%\n\n\n# 2D version:\n\n\ntrajectory_highlighter\n(\npsos\n,\n \nregularity\n;\n \n\u03b1\n \n=\n \n0.05\n,\n \nhname\n \n=\n \nregularity\n)\n\n\n# 3D version:\n\n\ntrajectory_highlighter\n(\ntrs\n[\n1\n:\n10\n:\nend\n],\n \nregularity\n[\n1\n:\n10\n:\nend\n];\n\n\nnbins\n \n=\n \n10\n,\n \n\u03b1\n \n=\n \n0.05\n,\n \nlinewidth\n \n=\n \n4.0\n,\n \nhname\n \n=\n \nregularity\n)\n\n\n\n\n\n\n2D Version:\n\n\n \n \n\n\n\n3D Version:", 
            "title": "Trajectory Highlighter"
        }, 
        {
            "location": "/interact/highlight/#trajectory-highlighter", 
            "text": "", 
            "title": "Trajectory Highlighter"
        }, 
        {
            "location": "/interact/highlight/#docstrings", 
            "text": "#  InteractiveChaos.trajectory_highlighter     Function .  trajectory_highlighter ( datasets ,   vals ;   kwargs ... )   Open an interactive application for highlighting specific datasets and properties of these datasets.  datasets  is a vector of  anything  from  DynamicalSystems.jl  that supports  plot_dataset  (currently  Dataset  or  Matrix ). Each dataset corresponds to a specific value from  vals  (a  Vector{ :Real} ). The value of  vals  gives each dataset a specific color based on a colormap.  The application is composed of two scenes: the left scene plots the datasets, while the right scene plots the histogram of the  vals . The function returns the two scenes  data_scene, hist_scene .  Interaction  Clicking on a bin of the histogram plot will \"highlight\" all data whose value belongs in that bin. Here highlighting actually means \"hidding\" (i.e. reducing their alpha value) all other data besides the ones you want to highlight. Clicking on empty space on the histogram plot will reset highlighting.  Clicking on a plotted series in the left window will highlight this series as well as the histogram bin that contains its value. Clicking on empty space will reset the highlighting.  Keyword Arguments   nbins = 10, closed = :left  : used in producing the histogram.  \u03b1 = 0.05  : the alpha value of the hidden data.  h\u03b1 = 0.2  : the alpha value of the hidden histogram bins.  cmap = :viridis  : the colormap used.  hname = \"value\"  : name for the histogram axis.  kwargs...  : Anything else is propagated to  plot_dataset .", 
            "title": "Docstrings"
        }, 
        {
            "location": "/interact/highlight/#function-video", 
            "text": "using   InteractiveChaos ,   Makie  ds   =   Systems . henonheiles ()  # Grid of initial conditions at given energy:  energy ( x , y , px , py )   =   0.5 ( px ^ 2   +   py ^ 2 )   +   potential ( x , y )  potential ( x ,   y )   =   0.5 ( x ^ 2   +   y ^ 2 )   +   ( x ^ 2 * y   -   ( y ^ 3 ) / 3 )  function   generate_ics ( E ,   n ) \n     ys   =   range ( - 0.4 ,   stop   =   1.0 ,   length   =   n ) \n     pys   =   range ( - 0.5 ,   stop   =   0.5 ,   length   =   n ) \n     ics   =   Vector { Vector { Float64 }}() \n     for   y   in   ys \n         V   =   potential ( 0.0 ,   y ) \n         V   \u2265   E     continue \n         for   py   in   pys \n             Ky   =   0.5 * ( py ^ 2 ) \n             Ky   +   V   \u2265   E     continue \n             px   =   sqrt ( 2 ( E   -   V   -   Ky )) \n             ic   =   [ 0.0 ,   y ,   px ,   py ] \n             push! ( ics ,   [ 0.0 ,   y ,   px ,   py ]) \n         end \n     end \n     return   ics  end  density   =   15  tfinal   =   2000.0  tgali   =   1000.0  E   =   0.13  ics   =   generate_ics ( E ,   density )  tinteg   =   tangent_integrator ( ds ,   4 )  regularity   =   Float64 [];   psos   =   Dataset { 2 ,   Float64 }[]  trs   =   Dataset { 3 ,   Float64 }[]  @time   for   u   in   ics \n     # compute gali (using advanced usage) \n     reinit! ( tinteg ,   u ,   orthonormal ( 4 , 4 )) \n     push! ( regularity ,   gali ( tinteg ,   tgali ,   1 ,   1e-12 )[ 2 ][ end ] / tgali ) \n     push! ( psos ,   poincaresos ( ds ,   ( 1 ,   0.0 ),   2000.0 ;   u0   =   u ,   idxs   =   [ 2 ,   4 ])) \n     tr   =   trajectory ( ds ,   200.0 ,   u )[ : ,   [ 1 ,   2 ,   4 ]] \n     push! ( trs ,   tr )  end  # %%  # 2D version:  trajectory_highlighter ( psos ,   regularity ;   \u03b1   =   0.05 ,   hname   =   regularity )  # 3D version:  trajectory_highlighter ( trs [ 1 : 10 : end ],   regularity [ 1 : 10 : end ];  nbins   =   10 ,   \u03b1   =   0.05 ,   linewidth   =   4.0 ,   hname   =   regularity )   2D Version:       3D Version:", 
            "title": "Function Video"
        }, 
        {
            "location": "/advanced/", 
            "text": "Advanced documentation\n\n\nThis section overviews the various integrators available from \nDynamicalSystemsBase\n, as well as gives some insight into the internals, so that other developers that want to use this library can build upon it.\n\n\n\n\nIntegrators\n\n\n#\n\n\nDynamicalSystemsBase.integrator\n \n \nFunction\n.\n\n\nintegrator\n(\nds\n::\nDynamicalSystem\n \n[,\n \nu0\n];\n \ndiffeq\n...\n)\n \n-\n \ninteg\n\n\n\n\n\n\nReturn an integrator object that can be used to evolve a system interactively using \nstep!(integ [, \u0394t])\n. Optionally specify an initial state \nu0\n.\n\n\nThe state of this integrator is a vector.\n\n\n\n\ndiffeq...\n are keyword arguments propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples. Only valid for continuous systems.\n\n\n\n\n#\n\n\nDynamicalSystemsBase.parallel_integrator\n \n \nFunction\n.\n\n\nparallel_integrator\n(\nds\n::\nDynamicalSystem\n,\n \nstates\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nReturn an integrator object that can be used to evolve many \nstates\n of a system in parallel at the \nexact same times\n, using \nstep!(integ [, \u0394t])\n.\n\n\nstates\n are expected as vectors of vectors.\n\n\nKeyword Arguments\n\n\n\n\ndiffeq...\n : Keyword arguments propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples. Only valid for continuous systems. These keywords can also include \ncallback\n for \nevent handling\n.\n\n\n\n\nIt is \nheavily\n advised to use the functions \nget_state\n and \nset_state!\n to manipulate the integrator. Provide \ni\n as a second argument to change the \ni\n-th state.\n\n\n#\n\n\nDynamicalSystemsBase.tangent_integrator\n \n \nFunction\n.\n\n\ntangent_integrator\n(\nds\n::\nDynamicalSystem\n,\n \nQ0\n \n|\n \nk\n::\nInt\n;\n \nkwargs\n...\n)\n\n\n\n\n\n\nReturn an integrator object that evolves in parallel both the system as well as deviation vectors living on the tangent space.\n\n\nQ0\n is a \nmatrix\n whose columns are initial values for deviation vectors. If instead of a matrix \nQ0\n an integer \nk\n is given, then \nk\n random orthonormal vectors are choosen as initial conditions.\n\n\nKeyword Arguments\n\n\n\n\nu0\n : Optional different initial state.\n\n\ndiffeq...\n : Keyword arguments propagated into \ninit\n of DifferentialEquations.jl. See \ntrajectory\n for examples. Only valid for continuous systems. These keywords can also include \ncallback\n for \nevent handling\n.\n\n\n\n\nIt is \nheavily\n advised to use the functions \nget_state\n, \nget_deviations\n, \nset_state!\n, \nset_deviations!\n to manipulate the integrator.\n\n\nDescription\n\n\nIf \nJ\nJ\n is the jacobian of the system then the \ntangent dynamics\n are the equations that evolve in parallel the system as well as a deviation vector (or matrix) \nw\nw\n:\n\n\n\n\n\n\\begin{aligned}\n\\dot{u} \n= f(u, p, t) \\\\\n\\dot{w} \n= J(u, p, t) \\times w\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{u} &= f(u, p, t) \\\\\n\\dot{w} &= J(u, p, t) \\times w\n\\end{aligned}\n\n\n\n\n\nwith \nf\nf\n being the equations of motion and \nu\nu\n the system state. Similar equations hold for the discrete case.\n\n\n\n\nNotice that the state type \nintegrator.u\n of each integrator is quite different and \ndoes change\n between the possible versions of a \nDynamicalSystem\n!\n\n\n\n\nIntegrator state functions\n\n\nThere are four functions associated with the integrators that we export:\n\n\n#\n\n\nDynamicalSystemsBase.get_state\n \n \nFunction\n.\n\n\nget_state\n(\nds\n::\nDynamicalSystem\n)\n\n\n\n\n\n\nReturn the state of \nds\n.\n\n\nget_state(integ [, i::Int = 1])\n\n\n\n\n\nReturn the state of the integrator, in the sense of the state of the dynamical system.\n\n\nIf the integrator is a \nparallel_integrator\n, passing \ni\n will return the \ni\n-th state. The function also correctly returns the true state of the system for tangent integrators.\n\n\n#\n\n\nDynamicalSystemsBase.set_state!\n \n \nFunction\n.\n\n\nset_state!\n(\ninteg\n,\n \nu\n \n[,\n \ni\n::\nInt\n \n=\n \n1\n])\n\n\n\n\n\n\nSet the state of the integrator to \nu\n, in the sense of the state of the dynamical system. Works for any integrator (normal, tangent, parallel).\n\n\nFor parallel integrator, you can choose which state to set (using \ni\n).\n\n\nAutomatically does \nu_modified!(integ, true)\n.\n\n\n#\n\n\nDynamicalSystemsBase.get_deviations\n \n \nFunction\n.\n\n\nget_deviations\n(\ntang_integ\n)\n\n\n\n\n\n\nReturn the deviation vectors of the \ntangent_integrator\n in a form of a matrix with columns the vectors.\n\n\n#\n\n\nDynamicalSystemsBase.set_deviations!\n \n \nFunction\n.\n\n\nset_deviations!\n(\ntang_integ\n,\n \nQ\n)\n\n\n\n\n\n\nSet the deviation vectors of the \ntangent_integrator\n to \nQ\n, which must be a matrix with each column being a deviation vector.\n\n\nAutomatically does \nu_modified!(tang_integ, true)\n.\n\n\n\n\nNote\n\n\nThese functions work with \nany\n possible integrator and it is best to use the to change states robustly!\n\n\n\n\n\n\nRe-initializing an integrator\n\n\nIt is more efficient to re-initialize an integrator using \nreinit!\n than to create a new one. This can be very helpful when looping over initial conditions and/or parameter values.\n\n\nAll high-level functions from \nChaosTools\n have a set-up part that creates an integrator, and a low-level part that does the computation. The low level part is your friend! Use it! See the \nUsing \ngali\n page for an example as well as the section below.\n\n\nThe \nreinit!\n call signature is the same for continuous and discrete systems. In the following, \nstate\n is supposed to be a \nD\n dimensional vector (state of the dynamical system).\n\n\n\n\nreinit!(integ, state)\n : to be used with standard \nintegrator\n.\n\n\nreinit!(integ, Vector_of_states)\n : to be used with the \nparallel_integrator\n.\n\n\nreinit!(integ, state, Q0::AbstractMatrix)\n : to be used with the \ntangent_integrator\n. This three argument version of \nreinit!\n is exported from \nDynamicalSystemsBase\n.\n\n\n\n\n\n\nRe-init of continuous tangent integrator\n\n\nHere we compute the \nlyapunovs\n for many different initial conditions.\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n\n\ntinteg\n \n=\n \ntangent_integrator\n(\nds\n,\n \n2\n)\n\n\nics\n \n=\n \n[\nrand\n(\n3\n)\n \nfor\n \ni\n \nin\n \n1\n:\n100\n]\n\n\nfor\n \nic\n \nin\n \nics\n\n  \nreinit!\n(\ntinteg\n,\n \nic\n,\n \northonormal\n(\n3\n,\n \n2\n))\n\n  \n\u03bb\n \n=\n \nlyapunovs\n(\ntinteg\n,\n \n1000\n,\n \n0.1\n,\n \n10.0\n)\n\n  \n# reminder: lyapunovs(tinteg, N, dt::Real, Ttr::Real = 0.0)\n\n\nend\n\n\n\n\n\n\n\n\nRe-init of discrete parallel integrator\n\n\nHere we compute the \nlyapunov\n for many different parameters.\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\nu0\n \n=\n \nrand\n(\nSVector\n{\n2\n})\n\n\nps\n \n=\n \n1.2\n:\n0.01\n:\n1.4\n\n\npinteg\n \n=\n \nparallel_integrator\n(\nds\n,\n \n[\nu0\n,\n \nu0\n \n+\n \n1e-9\nrand\n(\nSVector\n{\n2\n})])\n\n\nfor\n \np\n \nin\n \nps\n\n  \nset_parameter!\n(\nds\n,\n \n1\n,\n \np\n)\n\n  \nreinit!\n(\npinteg\n,\n \n[\nu0\n,\n \nu0\n \n+\n \n1e-9\nrand\n(\nSVector\n{\n2\n})])\n\n  \n\u03bb\n \n=\n \nlyapunov\n(\npinteg\n,\n \n1000\n,\n \n10\n,\n \n1\n,\n \n1e-9\n,\n \n1e-6\n,\n \n1e-12\n)\n\n  \n# reminder: lyapunov(pinteg, T, Ttr, dt, d0, ut, lt)\n\n\nend\n\n\n\n\n\n\n\n\nUsing callbacks with integrators\n\n\nFor the case of continuous systems you can add callbacks from the event handling of \nDifferentialEquations.jl\n. This is done simply as a keyword argument to the initializers.\n\n\nIn this example we use a simple \nSavingCallback\n to save the distance between the two states of a \nparallel_integrator\n.\n\n\nusing\n \nDynamicalSystems\n,\n \nDiffEqCallbacks\n\n\nusing\n \nLinearAlgebra\n:\n \nnorm\n\n\n\nkwargs\n \n=\n \n(\nabstol\n=\n1e-14\n,\n \nreltol\n=\n1e-14\n,\n \nmaxiters\n=\n1e9\n)\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n\n\nd0\n \n=\n \n1e-9\n\n\nT\n \n=\n \n100.0\n\n\n\nsave_func\n(\nu\n,\n \nt\n,\n \nintegrator\n)\n \n=\n \nnorm\n(\nu\n[\n1\n]\n \n-\n \nu\n[\n2\n])\n\n\nsaved_values\n \n=\n \nSavedValues\n(\neltype\n(\nds\n.\nt0\n),\n \neltype\n(\nget_state\n(\nds\n)))\n\n\ncb\n \n=\n \nSavingCallback\n(\nsave_func\n,\n \nsaved_values\n)\n\n\n\nu0\n \n=\n \nget_state\n(\nds\n)\n\n\npinteg\n \n=\n \nparallel_integrator\n(\nds\n,\n \n[\nu0\n,\n \nu0\n \n+\n \nrand\n(\nSVector\n{\n3\n})\n*\nd0\n*\u221a\n3\n];\n\n\nkwargs\n...\n,\n \ncallback\n \n=\n \ncb\n)\n\n\nstep!\n(\npinteg\n,\n \nT\n)\n\n\nt\n \n=\n \nsaved_values\n.\nt\n\n\nn\n \n=\n \nsaved_values\n.\nsaveval\n\n\n\n\n\n\n0-element Array{Float64,1}\n\n\n\n\n\nAs expected you can see that the recorded distance between two states is increasing.\n\n\n\n\nDynamicalSystem\n implementation\n\n\nabstract\n \ntype\n \nDynamicalSystem\n{\n\n        \nIIP\n,\n     \n# is in place , for dispatch purposes and clarity\n\n        \nS\n,\n       \n# state type\n\n        \nD\n,\n       \n# dimension\n\n        \nF\n,\n       \n# equations of motion\n\n        \nP\n,\n       \n# parameters\n\n        \nJAC\n,\n     \n# jacobian\n\n        \nJM\n,\n      \n# jacobian matrix\n\n        \nIAD\n}\n     \n# is auto-differentiated\n\n    \n# one-liner: {IIP, S, D, F, P, JAC, JM, IAD}\n\n    \n# Subtypes of DynamicalSystem have fields:\n\n    \n# 1. f\n\n    \n# 2. u0\n\n    \n# 3. p\n\n    \n# 4. t0\n\n    \n# 5. jacobian (function)\n\n    \n# 6. J (matrix)\n\n\nend\n\n\n\n\n\n\nThe \nDynamicalSystem\n stores only the absolutely necessary information. Every other functionality of \nDynamicalSystems.jl\n initializes an integrator.\n\n\nThe final type-parameter \nIAD\n is useful when creating the \ntangent_integrator\n, so that the vector field is not computed twice!", 
            "title": "Advanced Documentation"
        }, 
        {
            "location": "/advanced/#advanced-documentation", 
            "text": "This section overviews the various integrators available from  DynamicalSystemsBase , as well as gives some insight into the internals, so that other developers that want to use this library can build upon it.", 
            "title": "Advanced documentation"
        }, 
        {
            "location": "/advanced/#integrators", 
            "text": "#  DynamicalSystemsBase.integrator     Function .  integrator ( ds :: DynamicalSystem   [,   u0 ];   diffeq ... )   -   integ   Return an integrator object that can be used to evolve a system interactively using  step!(integ [, \u0394t]) . Optionally specify an initial state  u0 .  The state of this integrator is a vector.   diffeq...  are keyword arguments propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples. Only valid for continuous systems.   #  DynamicalSystemsBase.parallel_integrator     Function .  parallel_integrator ( ds :: DynamicalSystem ,   states ;   kwargs ... )   Return an integrator object that can be used to evolve many  states  of a system in parallel at the  exact same times , using  step!(integ [, \u0394t]) .  states  are expected as vectors of vectors.  Keyword Arguments   diffeq...  : Keyword arguments propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples. Only valid for continuous systems. These keywords can also include  callback  for  event handling .   It is  heavily  advised to use the functions  get_state  and  set_state!  to manipulate the integrator. Provide  i  as a second argument to change the  i -th state.  #  DynamicalSystemsBase.tangent_integrator     Function .  tangent_integrator ( ds :: DynamicalSystem ,   Q0   |   k :: Int ;   kwargs ... )   Return an integrator object that evolves in parallel both the system as well as deviation vectors living on the tangent space.  Q0  is a  matrix  whose columns are initial values for deviation vectors. If instead of a matrix  Q0  an integer  k  is given, then  k  random orthonormal vectors are choosen as initial conditions.  Keyword Arguments   u0  : Optional different initial state.  diffeq...  : Keyword arguments propagated into  init  of DifferentialEquations.jl. See  trajectory  for examples. Only valid for continuous systems. These keywords can also include  callback  for  event handling .   It is  heavily  advised to use the functions  get_state ,  get_deviations ,  set_state! ,  set_deviations!  to manipulate the integrator.  Description  If  J J  is the jacobian of the system then the  tangent dynamics  are the equations that evolve in parallel the system as well as a deviation vector (or matrix)  w w :   \n\\begin{aligned}\n\\dot{u}  = f(u, p, t) \\\\\n\\dot{w}  = J(u, p, t) \\times w\n\\end{aligned}  \n\\begin{aligned}\n\\dot{u} &= f(u, p, t) \\\\\n\\dot{w} &= J(u, p, t) \\times w\n\\end{aligned}   with  f f  being the equations of motion and  u u  the system state. Similar equations hold for the discrete case.   Notice that the state type  integrator.u  of each integrator is quite different and  does change  between the possible versions of a  DynamicalSystem !", 
            "title": "Integrators"
        }, 
        {
            "location": "/advanced/#integrator-state-functions", 
            "text": "There are four functions associated with the integrators that we export:  #  DynamicalSystemsBase.get_state     Function .  get_state ( ds :: DynamicalSystem )   Return the state of  ds .  get_state(integ [, i::Int = 1])  Return the state of the integrator, in the sense of the state of the dynamical system.  If the integrator is a  parallel_integrator , passing  i  will return the  i -th state. The function also correctly returns the true state of the system for tangent integrators.  #  DynamicalSystemsBase.set_state!     Function .  set_state! ( integ ,   u   [,   i :: Int   =   1 ])   Set the state of the integrator to  u , in the sense of the state of the dynamical system. Works for any integrator (normal, tangent, parallel).  For parallel integrator, you can choose which state to set (using  i ).  Automatically does  u_modified!(integ, true) .  #  DynamicalSystemsBase.get_deviations     Function .  get_deviations ( tang_integ )   Return the deviation vectors of the  tangent_integrator  in a form of a matrix with columns the vectors.  #  DynamicalSystemsBase.set_deviations!     Function .  set_deviations! ( tang_integ ,   Q )   Set the deviation vectors of the  tangent_integrator  to  Q , which must be a matrix with each column being a deviation vector.  Automatically does  u_modified!(tang_integ, true) .   Note  These functions work with  any  possible integrator and it is best to use the to change states robustly!", 
            "title": "Integrator state functions"
        }, 
        {
            "location": "/advanced/#re-initializing-an-integrator", 
            "text": "It is more efficient to re-initialize an integrator using  reinit!  than to create a new one. This can be very helpful when looping over initial conditions and/or parameter values.  All high-level functions from  ChaosTools  have a set-up part that creates an integrator, and a low-level part that does the computation. The low level part is your friend! Use it! See the  Using  gali  page for an example as well as the section below.  The  reinit!  call signature is the same for continuous and discrete systems. In the following,  state  is supposed to be a  D  dimensional vector (state of the dynamical system).   reinit!(integ, state)  : to be used with standard  integrator .  reinit!(integ, Vector_of_states)  : to be used with the  parallel_integrator .  reinit!(integ, state, Q0::AbstractMatrix)  : to be used with the  tangent_integrator . This three argument version of  reinit!  is exported from  DynamicalSystemsBase .", 
            "title": "Re-initializing an integrator"
        }, 
        {
            "location": "/advanced/#re-init-of-continuous-tangent-integrator", 
            "text": "Here we compute the  lyapunovs  for many different initial conditions.  ds   =   Systems . lorenz ()  tinteg   =   tangent_integrator ( ds ,   2 )  ics   =   [ rand ( 3 )   for   i   in   1 : 100 ]  for   ic   in   ics \n   reinit! ( tinteg ,   ic ,   orthonormal ( 3 ,   2 )) \n   \u03bb   =   lyapunovs ( tinteg ,   1000 ,   0.1 ,   10.0 ) \n   # reminder: lyapunovs(tinteg, N, dt::Real, Ttr::Real = 0.0)  end", 
            "title": "Re-init of continuous tangent integrator"
        }, 
        {
            "location": "/advanced/#re-init-of-discrete-parallel-integrator", 
            "text": "Here we compute the  lyapunov  for many different parameters.  ds   =   Systems . henon ()  u0   =   rand ( SVector { 2 })  ps   =   1.2 : 0.01 : 1.4  pinteg   =   parallel_integrator ( ds ,   [ u0 ,   u0   +   1e-9 rand ( SVector { 2 })])  for   p   in   ps \n   set_parameter! ( ds ,   1 ,   p ) \n   reinit! ( pinteg ,   [ u0 ,   u0   +   1e-9 rand ( SVector { 2 })]) \n   \u03bb   =   lyapunov ( pinteg ,   1000 ,   10 ,   1 ,   1e-9 ,   1e-6 ,   1e-12 ) \n   # reminder: lyapunov(pinteg, T, Ttr, dt, d0, ut, lt)  end", 
            "title": "Re-init of discrete parallel integrator"
        }, 
        {
            "location": "/advanced/#using-callbacks-with-integrators", 
            "text": "For the case of continuous systems you can add callbacks from the event handling of  DifferentialEquations.jl . This is done simply as a keyword argument to the initializers.  In this example we use a simple  SavingCallback  to save the distance between the two states of a  parallel_integrator .  using   DynamicalSystems ,   DiffEqCallbacks  using   LinearAlgebra :   norm  kwargs   =   ( abstol = 1e-14 ,   reltol = 1e-14 ,   maxiters = 1e9 )  ds   =   Systems . lorenz ()  d0   =   1e-9  T   =   100.0  save_func ( u ,   t ,   integrator )   =   norm ( u [ 1 ]   -   u [ 2 ])  saved_values   =   SavedValues ( eltype ( ds . t0 ),   eltype ( get_state ( ds )))  cb   =   SavingCallback ( save_func ,   saved_values )  u0   =   get_state ( ds )  pinteg   =   parallel_integrator ( ds ,   [ u0 ,   u0   +   rand ( SVector { 3 }) * d0 *\u221a 3 ];  kwargs ... ,   callback   =   cb )  step! ( pinteg ,   T )  t   =   saved_values . t  n   =   saved_values . saveval   0-element Array{Float64,1}  As expected you can see that the recorded distance between two states is increasing.", 
            "title": "Using callbacks with integrators"
        }, 
        {
            "location": "/advanced/#dynamicalsystem-implementation", 
            "text": "abstract   type   DynamicalSystem { \n         IIP ,       # is in place , for dispatch purposes and clarity \n         S ,         # state type \n         D ,         # dimension \n         F ,         # equations of motion \n         P ,         # parameters \n         JAC ,       # jacobian \n         JM ,        # jacobian matrix \n         IAD }       # is auto-differentiated \n     # one-liner: {IIP, S, D, F, P, JAC, JM, IAD} \n     # Subtypes of DynamicalSystem have fields: \n     # 1. f \n     # 2. u0 \n     # 3. p \n     # 4. t0 \n     # 5. jacobian (function) \n     # 6. J (matrix)  end   The  DynamicalSystem  stores only the absolutely necessary information. Every other functionality of  DynamicalSystems.jl  initializes an integrator.  The final type-parameter  IAD  is useful when creating the  tangent_integrator , so that the vector field is not computed twice!", 
            "title": "DynamicalSystem implementation"
        }, 
        {
            "location": "/contributors_guide/", 
            "text": "Contributor Guide\n\n\nThe ultimate goal for \nDynamicalSystems.jl\n is to be a useful \nlibrary\n for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.\n\n\nFor this to be achieved, many of us should try to work together to improve the library!\n\n\nIf you want to help the cause, there are many ways to contribute to the \nDynamicalSystems.jl\n library:\n\n\n\n\nJust \nuse it\n. If you encountered unexpected behavior simply report it either on our \ngitter chatroom\n or using the \nDynamicalSystems.jl Issues\n page.\n\n\nSuggest methods that you think should be included in our library. This should be done by opening a new issue that describes the method, gives references to papers using the method and also justifies why the method should be included.\n\n\nContribute code by solving issues. The easiest issues to tackle are the ones with label \n\"good first issue\"\n.\n\n\nContribute code by implementing new methods! That is the most \nawesome\n way to contribute! The individual packages that compose \nDynamicalSystems.jl\n have plenty of issues with the tag \n\"wanted feature\"\n, which can get you started on a big contribution!\n\n\nContribute code by defining a new pre-defined dynamical system that you found useful.\n\n\n\n\n\n\nContributing Code\n\n\nWhen contributing code, you should keep these things in mind:\n\n\n\n\nIn general, the speed of the implementation is important, but not as important as the \nreliability of the implementation\n. One of cornerstones of all of \nDynamicalSystems.jl\n is to have clear and readable source code. Fortunately, Julia allows you to have perfectly readable code but also super fast ;)\n\n\nFor new methods and systems please follow the convention of the documentation strings (do e.g. \n?lyapunov\n to see how they are structured).\n\n\nHave enough comments in your code so that somebody that knows the method, can also understand the code immediately.\n\n\nAlways have a reference to the original work that introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in a similar manner.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributor-guide", 
            "text": "The ultimate goal for  DynamicalSystems.jl  is to be a useful  library  for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.  For this to be achieved, many of us should try to work together to improve the library!  If you want to help the cause, there are many ways to contribute to the  DynamicalSystems.jl  library:   Just  use it . If you encountered unexpected behavior simply report it either on our  gitter chatroom  or using the  DynamicalSystems.jl Issues  page.  Suggest methods that you think should be included in our library. This should be done by opening a new issue that describes the method, gives references to papers using the method and also justifies why the method should be included.  Contribute code by solving issues. The easiest issues to tackle are the ones with label  \"good first issue\" .  Contribute code by implementing new methods! That is the most  awesome  way to contribute! The individual packages that compose  DynamicalSystems.jl  have plenty of issues with the tag  \"wanted feature\" , which can get you started on a big contribution!  Contribute code by defining a new pre-defined dynamical system that you found useful.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributing-code", 
            "text": "When contributing code, you should keep these things in mind:   In general, the speed of the implementation is important, but not as important as the  reliability of the implementation . One of cornerstones of all of  DynamicalSystems.jl  is to have clear and readable source code. Fortunately, Julia allows you to have perfectly readable code but also super fast ;)  For new methods and systems please follow the convention of the documentation strings (do e.g.  ?lyapunov  to see how they are structured).  Have enough comments in your code so that somebody that knows the method, can also understand the code immediately.  Always have a reference to the original work that introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in a similar manner.", 
            "title": "Contributing Code"
        }, 
        {
            "location": "/news/", 
            "text": "News\n\n\n\n\nNew default solver in v1.2; \nOrdinaryDiffEq\n dependency dropped!\n\n\nIn the newest version of \nDynamicalSystems.jl\n, which includes \nDynamicalSystemsBase v1.2\n, the default solver for all continuous systems has been changed to \nSimpleATsit5\n from the package \nSimpleDiffEq.jl\n. The previous default solver was \nVern9\n from \nOrdinaryDiffEq\n This has reduced the \"first run time\" massively for functions that use a \nContinuousDynamicalSystem\n!\n\n\nIn addition the \nOrdinaryDiffEq\n dependency was dropped. This is a big benefit for precompilation times! This does \nnot\n mean that you can't use all the solvers from \nOrdinaryDiffEq\n! You can still use any solver you want, provided that you do \nusing OrdinaryDiffEq\n to access the solvers!\n\n\n\n\nNumeric values will change slightly\n\n\nAlthough there was no API change the default solver did change. This means that if you were using the default solver for some code, the numeric values you will now obtain will slightly change as a result. This does not mean that any functionality broke, but be aware that if you were depending on the \nexact value\n of e.g. \nlyapunovs\n, you will now have a different value instead.\n\n\nProvided that you have already been using long enough integration times, the convergence of your results has not been affected though.\n\n\n\n\n\n\nRecurrenceAnalysis\n joins \nDynamicalSystems.jl\n in v1.1!\n\n\nThe excellent Julia package \nRecurrenceAnalysis\n (authored by Helios de Rosario, \n@heliosdrm\n) is now part of \nDynamicalSystems.jl\n and reexported by it. Besides adding all the amazing functionality of \nRecurrenceAnalysis\n to \nDynamicalSystems.jl\n, other benefits also sprung up:\n\n\n\n\nNew package \nDelayEmbeddings\n that defines \nDataset\n and provides all delay embedding functionality.\n\n\nMethod to estimate delay embedding dimension (now in \nDelayEmbeddings\n) was enriched with two more algorithms!\n\n\nMutual information (currently wip) is also being improved.\n\n\nRecurrenceAnalysis\n now also has a documentation page, soon to be updated with more real world examples.\n\n\n\n\n\n\nDynamicalSystems v1.0 - Julia 1.0 release\n\n\nAll support for any Julia version before 0.7 is dropped.\n\n\nPlease be sure to check out the \nCHANGELOG.md\n files of the individual repositories. There all changes are listed in detail. Here we note only the most important ones.\n\n\n\n\nTimeseriesPrediction\n is \nnot\n installed with \nDynamicalSystems\n for version 1.0, because it is undergoing major changes. It is not even ready for Julia 1.0 actually.\n\n\nDynamicalSystem\n has been totally reworked for better clarity: it does not store a \"problem\" anymore, only the absolutely necessary ingredients to create one. The API did not change though!\n\n\nReconstruction\n has been renamed to \nreconstruct\n, and now always returns a \nDataset\n. In addition, now the parameter \nD\n (now renamed to \n\u03b3\n) stands for the number of temporal neighbors. \nThis is a breaking change!\n. The change allows more intuition across the different versions of \nreconstruct\n.\n\n\nThe various offered integrators became more robust, and now allow passing callbacks etc. for the DifferentialEquations.jl event handling.\n\n\nBrand new algorithm for computing Poincare surfaces of section. It is not also more clear and understandable from the old one, but also much faster as well!!!\n\n\nMutual information computation method. Also new method for optimal delay time using the Mutual information!\n\n\n\n\nAs always: be sure to read the documentation string before using a function: the docstrings are always updated and will show latest changes even if we (mistakenly) missed them when writing the documentation pages!\n\n\n\n\nTimeseries Prediction\n\n\nA new module has been added to \nDynamicalSystems.jl\n: \nTimeseriesPrediction\n (version \nv0.2.0\n), which tries to predict timeseries using methods from nonlinear dynamics and chaos!\n\n\nThe first available method is \nlocalmodel_tsp\n that uses local averages! See the new documentation page for more!\n\n\n\n\nCao's Method\n\n\nWith \nChaosTools v0.8.0\n, the well-known method for estimating dimension for a \nReconstruction\n is now implemented and exported! See \nestimate_dimension\n.\n\n\n\n\nMulti-time, Multi-Diensional Reconstructions\n\n\nWith the latest version of \nDynamicalSystemsBase v0.8.0\n we now have the possibility for both multi-time and multi-dimensional delay reconstructions! The new documentation string for \nReconstruction\n has all the relevant information.\n\n\n\n\nRelease v0.11.0\n\n\nWith new version v0.11.0 for \nDynamicalSytems.jl\n (\nDynamicalSystemsBase\n and \nChaosTools\n at version 0.6) we have some major improvements of the library all around. Here I list the syntactic changes, the internal changes, the prospect for other developers and the gains we have from making all these changes!\n\n\n\n\nSyntax changes\n\n\nThere are no syntax changes (or \nany\n changes) to functions that handle numerical data (\nDataset\n and the likes).\n\n\nThe syntax for both discrete and continuous systems has changed to\n\n\nDiscreteDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n::\nInt\n \n=\n \n0\n)\n\n\nContinuousDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n \n=\n \n0.0\n)\n\n\n\n\n\n\nThe equations of motion function \neom\n can be one of two forms:\n\n\n\n\niip\n : The \neom\n \nmust\n be in the form \neom(x, p, t) -\n SVector\n which means that given a state \nx::SVector\n and some parameter container \np\n it returns an \nSVector\n containing the next state.\n\n\noop\n : The \neom\n \nmust\n be in the form \neom!(xnew, x, p, t)\n which means that given a state \nx::Vector\n and some parameter container \np\n, it writes in-place the new state in \nxnew\n.\n\n\n\n\nThere is no constructor that takes an \nODEProblem\n anymore.\n\n\nIn addition, \nDynamicalSystem\n and subtypes are now \nimmutable\n. One cannot set their state in place, or anything like that. Instead, all high-level functions allow you to choose an initial state.\n\n\nIn summary:\n\n\n\n\nAll discrete systems are now simply \nDiscreteDynamicalSystem\n.\n\n\nContinuous systems have been renamed to \nContinuousDynamicalSystem\n.\n\n\nDon't use \nset_state!\n, etc. Instead use the keyword argument \nu0\n of methods like e.g. \ngali\n.\n\n\n\n\nThere are some syntax changes to high-level functions from \nChaosTools\n as well. For example, \nlyapunovs\n now has call signature\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n,\n \nk\n::\nInt\n \n|\n \nQ0\n;\n \nkwargs\n...\n)\n \n-\n \n\u03bbs\n\n\n\n\n\n\nIt is advised to first look the documentation string of a function you want to use before usage!\n\n\n\n\nInternal changes \n Prospects\n\n\nThe internals of \nDynamicalSystemsBase\n have been completely re-worked from the ground up. Here are the highlights:\n\n\n\n\nAll \nDynamicalSystem\n objects are immutable, and contain a problem \nprob\n the jacobian function and an initialized Jacobian matrix.\n\n\nAll functions that use a \nDynamicalSystem\n have changed behavior. The way the functions work now is that when given a \nDynamicalSystem\n the create an appropriate \nintegrator\n from it. Then we use \nstep!(integrator, dt)\n and use the integrator state to perform calculations.\n\n\n\n\nEight possible system types are now available:\n\n\n\n\nContinuous or Discrete.\n\n\nIn-place or out-of-place (large versus small systems).\n\n\nAuto-differentiated or not (for the Jacobian function).\n\n\nThis is only possible due to the strictness of defining the \neom\n function.\n\n\nRobust multiple dispatch on all 8 types (again, only possible due to the strictness of the \neom\n function).\n\n\n\n\n\n\n\n\nThree low-lever integrator constructing functions are available, that only need a \nDynamicalSystem\n and (optionally) an initial state:\n\n\n\n\nintegrator\n for \"normal\" integration of a system.\n\n\ntangent_integrator\n for integration of a state and deviation vectors (that live on the tangent space).\n\n\nparallel_integrator\n for integrating in \"parallel\" a number of states. Notice that the states are integrated at \nexact\n same times, even for continuous systems.\n\n\n\n\n\n\n\n\nAll three of the above integrators work perfectly fine for all eight combinations of systems and also have performant implementations.\n\n\n\n\nSimple internal implementation for Discrete system integrator that is tailored to the needs of \nDynamicalSystems.jl\n. It follows the high-level syntax of DifferentialEquations.jl: there is an implementation of a minimal discrete problem, as well as a minimal discrete integrator that steps via \nstep!(integrator, dt)\n.\n\n\nDynamicalSystem\n is type-parameterized in such a way that allows for easy multiple dispatch and clear source code.\n\n\n\n\nBecause the resulting behavior is very robust and efficient, it allows \nDynamicalSystemsBase\n to also be a library used by other developers that want to develop techniques/functions for dynamical systems.\n\n\nIn addition, there is absolutely no drawback in having a \nContinuousDynamicalSystem\n instead of an \nODEProblem\n, since the field \n.prob\n of the system is exactly this \nODEProblem\n, and can be passed directly to things like \nsolve\n from DifferentialEquations.jl.\n\n\n\n\nGains\n\n\n\n\nOut-of-place continuous systems are now possible!\n\n\nAuto-differentiated methods compute the vector field only once.\n\n\nSafe, robust implementations due to the immutability of the central structure \nDynamicalSystem\n.\n\n\nNo problems with parallelization/threading/etc.\n\n\nEven clearer source code! Most \nChaosTools\n functions are now composed of a set-up part and an implementation part, both of which are clear to read and understand.     * Also clarity on discrete systems, since they are all fused into one structure.     * Low-level functions can be used easily by users that want performance for loops.\n\n\nLyapunov exponent calculating functions now have full flexibility in all aspects (initial deviation vectors/transient times/pretty much anything).\n\n\n\n\nBig performance gains all around, and especially in methods that propagate tangent space. For example, the function that calculates the Lyapunov spectrum of the towel map, needs:\n\n\njulia\nusing DynamicalSystems\nds = Systems.towel()\nl = lyapunovs(ds, 1000)\n\n\nFloat64[3]\n0.42883526635723973\n0.36501911701374234\n-3.2835393321781092\n\n\njulia\nusing BenchmarkTools\n@btime lyapunovs($ds, 1000);\n228.265 \u03bcs (176 allocations: 11.28 KiB)", 
            "title": "News"
        }, 
        {
            "location": "/news/#news", 
            "text": "", 
            "title": "News"
        }, 
        {
            "location": "/news/#new-default-solver-in-v12-ordinarydiffeq-dependency-dropped", 
            "text": "In the newest version of  DynamicalSystems.jl , which includes  DynamicalSystemsBase v1.2 , the default solver for all continuous systems has been changed to  SimpleATsit5  from the package  SimpleDiffEq.jl . The previous default solver was  Vern9  from  OrdinaryDiffEq  This has reduced the \"first run time\" massively for functions that use a  ContinuousDynamicalSystem !  In addition the  OrdinaryDiffEq  dependency was dropped. This is a big benefit for precompilation times! This does  not  mean that you can't use all the solvers from  OrdinaryDiffEq ! You can still use any solver you want, provided that you do  using OrdinaryDiffEq  to access the solvers!   Numeric values will change slightly  Although there was no API change the default solver did change. This means that if you were using the default solver for some code, the numeric values you will now obtain will slightly change as a result. This does not mean that any functionality broke, but be aware that if you were depending on the  exact value  of e.g.  lyapunovs , you will now have a different value instead.  Provided that you have already been using long enough integration times, the convergence of your results has not been affected though.", 
            "title": "New default solver in v1.2; OrdinaryDiffEq dependency dropped!"
        }, 
        {
            "location": "/news/#recurrenceanalysis-joins-dynamicalsystemsjl-in-v11", 
            "text": "The excellent Julia package  RecurrenceAnalysis  (authored by Helios de Rosario,  @heliosdrm ) is now part of  DynamicalSystems.jl  and reexported by it. Besides adding all the amazing functionality of  RecurrenceAnalysis  to  DynamicalSystems.jl , other benefits also sprung up:   New package  DelayEmbeddings  that defines  Dataset  and provides all delay embedding functionality.  Method to estimate delay embedding dimension (now in  DelayEmbeddings ) was enriched with two more algorithms!  Mutual information (currently wip) is also being improved.  RecurrenceAnalysis  now also has a documentation page, soon to be updated with more real world examples.", 
            "title": "RecurrenceAnalysis joins DynamicalSystems.jl in v1.1!"
        }, 
        {
            "location": "/news/#dynamicalsystems-v10-julia-10-release", 
            "text": "All support for any Julia version before 0.7 is dropped.  Please be sure to check out the  CHANGELOG.md  files of the individual repositories. There all changes are listed in detail. Here we note only the most important ones.   TimeseriesPrediction  is  not  installed with  DynamicalSystems  for version 1.0, because it is undergoing major changes. It is not even ready for Julia 1.0 actually.  DynamicalSystem  has been totally reworked for better clarity: it does not store a \"problem\" anymore, only the absolutely necessary ingredients to create one. The API did not change though!  Reconstruction  has been renamed to  reconstruct , and now always returns a  Dataset . In addition, now the parameter  D  (now renamed to  \u03b3 ) stands for the number of temporal neighbors.  This is a breaking change! . The change allows more intuition across the different versions of  reconstruct .  The various offered integrators became more robust, and now allow passing callbacks etc. for the DifferentialEquations.jl event handling.  Brand new algorithm for computing Poincare surfaces of section. It is not also more clear and understandable from the old one, but also much faster as well!!!  Mutual information computation method. Also new method for optimal delay time using the Mutual information!   As always: be sure to read the documentation string before using a function: the docstrings are always updated and will show latest changes even if we (mistakenly) missed them when writing the documentation pages!", 
            "title": "DynamicalSystems v1.0 - Julia 1.0 release"
        }, 
        {
            "location": "/news/#timeseries-prediction", 
            "text": "A new module has been added to  DynamicalSystems.jl :  TimeseriesPrediction  (version  v0.2.0 ), which tries to predict timeseries using methods from nonlinear dynamics and chaos!  The first available method is  localmodel_tsp  that uses local averages! See the new documentation page for more!", 
            "title": "Timeseries Prediction"
        }, 
        {
            "location": "/news/#caos-method", 
            "text": "With  ChaosTools v0.8.0 , the well-known method for estimating dimension for a  Reconstruction  is now implemented and exported! See  estimate_dimension .", 
            "title": "Cao's Method"
        }, 
        {
            "location": "/news/#multi-time-multi-diensional-reconstructions", 
            "text": "With the latest version of  DynamicalSystemsBase v0.8.0  we now have the possibility for both multi-time and multi-dimensional delay reconstructions! The new documentation string for  Reconstruction  has all the relevant information.", 
            "title": "Multi-time, Multi-Diensional Reconstructions"
        }, 
        {
            "location": "/news/#release-v0110", 
            "text": "With new version v0.11.0 for  DynamicalSytems.jl  ( DynamicalSystemsBase  and  ChaosTools  at version 0.6) we have some major improvements of the library all around. Here I list the syntactic changes, the internal changes, the prospect for other developers and the gains we have from making all these changes!", 
            "title": "Release v0.11.0"
        }, 
        {
            "location": "/news/#syntax-changes", 
            "text": "There are no syntax changes (or  any  changes) to functions that handle numerical data ( Dataset  and the likes).  The syntax for both discrete and continuous systems has changed to  DiscreteDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0 :: Int   =   0 )  ContinuousDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0   =   0.0 )   The equations of motion function  eom  can be one of two forms:   iip  : The  eom   must  be in the form  eom(x, p, t) -  SVector  which means that given a state  x::SVector  and some parameter container  p  it returns an  SVector  containing the next state.  oop  : The  eom   must  be in the form  eom!(xnew, x, p, t)  which means that given a state  x::Vector  and some parameter container  p , it writes in-place the new state in  xnew .   There is no constructor that takes an  ODEProblem  anymore.  In addition,  DynamicalSystem  and subtypes are now  immutable . One cannot set their state in place, or anything like that. Instead, all high-level functions allow you to choose an initial state.  In summary:   All discrete systems are now simply  DiscreteDynamicalSystem .  Continuous systems have been renamed to  ContinuousDynamicalSystem .  Don't use  set_state! , etc. Instead use the keyword argument  u0  of methods like e.g.  gali .   There are some syntax changes to high-level functions from  ChaosTools  as well. For example,  lyapunovs  now has call signature  lyapunovs ( ds :: DynamicalSystem ,   N ,   k :: Int   |   Q0 ;   kwargs ... )   -   \u03bbs   It is advised to first look the documentation string of a function you want to use before usage!", 
            "title": "Syntax changes"
        }, 
        {
            "location": "/news/#internal-changes-prospects", 
            "text": "The internals of  DynamicalSystemsBase  have been completely re-worked from the ground up. Here are the highlights:   All  DynamicalSystem  objects are immutable, and contain a problem  prob  the jacobian function and an initialized Jacobian matrix.  All functions that use a  DynamicalSystem  have changed behavior. The way the functions work now is that when given a  DynamicalSystem  the create an appropriate  integrator  from it. Then we use  step!(integrator, dt)  and use the integrator state to perform calculations.   Eight possible system types are now available:   Continuous or Discrete.  In-place or out-of-place (large versus small systems).  Auto-differentiated or not (for the Jacobian function).  This is only possible due to the strictness of defining the  eom  function.  Robust multiple dispatch on all 8 types (again, only possible due to the strictness of the  eom  function).     Three low-lever integrator constructing functions are available, that only need a  DynamicalSystem  and (optionally) an initial state:   integrator  for \"normal\" integration of a system.  tangent_integrator  for integration of a state and deviation vectors (that live on the tangent space).  parallel_integrator  for integrating in \"parallel\" a number of states. Notice that the states are integrated at  exact  same times, even for continuous systems.     All three of the above integrators work perfectly fine for all eight combinations of systems and also have performant implementations.   Simple internal implementation for Discrete system integrator that is tailored to the needs of  DynamicalSystems.jl . It follows the high-level syntax of DifferentialEquations.jl: there is an implementation of a minimal discrete problem, as well as a minimal discrete integrator that steps via  step!(integrator, dt) .  DynamicalSystem  is type-parameterized in such a way that allows for easy multiple dispatch and clear source code.   Because the resulting behavior is very robust and efficient, it allows  DynamicalSystemsBase  to also be a library used by other developers that want to develop techniques/functions for dynamical systems.  In addition, there is absolutely no drawback in having a  ContinuousDynamicalSystem  instead of an  ODEProblem , since the field  .prob  of the system is exactly this  ODEProblem , and can be passed directly to things like  solve  from DifferentialEquations.jl.", 
            "title": "Internal changes &amp; Prospects"
        }, 
        {
            "location": "/news/#gains", 
            "text": "Out-of-place continuous systems are now possible!  Auto-differentiated methods compute the vector field only once.  Safe, robust implementations due to the immutability of the central structure  DynamicalSystem .  No problems with parallelization/threading/etc.  Even clearer source code! Most  ChaosTools  functions are now composed of a set-up part and an implementation part, both of which are clear to read and understand.     * Also clarity on discrete systems, since they are all fused into one structure.     * Low-level functions can be used easily by users that want performance for loops.  Lyapunov exponent calculating functions now have full flexibility in all aspects (initial deviation vectors/transient times/pretty much anything).   Big performance gains all around, and especially in methods that propagate tangent space. For example, the function that calculates the Lyapunov spectrum of the towel map, needs:  julia\nusing DynamicalSystems\nds = Systems.towel()\nl = lyapunovs(ds, 1000)  Float64[3]\n0.42883526635723973\n0.36501911701374234\n-3.2835393321781092  julia\nusing BenchmarkTools\n@btime lyapunovs($ds, 1000);\n228.265 \u03bcs (176 allocations: 11.28 KiB)", 
            "title": "Gains"
        }
    ]
}