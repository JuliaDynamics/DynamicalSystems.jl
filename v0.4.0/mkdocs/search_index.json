{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nDynamicalSystems.jl\n is a Julia package for the exploration of continuous and discrete dynamical systems. It aims to be a useful and powerful companion for students and scientists treading on the fields of Chaos, nonlinear dynamics and dynamical systems in general.\n\n\nOne of a major goals of this package is to be completely transparent as to what is going on \"under the hood\". In scientific research, you never want to use \nblack boxes\n, e.g. functions that give a result without telling you how it was calculated. \nDynamicalSystems.jl\n battles this in 2 ways: Firstly, it is written entirely in Julia, making the source code clear and easy to understand for even novice users. Secondly, almost every documentation string gives \ndirect references to the original papers\n where the algorithm is taken from, in case some users don't understand (or simply don't want to read) the source code. For example, the documentation string of \n?lyapunovs\n will cite relevant publications for the definition and computation of the lyapunov spectrum.\n\n\nYou can \njoin our chatroom\n for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!\n\n\nBe sure to visit the \nContributor Guide\n page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on \nGitHub\n! This gives us an accurate lower bound of users that this package has already helped!\n\n\n\n\nContents\n\n\nCurrently the package allows for the following types of dynamical systems:\n\n\n\n\nDiscrete Maps\n\n\nContinuous Flows\n\n\nNumerical Data\n\n\n\n\nThis is the list of methods and algorithms this package currently offers (updated very frequently):\n\n\n\n\nSystem Definition\n\n\n\n\nIntuitive, consistent APIs for the definition of general dynamical systems\n\n\nAutomatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\n\n\nInterface for \nDifferentialEquations.jl\n for flexible integration of continuous system.\n\n\nWell-defined functions for evolving dynamical systems.\n\n\nDedicated interface (\nDataset\n) for handling sets of data (numbers), in a way that feels familiar to scientists.\n\n\nLibrary of predefined well-known dynamical systems that have been used extensively in scientific research.\n\n\n\n\n\n\nLyapunov Exponents\n\n\n\n\nMaximum Lyapunov exponent for both discrete and continuous systems.\n\n\nLyapunov \nspectrum\n for both discrete and continuous systems.\n\n\n\n\n\n\nEntropies and Dimensions\n\n\n\n\nGeneralized (Renyi) entropy and all related entropies.\n\n\nUltra-fast and cheap method for computing entropies of large datasets without ever having to worry about memory overflow. It uses typically 3-6 orders of magnitude less time and memory than traditional histogram-based methods.\n\n\nGeneralized Dimensions (e.g. capacity dimension, information dimension, etc.).\n\n\nKaplan-Yorke dimension.\n\n\nPartitioning of a function \n\\(y(x)\\)\n vs. \n\\(x\\)\n into regions where it is approximated by a straight line, using a flexible function with a lot of control over the outcome.\n\n\nDetection of largest linear region of a function \n\\(y(x)\\)\n vs. \n\\(x\\)\n and extraction of the slope of this region (used e.g. in estimating dimensions of chaotic tractors).\n\n\nMethods for detecting best algorithmic parameters for calculating attractor dimensions, including a fast implementation of minimum pairwise distance of a \nDataset\n.\n\n\n\n\n\n\nNonlinear Timeseries Analysis\n\n\n\n\nFlexible and abstracted \nReconstruction\n interface, that creates the delay-coordinates reconstruction of a 1D timeseries efficiently.\n\n\nMethods for estimating good \nReconstruction\n parameters (delay and dimension).\n\n\nFour\n different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries.\n\n\nFast computation of the above algorithms made possible by the interaction of \nNearestNeighbors.jl\n, multiple dispatch and smart indexing (through the \nReconstruction\n abstraction).\n\n\n\n\n\n\nPeriodicity\n\n\n\n\nNumerical method to find unstable and stable fixed points of \nany order\n of a discrete map (of any dimensionality). Fixed points of order \n\\(n\n1\\)\n are simply periodic orbits of order \n\\(n.\\)\n\n\nConvenience functions for defining and realizing all possible combinations of\n\\(\\mathbf{\\Lambda}_k\\)\n matrices required in the above method.\n\n\n\n\n\n\nWanted Features\n\n\nThe \nwanted features GitHub page\n lists features that are wanted by the \nDynamicalSystems\n, and are open to contributors.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "DynamicalSystems.jl  is a Julia package for the exploration of continuous and discrete dynamical systems. It aims to be a useful and powerful companion for students and scientists treading on the fields of Chaos, nonlinear dynamics and dynamical systems in general.  One of a major goals of this package is to be completely transparent as to what is going on \"under the hood\". In scientific research, you never want to use  black boxes , e.g. functions that give a result without telling you how it was calculated.  DynamicalSystems.jl  battles this in 2 ways: Firstly, it is written entirely in Julia, making the source code clear and easy to understand for even novice users. Secondly, almost every documentation string gives  direct references to the original papers  where the algorithm is taken from, in case some users don't understand (or simply don't want to read) the source code. For example, the documentation string of  ?lyapunovs  will cite relevant publications for the definition and computation of the lyapunov spectrum.  You can  join our chatroom  for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!  Be sure to visit the  Contributor Guide  page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on  GitHub ! This gives us an accurate lower bound of users that this package has already helped!", 
            "title": "Introduction"
        }, 
        {
            "location": "/#contents", 
            "text": "Currently the package allows for the following types of dynamical systems:   Discrete Maps  Continuous Flows  Numerical Data   This is the list of methods and algorithms this package currently offers (updated very frequently):", 
            "title": "Contents"
        }, 
        {
            "location": "/#system-definition", 
            "text": "Intuitive, consistent APIs for the definition of general dynamical systems  Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.  Interface for  DifferentialEquations.jl  for flexible integration of continuous system.  Well-defined functions for evolving dynamical systems.  Dedicated interface ( Dataset ) for handling sets of data (numbers), in a way that feels familiar to scientists.  Library of predefined well-known dynamical systems that have been used extensively in scientific research.", 
            "title": "System Definition"
        }, 
        {
            "location": "/#lyapunov-exponents", 
            "text": "Maximum Lyapunov exponent for both discrete and continuous systems.  Lyapunov  spectrum  for both discrete and continuous systems.", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/#entropies-and-dimensions", 
            "text": "Generalized (Renyi) entropy and all related entropies.  Ultra-fast and cheap method for computing entropies of large datasets without ever having to worry about memory overflow. It uses typically 3-6 orders of magnitude less time and memory than traditional histogram-based methods.  Generalized Dimensions (e.g. capacity dimension, information dimension, etc.).  Kaplan-Yorke dimension.  Partitioning of a function  \\(y(x)\\)  vs.  \\(x\\)  into regions where it is approximated by a straight line, using a flexible function with a lot of control over the outcome.  Detection of largest linear region of a function  \\(y(x)\\)  vs.  \\(x\\)  and extraction of the slope of this region (used e.g. in estimating dimensions of chaotic tractors).  Methods for detecting best algorithmic parameters for calculating attractor dimensions, including a fast implementation of minimum pairwise distance of a  Dataset .", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/#nonlinear-timeseries-analysis", 
            "text": "Flexible and abstracted  Reconstruction  interface, that creates the delay-coordinates reconstruction of a 1D timeseries efficiently.  Methods for estimating good  Reconstruction  parameters (delay and dimension).  Four  different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries.  Fast computation of the above algorithms made possible by the interaction of  NearestNeighbors.jl , multiple dispatch and smart indexing (through the  Reconstruction  abstraction).", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/#periodicity", 
            "text": "Numerical method to find unstable and stable fixed points of  any order  of a discrete map (of any dimensionality). Fixed points of order  \\(n 1\\)  are simply periodic orbits of order  \\(n.\\)  Convenience functions for defining and realizing all possible combinations of \\(\\mathbf{\\Lambda}_k\\)  matrices required in the above method.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/#wanted-features", 
            "text": "The  wanted features GitHub page  lists features that are wanted by the  DynamicalSystems , and are open to contributors.", 
            "title": "Wanted Features"
        }, 
        {
            "location": "/system_definition/", 
            "text": "System Definition\n\n\nFor \nDynamicalSystems.jl\n a system is simple a structure that contains the system's state, the equations of motion and the Jacobian. The last two are \nfunctions\n that take as an input a state.\n\n\nThis of course stands for systems where one already \nknows the equations of motion\n. if instead, your \"system\" is in the form of \nnumerical data\n, then see the appropriate section.\n\n\n\n\nNon-autonomous systems\n\n\nThis package does \nnot\n accept non-autonomous systems. To use such systems with this package increase the dimensionality of your system by 1, by introducing an additional variable \n\u03c4\n such that \nd\u03c4dt = 1\n (or \n\u03c4_next = \u03c4_prev + 1\n). This additional variable will serve as the \"time\" in your equations of motion.\n\n\n\n\n\n\nDiscrete Systems\n\n\nDiscrete systems are of the form:\n\n\n\\[\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\\]\nThe Type representing such systems is called \nDiscreteDS\n:\n\n\n#\n\n\nDynamicalSystems.DiscreteDS\n \n \nType\n.\n\n\nDiscreteDS(state, eom [, jacob]) \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional discrete dynamical system (used for \nD \u2264 10\n).\n\n\nFields:\n\n\n\n\nstate::SVector{D}\n : Current state-vector of the system, stored in the data format of \nStaticArray\n's \nSVector\n.\n\n\neom\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom(u) -\n SVector\n which means that given a state-vector \nu\n it returns an \nSVector\n containing the next state.\n\n\njacob::J\n (function) : A function that calculates the system's jacobian matrix, based on the format: \njacob(u) -\n SMatrix\n which means that given a state-vector \nu\n it returns an \nSMatrix\n containing the Jacobian at that state.\n\n\n\n\nIf the \njacob\n is not provided by the user, it is created efficiently using the module \nForwardDiff\n.\n\n\nsource\n\n\n\n\nThe documentation string of the constructor is perfectly self-contained, but for the sake of clarity we will go through all the steps in the following.\n\n\nstate\n is simply the state the system starts (a.k.a. initial conditions) and \neom\n is a \nfunction\n that takes a \nstate\n as an input and returns the next state as an output. The \njacob\n is also a \nfunction\n that takes a \nstate\n as an input and returns the Jacobian matrix of the system (at this state). This however is optional and if not provided by the user, will be calculated automatically using the package \nForwardDiff.jl\n.\n\n\n\n\nReturn form of the \neom\n function\n\n\nIt is \nheavily\n advised that the equations of motion \neom\n function returns an \nSVector\n from the julia package \nStaticArrays.jl\n and similarly the \njacob\n function returns an \nSMatrix\n. \nNumerous benchmarks\n have been made in order to deduce the most efficient possible way to define a system, and this way was proved to be the best when the system's dimension is small.\n\n\n\n\nFor example, let's create one of the \nPredefined Systems\n offered by this package, the H\u00e9non map:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nStaticArrays\n \n#only necessary when defining a system\n\n\n\neom_henon\n(\nx\n)\n \n=\n \nSVector\n{\n2\n}(\n1.0\n \n-\n \na\n*\nx\n[\n1\n]\n^\n2\n \n+\n \nx\n[\n2\n],\n \nb\n*\nx\n[\n1\n])\n\n\njacob_henon\n(\nx\n)\n \n=\n \n@SMatrix\n \n[\n-\n2\n*\na\n*\nx\n[\n1\n]\n \n1.0\n;\n \nb\n \n0.0\n]\n\n\n\nhen\n \n=\n \nDiscreteDS\n(\nrand\n(\n2\n),\n \neom_henon\n,\n \njacob_henon\n)\n\n\n\n\n\n\nIf we did not want to write a Jacobian, we could do\n\n\nhen_nojac\n \n=\n \nDiscreteDS\n(\nrand\n(\n2\n),\n \neom_henon\n)\n\n\n\n\n\n\nand the Jacobian function would be created automatically.\n\n\n\n\n1-dimensional Discrete Systems\n\n\nIn the case of maps, there a special structure for one-dimensional systems, since they are commonly used in scientific research. The syntax is \nDiscreteDS1D(state, eom [, deriv])\n. In this one-dimensional case, you don't need to worry about \nStaticArrays.jl\n because everything is in plain numbers. For example:\n\n\nusing\n \nDynamicalSystems\n\n\n\n@inline\n \neom_logistic\n(\nr\n)\n \n=\n \n(\nx\n)\n \n-\n \nr\n*\nx\n*\n(\n1\n-\nx\n)\n  \n# this is a closure\n\n\n@inline\n \nderiv_logistic\n(\nr\n)\n \n=\n \n(\nx\n)\n \n-\n \nr\n*\n(\n1\n-\n2\nx\n)\n \n# this is a closure\n\n\nr\n \n=\n \n3.7\n\n\nlogistic\n \n=\n \nDiscreteDS1D\n(\nrand\n(),\n \neom_logistic\n(\nr\n),\n \nderiv_logistic\n(\nr\n))\n\n\n\n\n\n\nOnce again, if you skip the derivative functions it will be calculated automatically using \nForwardDiff.jl\n.\n\n\n\n\nContinuous Systems\n\n\nContinuous systems of the form :$ \\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}), :$ are defined in a similar manner with the discrete systems:\n\n\n#\n\n\nDynamicalSystems.ContinuousDS\n \n \nType\n.\n\n\nContinuousDS(state, eom! [, jacob]) \n: DynamicalSystem\n\n\n\n\n\nD\n-dimensional continuous dynamical system.\n\n\nFields:\n\n\n\n\nstate::Vector{T}\n : Current state-vector of the system\n\n\neom!\n (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format: \neom!(du, u)\n which means that it is \nin-place\n, with the Julian syntax (the mutated argument \ndu\n is the first).\n\n\njacob\n (function) : The function that represents the Jacobian of the system, given in the format: \njacob(u) =\n J\n (i.e. returns a matrix). If the matrix is an \nSMatrix\n from \nStaticArrays.jl\n there are major performance gains.\n\n\n\n\nBecause the \njacob\n function is only necessary for a small subset of algorithms, you do not have to provide it necessarily to the constructor (but then you can't use these functions).\n\n\nsource\n\n\n\n\nThere are two major differences compared to the discrete case:\n\n\n\n\nThe second field \neom!\n ends with an \n!\n to remind users that it is an in-place function. This is necessary because the integration of continuous systems using \nDifferentialEquations.jl\n is much better this way.\n\n\nAutomated Jacobian function evaluation is not yet supported due to the dissonance of the interfaces of \nDifferentialEquations.jl\n and \nForwardDiff.jl\n\n\n\n\nNotice that providing a Jacobian is not necessary, since currently it is only used by the function \nlyapunovs\n. If you do provide a Jacobian, it is best if it returns an \nSMatrix\n, just like with the discrete systems case.\n\n\nAs an example, the continuous R\u00f6ssler system can be defined as:\n\n\n@inline\n \n@inbounds\n \nfunction\n \neom_roessler!\n(\ndu\n,\n \nu\n)\n\n    \na\n \n=\n \n0.2\n;\n \nb\n \n=\n \n0.2\n;\n \nc\n \n=\n \n5.7\n\n    \ndu\n[\n1\n]\n \n=\n \n-\nu\n[\n2\n]\n-\nu\n[\n3\n]\n\n    \ndu\n[\n2\n]\n \n=\n \nu\n[\n1\n]\n \n+\n \na\n*\nu\n[\n2\n]\n\n    \ndu\n[\n3\n]\n \n=\n \nb\n \n+\n \nu\n[\n3\n]\n*\n(\nu\n[\n1\n]\n \n-\n \nc\n)\n\n\nend\n\n\n@inline\n \n@inbounds\n \nfunction\n \njacob_roessler\n(\nu\n)\n\n    \ni\n \n=\n \none\n(\neltype\n(\nu\n))\n\n    \no\n \n=\n \nzero\n(\neltype\n(\nu\n))\n\n    \n@SMatrix\n \n[\no\n     \n-\ni\n      \n-\ni\n;\n\n              \ni\n      \na\n       \no\n;\n\n              \nu\n[\n3\n]\n   \no\n       \nu\n[\n1\n]\n \n-\n \nc\n]\n\n\nend\n\n\n\nros\n \n=\n \nContinuousDS\n(\nrand\n(\n3\n),\n \neom_roessler!\n,\n \njacob_roessler\n)\n\n\n\n\n\n\n\n\nSystem evolution\n\n\nDynamicalSystems.jl\n provides convenient interfaces for the evolution of systems. Especially in the continuous case, an interface is provided to the module \nDifferentialEquations.jl\n, with an approach that fits more the structuring of the present package (e.g. time is never passed to the equations of motion).\n\n\nNotice that if you want to do repeated evolutions of a system, use the \nevolve!(::ODEProblem)\n interface, which does not create a new \nODEProblem\n every time.\n\n\nThese are the functions related to system-evolution:\n\n\n#\n\n\nDynamicalSystems.evolve\n \n \nFunction\n.\n\n\nevolve\n(\nds\n::\nDynamicalSystem\n,\n \nT\n=\n1\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n \n-\n \nfinal_state\n\n\n\n\n\n\nEvolve a \nds\n for total \"time\" \nT\n and return the \nfinal_state\n (does not change \nds.state\n). For discrete systems \nT\n corresponds to steps and thus it must be integer. See \ntimeseries\n for using \ndiff_eq_kwargs\n.\n\n\nThis function \ndoes not store\n any information about intermediate steps. Use \ntimeseries\n if you want to produce timeseries of the system. If you want to perform step-by-step evolution of a continuous system, use \nODEIntegrator(ds, t_final)\n and the \nstep!(integrator)\n function provided by \nDifferentialEquations\n.\n\n\nSee also \nevolve!\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.evolve!\n \n \nFunction\n.\n\n\nevolve\n!(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \ndiff_eq_kwargs\n \n=\n \nDict\n())\n \n-\n \nds\n\n\n\n\n\n\nEvolve (in-place) a dynamical system for total \"time\" \nT\n, setting the final state as the system's state. For discrete systems \nT\n corresponds to steps and thus it must be integer. See \ntimeseries\n for using \ndiff_eq_kwargs\n. See \ntimeseries\n for using \ndiff_eq_kwargs\n.\n\n\nThis function \ndoes not store\n any information about intermediate steps. Use \ntimeseries\n if you want to produce timeseries of the system. If you want to perform step-by-step evolution of a continuous system, use \nODEIntegrator(ds, t_final)\n and the \nstep!(integrator)\n function provided by \nDifferentialEquations\n.\n\n\nSee also \nevolve\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.timeseries\n \n \nFunction\n.\n\n\ntimeseries\n(\nds\n::\nDynamicalSystem\n,\n \nT\n;\n \nkwargs\n...\n)\n \n-\n \ndataset\n\n\n\n\n\n\nReturn a dataset what will contain the timeseries of the sytem, after evolving it for time \nT\n. See \nDataset\n for info on how to manipulate this object.\n\n\nFor the discrete case, \nT\n is an integer and a \nT\u00d7D\n dataset is returned (\nD\n is the system dimensionality). For the continuous case, a \nW\u00d7D\n dataset is returned, with \nW = length(0:dt:T)\n with \n0:dt:T\n representing the time vector (\nnot\n returned).\n\n\nKeywords:\n\n\n\n\ndt = 0.05\n : (only for continuous) Time step of value output during the solving of the continuous system.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) A dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \nsolve\n of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :maxiters =\n 1e9)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\n\n\nsource\n\n\n\n\nIn addition, interfaces are provided for usage directly with \nDifferentialEquations.jl\n, by giving additional constructors:\n\n\n#\n\n\nDiffEqBase.ODEProblem\n \n \nType\n.\n\n\nODEProblem\n(\nds\n::\nContinuousDS\n,\n \nt\n)\n\n\n\n\n\n\nReturn an \nODEProblem\n with the given system information (t0 is zero). This can be passed directly into \nsolve\n from \nDifferentialEquations\n.\n\n\nsource\n\n\n#\n\n\nOrdinaryDiffEq.ODEIntegrator\n \n \nType\n.\n\n\nODEIntegrator\n(\nds\n::\nContinuousDS\n,\n \nt\n;\n \ndiff_eq_kwargs\n)\n\n\n\n\n\n\nReturn an \nODEIntegrator\n, by first creating an \nODEProblem(ds, t)\n. This can be used directly with the interfaces of \nDifferentialEquations\n.\n\n\ndiff_eq_kwargs = Dict()\n is a dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the \ninit\n of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :tstops =\n 0:0.01:t)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers.\n\n\nsource\n\n\n\n\n\n\nNumerical Data\n\n\nNumerical data in \nDynamicalSystems.jl\n are represented by a structure called \nDataset\n:\n\n\n#\n\n\nDynamicalSystems.Dataset\n \n \nType\n.\n\n\nDataset{D, T, V} \n: AbstractDataset{D}\n\n\n\n\n\nA \nDataset\n is an interface for vectors of vectors, originally inspired by \nRecursiveArrayTools.jl\n. It contains \nequally-sized datapoints\n of length \nD\n, represented by vectors of type \nV\n, containing numbers of type \nT\n.\n\n\nThis data representation is more efficient than having a \nMatrix\n and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables. For example,\n\n\ndata\n \n=\n \ntimeseries\n(\nds\n,\n \n100.0\n)\n \n#this gives a dataset that behaves like a matrix\n\n\ndata\n[\n:\n,\n \n2\n]\n \n# this is the second variable timeseries\n\n\ndata\n[\n1\n]\n \n==\n \ndata\n[\n1\n,\n \n:\n]\n \n# this is the first datapoint of the dataset (D-dimensional)\n\n\ndata\n[\n5\n,\n \n3\n]\n \n# this is the value of the third variable, at the 5th timepoint\n\n\n\n\n\n\nUse \nconvert(Matrix, dataset)\n to create a \nMatrix\n, and \nconvert(Dataset, matrix)\n to create a \nDataset\n from a matrix. \nNotice:\n  \nconvert(Dataset, matrix)\n assumes that each column of the matrix represents one dynamic variable. If instead each column of the matrix represents a datapoint, use \nreinterpret(Dataset, matrix)\n.\n\n\nIf you have various timeseries vectors \nx, y, z, ...\n pass them like \nDataset(x, y, z, ...)\n.`\n\n\nsource\n\n\n\n\nIn essence a \nDataset\n is simply a container for a \nVector\n of \nVector\ns, but only for cases where the all inner vectors are of equal size. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the \ncolumn\n direction). It also offers a lot more functionality and pretty-printing. Besides the examples in the documentation string, you can also do:\n\n\ndata\n \n=\n \ntimeseries\n(\nhen\n,\n \n10000\n)\n\n\nfor\n \npoint\n \nin\n \ndata\n\n\n# do stuff with each datapoint (vector with as many elements as system dimension)\n\n\nend\n\n\n\n\n\n\nAll functions that manipulate and use data are expecting a \nDataset\n instance. If given a matrix, they will first convert to \nDataset\n. This means that you should first convert your data to a \nDataset\n if you want to call functions more than once, to avoid constantly converting.\n\n\n\n\nPredefined Systems\n\n\nPredefined systems exist in the \nSystems\n submodule exported by \nDynamicalSystems\n, in the form of functions that return a \nDynamicalSystem\n. They are accessed like:\n\n\nusing\n \nDynamicalSystems\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n\n\nts\n \n=\n \ntimeseries\n(\nds\n,\n \n10.0\n)\n\n\n\n\n\n\nAll of these functions have very similar documentation strings:\n\n\n\n\nCall signature (parameters of the system are always passed as keyword arguments).\n\n\nEquations of the system in \n\\(\\LaTeX\\)\n (how cool is that!).\n\n\nIntroductory text about what this system is and who introduced it first.\n\n\nCouple of sentences that contain cool science info about the system.\n\n\nReference to the original papers.\n\n\n\n\nSo far, the predefined systems that exist in the \nSystems\n sub-module are:\n\n\n#\n\n\nDynamicalSystems.Systems.double_pendulum\n \n \nFunction\n.\n\n\ndouble_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)\n\n\n\n\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\n\nThe variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].\n\n\nJacobian is not created! So no \nlyapunovs\n for you!\n\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.henon\n \n \nFunction\n.\n\n\nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\nx_{n+1} \n= 1 - ax^2_n+y_n \\\\\ny_{n+1} \n = bx_n\n\\end{align*}\n\\]\nThe H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : M. H\u00e9non, Commun.Math. Phys. \n50\n, pp 69 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.logistic\n \n \nFunction\n.\n\n\nlogistic\n(\nx0\n \n=\n \nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n\n\n\n\n\n\\[\nx_{n+1} = rx_n(1-x_n)\n\\]\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].\n\n\n[1] : R. M. May, Nature \n261\n, pp 459 (1976)\n\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. \n19\n, pp 25 (1978)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.lorenz\n \n \nFunction\n.\n\n\nlorenz\n(\nu0\n=\n[\n0.0\n,\n \n10.0\n,\n \n0.0\n];\n \n\u03c3\n \n=\n \n10.0\n,\n \n\u03c1\n \n=\n \n28.0\n,\n \n\u03b2\n \n=\n \n8\n/\n3\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\dot{X} \n= \\sigma(Y-X) \\\\\n\\dot{Y} \n= -XZ + \\rho X -Y \\\\\n\\dot{Z} \n= XY - \\beta Z\n\\end{align*}\n\\]\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\n\n[1] : E. N. Lorenz, J. atmos. Sci. \n20\n, pp 130 (1963)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.roessler\n \n \nFunction\n.\n\n\nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\dot{x} \n= -y-z \\\\\n\\dot{y} \n= x+ay \\\\\n\\dot{z} \n= -b + z(x-c)\n\\end{align*}\n\\]\nThis three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the \nlorenz\n system and displays a (fractal) strange attractor.\n\n\nHowever, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n57A\n, pp 397 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.standardmap\n \n \nFunction\n.\n\n\nstandardmap\n(\nu0\n=\n0.001\nrand\n(\n2\n);\n \nk\n \n=\n \n0.971635\n)\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\theta_{n+1} \n= \\theta_n + p_{n+1} \\\\\np_{n+1} \n= p_n + k\\sin(\\theta_n)\n\\end{align*}\n\\]\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\n\nThe map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter \nk\n transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\n\nThe default parameter \nk\n is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable \n\u03b8\n to be the first, and the angular momentum \np\n to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).\n\n\n[1] : B. V. Chirikov, Preprint N. \n267\n, Institute of Nuclear Physics, Novosibirsk (1969)\n\n\n[2] : J. M. Greene, J. Math. Phys. \n20\n, pp 1183 (1979)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.Systems.towel\n \n \nFunction\n.\n\n\ntowel\n(\nu0\n \n=\n \n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n])\n\n\n\n\n\n\n\\[\n\\begin{align*}\nx_{n+1} \n= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} \n= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} \n= 3.78 z_n (1-z_n) + b y_n\n\\end{align*}\n\\]\nThe folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative lyapunov exponent.\n\n\nThe name comes from the fact that when plotted looks like a folded towel, in every projection.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n71A\n, pp 155 (1979)\n\n\nsource", 
            "title": "System Definition"
        }, 
        {
            "location": "/system_definition/#system-definition", 
            "text": "For  DynamicalSystems.jl  a system is simple a structure that contains the system's state, the equations of motion and the Jacobian. The last two are  functions  that take as an input a state.  This of course stands for systems where one already  knows the equations of motion . if instead, your \"system\" is in the form of  numerical data , then see the appropriate section.   Non-autonomous systems  This package does  not  accept non-autonomous systems. To use such systems with this package increase the dimensionality of your system by 1, by introducing an additional variable  \u03c4  such that  d\u03c4dt = 1  (or  \u03c4_next = \u03c4_prev + 1 ). This additional variable will serve as the \"time\" in your equations of motion.", 
            "title": "System Definition"
        }, 
        {
            "location": "/system_definition/#discrete-systems", 
            "text": "Discrete systems are of the form:  \\[\n\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n).\n\\] The Type representing such systems is called  DiscreteDS :  #  DynamicalSystems.DiscreteDS     Type .  DiscreteDS(state, eom [, jacob])  : DynamicalSystem  D -dimensional discrete dynamical system (used for  D \u2264 10 ).  Fields:   state::SVector{D}  : Current state-vector of the system, stored in the data format of  StaticArray 's  SVector .  eom  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom(u) -  SVector  which means that given a state-vector  u  it returns an  SVector  containing the next state.  jacob::J  (function) : A function that calculates the system's jacobian matrix, based on the format:  jacob(u) -  SMatrix  which means that given a state-vector  u  it returns an  SMatrix  containing the Jacobian at that state.   If the  jacob  is not provided by the user, it is created efficiently using the module  ForwardDiff .  source   The documentation string of the constructor is perfectly self-contained, but for the sake of clarity we will go through all the steps in the following.  state  is simply the state the system starts (a.k.a. initial conditions) and  eom  is a  function  that takes a  state  as an input and returns the next state as an output. The  jacob  is also a  function  that takes a  state  as an input and returns the Jacobian matrix of the system (at this state). This however is optional and if not provided by the user, will be calculated automatically using the package  ForwardDiff.jl .   Return form of the  eom  function  It is  heavily  advised that the equations of motion  eom  function returns an  SVector  from the julia package  StaticArrays.jl  and similarly the  jacob  function returns an  SMatrix .  Numerous benchmarks  have been made in order to deduce the most efficient possible way to define a system, and this way was proved to be the best when the system's dimension is small.   For example, let's create one of the  Predefined Systems  offered by this package, the H\u00e9non map:  using   DynamicalSystems  using   StaticArrays   #only necessary when defining a system  eom_henon ( x )   =   SVector { 2 }( 1.0   -   a * x [ 1 ] ^ 2   +   x [ 2 ],   b * x [ 1 ])  jacob_henon ( x )   =   @SMatrix   [ - 2 * a * x [ 1 ]   1.0 ;   b   0.0 ]  hen   =   DiscreteDS ( rand ( 2 ),   eom_henon ,   jacob_henon )   If we did not want to write a Jacobian, we could do  hen_nojac   =   DiscreteDS ( rand ( 2 ),   eom_henon )   and the Jacobian function would be created automatically.", 
            "title": "Discrete Systems"
        }, 
        {
            "location": "/system_definition/#1-dimensional-discrete-systems", 
            "text": "In the case of maps, there a special structure for one-dimensional systems, since they are commonly used in scientific research. The syntax is  DiscreteDS1D(state, eom [, deriv]) . In this one-dimensional case, you don't need to worry about  StaticArrays.jl  because everything is in plain numbers. For example:  using   DynamicalSystems  @inline   eom_logistic ( r )   =   ( x )   -   r * x * ( 1 - x )    # this is a closure  @inline   deriv_logistic ( r )   =   ( x )   -   r * ( 1 - 2 x )   # this is a closure  r   =   3.7  logistic   =   DiscreteDS1D ( rand (),   eom_logistic ( r ),   deriv_logistic ( r ))   Once again, if you skip the derivative functions it will be calculated automatically using  ForwardDiff.jl .", 
            "title": "1-dimensional Discrete Systems"
        }, 
        {
            "location": "/system_definition/#continuous-systems", 
            "text": "Continuous systems of the form :$ \\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}), :$ are defined in a similar manner with the discrete systems:  #  DynamicalSystems.ContinuousDS     Type .  ContinuousDS(state, eom! [, jacob])  : DynamicalSystem  D -dimensional continuous dynamical system.  Fields:   state::Vector{T}  : Current state-vector of the system  eom!  (function) : The function that represents the system's equations of motion (also called vector field). The function is of the format:  eom!(du, u)  which means that it is  in-place , with the Julian syntax (the mutated argument  du  is the first).  jacob  (function) : The function that represents the Jacobian of the system, given in the format:  jacob(u) =  J  (i.e. returns a matrix). If the matrix is an  SMatrix  from  StaticArrays.jl  there are major performance gains.   Because the  jacob  function is only necessary for a small subset of algorithms, you do not have to provide it necessarily to the constructor (but then you can't use these functions).  source   There are two major differences compared to the discrete case:   The second field  eom!  ends with an  !  to remind users that it is an in-place function. This is necessary because the integration of continuous systems using  DifferentialEquations.jl  is much better this way.  Automated Jacobian function evaluation is not yet supported due to the dissonance of the interfaces of  DifferentialEquations.jl  and  ForwardDiff.jl   Notice that providing a Jacobian is not necessary, since currently it is only used by the function  lyapunovs . If you do provide a Jacobian, it is best if it returns an  SMatrix , just like with the discrete systems case.  As an example, the continuous R\u00f6ssler system can be defined as:  @inline   @inbounds   function   eom_roessler! ( du ,   u ) \n     a   =   0.2 ;   b   =   0.2 ;   c   =   5.7 \n     du [ 1 ]   =   - u [ 2 ] - u [ 3 ] \n     du [ 2 ]   =   u [ 1 ]   +   a * u [ 2 ] \n     du [ 3 ]   =   b   +   u [ 3 ] * ( u [ 1 ]   -   c )  end  @inline   @inbounds   function   jacob_roessler ( u ) \n     i   =   one ( eltype ( u )) \n     o   =   zero ( eltype ( u )) \n     @SMatrix   [ o       - i        - i ; \n               i        a         o ; \n               u [ 3 ]     o         u [ 1 ]   -   c ]  end  ros   =   ContinuousDS ( rand ( 3 ),   eom_roessler! ,   jacob_roessler )", 
            "title": "Continuous Systems"
        }, 
        {
            "location": "/system_definition/#system-evolution", 
            "text": "DynamicalSystems.jl  provides convenient interfaces for the evolution of systems. Especially in the continuous case, an interface is provided to the module  DifferentialEquations.jl , with an approach that fits more the structuring of the present package (e.g. time is never passed to the equations of motion).  Notice that if you want to do repeated evolutions of a system, use the  evolve!(::ODEProblem)  interface, which does not create a new  ODEProblem  every time.  These are the functions related to system-evolution:  #  DynamicalSystems.evolve     Function .  evolve ( ds :: DynamicalSystem ,   T = 1 ;   diff_eq_kwargs   =   Dict ())   -   final_state   Evolve a  ds  for total \"time\"  T  and return the  final_state  (does not change  ds.state ). For discrete systems  T  corresponds to steps and thus it must be integer. See  timeseries  for using  diff_eq_kwargs .  This function  does not store  any information about intermediate steps. Use  timeseries  if you want to produce timeseries of the system. If you want to perform step-by-step evolution of a continuous system, use  ODEIntegrator(ds, t_final)  and the  step!(integrator)  function provided by  DifferentialEquations .  See also  evolve! .  source  #  DynamicalSystems.evolve!     Function .  evolve !( ds :: DynamicalSystem ,   T ;   diff_eq_kwargs   =   Dict ())   -   ds   Evolve (in-place) a dynamical system for total \"time\"  T , setting the final state as the system's state. For discrete systems  T  corresponds to steps and thus it must be integer. See  timeseries  for using  diff_eq_kwargs . See  timeseries  for using  diff_eq_kwargs .  This function  does not store  any information about intermediate steps. Use  timeseries  if you want to produce timeseries of the system. If you want to perform step-by-step evolution of a continuous system, use  ODEIntegrator(ds, t_final)  and the  step!(integrator)  function provided by  DifferentialEquations .  See also  evolve .  source  #  DynamicalSystems.timeseries     Function .  timeseries ( ds :: DynamicalSystem ,   T ;   kwargs ... )   -   dataset   Return a dataset what will contain the timeseries of the sytem, after evolving it for time  T . See  Dataset  for info on how to manipulate this object.  For the discrete case,  T  is an integer and a  T\u00d7D  dataset is returned ( D  is the system dimensionality). For the continuous case, a  W\u00d7D  dataset is returned, with  W = length(0:dt:T)  with  0:dt:T  representing the time vector ( not  returned).  Keywords:   dt = 0.05  : (only for continuous) Time step of value output during the solving of the continuous system.  diff_eq_kwargs = Dict()  : (only for continuous) A dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  solve  of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :maxiters =  1e9) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.   source   In addition, interfaces are provided for usage directly with  DifferentialEquations.jl , by giving additional constructors:  #  DiffEqBase.ODEProblem     Type .  ODEProblem ( ds :: ContinuousDS ,   t )   Return an  ODEProblem  with the given system information (t0 is zero). This can be passed directly into  solve  from  DifferentialEquations .  source  #  OrdinaryDiffEq.ODEIntegrator     Type .  ODEIntegrator ( ds :: ContinuousDS ,   t ;   diff_eq_kwargs )   Return an  ODEIntegrator , by first creating an  ODEProblem(ds, t) . This can be used directly with the interfaces of  DifferentialEquations .  diff_eq_kwargs = Dict()  is a dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the  init  of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :tstops =  0:0.01:t) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers.  source", 
            "title": "System evolution"
        }, 
        {
            "location": "/system_definition/#numerical-data", 
            "text": "Numerical data in  DynamicalSystems.jl  are represented by a structure called  Dataset :  #  DynamicalSystems.Dataset     Type .  Dataset{D, T, V}  : AbstractDataset{D}  A  Dataset  is an interface for vectors of vectors, originally inspired by  RecursiveArrayTools.jl . It contains  equally-sized datapoints  of length  D , represented by vectors of type  V , containing numbers of type  T .  This data representation is more efficient than having a  Matrix  and also leads to faster numerical computation of other quantities (like e.g. entropies). However, it can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables. For example,  data   =   timeseries ( ds ,   100.0 )   #this gives a dataset that behaves like a matrix  data [ : ,   2 ]   # this is the second variable timeseries  data [ 1 ]   ==   data [ 1 ,   : ]   # this is the first datapoint of the dataset (D-dimensional)  data [ 5 ,   3 ]   # this is the value of the third variable, at the 5th timepoint   Use  convert(Matrix, dataset)  to create a  Matrix , and  convert(Dataset, matrix)  to create a  Dataset  from a matrix.  Notice:    convert(Dataset, matrix)  assumes that each column of the matrix represents one dynamic variable. If instead each column of the matrix represents a datapoint, use  reinterpret(Dataset, matrix) .  If you have various timeseries vectors  x, y, z, ...  pass them like  Dataset(x, y, z, ...) .`  source   In essence a  Dataset  is simply a container for a  Vector  of  Vector s, but only for cases where the all inner vectors are of equal size. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the  column  direction). It also offers a lot more functionality and pretty-printing. Besides the examples in the documentation string, you can also do:  data   =   timeseries ( hen ,   10000 )  for   point   in   data  # do stuff with each datapoint (vector with as many elements as system dimension)  end   All functions that manipulate and use data are expecting a  Dataset  instance. If given a matrix, they will first convert to  Dataset . This means that you should first convert your data to a  Dataset  if you want to call functions more than once, to avoid constantly converting.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/system_definition/#predefined-systems", 
            "text": "Predefined systems exist in the  Systems  submodule exported by  DynamicalSystems , in the form of functions that return a  DynamicalSystem . They are accessed like:  using   DynamicalSystems  ds   =   Systems . lorenz ( \u03c1   =   32.0 )  ts   =   timeseries ( ds ,   10.0 )   All of these functions have very similar documentation strings:   Call signature (parameters of the system are always passed as keyword arguments).  Equations of the system in  \\(\\LaTeX\\)  (how cool is that!).  Introductory text about what this system is and who introduced it first.  Couple of sentences that contain cool science info about the system.  Reference to the original papers.   So far, the predefined systems that exist in the  Systems  sub-module are:  #  DynamicalSystems.Systems.double_pendulum     Function .  double_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)  Famous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).  The variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].  Jacobian is not created! So no  lyapunovs  for you!  (please contribute the Jacobian and the e.o.m. in LaTeX :smile:)  source  #  DynamicalSystems.Systems.henon     Function .  henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 )   \\[\n\\begin{align*}\nx_{n+1}  = 1 - ax^2_n+y_n \\\\\ny_{n+1}   = bx_n\n\\end{align*}\n\\] The H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.  According to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible.  Default values are the ones used in the original paper.  [1] : M. H\u00e9non, Commun.Math. Phys.  50 , pp 69 (1976)  source  #  DynamicalSystems.Systems.logistic     Function .  logistic ( x0   =   rand ();   r   =   4.0 )   \\[\nx_{n+1} = rx_n(1-x_n)\n\\] The logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.  Originally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].  [1] : R. M. May, Nature  261 , pp 459 (1976)  [2] : M. J. Feigenbaum, J. Stat. Phys.  19 , pp 25 (1978)  source  #  DynamicalSystems.Systems.lorenz     Function .  lorenz ( u0 = [ 0.0 ,   10.0 ,   0.0 ];   \u03c3   =   10.0 ,   \u03c1   =   28.0 ,   \u03b2   =   8 / 3 )   \\[\n\\begin{align*}\n\\dot{X}  = \\sigma(Y-X) \\\\\n\\dot{Y}  = -XZ + \\rho X -Y \\\\\n\\dot{Z}  = XY - \\beta Z\n\\end{align*}\n\\] The famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.  Currently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.  [1] : E. N. Lorenz, J. atmos. Sci.  20 , pp 130 (1963)  source  #  DynamicalSystems.Systems.roessler     Function .  roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 )   \\[\n\\begin{align*}\n\\dot{x}  = -y-z \\\\\n\\dot{y}  = x+ay \\\\\n\\dot{z}  = -b + z(x-c)\n\\end{align*}\n\\] This three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the  lorenz  system and displays a (fractal) strange attractor.  However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  57A , pp 397 (1976)  source  #  DynamicalSystems.Systems.standardmap     Function .  standardmap ( u0 = 0.001 rand ( 2 );   k   =   0.971635 )   \\[\n\\begin{align*}\n\\theta_{n+1}  = \\theta_n + p_{n+1} \\\\\np_{n+1}  = p_n + k\\sin(\\theta_n)\n\\end{align*}\n\\] The standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.  The map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter  k  transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.  The default parameter  k  is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable  \u03b8  to be the first, and the angular momentum  p  to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).  [1] : B. V. Chirikov, Preprint N.  267 , Institute of Nuclear Physics, Novosibirsk (1969)  [2] : J. M. Greene, J. Math. Phys.  20 , pp 1183 (1979)  source  #  DynamicalSystems.Systems.towel     Function .  towel ( u0   =   [ 0.085 ,   - 0.121 ,   0.075 ])   \\[\n\\begin{align*}\nx_{n+1}  = a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1}  = 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1}  = 3.78 z_n (1-z_n) + b y_n\n\\end{align*}\n\\] The folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative lyapunov exponent.  The name comes from the fact that when plotted looks like a folded towel, in every projection.  Default values are the ones used in the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  71A , pp 155 (1979)  source", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/lyapunovs/", 
            "text": "Lyapunov Exponents\n\n\nLyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The \nWikipedia\n and the \nScholarpedia\n entries have a lot of valuable information about the history and usage of these quantities.\n\n\nThe naming comes after Aleksandr M. Lyapunov, a Russian mathematician/physicist that had major impact on the analysis of the stability of systems.\n\n\nThis page treats systems where the equations of motion are known. If instead you have numerical data, see the nonlinear \ntimeseries analysis page\n.\n\n\n\n\nLyapunov Spectrum\n\n\nThe function \nlyapunovs\n calculates the entire spectrum of the Lyapunov exponents of a system:\n\n\n#\n\n\nDynamicalSystems.lyapunovs\n \n \nFunction\n.\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n;\n \nkwargs\n...\n)\n \n-\n \n[\n\u03bb1\n,\n \n\u03bb2\n,\n \n...\n,\n \n\u03bbD\n]\n\n\n\n\n\n\nCalculate the spectrum of lyapunov [1] exponents of \nds\n by applying the QR-decomposition method \nN\n times (see method \"H2\" of [2], or directly the original paper(s) [3]). Returns a vector with the \nfinal\n values of the lyapunov exponents in descending order.\n\n\nKeyword Arguments:\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\ndt = 1.0\n : (only for continuous) Time of individual evolutions between sucessive orthonormalization steps.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntimeseries\n for more info).\n\n\n\n\n[1] : A. M. Lyapunov, \nThe General Problem of the Stability of Motion\n, Taylor \n Francis (1992)\n\n\n[2] : K. Geist \net al.\n, Progr. Theor. Phys. \n83\n, pp 875 (1990)\n\n\n[3] : G. Benettin \net al.\n, Meccanica \n15\n, pp 9-20 \n 21-30 (1980)\n\n\nsource\n\n\n\n\nAs you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the \nfolded towel map\n is calculated as:\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nds\n,\n \n10000\n)\n\n\n# result:\n\n\n[\n0.432253\n,\n \n0.371617\n,\n \n-\n3.29632\n]\n\n\n\n\n\n\nSimilarly, for a continuous system, e.g. the Lorenz system, you would do:\n\n\nusing\n \nDynamicalSystems\n\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n \n#this is not the original parameter!\n\n\nissubtype\n(\ntypeof\n(\nds\n),\n \nContinuousDS\n)\n \n# true\n\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nlor\n,\n \n10000\n,\n\n\ndt\n \n=\n \n0.1\n,\n \ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nabstol\n \n=\n \n1e-9\n,\n \n:\nreltol\n \n=\n \n1e-9\n))\n\n\n# result:\n\n\n[\n0.999176\n,\n \n0.000774754\n,\n \n-\n14.6666\n]\n\n\n\n\n\n\n\n\nMaximum Lyapunov Exponent\n\n\nThe function \nlyapunov\n calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of \nlyapunovs\n:\n\n\n#\n\n\nDynamicalSystems.lyapunov\n \n \nFunction\n.\n\n\nlyapunov\n(\nds\n::\nDynamicalSystem\n,\n \n\u03a4\n;\n \nkwargs\n...\n)\n \n-\n \n\u03bb\n\n\n\n\n\n\nCalculate the maximum lyapunov exponent \n\u03bb\n using a method due to Benettin [1], which simply evolves two neighboring trajectories while constantly rescaling one of the two. \nT\n  denotes the total time of evolution (should be \nInt\n for discrete systems).\n\n\nKeyword Arguments:\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems.\n\n\nd0 = 1e-9\n : Initial \n rescaling distance between two neighboring trajectories.\n\n\nthreshold = 10^3*d0\n : Threshold to rescale the test trajectory.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (\ntimeseries\n for more info).\n\n\ndt = 0.1\n : (only for continuous) Time of evolution between each check of distance exceeding the \nthreshold\n.\n\n\n\n\nThis function returns only the final value of the computation of the maximum lyapunov exponent. Use the function \nlyapunov_full\n to get a vector of the convergence of the computation versus time.\n\n\n[1] : G. Benettin \net al.\n, Phys. Rev. A \n14\n, pp 2338 (1976)\n\n\nsource\n\n\n\n\nFor example:\n\n\nusing\n \nDynamicalSystems\n\n\n\nhenon\n \n=\n \nSystems\n.\nhenon\n()\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nhenon\n,\n \n10000\n,\n \nd0\n \n=\n \n1e-7\n,\n \nthreshold\n \n=\n \n1e-4\n,\n \nTtr\n \n=\n \n100\n)\n\n\n# result:\n\n\n0.42011626111385747\n\n\n\n\n\n\nThe same is done for continuous systems:\n\n\nusing\n \nDynamicalSystems\n,\n \nOrdinaryDiffEq\n\n\n\nross\n \n=\n \nSystems\n.\nroessler\n(\na\n \n=\n \n0.1\n,\n \nb\n \n=\n \n0.1\n,\n \nc\n \n=\n \n14.0\n)\n \n#not original parameters\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nross\n,\n \n10000\n,\n \ndt\n \n=\n \n0.5\n,\n \ndiff_eq_kwargs\n \n=\n \nDict\n(\n:\nsolver\n \n=\n \nVern8\n()))\n\n\n# result:\n\n\n0.06957484163052223\n\n\n\n\n\n\n\n\nConvergence Timeseries\n\n\nThe above functions converge to values with increasing time. One may want to see the convergence timeseries of the Lyapunov exponents for better fine-tuning of parameters of the algorithms.\n\n\nThis feature is coming soon! See \nthis GitHub issue\n if you want to contribute.", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/lyapunovs/#lyapunov-exponents", 
            "text": "Lyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The  Wikipedia  and the  Scholarpedia  entries have a lot of valuable information about the history and usage of these quantities.  The naming comes after Aleksandr M. Lyapunov, a Russian mathematician/physicist that had major impact on the analysis of the stability of systems.  This page treats systems where the equations of motion are known. If instead you have numerical data, see the nonlinear  timeseries analysis page .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/lyapunovs/#lyapunov-spectrum", 
            "text": "The function  lyapunovs  calculates the entire spectrum of the Lyapunov exponents of a system:  #  DynamicalSystems.lyapunovs     Function .  lyapunovs ( ds :: DynamicalSystem ,   N ;   kwargs ... )   -   [ \u03bb1 ,   \u03bb2 ,   ... ,   \u03bbD ]   Calculate the spectrum of lyapunov [1] exponents of  ds  by applying the QR-decomposition method  N  times (see method \"H2\" of [2], or directly the original paper(s) [3]). Returns a vector with the  final  values of the lyapunov exponents in descending order.  Keyword Arguments:   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  dt = 1.0  : (only for continuous) Time of individual evolutions between sucessive orthonormalization steps.  diff_eq_kwargs = Dict()  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  timeseries  for more info).   [1] : A. M. Lyapunov,  The General Problem of the Stability of Motion , Taylor   Francis (1992)  [2] : K. Geist  et al. , Progr. Theor. Phys.  83 , pp 875 (1990)  [3] : G. Benettin  et al. , Meccanica  15 , pp 9-20   21-30 (1980)  source   As you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the  folded towel map  is calculated as:  using   DynamicalSystems  ds   =   Systems . towel ()  \u03bb\u03bb   =   lyapunovs ( ds ,   10000 )  # result:  [ 0.432253 ,   0.371617 ,   - 3.29632 ]   Similarly, for a continuous system, e.g. the Lorenz system, you would do:  using   DynamicalSystems  lor   =   Systems . lorenz ( \u03c1   =   32.0 )   #this is not the original parameter!  issubtype ( typeof ( ds ),   ContinuousDS )   # true  \u03bb\u03bb   =   lyapunovs ( lor ,   10000 ,  dt   =   0.1 ,   diff_eq_kwargs   =   Dict ( : abstol   =   1e-9 ,   : reltol   =   1e-9 ))  # result:  [ 0.999176 ,   0.000774754 ,   - 14.6666 ]", 
            "title": "Lyapunov Spectrum"
        }, 
        {
            "location": "/lyapunovs/#maximum-lyapunov-exponent", 
            "text": "The function  lyapunov  calculates the maximum lyapunov exponent of a system, much more efficiently than getting the first result of  lyapunovs :  #  DynamicalSystems.lyapunov     Function .  lyapunov ( ds :: DynamicalSystem ,   \u03a4 ;   kwargs ... )   -   \u03bb   Calculate the maximum lyapunov exponent  \u03bb  using a method due to Benettin [1], which simply evolves two neighboring trajectories while constantly rescaling one of the two.  T   denotes the total time of evolution (should be  Int  for discrete systems).  Keyword Arguments:   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems.  d0 = 1e-9  : Initial   rescaling distance between two neighboring trajectories.  threshold = 10^3*d0  : Threshold to rescale the test trajectory.  diff_eq_kwargs = Dict()  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package ( timeseries  for more info).  dt = 0.1  : (only for continuous) Time of evolution between each check of distance exceeding the  threshold .   This function returns only the final value of the computation of the maximum lyapunov exponent. Use the function  lyapunov_full  to get a vector of the convergence of the computation versus time.  [1] : G. Benettin  et al. , Phys. Rev. A  14 , pp 2338 (1976)  source   For example:  using   DynamicalSystems  henon   =   Systems . henon ()  \u03bb   =   lyapunov ( henon ,   10000 ,   d0   =   1e-7 ,   threshold   =   1e-4 ,   Ttr   =   100 )  # result:  0.42011626111385747   The same is done for continuous systems:  using   DynamicalSystems ,   OrdinaryDiffEq  ross   =   Systems . roessler ( a   =   0.1 ,   b   =   0.1 ,   c   =   14.0 )   #not original parameters  \u03bb   =   lyapunov ( ross ,   10000 ,   dt   =   0.5 ,   diff_eq_kwargs   =   Dict ( : solver   =   Vern8 ()))  # result:  0.06957484163052223", 
            "title": "Maximum Lyapunov Exponent"
        }, 
        {
            "location": "/lyapunovs/#convergence-timeseries", 
            "text": "The above functions converge to values with increasing time. One may want to see the convergence timeseries of the Lyapunov exponents for better fine-tuning of parameters of the algorithms.  This feature is coming soon! See  this GitHub issue  if you want to contribute.", 
            "title": "Convergence Timeseries"
        }, 
        {
            "location": "/entropies/", 
            "text": "Entropies and Dimensions\n\n\n\n\nEntropies\n\n\nIn the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known \nthermodynamic ones\n, used in Statistical Physics. Rather, they are more like the to the entropies of \ninformation theory\n, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.\n\n\nDynamicalSystems.jl\n defines a lot entropies, summarized in the following sections.\n\n\n\n\nGeneralized Entropy \n Co.\n\n\nThe generalized entropy is a concept mainly attributed to R\u00e9nyi (see below).\n\n\n#\n\n\nDynamicalSystems.genentropy\n \n \nFunction\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \n\u03b5\n,\n \ndataset\n)\n\n\n\n\n\n\nCompute the \n\u03b1\n order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length \n\u03b5\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \np\n::\nAbstractArray\n)\n\n\n\n\n\n\nCompute the entropy of an Array \np\n directly, assuming that \np\n is sum-normalized.\n\n\nlog base-e is used in both cases, i.e. units of \"nat\".\n\n\nThe R\u00e9nyi entropy\n\n\n\\[\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p_i^\\alpha\n\\]\ngeneralizes other known entropies, like e.g. the information entropy (\n\\(\\alpha = 1\\)\n, see \nthe\n Shannon paper [2]), the maximum entropy (\n\\(\\alpha=0\\)\n, also known as Hartley entropy), or the correlation entropy (\n\\(\\alpha = 2\\)\n, also known as collision entropy).\n\n\nThe following aliases are provided:\n\n\n\n\nrenyi = genentropy\n\n\nshannon(args...) = genentropy(1, args...)\n\n\nhartley(args...) = genentropy(0, args...)\n\n\n\n\n[1] : A. R\u00e9nyi, \nProceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability\n, pp 547 (1960)\n\n\n[2] : C. E. Shannon, Bell Systems Technical Journal \n27\n, pp 379 (1948)\n\n\nsource\n\n\n\n\nBasically, given a \ndataset\n you can partition it into boxes to calculate an entropy.\n\n\n\n\nWorried about memory overflow? Don't be!\n\n\nPartitioning the dataset (i.e. doing a \nhistogram\n) is in general a costly operation that depends exponentially on the number of dimensions of the system. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!\n\n\n\n\nThe function used internally is \nnon0hist\n:\n\n\n#\n\n\nDynamicalSystems.non0hist\n \n \nFunction\n.\n\n\nnon0hist\n(\n\u03b5\n,\n \ndataset\n)\n\n\n\n\n\n\nPartition a dataset into tabulated intervals (boxes) of size \n\u03b5\n and return the \nsum-normalized\n histogram in an \nunordered 1D form\n, \ndiscarding all zero\n elements. This method is extremely effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins.\n\n\nUse e.g. \nfit(Histogram, ...)\n from \nStatsBase\n if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\nsource\n\n\n\n\nIt typically outperforms traditional histograms by \nseveral orders of magnitude\n in both memory and speed. You can compare \nDynamicalSystems.perform_non0hist\n with \nfit(Histogram, ...)\n of \nStatsBase\n for specific numbers on your machine.\n\n\nFor example, the Shannon entropy of a coin-flip process should be one bit, \nby definition\n. Let's see...\n\n\nusing\n \nDynamicalSystems\n\n\ny\n \n=\n \nInt\n.\n(\nrand\n(\nBool\n,\n \n10000\n))\n \n# just some coin tosses\n\n\nsh\n \n=\n \nshannon\n(\n0.01\n,\n \ny\n)\n       \n# \u2261 genentropy(1, 0.01, y)\n\n\nisapprox\n(\nsh\n,\n \nlog\n(\n2\n),\n  \nrtol\n \n=\n \n1e-3\n)\n \n# true!\n\n\n\n\n\n\nBecause all entropies are calculated on base-e, the unit of measurement is \"nat\", and one bit is log(2)\u00d7nat.\n\n\n\n\nKolmogorov-Sinai Entropy\n\n\nTBA.\n\n\n\n\nAttractor Dimension Estimation\n\n\nThere are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the \nFractal dimension\n. This real number can offer a lot of information about the object that the dataset represents.\n\n\n\n\nGeneralized Dimensions \n Co.\n\n\nBased on the definition of the \ngeneralized entropy\n, one can calculate an appropriate dimension, called \ngeneralized dimension\n:\n\n\n#\n\n\nDynamicalSystems.generalized_dim\n \n \nFunction\n.\n\n\ngeneralized_dim(\u03b1, dataset) -\n D_\u03b1\n\n\n\n\n\nReturn the \n\u03b1\n order generalized dimension that corresponds to the given dataset. This quantity corresponds to the power law exponent of the scaling of the \ngenentropy\n versus the box size \n\u03b5\n.\n\n\nWARNING\n - This call performs a lot of automated steps:\n\n\n\n\nA vector of box sizes is decided by calling \nes = estimate_boxsizes(dataset)\n.\n\n\nFor each element of \nes\n the appropriate entropy is calculated, through \nd[i] = genentropy(\u03b1, es[i], dataset)\n. Let \nx = -log.(es)\n.\n\n\nThe curve d(x) is decomposed into linear regions, using \nlinear_regions(x, d)\n.\n\n\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the package \nLsqFit\n (see \nlinear_region\n).\n\n\nThis fitted slope is returned.\n\n\n\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\n\nThe following aliases are provided:\n\n\n\n\n\u03b1 = 0 : \nboxcounting_dim\n, \ncapacity_dim\n\n\n\u03b1 = 1 : \ninformation_dim\n\n\n\u03b1 = 2 : \ncorrelation_dim\n, \ncollision_dim\n\n\n\n\nsource\n\n\n\n\nAs stated clearly, this call performs a lot of automated steps. One is always better better of performing the steps one by one to attain maximum control.\n\n\nFor example, we will calculate the dimensions of the strange attractors of the \nH\u00e9non map\n and the \nLorenz system\n:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n(\n-\nrand\n(\n2\n))\n\n\nts\n \n=\n \ntimeseries\n(\nhen\n,\n \n200000\n)\n\n\nD_hen\n \n=\n \ninformation_dim\n(\nts\n)\n\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\nrand\n(\n3\n))\n\n\nts\n \n=\n \ntimeseries\n(\nlor\n,\n \n5000\n,\n \ndt\n \n=\n \n0.05\n)\n\n\nD_lor\n \n=\n \ncapacity_dim\n(\nts\n)\n\n\n\n\n\n\nYou will find that \nD_hen\n is around \n1.2\n and \nD_lor\n is around \n1.95\n, both of which \nare correct values\n. As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D \n56\n, pp 185-187 (1992)).\n\n\n\n\nKaplan-Yorke Dimension (aka Lyapunov Dimension)\n\n\n#\n\n\nDynamicalSystems.kaplanyorke_dim\n \n \nFunction\n.\n\n\nkaplanyorke_dim(lyapunovs::AbstractVector)\n\n\n\n\n\nCalculate the Kaplan-Yorke dimension \n1\n. This simply is the point where \ncumsum(lyapunovs)\n becomes zero (interpolated). Returns the length of the vector if the sum of the exponents never becomes negative.\n\n\n[1] :  J. Kaplan \n J. Yorke, \nChaotic behavior of multidimensional difference equations\n, Lecture Notes in Mathematics vol. \n730\n, Springer (1979)\n\n\nsource\n\n\n\n\nNotice that calling this function requires you to pass the lyapunov exponents in an ordered vector form (largest to smallest). Example:\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nD_kp\n \n=\n \nkaplanyorke_dim\n(\nlyapunovs\n(\nhen\n,\n \n200000\n))", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/entropies/#entropies-and-dimensions", 
            "text": "", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/entropies/#entropies", 
            "text": "In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known  thermodynamic ones , used in Statistical Physics. Rather, they are more like the to the entropies of  information theory , which represents information contained within a dataset, or information about the dimensional scaling of a dataset.  DynamicalSystems.jl  defines a lot entropies, summarized in the following sections.", 
            "title": "Entropies"
        }, 
        {
            "location": "/entropies/#generalized-entropy-co", 
            "text": "The generalized entropy is a concept mainly attributed to R\u00e9nyi (see below).  #  DynamicalSystems.genentropy     Function .  genentropy ( \u03b1 ,   \u03b5 ,   dataset )   Compute the  \u03b1  order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length  \u03b5 .  genentropy ( \u03b1 ,   p :: AbstractArray )   Compute the entropy of an Array  p  directly, assuming that  p  is sum-normalized.  log base-e is used in both cases, i.e. units of \"nat\".  The R\u00e9nyi entropy  \\[\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p_i^\\alpha\n\\] generalizes other known entropies, like e.g. the information entropy ( \\(\\alpha = 1\\) , see  the  Shannon paper [2]), the maximum entropy ( \\(\\alpha=0\\) , also known as Hartley entropy), or the correlation entropy ( \\(\\alpha = 2\\) , also known as collision entropy).  The following aliases are provided:   renyi = genentropy  shannon(args...) = genentropy(1, args...)  hartley(args...) = genentropy(0, args...)   [1] : A. R\u00e9nyi,  Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability , pp 547 (1960)  [2] : C. E. Shannon, Bell Systems Technical Journal  27 , pp 379 (1948)  source   Basically, given a  dataset  you can partition it into boxes to calculate an entropy.   Worried about memory overflow? Don't be!  Partitioning the dataset (i.e. doing a  histogram ) is in general a costly operation that depends exponentially on the number of dimensions of the system. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!   The function used internally is  non0hist :  #  DynamicalSystems.non0hist     Function .  non0hist ( \u03b5 ,   dataset )   Partition a dataset into tabulated intervals (boxes) of size  \u03b5  and return the  sum-normalized  histogram in an  unordered 1D form ,  discarding all zero  elements. This method is extremely effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins.  Use e.g.  fit(Histogram, ...)  from  StatsBase  if you wish to keep information about the edges of the binning as well as the zero elements.  source   It typically outperforms traditional histograms by  several orders of magnitude  in both memory and speed. You can compare  DynamicalSystems.perform_non0hist  with  fit(Histogram, ...)  of  StatsBase  for specific numbers on your machine.  For example, the Shannon entropy of a coin-flip process should be one bit,  by definition . Let's see...  using   DynamicalSystems  y   =   Int . ( rand ( Bool ,   10000 ))   # just some coin tosses  sh   =   shannon ( 0.01 ,   y )         # \u2261 genentropy(1, 0.01, y)  isapprox ( sh ,   log ( 2 ),    rtol   =   1e-3 )   # true!   Because all entropies are calculated on base-e, the unit of measurement is \"nat\", and one bit is log(2)\u00d7nat.", 
            "title": "Generalized Entropy &amp; Co."
        }, 
        {
            "location": "/entropies/#kolmogorov-sinai-entropy", 
            "text": "TBA.", 
            "title": "Kolmogorov-Sinai Entropy"
        }, 
        {
            "location": "/entropies/#attractor-dimension-estimation", 
            "text": "There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the  Fractal dimension . This real number can offer a lot of information about the object that the dataset represents.", 
            "title": "Attractor Dimension Estimation"
        }, 
        {
            "location": "/entropies/#generalized-dimensions-co", 
            "text": "Based on the definition of the  generalized entropy , one can calculate an appropriate dimension, called  generalized dimension :  #  DynamicalSystems.generalized_dim     Function .  generalized_dim(\u03b1, dataset) -  D_\u03b1  Return the  \u03b1  order generalized dimension that corresponds to the given dataset. This quantity corresponds to the power law exponent of the scaling of the  genentropy  versus the box size  \u03b5 .  WARNING  - This call performs a lot of automated steps:   A vector of box sizes is decided by calling  es = estimate_boxsizes(dataset) .  For each element of  es  the appropriate entropy is calculated, through  d[i] = genentropy(\u03b1, es[i], dataset) . Let  x = -log.(es) .  The curve d(x) is decomposed into linear regions, using  linear_regions(x, d) .  The biggest linear region is chosen, and a fit for the slope of that region is performed using the package  LsqFit  (see  linear_region ).  This fitted slope is returned.   By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.  The following aliases are provided:   \u03b1 = 0 :  boxcounting_dim ,  capacity_dim  \u03b1 = 1 :  information_dim  \u03b1 = 2 :  correlation_dim ,  collision_dim   source   As stated clearly, this call performs a lot of automated steps. One is always better better of performing the steps one by one to attain maximum control.  For example, we will calculate the dimensions of the strange attractors of the  H\u00e9non map  and the  Lorenz system :  using   DynamicalSystems  hen   =   Systems . henon ( - rand ( 2 ))  ts   =   timeseries ( hen ,   200000 )  D_hen   =   information_dim ( ts )  lor   =   Systems . lorenz ( rand ( 3 ))  ts   =   timeseries ( lor ,   5000 ,   dt   =   0.05 )  D_lor   =   capacity_dim ( ts )   You will find that  D_hen  is around  1.2  and  D_lor  is around  1.95 , both of which  are correct values . As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D  56 , pp 185-187 (1992)).", 
            "title": "Generalized Dimensions &amp; Co."
        }, 
        {
            "location": "/entropies/#kaplan-yorke-dimension-aka-lyapunov-dimension", 
            "text": "#  DynamicalSystems.kaplanyorke_dim     Function .  kaplanyorke_dim(lyapunovs::AbstractVector)  Calculate the Kaplan-Yorke dimension  1 . This simply is the point where  cumsum(lyapunovs)  becomes zero (interpolated). Returns the length of the vector if the sum of the exponents never becomes negative.  [1] :  J. Kaplan   J. Yorke,  Chaotic behavior of multidimensional difference equations , Lecture Notes in Mathematics vol.  730 , Springer (1979)  source   Notice that calling this function requires you to pass the lyapunov exponents in an ordered vector form (largest to smallest). Example:  hen   =   Systems . henon ()  D_kp   =   kaplanyorke_dim ( lyapunovs ( hen ,   200000 ))", 
            "title": "Kaplan-Yorke Dimension (aka Lyapunov Dimension)"
        }, 
        {
            "location": "/nlts/", 
            "text": "Nonlinear Timeseries Analysis\n\n\n\n\nDelay Coordinates Reconstruction\n\n\nA mono-dimensional timeseries recorded in some manner from a dynamcal system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as \ndelay coordinates embedding\n.\n\n\nIn \nDynamicalSystems.jl\n this is done through the \nreconstruct\n interface:\n\n\n#\n\n\nDynamicalSystems.Reconstruction\n \n \nType\n.\n\n\nReconstruction{V, T, D, \u03c4}\n\n\n\n\n\nD\n-dimensional reconstruction object with delay \n\u03c4\n, created from a vector \ns::V\n. \ns\n is the only field of \nReconstruction\n.\n\n\nThe \nn\nth row of this object is formally the \nD\n-dimensional vector:\n\n\n\\[\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\\]\nSee \nreconstruct\n for usage.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.reconstruct\n \n \nFunction\n.\n\n\nreconstruct(s::AbstractVector, D::Int, \u03c4::Int) -\n R::Reconstruction\n\n\n\n\n\nCreate and return an efficient \nReconstruction\n data structure that serves as the delay coordinates embedding [1, 2] reconstruction of the signal \ns\n. The reconstuction has dimension \nD\n and delay \n\u03c4\n (measured in indices). This object can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper \nD\n and \n\u03c4\n [1, 2].\n\n\nR\n interfaces \ns\n and can be accessed similarly to a \nDataset\n:\n\n\nR\n \n=\n \nreconstruct\n(\ns\n,\n \n4\n,\n \n1\n)\n \n# delay coords. reconstruction of dimension 4 and delay 1\n\n\nR\n[\n3\n]\n \n# third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])\n\n\nR\n[\n1\n,\n \n2\n]\n \n# Second element of first point of reconstruction, \u2261 s[2]\n\n\n\n\n\n\n(this is only smart indexing, no Vectors or SVectors are created during the construction of \nR\n)\n\n\nR\n can also be given to all functions that accept a \nDataset\n, but it is first converted to a \nDataset\n at each call. This means that you should first convert it yourself, using \nDataset(R)\n if you call functions like \ngeneralized_dim\n multiple times.\n\n\nThe functions \ndimension(R)\n and \ndelay(R)\n return \nD\n and \n\u03c4\n respectively. Notice that \nlength(R) = length(s) - (D-1)*\u03c4\n (i.e. the amount of D-dimensional points \"contained\" in \nR\n) but \nsize(R) = (length(R), D)\n.\n\n\n[1] : F. Takens, \nDetecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence\n, Lecture Notes in Mathematics \n366\n, Springer (1981)\n\n\n[2] : T. Sauer \net al.\n, J. Stat. Phys. \n65\n, pp 579 (1991)\n\n\nsource\n\n\n\n\nAs an example, let's pass a \nReconstruction\n into e.g. a method that calculates the attractor dimension:\n\n\nusing\n \nDynamicalSystems\n\n\nhe\n \n=\n \nSystems\n.\nhenon\n()\n\n\nts\n \n=\n \ntimeseries\n(\nhe\n,\n \n100000\n)\n\n\nD1\n \n=\n \ninformation_dim\n(\nts\n)\n \n# around 1.20\n\n\nx\n \n=\n \nts\n[\n:\n,\n \n1\n]\n \n# some \nrecorded\n timeseries\n\n\nR\n \n=\n \nreconstruct\n(\nx\n,\n \n2\n,\n \n1\n)\n \n# delay coords. reconstruction of dimension 2 and delay 1\n\n\nR\n[\n1\n]\n \n# first point of reconstruction, \u2261 (x[1], x[2])\n\n\nR\n[\n:\n,\n \n2\n]\n \n# Second COLUMN of the reconstruction, \u2261 x[2:end] since \u03c4=1\n\n\nD2\n \n=\n \ninformation_dim\n(\nR\n)\n \n#around 1.20\n\n\nprintln\n(\nD2 - D1 = \n$\n(\nabs\n(\nD2\n-\n \nD1\n))\n)\n\n\n# Prints something like 0.0032000971757613073\n\n\n\n\n\n\nThe 2 numbers \nD1\n and \nD2\n are \nvery close\n, but of course I knew before-hand good parameter values for \nD\n and \n\u03c4\n (I cheated, huhu!).\n\n\n\n\nNumerical Lyapunov Estimation\n\n\nGiven any timeseries, one can first \nreconstruct\n it, and then calculate a maximum lyapunov exponent for it, provided that the system the timeseries was recorded from actually exhibits exponential separation of nearby trajectories. This is done with\n\n\n#\n\n\nDynamicalSystems.numericallyapunov\n \n \nFunction\n.\n\n\nnumericallyapunov\n(\nR\n::\nReconstruction\n,\n \nks\n;\n  \nrefstates\n,\n \ndistance\n,\n \nmethod\n)\n\n\n\n\n\n\nReturn \nE = [E(k) for k \u2208 ks]\n, where \nE(k)\n is the average logarithmic distance for nearby states that are evolved in time for \nk\n steps. If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold:\n\n\n\\[\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\\]\nfor a \nwell defined region\n in the \nk\n axis, where \n\\(\\lambda\\)\n is the approximated maximum Lyapunov exponent. \n\u0394t\n is the time between samples in the original timeseries. You can use \nlinear_region(ks, E)\n to identify the slope immediatelly, assuming you have choosen sufficiently small \nks\n such that the linear scaling region is bigger than the saturated region.\n\n\nThe algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index \nk\n increases. The average of the above over all neighborhood states over all reference states is the returned result. Notice that this linear scaling region (if it exists) is very \"short\" versus \nk\n due to no states being arbitrarily close and nonlinear folding taking place. One should then be careful to choose a sufficiently small \nks\n range.\n\n\nThe following keywords tune the algorithm behavior:\n\n\n\n\nrefstates::AbstractVector{Int} = 1:(length(R) - length(ks))\n : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in \nrefstates\n.\n\n\ndistance::Metric = Cityblock()\n : The distance function used in the logarithmic distance of nearby states. The allowed distances are \nCityblock()\n and \nEuclidean()\n from the package \nDistances.jl\n (re-exported here). See below for more info on this choice which has fundamental impact on the algorithm.\n\n\nmethod::AbstractNeighborhood = FixedMassNeighborhood(1)\n : The method to be used when evaluating the neighborhood of each reference state. See \nAbstractNeighborhood\n for more info on this choice.\n\n\n\n\nIf the \nMetric\n is \nEuclidean()\n then calculate the Euclidean distance of the full \nD\n-dimensional points (distance \n\\(d_E\\)\n in ref. [1]). If however the \nMetric\n is \nCityblock()\n, calculate the absolute distance of \nonly the first elements\n of the \nm+k\n and \nn+k\n points of the reconstruction \nR\n, which are the \nm+k\n and \nn+k\n elements of vector \nR.s\n (distance \n\\(d_F\\)\n in ref. [1]). Notice that the distances used are defined in the package \nDistances.jl\n, but are re-exported in \nDynamicalSystems.jl\n for ease-of-use (the distances are used for dispatch purposes \nonly\n).\n\n\nIt is shown in [1] that the second type of distance function makes little difference in the lyapunov estimation versus e.g. the Euclidean distance, but it is \nmuch cheaper to evaluate\n, you only need to perform one subtraction and one absolute value!\n\n\nThis function assumes that the Theiler window (see [1]) is the same as the delay time: \n\\(w  = \\tau\\)\n.\n\n\n[1] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 1 (section 1.3.2), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n[2] : Kantz, H., Phys. Lett. A \n185\n, pp 77\u201387 (1994)\n\n\nsource\n\n\n\n\n\n\nNeighborhoods\n\n\nThe function \nnumericallyapunov\n has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.\n\n\nThe methods for the neighborhoods are subtypes of \nAbstractNeighborhood\n, and offer a convenient way to find neighboring points to a given point in a dataset.\n\n\n#\n\n\nDynamicalSystems.AbstractNeighborhood\n \n \nType\n.\n\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\n\nConcrete subtypes:\n\n\n\n\nFixedMassNeighborhood(K::Int)\n  : The neighborhood of a point consists of the \nK\n nearest neighbors of the point.\n\n\nFixedSizeNeighborhood(\u03f5::Real)\n : The neighborhood of a point consists of all neighbors that have distance \n \n\u03f5\n from the point.\n\n\n\n\nNotice that these distances are always computed using the \nEuclidean()\n distance in \nD\n-dimensional space, irrespectively of the \ndistance\n used in the function \nnumericallyapunov\n.\n\n\nSee also \nneighborhood\n or \nnumericallyapunov\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.neighborhood\n \n \nFunction\n.\n\n\nneighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)\n\n\n\n\n\nReturn a vector of indices which are the neighborhood of \npoint\n, whose index in the original data is \nn\n. Both \npoint\n and \nn\n must be provided because the \ntree\n has indices in different sorting (thus making \ntree.data[n]\n incorrect). The \nmethod\n can be a subtype of \nAbstractNeighborhood\n (see its documentation string for more).\n\n\nneighborhood\n can be used for \nany\n dataset. Just do:\n\n\nR\n \n=\n \nsome_dataset\n\n\ntree\n \n=\n \nKDTree\n(\nR\n)\n\n\nneigh\n \n=\n \nneighborhood\n(\nn\n,\n \nR\n[\nn\n],\n \ntree\n,\n \nmethod\n)\n\n\n\n\n\n\nwhere \nR\n can be \neither\n a \nDataset\n or a \nReconstruction\n.\n\n\nNotice that the distances in the trees are always computed using the \nEuclidean()\n distance in \nD\n-dimensional space, irrespectively of the \ndistance\n used in the \nnumericallyapunov\n function.\n\n\nneighborhood\n \nsimply interfaces\n the functions \nknn\n and \ninrange\n from \nNearestNeighbors.jl\n by using the last argument, \nmethod\n.\n\n\nsource\n\n\n\n\nAs you can see, the function \nneighborhood\n is generally applicable!\n\n\n\n\nExample of Numerical Lyapunov computation\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntimeseries\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\nks\n \n=\n \n1\n:\n20\n\n\n\u211c\n \n=\n \n1\n:\n10000\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n6\n))\n\n\ni\n \n=\n \n1\n\n\n\nfor\n \n(\ni\n,\n \ndi\n)\n \nin\n \nenumerate\n([\nEuclidean\n(),\n \nCityblock\n()])\n\n  \nsubplot\n(\n1\n,\n \n2\n,\n \ni\n)\n\n  \ni\n+=\n1\n\n  \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n)\n\n\n  \ntitle\n(\nDistance: \n$\n(\ndi\n)\n,\n \nsize\n \n=\n \n18\n)\n\n  \nfor\n \nD\n \nin\n \n[\n2\n,\n \n4\n,\n \n7\n]\n\n    \nR\n \n=\n \nreconstruct\n(\nx\n,\n \nD\n,\n \n1\n)\n\n    \nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n;\n\n    \nrefstates\n \n=\n \n\u211c\n,\n \ndistance\n \n=\n \ndi\n,\n \nmethod\n \n=\n \nmethod\n)\n\n    \n# The following operation:\n\n    \n\u0394t\n \n=\n \n1\n\n    \n\u03bb\n \n=\n \nlinear_region\n(\nks\n.*\n\u0394t\n,\n \nE\n)[\n2\n]\n\n    \n# gives the linear slope, i.e. the Lyapunov exponent\n\n    \nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$D\n, \u03bb=\n$\n(\nround\n(\n\u03bb\n,\n \n3\n))\n)\n\n    \nlegend\n()\n\n    \ntight_layout\n()\n\n  \nend\n\n\n\n\nend\n\n\n\n\n\n\nwhich gives the result \n\n\n\n\nBad Time-axis (\nks\n) length\n\n\n\n\nLarge \nks\n\n\nEven though it was stressed in the documentation string of \nnumericallyapunov\n, it simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!\n\n\n\n\nLet's revisit the example of the previous section:\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntimeseries\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\n\n\n\nThe timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following\n\n\nks\n \n=\n \n1\n:\n100\n\n\nR\n \n=\n \nreconstruct\n(\nx\n,\n \n2\n,\n \n1\n)\n\n\nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n,\n \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n))\n\n\nfigure\n()\n\n\nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n])\n\n\nprintln\n(\nLyappunov: \n,\n \nlinear_region\n(\nks\n,\n \nE\n)[\n2\n])\n\n\n\n\n\n\ngives this plot: \n and prints \"Lyapunov: 0.4161...\".\n\n\nNotice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function \nlinear_region\n would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)\n\n\n\n\nCase of a Continuous system\n\n\nTo-do.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/nlts/#nonlinear-timeseries-analysis", 
            "text": "", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/nlts/#delay-coordinates-reconstruction", 
            "text": "A mono-dimensional timeseries recorded in some manner from a dynamcal system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as  delay coordinates embedding .  In  DynamicalSystems.jl  this is done through the  reconstruct  interface:  #  DynamicalSystems.Reconstruction     Type .  Reconstruction{V, T, D, \u03c4}  D -dimensional reconstruction object with delay  \u03c4 , created from a vector  s::V .  s  is the only field of  Reconstruction .  The  n th row of this object is formally the  D -dimensional vector:  \\[\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\\] See  reconstruct  for usage.  source  #  DynamicalSystems.reconstruct     Function .  reconstruct(s::AbstractVector, D::Int, \u03c4::Int) -  R::Reconstruction  Create and return an efficient  Reconstruction  data structure that serves as the delay coordinates embedding [1, 2] reconstruction of the signal  s . The reconstuction has dimension  D  and delay  \u03c4  (measured in indices). This object can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper  D  and  \u03c4  [1, 2].  R  interfaces  s  and can be accessed similarly to a  Dataset :  R   =   reconstruct ( s ,   4 ,   1 )   # delay coords. reconstruction of dimension 4 and delay 1  R [ 3 ]   # third point of reconstruction, \u2261 (s[3], s[4], s[5], s[6])  R [ 1 ,   2 ]   # Second element of first point of reconstruction, \u2261 s[2]   (this is only smart indexing, no Vectors or SVectors are created during the construction of  R )  R  can also be given to all functions that accept a  Dataset , but it is first converted to a  Dataset  at each call. This means that you should first convert it yourself, using  Dataset(R)  if you call functions like  generalized_dim  multiple times.  The functions  dimension(R)  and  delay(R)  return  D  and  \u03c4  respectively. Notice that  length(R) = length(s) - (D-1)*\u03c4  (i.e. the amount of D-dimensional points \"contained\" in  R ) but  size(R) = (length(R), D) .  [1] : F. Takens,  Detecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence , Lecture Notes in Mathematics  366 , Springer (1981)  [2] : T. Sauer  et al. , J. Stat. Phys.  65 , pp 579 (1991)  source   As an example, let's pass a  Reconstruction  into e.g. a method that calculates the attractor dimension:  using   DynamicalSystems  he   =   Systems . henon ()  ts   =   timeseries ( he ,   100000 )  D1   =   information_dim ( ts )   # around 1.20  x   =   ts [ : ,   1 ]   # some  recorded  timeseries  R   =   reconstruct ( x ,   2 ,   1 )   # delay coords. reconstruction of dimension 2 and delay 1  R [ 1 ]   # first point of reconstruction, \u2261 (x[1], x[2])  R [ : ,   2 ]   # Second COLUMN of the reconstruction, \u2261 x[2:end] since \u03c4=1  D2   =   information_dim ( R )   #around 1.20  println ( D2 - D1 =  $ ( abs ( D2 -   D1 )) )  # Prints something like 0.0032000971757613073   The 2 numbers  D1  and  D2  are  very close , but of course I knew before-hand good parameter values for  D  and  \u03c4  (I cheated, huhu!).", 
            "title": "Delay Coordinates Reconstruction"
        }, 
        {
            "location": "/nlts/#numerical-lyapunov-estimation", 
            "text": "Given any timeseries, one can first  reconstruct  it, and then calculate a maximum lyapunov exponent for it, provided that the system the timeseries was recorded from actually exhibits exponential separation of nearby trajectories. This is done with  #  DynamicalSystems.numericallyapunov     Function .  numericallyapunov ( R :: Reconstruction ,   ks ;    refstates ,   distance ,   method )   Return  E = [E(k) for k \u2208 ks] , where  E(k)  is the average logarithmic distance for nearby states that are evolved in time for  k  steps. If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold:  \\[\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\\] for a  well defined region  in the  k  axis, where  \\(\\lambda\\)  is the approximated maximum Lyapunov exponent.  \u0394t  is the time between samples in the original timeseries. You can use  linear_region(ks, E)  to identify the slope immediatelly, assuming you have choosen sufficiently small  ks  such that the linear scaling region is bigger than the saturated region.  The algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index  k  increases. The average of the above over all neighborhood states over all reference states is the returned result. Notice that this linear scaling region (if it exists) is very \"short\" versus  k  due to no states being arbitrarily close and nonlinear folding taking place. One should then be careful to choose a sufficiently small  ks  range.  The following keywords tune the algorithm behavior:   refstates::AbstractVector{Int} = 1:(length(R) - length(ks))  : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in  refstates .  distance::Metric = Cityblock()  : The distance function used in the logarithmic distance of nearby states. The allowed distances are  Cityblock()  and  Euclidean()  from the package  Distances.jl  (re-exported here). See below for more info on this choice which has fundamental impact on the algorithm.  method::AbstractNeighborhood = FixedMassNeighborhood(1)  : The method to be used when evaluating the neighborhood of each reference state. See  AbstractNeighborhood  for more info on this choice.   If the  Metric  is  Euclidean()  then calculate the Euclidean distance of the full  D -dimensional points (distance  \\(d_E\\)  in ref. [1]). If however the  Metric  is  Cityblock() , calculate the absolute distance of  only the first elements  of the  m+k  and  n+k  points of the reconstruction  R , which are the  m+k  and  n+k  elements of vector  R.s  (distance  \\(d_F\\)  in ref. [1]). Notice that the distances used are defined in the package  Distances.jl , but are re-exported in  DynamicalSystems.jl  for ease-of-use (the distances are used for dispatch purposes  only ).  It is shown in [1] that the second type of distance function makes little difference in the lyapunov estimation versus e.g. the Euclidean distance, but it is  much cheaper to evaluate , you only need to perform one subtraction and one absolute value!  This function assumes that the Theiler window (see [1]) is the same as the delay time:  \\(w  = \\tau\\) .  [1] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 1 (section 1.3.2), Lecture Notes in Physics  915 , Springer (2016)  [2] : Kantz, H., Phys. Lett. A  185 , pp 77\u201387 (1994)  source", 
            "title": "Numerical Lyapunov Estimation"
        }, 
        {
            "location": "/nlts/#neighborhoods", 
            "text": "The function  numericallyapunov  has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.  The methods for the neighborhoods are subtypes of  AbstractNeighborhood , and offer a convenient way to find neighboring points to a given point in a dataset.  #  DynamicalSystems.AbstractNeighborhood     Type .  Supertype of methods for deciding the neighborhood of points for a given point.  Concrete subtypes:   FixedMassNeighborhood(K::Int)   : The neighborhood of a point consists of the  K  nearest neighbors of the point.  FixedSizeNeighborhood(\u03f5::Real)  : The neighborhood of a point consists of all neighbors that have distance    \u03f5  from the point.   Notice that these distances are always computed using the  Euclidean()  distance in  D -dimensional space, irrespectively of the  distance  used in the function  numericallyapunov .  See also  neighborhood  or  numericallyapunov .  source  #  DynamicalSystems.neighborhood     Function .  neighborhood(n, point, tree::KDTree, method::AbstractNeighborhood)  Return a vector of indices which are the neighborhood of  point , whose index in the original data is  n . Both  point  and  n  must be provided because the  tree  has indices in different sorting (thus making  tree.data[n]  incorrect). The  method  can be a subtype of  AbstractNeighborhood  (see its documentation string for more).  neighborhood  can be used for  any  dataset. Just do:  R   =   some_dataset  tree   =   KDTree ( R )  neigh   =   neighborhood ( n ,   R [ n ],   tree ,   method )   where  R  can be  either  a  Dataset  or a  Reconstruction .  Notice that the distances in the trees are always computed using the  Euclidean()  distance in  D -dimensional space, irrespectively of the  distance  used in the  numericallyapunov  function.  neighborhood   simply interfaces  the functions  knn  and  inrange  from  NearestNeighbors.jl  by using the last argument,  method .  source   As you can see, the function  neighborhood  is generally applicable!", 
            "title": "Neighborhoods"
        }, 
        {
            "location": "/nlts/#example-of-numerical-lyapunov-computation", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . henon ()  data   =   timeseries ( ds ,   100000 )  x   =   data [ : ,   1 ]  ks   =   1 : 20  \u211c   =   1 : 10000  fig   =   figure ( figsize = ( 10 , 6 ))  i   =   1  for   ( i ,   di )   in   enumerate ([ Euclidean (),   Cityblock ()]) \n   subplot ( 1 ,   2 ,   i ) \n   i += 1 \n   method   =   FixedMassNeighborhood ( 2 ) \n\n   title ( Distance:  $ ( di ) ,   size   =   18 ) \n   for   D   in   [ 2 ,   4 ,   7 ] \n     R   =   reconstruct ( x ,   D ,   1 ) \n     E   =   numericallyapunov ( R ,   ks ; \n     refstates   =   \u211c ,   distance   =   di ,   method   =   method ) \n     # The following operation: \n     \u0394t   =   1 \n     \u03bb   =   linear_region ( ks .* \u0394t ,   E )[ 2 ] \n     # gives the linear slope, i.e. the Lyapunov exponent \n     plot ( ks - 1 ,   E - E [ 1 ],   label   =   D= $D , \u03bb= $ ( round ( \u03bb ,   3 )) ) \n     legend () \n     tight_layout () \n   end  end   which gives the result", 
            "title": "Example of Numerical Lyapunov computation"
        }, 
        {
            "location": "/nlts/#bad-time-axis-ks-length", 
            "text": "Large  ks  Even though it was stressed in the documentation string of  numericallyapunov , it simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!   Let's revisit the example of the previous section:  ds   =   Systems . henon ()  data   =   timeseries ( ds ,   100000 )  x   =   data [ : ,   1 ]   The timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following  ks   =   1 : 100  R   =   reconstruct ( x ,   2 ,   1 )  E   =   numericallyapunov ( R ,   ks ,   method   =   FixedMassNeighborhood ( 2 ))  figure ()  plot ( ks - 1 ,   E - E [ 1 ])  println ( Lyappunov:  ,   linear_region ( ks ,   E )[ 2 ])   gives this plot:   and prints \"Lyapunov: 0.4161...\".  Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function  linear_region  would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)", 
            "title": "Bad Time-axis (ks) length"
        }, 
        {
            "location": "/nlts/#case-of-a-continuous-system", 
            "text": "To-do.", 
            "title": "Case of a Continuous system"
        }, 
        {
            "location": "/periodicity/", 
            "text": "Detecting Stable and Unstable Periodic Orbits of Maps\n\n\nChaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the \nunstable periodic orbits\n existing in the chaotic sea.\n\n\nFinding unstable (or stable) periodic orbits in the sea of a discrete mapping analytically rapidly becomes \nimpossible\n for higher orders of Fixed Points. Fortunately there is a numeric algorithm due to Schmelcher \n Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at \nunstable\n ones and may not work for all stable ones.\n\n\nThe functions \nperiodicorbits\n and \nlambdamatrix\n implement the algorithm:\n\n\n#\n\n\nDynamicalSystems.periodicorbits\n \n \nFunction\n.\n\n\nperiodicorbits\n(\nds\n::\nDiscreteDS\n,\n \no\n,\n \nics\n \n[\n,\n \n\u03bb\ns\n,\n \nindss\n,\n \nsingss\n]\n \n;\n \nkwargs\n...)\n \n-\n \nFP\n\n\n\n\n\n\nFind stable and unstable fixed points \nFP\n the system \nds\n of order \no\n using the algorithm due to Schmelcher \n Diakonos [1], which turns unstable fixed points of the original map to dissipatively stable through the transformation:\n\n\n\\[\n\\mathbf{x}_{n+1} = S_k(\\mathbf{x}_n) = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(\\mathbf{f}^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\\]\nwith \n\\(\\mathbf{f}\\)\n = \nds.eom\n. \nics\n is a collection of initial conditions (container of \nSVector\ns) to be evolved.\n\n\nThe optional arguments \n\u03bbs, indss, singss\n \nmust be containers\n of appropriate values, besides \n\u03bbs\n which can also be a number. The elements of those lists are passed to: \nlambdamatrix(\u03bb, inds, sings)\n, which creates the appropriate \n\\(\\mathbf{\\Lambda}_k\\)\n matrix. See the documentation of \nlambdamatrix\n to choose these values properly. If these arguments are not given, a random permutation will be chosen for them (with \n\u03bb=0.001\n).\n\n\nAll initial conditions are evolved for all\n \n\\(\\mathbf{\\Lambda}_k\\)\n which can very quickly lead to extremely long computation times (so be wise on your choice of \n\u03bbs, indss, singss\n)!\n\n\nNotice that by appropriately choosing various values for \n\u03bb\n, one can sort periodic orbits from e.g. least unstable to most unstable, see [2] for details.\n\n\nThe following \nkeyword\n arguments fine-tune the algorithm convergence and output (i.c. stands for initial condition):\n\n\n\n\nmaxiters::Int = 100000\n : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\n\n\ndisttol = 1e-10\n : Distance tolerance. If the 2-norm of a previous state with  the next one is \n\u2264 disttol\n then it has converged to a fixed point.\n\n\ninftol = 10.0\n : If a state reaches \nnorm(state) \u2265 inftol\n it is assumed that  it has escaped to infinity (and is thus abandoned).\n\n\nroundtol::Int = 4\n : The found fixed points are rounded  to \nroundtol\n digits before pushed into the list of returned fixed points \nFP\n,  \nif\n they are not already contained in \nFP\n.  This is done so that \nFP\n doesn't contain duplicate fixed points (notice  that this has nothing to do with \ndisttol\n). Turn this to \n16\n to get the full  precision of the algorithm.\n\n\n\n\n[1] : P. Schmelcher \n F. K. Diakonos, Phys. Rev. Lett. \n78\n, pp 4733 (1997)\n\n\n[2] : F. K. Diakonos \net al.\n, Phys. Rev. Lett. \n81\n, pp 4349 (1998)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.lambdamatrix\n \n \nFunction\n.\n\n\nlambdamatrix(\u03bb, inds::Vector{Int}, sings) -\n \u039bk\n\n\n\n\n\nReturn the matrix \n\\(\\mathbf{\\Lambda}_k\\)\n used to create a new dynamical system with some unstable fixed points turned to stable (see \nperiodicorbits\n).\n\n\nArguments:\n\n\n\n\n\u03bb\n:Real\n : the multiplier of the \n\\(C_k\\)\n matrix, with \n0\n\u03bb\n1\n.\n\n\ninds::Vector{Int}\n : The \ni\nth entry of this vector gives the \nrow\n of the nonzero element of the \ni\nth column of \n\\(C_k\\)\n. Each element of \ninds\n \nmust be unique\n such that the resulting matrix is orthogonal \nand\n represents the group of special reflections and permutations.\n\n\nsings::Vector{\n:Real}\n : The element of the \ni\nth column of \n\\(C_k\\)\n is +1 if \nsigns[i] \n 0\n and -1 otherwise (\nsings\n can also be \nBool\n vector).\n\n\n\n\nDeciding the appropriate values for \n\u03bb, inds, sings\n is not trivial. However, in ref. [3] there is a lot of information that can help with that decision.\n\n\nlambdamatrix(\u03bb, D::Integer)\n\n\n\n\n\nCreate a random \n\\(\\mathbf{\\Lambda}_k\\)\n by randomly generating an \ninds\n and a \nsings\n from all possible combinations. The \ncollections\n of all these combinations can be obtained by:\n\n\nindperms\n,\n \nsingperms\n \n=\n \nlambdaperms\n(\nD\n)\n\n\n\n\n\n\n[3] : D. Pingel \net al.\n, Phys. Rev. E \n62\n, pp 2119 (2000)\n\n\nsource\n\n\n#\n\n\nDynamicalSystems.lambdaperms\n \n \nFunction\n.\n\n\nlambdaperms(D) -\n indperms, singperms\n\n\n\n\n\nReturn two collections that each contain all possible combinations of indices (total of \n\\(D!\\)\n) and sings (total of \n\\(2^D\\)\n) for dimension \nD\n (see \nlambdamatrix\n).\n\n\nsource\n\n\n\n\n\n\nStandard Map example\n\n\nFor example, let's find the fixed points of the \nStandard Map\n of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the \nsigns\n but only one for the \ninds\n. We will also only use one \n\u03bb\n value, and a 21\u00d721 density of initial conditions:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\nxs\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \n21\n);\n \nys\n \n=\n \ncopy\n(\nxs\n)\n\n\nics\n \n=\n \n[\nSVector\n{\n2\n}(\nx\n,\ny\n)\n \nfor\n \nx\n \nin\n \nxs\n \nfor\n \ny\n \nin\n \nys\n]\n\n\n\n# All permutations of [\u00b11, \u00b11]:\n\n\nsingss\n \n=\n \n[[\n+\n1\n,\n \n+\n1\n],\n \n[\n-\n1\n,\n \n-\n1\n],\n \n[\n+\n1\n,\n \n-\n1\n],\n \n[\n-\n1\n,\n \n+\n1\n]]\n\n\n# I know from personal research I only need this `inds`:\n\n\nindss\n \n=\n \n[[\n1\n,\n2\n]]\n \n# \n- must be container of vectors!!!\n\n\n\u03bbs\n \n=\n \n0.005\n \n# \n- only this allowed to not be vector (could also be vector)\n\n\n\norders\n \n=\n \n[\n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n,\n \n8\n]\n\n\nALLFP\n \n=\n \nAny\n[]\n\n\n\nttt\n \n=\n \ntime\n()\n\n\nfor\n \no\n \nin\n \norders\n\n    \nFP\n \n=\n \nperiodicorbits\n(\nds\n,\n \no\n,\n \nics\n,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n)\n\n    \npush!\n(\nALLFP\n,\n \nFP\n)\n\n\nend\n\n\nprintln\n(\nTotal time: \n$\n((\ntime\n()\n \n-\n \nttt\n)\n/\n60\n)\n mins.\n)\n\n\n# It takes a good 3-5 minutes to do all computations!\n\n\n\n\n# Create phase-space plot:\n\n\niters\n \n=\n \n1000\n\n\ndataset\n \n=\n \ntimeseries\n(\nds\n,\n \niters\n)\n\n\nfor\n \nx\n \nin\n \nxs\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\nx\n,\n \ny\n)\n\n        \nappend!\n(\ndataset\n,\n \ntimeseries\n(\nds\n,\n \niters\n))\n\n    \nend\n\n\nend\n\n\nm\n \n=\n \nMatrix\n(\ndataset\n)\n\n\nPyPlot\n.\nscatter\n(\nview\n(\nm\n,\n \n:\n,\n \n1\n),\n \nview\n(\nm\n,\n \n:\n,\n \n2\n),\n \ns\n=\n \n1\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nPyPlot\n.\nxlim\n(\nxs\n[\n1\n],\n \nxs\n[\nend\n])\n\n\nPyPlot\n.\nylim\n(\nys\n[\n1\n],\n \nys\n[\nend\n])\n\n\n\n# Plot fixed points:\n\n\nmarkers\n \n=\n \n[\nD\n,\n \n^\n,\n \ns\n,\n \np\n,\n \nh\n,\n \n8\n]\n\n\ncolors\n \n=\n \n[\nb\n,\n \ng\n,\n \nr\n,\n \nc\n,\n \nm\n,\n \ngrey\n]\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n6\n\n    \nFP\n \n=\n \nALLFP\n[\ni\n]\n\n    \no\n \n=\n \norders\n[\ni\n]\n\n    \nPyPlot\n.\nplot\n([\ns\n[\n1\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n \n[\ns\n[\n2\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n\n    \nmarker\n=\nmarkers\n[\ni\n],\n \ncolor\n \n=\n \ncolors\n[\ni\n],\n \nmarkersize\n=\n10.0\n \n+\n \n(\n8\n-\no\n),\n \nlinewidth\n=\n0.0\n,\n\n    \nlabel\n \n=\n \norder \n$o\n,\n \nmarkeredgecolor\n \n=\n \nyellow\n,\n \nmarkeredgewidth\n \n=\n \n0.5\n)\n\n\nend\n\n\nlegend\n(\nloc\n=\nupper right\n,\n \nframealpha\n=\n0.9\n)\n\n\nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n\nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\nAfter 3 to 5 minutes, you will get this plot: \n\n\nYou can confirm for yourself that this is correct, for many reasons:\n\n\n\n\nIt is the same \nfig. 12 of this publication\n.\n\n\nFixed points of order \n\\(n\\)\n are also fixed points of order \n\\(2n, 3n, 4n, ...\\)\n\n\nBesides fixed points of previous orders, \noriginal\n fixed points of order \n\\(n\\)\n come in \n\\(2n\\)\n-sized pairs (see e.g. order 5). This is correct because in a conservative map the fixed points must be pairs of elliptic-hyperbolic.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/periodicity/#detecting-stable-and-unstable-periodic-orbits-of-maps", 
            "text": "Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the  unstable periodic orbits  existing in the chaotic sea.  Finding unstable (or stable) periodic orbits in the sea of a discrete mapping analytically rapidly becomes  impossible  for higher orders of Fixed Points. Fortunately there is a numeric algorithm due to Schmelcher   Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at  unstable  ones and may not work for all stable ones.  The functions  periodicorbits  and  lambdamatrix  implement the algorithm:  #  DynamicalSystems.periodicorbits     Function .  periodicorbits ( ds :: DiscreteDS ,   o ,   ics   [ ,   \u03bb s ,   indss ,   singss ]   ;   kwargs ...)   -   FP   Find stable and unstable fixed points  FP  the system  ds  of order  o  using the algorithm due to Schmelcher   Diakonos [1], which turns unstable fixed points of the original map to dissipatively stable through the transformation:  \\[\n\\mathbf{x}_{n+1} = S_k(\\mathbf{x}_n) = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(\\mathbf{f}^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\\] with  \\(\\mathbf{f}\\)  =  ds.eom .  ics  is a collection of initial conditions (container of  SVector s) to be evolved.  The optional arguments  \u03bbs, indss, singss   must be containers  of appropriate values, besides  \u03bbs  which can also be a number. The elements of those lists are passed to:  lambdamatrix(\u03bb, inds, sings) , which creates the appropriate  \\(\\mathbf{\\Lambda}_k\\)  matrix. See the documentation of  lambdamatrix  to choose these values properly. If these arguments are not given, a random permutation will be chosen for them (with  \u03bb=0.001 ).  All initial conditions are evolved for all   \\(\\mathbf{\\Lambda}_k\\)  which can very quickly lead to extremely long computation times (so be wise on your choice of  \u03bbs, indss, singss )!  Notice that by appropriately choosing various values for  \u03bb , one can sort periodic orbits from e.g. least unstable to most unstable, see [2] for details.  The following  keyword  arguments fine-tune the algorithm convergence and output (i.c. stands for initial condition):   maxiters::Int = 100000  : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.  disttol = 1e-10  : Distance tolerance. If the 2-norm of a previous state with  the next one is  \u2264 disttol  then it has converged to a fixed point.  inftol = 10.0  : If a state reaches  norm(state) \u2265 inftol  it is assumed that  it has escaped to infinity (and is thus abandoned).  roundtol::Int = 4  : The found fixed points are rounded  to  roundtol  digits before pushed into the list of returned fixed points  FP ,   if  they are not already contained in  FP .  This is done so that  FP  doesn't contain duplicate fixed points (notice  that this has nothing to do with  disttol ). Turn this to  16  to get the full  precision of the algorithm.   [1] : P. Schmelcher   F. K. Diakonos, Phys. Rev. Lett.  78 , pp 4733 (1997)  [2] : F. K. Diakonos  et al. , Phys. Rev. Lett.  81 , pp 4349 (1998)  source  #  DynamicalSystems.lambdamatrix     Function .  lambdamatrix(\u03bb, inds::Vector{Int}, sings) -  \u039bk  Return the matrix  \\(\\mathbf{\\Lambda}_k\\)  used to create a new dynamical system with some unstable fixed points turned to stable (see  periodicorbits ).  Arguments:   \u03bb :Real  : the multiplier of the  \\(C_k\\)  matrix, with  0 \u03bb 1 .  inds::Vector{Int}  : The  i th entry of this vector gives the  row  of the nonzero element of the  i th column of  \\(C_k\\) . Each element of  inds   must be unique  such that the resulting matrix is orthogonal  and  represents the group of special reflections and permutations.  sings::Vector{ :Real}  : The element of the  i th column of  \\(C_k\\)  is +1 if  signs[i]   0  and -1 otherwise ( sings  can also be  Bool  vector).   Deciding the appropriate values for  \u03bb, inds, sings  is not trivial. However, in ref. [3] there is a lot of information that can help with that decision.  lambdamatrix(\u03bb, D::Integer)  Create a random  \\(\\mathbf{\\Lambda}_k\\)  by randomly generating an  inds  and a  sings  from all possible combinations. The  collections  of all these combinations can be obtained by:  indperms ,   singperms   =   lambdaperms ( D )   [3] : D. Pingel  et al. , Phys. Rev. E  62 , pp 2119 (2000)  source  #  DynamicalSystems.lambdaperms     Function .  lambdaperms(D) -  indperms, singperms  Return two collections that each contain all possible combinations of indices (total of  \\(D!\\) ) and sings (total of  \\(2^D\\) ) for dimension  D  (see  lambdamatrix ).  source", 
            "title": "Detecting Stable and Unstable Periodic Orbits of Maps"
        }, 
        {
            "location": "/periodicity/#standard-map-example", 
            "text": "For example, let's find the fixed points of the  Standard Map  of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the  signs  but only one for the  inds . We will also only use one  \u03bb  value, and a 21\u00d721 density of initial conditions:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . standardmap ()  xs   =   linspace ( 0 ,   2 \u03c0 ,   21 );   ys   =   copy ( xs )  ics   =   [ SVector { 2 }( x , y )   for   x   in   xs   for   y   in   ys ]  # All permutations of [\u00b11, \u00b11]:  singss   =   [[ + 1 ,   + 1 ],   [ - 1 ,   - 1 ],   [ + 1 ,   - 1 ],   [ - 1 ,   + 1 ]]  # I know from personal research I only need this `inds`:  indss   =   [[ 1 , 2 ]]   #  - must be container of vectors!!!  \u03bbs   =   0.005   #  - only this allowed to not be vector (could also be vector)  orders   =   [ 2 ,   3 ,   4 ,   5 ,   6 ,   8 ]  ALLFP   =   Any []  ttt   =   time ()  for   o   in   orders \n     FP   =   periodicorbits ( ds ,   o ,   ics ,   \u03bbs ,   indss ,   singss ) \n     push! ( ALLFP ,   FP )  end  println ( Total time:  $ (( time ()   -   ttt ) / 60 )  mins. )  # It takes a good 3-5 minutes to do all computations!  # Create phase-space plot:  iters   =   1000  dataset   =   timeseries ( ds ,   iters )  for   x   in   xs \n     for   y   in   ys \n         ds . state   =   SVector { 2 }( x ,   y ) \n         append! ( dataset ,   timeseries ( ds ,   iters )) \n     end  end  m   =   Matrix ( dataset )  PyPlot . scatter ( view ( m ,   : ,   1 ),   view ( m ,   : ,   2 ),   s =   1 ,   color   =   black )  PyPlot . xlim ( xs [ 1 ],   xs [ end ])  PyPlot . ylim ( ys [ 1 ],   ys [ end ])  # Plot fixed points:  markers   =   [ D ,   ^ ,   s ,   p ,   h ,   8 ]  colors   =   [ b ,   g ,   r ,   c ,   m ,   grey ]  for   i   in   1 : 6 \n     FP   =   ALLFP [ i ] \n     o   =   orders [ i ] \n     PyPlot . plot ([ s [ 1 ]   for   s   in   FP ],   [ s [ 2 ]   for   s   in   FP ], \n     marker = markers [ i ],   color   =   colors [ i ],   markersize = 10.0   +   ( 8 - o ),   linewidth = 0.0 , \n     label   =   order  $o ,   markeredgecolor   =   yellow ,   markeredgewidth   =   0.5 )  end  legend ( loc = upper right ,   framealpha = 0.9 )  xlabel ( \\$\\\\ theta \\$ )  ylabel ( \\$ p \\$ )   After 3 to 5 minutes, you will get this plot:   You can confirm for yourself that this is correct, for many reasons:   It is the same  fig. 12 of this publication .  Fixed points of order  \\(n\\)  are also fixed points of order  \\(2n, 3n, 4n, ...\\)  Besides fixed points of previous orders,  original  fixed points of order  \\(n\\)  come in  \\(2n\\) -sized pairs (see e.g. order 5). This is correct because in a conservative map the fixed points must be pairs of elliptic-hyperbolic.", 
            "title": "Standard Map example"
        }, 
        {
            "location": "/contributors_guide/", 
            "text": "Contributor Guide\n\n\nYou can contribute to this package even if you are not familiar with Julia or coding.\n\n\nThe ultimate goal for \nDynamicalSystems.jl\n is to be a useful tool for scientists working on chaos \n nonlinear dynamics and in general dynamical systems.\n\n\nFor such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!\n\n\nFor a something to be implemented in this package, the following steps have to happen:\n\n\n\n\nA suggestion that a method should be included\n has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.\n\n\nAn algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.\n\n\nThe source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the \nreliability of the implementation\n.\n\n\n\n\nIt is clear that one can contribute to \nDynamicalSystems.jl\n by contributing in steps (1) and (2). Neither of those require any knowledge of coding with Julia.\n\n\nFor step (1), you can open a new issue at the \nDynamicalSystems.jl Issues\n page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features \nhere\n and see for yourself if you can contribute to some of them!\n\n\nOf course, you can always contribute in the enhancement of the existing package by solving the \nGitHub issues\n.\n\n\nIf you have any idea about how to improve this package please do not hesitate to \njoin our chatroom\n and share your ideas!\n\n\nDon't forget; you always help this package simply by \nusing it\n and reporting any unexpected behavior! So far we had very few testers and tested on a small subset of dynamical systems thus any extra testing is welcomed!\n\n\n\n\nExamples of new things you could contribute\n\n\n\n\nAny method that calculates a quantity that has been used in at least one published (and peer-reviewed) journal.\n\n\nAny kind of new \nType\n of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of \nDynamicalSystem\n. I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.\n\n\nAny kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the \nfamous_systems.jl\n file).\n\n\n\n\nNotice that the above are not conclusive, but only examples!\n\n\n\n\nHow you should contribute \ncode\n\n\n\n\nFor new methods and systems please always have very clear and self-contained documentation strings.\n\n\nHave enough comments in your code so that somebody that knows the method, can also understand the code.\n\n\nAlways have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.\n\n\nIf you are adding a new system type accompanied by new methods and quantities, please introduce a new file in the \n/src\n folder, or even better create your own subfolder, instead of adding code to the existing files.\n\n\n\n\nWhen enhancing already existing code, make sure to:\n\n\n\n\nHave enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributor-guide", 
            "text": "You can contribute to this package even if you are not familiar with Julia or coding.  The ultimate goal for  DynamicalSystems.jl  is to be a useful tool for scientists working on chaos   nonlinear dynamics and in general dynamical systems.  For such a feat to be accomplished, many different methods across this interdisciplinary field have to be not only implemented but suggested in the first place!  For a something to be implemented in this package, the following steps have to happen:   A suggestion that a method should be included  has to be brought upon notice of the developers. Since the current amount of developers actively maintaining the package is small, so is the amount of knowledge of important methods.  An algorithm that describes how the method will be implemented has to be formulated. This algorithm most probably already exist in the papers that first introduce the method, however it may not be trivial to transform this algorithm from a mathematical abstraction to something realistic and applicable in a computational manner.  The source code for the above has to be implemented in Julia. In general, the speed of the implementation is important, but not as important as the  reliability of the implementation .   It is clear that one can contribute to  DynamicalSystems.jl  by contributing in steps (1) and (2). Neither of those require any knowledge of coding with Julia.  For step (1), you can open a new issue at the  DynamicalSystems.jl Issues  page. All issues that refer methods that we would want to have in our package are labeled as \"wanted_feature\". You can view the current wanted features  here  and see for yourself if you can contribute to some of them!  Of course, you can always contribute in the enhancement of the existing package by solving the  GitHub issues .  If you have any idea about how to improve this package please do not hesitate to  join our chatroom  and share your ideas!  Don't forget; you always help this package simply by  using it  and reporting any unexpected behavior! So far we had very few testers and tested on a small subset of dynamical systems thus any extra testing is welcomed!", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#examples-of-new-things-you-could-contribute", 
            "text": "Any method that calculates a quantity that has been used in at least one published (and peer-reviewed) journal.  Any kind of new  Type  of Dynamical system, provided it is also used in research. If you do want to make something like this, please make it a subtype of  DynamicalSystem . I have created the discrete and continuous general types, but more specialized types would allow for specialized methods.  Any kind of existing discrete or continuous system that have been used in published literature at least once and you find it useful (put this in the  famous_systems.jl  file).   Notice that the above are not conclusive, but only examples!", 
            "title": "Examples of new things you could contribute"
        }, 
        {
            "location": "/contributors_guide/#how-you-should-contribute-code", 
            "text": "For new methods and systems please always have very clear and self-contained documentation strings.  Have enough comments in your code so that somebody that knows the method, can also understand the code.  Always have a reference to the original work that first introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.  If you are adding a new system type accompanied by new methods and quantities, please introduce a new file in the  /src  folder, or even better create your own subfolder, instead of adding code to the existing files.   When enhancing already existing code, make sure to:   Have enough comments at parts that are not easily understood, so that somebody else may continue your work in the future.", 
            "title": "How you should contribute code"
        }
    ]
}