{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nDynamicalSystems.jl\n is a Julia software library for the exploration of chaos and nonlinear dynamics.\n\n\nThe current documentation was built with the following versions\n\n\n - DynamicalSystemsBase          0.8.2\n - ChaosTools                    0.7.0\n\n\n\n\n\nSee the \nNews\n page for recent updates!\n\n\n\n\nContents\n\n\n\n\nFundamentals\n\n\n\n\n\n\nIntuitive, consistent APIs for the definition of general \ndynamical systems\n, both maps and flows. The following combinations are possible:\n\n\n\n\nContinuous or Discrete systems.\n\n\nIn-place or out-of-place (large versus small systems).\n\n\nAuto-differentiated or not (for the Jacobian function).\n\n\n\n\n\n\n\n\nDedicated interface for \nnumerical data\n.\n\n\n\n\nAutomatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.\n\n\nRobust implementations of all kinds of integrators, that evolve the system, many states of the system, or even deviation vectors. See the \nadvanced documentation\n for this.\n\n\nDelay Coordinates Embedding.\n\n\nLibrary of \npredefined well-known dynamical systems\n that have been used extensively in scientific research.\n\n\n\n\n\n\nChaosTools\n\n\nPlease see the \noverview section\n for a full list of features. Here is a quick summary:\n\n\n\n\nPoincare S.O.S. and orbit diagrams\n\n\nLyapunov Exponents\n\n\nEntropies and Dimensions\n\n\nNeighborhood estimation\n\n\nLyapunov exponent of a timeseries\n\n\nFinding Fixed Points of Maps\n\n\nDetecting Chaos\n\n\n\n\n\n\nOur Goals\n\n\nThe ultimate goal for \nDynamicalSystems.jl\n is to be a useful \nlibrary\n for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.\n\n\nWith \nDynamicalSystems.jl\n we try to\n\n\n\n\nBe concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the \nLorenz attractor\n, or a high dimensional discrete map like \ncoupled standard maps\n.\n\n\nBe accurate, reliable and performant.\n\n\nBe transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.\n\n\n\n\nFor example, provided you have first defined a \nDynamicalSystem\n (which simply reduces to writing a function for the equations of motion), you should be able to e.g. calculate the Lyapunov spectrum for it in a single line:\n\n\nlyapunovs\n(\nsystem\n,\n \ntimes_to_do_QR\n;\n \nkeywords\n...\n)\n\n\n\n\n\n\nThe same function call works with any system, no discriminations here!\n\n\n\n\nInstallation\n\n\nSimply use \nPkg.add(\"DynamicalSystems\")\n to install \neverything\n.\n\n\n\n\nContacting\n\n\nYou can \njoin our chatroom\n for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!\n\n\nBe sure to visit the \nContributor Guide\n page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on \nGitHub\n! This gives us an accurate lower bound of users that this package has already helped!\n\n\n\n\nUse latest documentation\n\n\nWe highly suggest our users to read the  \nlatest\n documentation   and not the \nstable\n one.\n\n\n\n\n\n\nWanted Features\n\n\nThe following lists state features that are wanted by the \nDynamicalSystems.jl\n ecosystem and are open to contributors. These are structured in the form of GitHub Issues, with the label \nwanted_feature\n:\n\n\n\n\nDynamicalSystemsBase.jl wanted features\n\n\nChaosTools.jl wanted features", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "DynamicalSystems.jl  is a Julia software library for the exploration of chaos and nonlinear dynamics.  The current documentation was built with the following versions   - DynamicalSystemsBase          0.8.2\n - ChaosTools                    0.7.0  See the  News  page for recent updates!", 
            "title": "Introduction"
        }, 
        {
            "location": "/#contents", 
            "text": "", 
            "title": "Contents"
        }, 
        {
            "location": "/#fundamentals", 
            "text": "Intuitive, consistent APIs for the definition of general  dynamical systems , both maps and flows. The following combinations are possible:   Continuous or Discrete systems.  In-place or out-of-place (large versus small systems).  Auto-differentiated or not (for the Jacobian function).     Dedicated interface for  numerical data .   Automatic \"completion\" of the dynamics of the system with numerically computed Jacobians, in case they are not provided by the user.  Robust implementations of all kinds of integrators, that evolve the system, many states of the system, or even deviation vectors. See the  advanced documentation  for this.  Delay Coordinates Embedding.  Library of  predefined well-known dynamical systems  that have been used extensively in scientific research.", 
            "title": "Fundamentals"
        }, 
        {
            "location": "/#chaostools", 
            "text": "Please see the  overview section  for a full list of features. Here is a quick summary:   Poincare S.O.S. and orbit diagrams  Lyapunov Exponents  Entropies and Dimensions  Neighborhood estimation  Lyapunov exponent of a timeseries  Finding Fixed Points of Maps  Detecting Chaos", 
            "title": "ChaosTools"
        }, 
        {
            "location": "/#our-goals", 
            "text": "The ultimate goal for  DynamicalSystems.jl  is to be a useful  library  for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.  With  DynamicalSystems.jl  we try to   Be concise, intuitive, and general. All functions we offer work just as well with any system, whether it is a simple continuous chaotic system, like the  Lorenz attractor , or a high dimensional discrete map like  coupled standard maps .  Be accurate, reliable and performant.  Be transparent with respect to what is happening \"under the hood\", i.e. be clear about exactly what each function call does. We take care of this aspect in many ways; by being well-documented, giving references to scientific papers and having clear source code.   For example, provided you have first defined a  DynamicalSystem  (which simply reduces to writing a function for the equations of motion), you should be able to e.g. calculate the Lyapunov spectrum for it in a single line:  lyapunovs ( system ,   times_to_do_QR ;   keywords ... )   The same function call works with any system, no discriminations here!", 
            "title": "Our Goals"
        }, 
        {
            "location": "/#installation", 
            "text": "Simply use  Pkg.add(\"DynamicalSystems\")  to install  everything .", 
            "title": "Installation"
        }, 
        {
            "location": "/#contacting", 
            "text": "You can  join our chatroom  for discussions related to dynamical systems and Julia as well as for asking questions about the packages of the JuliaDynamics organization!  Be sure to visit the  Contributor Guide  page, because you can help make this package better without having to write a single line of code! Also, if you find this package helpful please consider staring it on  GitHub ! This gives us an accurate lower bound of users that this package has already helped!   Use latest documentation  We highly suggest our users to read the   latest  documentation   and not the  stable  one.", 
            "title": "Contacting"
        }, 
        {
            "location": "/#wanted-features", 
            "text": "The following lists state features that are wanted by the  DynamicalSystems.jl  ecosystem and are open to contributors. These are structured in the form of GitHub Issues, with the label  wanted_feature :   DynamicalSystemsBase.jl wanted features  ChaosTools.jl wanted features", 
            "title": "Wanted Features"
        }, 
        {
            "location": "/definition/general/", 
            "text": "Dynamical Systems\n\n\nCurrently a system in \nDynamicalSystems.jl\n can be either continuous\n\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, t),\n\n\n\n\n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, t),\n\n\n\n\n\nor discrete\n\n\n\n\n\n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, n).\n\n\n\n\n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, n).\n\n\n\n\n\nKeep in mind that almost all functions of \nDynamicalSystems.jl\n assume that \n\\vec{f}\n\\vec{f}\n is differentiable!\n\n\n\n\nCreating a Dynamical System\n\n\n#\n\n\nDynamicalSystemsBase.DynamicalSystem\n \n \nType\n.\n\n\nDynamicalSystem\n\n\n\n\n\nThe central structure of \nDynamicalSystems.jl\n. All functions of the suite that handle systems \"analytically\" (in the sense that they can use known equations of motion) expect an instance of this type.\n\n\nContains a problem defining the system (field \nprob\n), the jacobian function (field \njacobian\n) and the initialized Jacobian matrix (field \nJ\n).\n\n\nConstructing a \nDynamicalSystem\n\n\nDiscreteDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n::\nInt\n \n=\n \n0\n)\n\n\nContinuousDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n \n=\n \n0.0\n)\n\n\n\n\n\n\nwith \neom\n the equations of motion function. \np\n is a parameter container, which we highly suggest to use a mutable object like \nArray\n, \nLMArray\n or a dictionary. Pass \nnothing\n in the place of \np\n if your system does not have parameters. With these constructors you also do not need to provide some final time, since it is not used by \nDynamicalSystems.jl\n in any manner.\n\n\nt0\n, \nJ0\n allow you to choose the initial time and provide an initialized Jacobian matrix.\n\n\nContinuous system solvers use \nDifferentialEquations.jl\n and by default are integrated with a 9th order Verner solver \nVern9()\n with tolerances \nabstol = reltol = 1e-9\n.\n\n\nEquations of motion\n\n\nThe are two \"versions\" for \nDynamicalSystem\n, depending on whether the equations of motion (\neom\n) are in-place (iip) or out-of-place (oop). Here is how to define them:\n\n\n\n\niip\n : The \neom\n \nmust\n be in the form \neom(x, p, t) -\n SVector\n which means that given a state \nx::SVector\n and some parameter container \np\n it returns an \nSVector\n (from the \nStaticArrays\n module) containing the next state.\n\n\noop\n : The \neom\n \nmust\n be in the form \neom!(xnew, x, p, t)\n which means that given a state \nx::Vector\n and some parameter container \np\n, it writes in-place the new state in \nxnew\n.\n\n\n\n\nt\n stands for time (integer for discrete systems). iip is suggested for big systems, whereas oop is suggested for small systems. The break-even point at around 100 dimensions, and for using functions that use the tangent space (like e.g. \nlyapunovs\n or \ngali\n), the break-even point is at around 10 dimensions.\n\n\nThe constructor deduces automatically whether \neom\n is iip or oop. It is not possible however to deduce whether the system is continuous or discrete just from the equations of motion, hence the 2 constructors.\n\n\nJacobian\n\n\nThe optional argument \njacobian\n for the constructors is a \nfunction\n and (if given) must also be of the same form as the \neom\n, \njacobian(x, p, n) -\n SMatrix\n for the out-of-place version and \njacobian!(xnew, x, p, n)\n for the in-place version.\n\n\nIf \njacobian\n is not given, it is constructed automatically using the module \nForwardDiff\n.\n\n\nGetting a \nSolution\n struct\n\n\nThe continuous constructor creates a standard \nODEProblem\n from \nDifferentialEquations.jl\n. You can \nalways\n take advantage of the full capabilities of the \nSolution\n struct by doing:\n\n\nsol\n \n=\n \nsolve\n(\nds\n.\nprob\n,\n \nalg\n;\n \nkwargs\n...\n)\n\n\n# do stuff with sol\n\n\n\n\n\n\nRelevant Functions\n\n\ntrajectory\n, \njacobian\n, \ndimension\n, \nset_parameter!\n.\n\n\nsource\n\n\n\n\n\n\nDefinition Table\n\n\nHere is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:\n\n\n\n\n\n\n\n\nSystem Type\n\n\nequations of motion\n\n\nJacobian\n\n\n\n\n\n\n\n\n\n\nin-place (big systems)\n\n\neom!(du, u, p, t)\n\n\njacobian!(J, u, p, t)\n\n\n\n\n\n\nout-of-place (small systems)\n\n\neom(u, p, t) -\n SVector\n\n\njacobian(u, p, t) -\n SMatrix\n\n\n\n\n\n\n\n\n\n\nUse mutable containers for the parameters\n\n\nIt is highly suggested to use a subtype of \nArray\n,  \nLMArray\n or a dictionary for the container of the model's parameters. Some functions offered by \nDynamicalSystems.jl\n, like e.g. \norbitdiagram\n, assume that the parameters can be first accessed by \np[x]\n with \nx\n some qualifier as well as that this value can be set by \np[x] = newvalue\n.\n\n\nThe \nLabelled Arrays\n package offers \nArray\n implementations that can be accessed both by index as well as by some name.\n\n\n\n\n\n\nGeneral Functions\n\n\nThe following functions are defined for convenience for any dynamical system:\n\n\n#\n\n\nDynamicalSystemsBase.dimension\n \n \nFunction\n.\n\n\ndimension(thing) -\n D\n\n\n\n\n\nReturn the dimension of the \nthing\n, in the sense of state-space dimensionality.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.jacobian\n \n \nFunction\n.\n\n\njacobian(ds::DynamicalSystem, u = ds.prob.u0)\n\n\n\n\n\nReturn the jacobian of the system at \nu\n (at initial time).\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.set_parameter!\n \n \nFunction\n.\n\n\nset_parameter!(ds::DynamicalSystem, index, value)\nset_parameter!(ds::DynamicalSystem, values)\n\n\n\n\n\nChange one or many parameters of the system by setting \np[index] = value\n in the first case and \np .= values\n in the second.\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\nContinuous, out-of-place\n\n\nLet's see an example for a small system, which is a case where out-of-place equations of motion are preferred.\n\n\nusing\n \nDynamicalSystems\n,\n \nStaticArrays\n\n\n# Lorenz system\n\n\n# Equations of motion:\n\n\n@inline\n \n@inbounds\n \nfunction\n \nloop\n(\nu\n,\n \np\n,\n \nt\n)\n\n    \n\u03c3\n \n=\n \np\n[\n1\n];\n \n\u03c1\n \n=\n \np\n[\n2\n];\n \n\u03b2\n \n=\n \np\n[\n3\n]\n\n    \ndu1\n \n=\n \n\u03c3\n*\n(\nu\n[\n2\n]\n-\nu\n[\n1\n])\n\n    \ndu2\n \n=\n \nu\n[\n1\n]\n*\n(\n\u03c1\n-\nu\n[\n3\n])\n \n-\n \nu\n[\n2\n]\n\n    \ndu3\n \n=\n \nu\n[\n1\n]\n*\nu\n[\n2\n]\n \n-\n \n\u03b2\n*\nu\n[\n3\n]\n\n    \nreturn\n \nSVector\n{\n3\n}(\ndu1\n,\n \ndu2\n,\n \ndu3\n)\n\n\nend\n\n\n# Jacobian:\n\n\n@inline\n \n@inbounds\n \nfunction\n \nloop_jac\n(\nu\n,\n \np\n,\n \nt\n)\n\n    \n\u03c3\n,\n \n\u03c1\n,\n \n\u03b2\n \n=\n \np\n\n    \nJ\n \n=\n \n@SMatrix\n \n[\n-\n\u03c3\n  \n\u03c3\n  \n0\n;\n\n    \n\u03c1\n \n-\n \nu\n[\n3\n]\n  \n(\n-\n1\n)\n  \n(\n-\nu\n[\n1\n]);\n\n    \nu\n[\n2\n]\n   \nu\n[\n1\n]\n  \n-\n\u03b2\n]\n\n    \nreturn\n \nJ\n\n\nend\n\n\n\nds\n \n=\n \nContinuousDynamicalSystem\n(\nloop\n,\n \nrand\n(\n3\n),\n \n[\n10.0\n,\n \n28.0\n,\n \n8\n/\n3\n],\n \nloop_jac\n)\n\n\n\n\n\n\n3-dimensional continuous dynamical system\n state:     [0.068248, 0.828095, 0.0743729]\n e.o.m.:    loop\n in-place?  false\n jacobian:  loop_jac\n\n\n\n\n\n\n\nDiscrete, in-place\n\n\nThe following example is only 2-dimensional, and thus once again it is \"correct\" to use out-of-place version with \nSVector\n. For the sake of example though, we use the in-place version.\n\n\n# Henon map.\n\n\n# equations of motion:\n\n\nfunction\n \nhiip\n(\ndx\n,\n \nx\n,\n \np\n,\n \nn\n)\n\n    \ndx\n[\n1\n]\n \n=\n \n1.0\n \n-\n \np\n[\n1\n]\n*\nx\n[\n1\n]\n^\n2\n \n+\n \nx\n[\n2\n]\n\n    \ndx\n[\n2\n]\n \n=\n \np\n[\n2\n]\n*\nx\n[\n1\n]\n\n    \nreturn\n\n\nend\n\n\n# Jacobian:\n\n\nfunction\n \nhiip_jac\n(\nJ\n,\n \nx\n,\n \np\n,\n \nn\n)\n\n    \nJ\n[\n1\n,\n1\n]\n \n=\n \n-\n2\n*\np\n[\n1\n]\n*\nx\n[\n1\n]\n\n    \nJ\n[\n1\n,\n2\n]\n \n=\n \n1.0\n\n    \nJ\n[\n2\n,\n1\n]\n \n=\n \np\n[\n2\n]\n\n    \nJ\n[\n2\n,\n2\n]\n \n=\n \n0.0\n\n    \nreturn\n\n\nend\n\n\nds\n \n=\n \nDiscreteDynamicalSystem\n(\nhiip\n,\n \nzeros\n(\n2\n),\n \n[\n1.4\n,\n \n0.3\n],\n \nhiip_jac\n)\n\n\n\n\n\n\n2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  hiip_jac\n\n\n\n\n\nOr, if you don't want to write a Jacobian and want to use the auto-differentiation capabilities of \nDynamicalSystems.jl\n, which use the module \nForwardDiff\n:\n\n\nds\n \n=\n \nDiscreteDynamicalSystem\n(\nhiip\n,\n \nzeros\n(\n2\n),\n \n[\n1.4\n,\n \n0.3\n])\n\n\n\n\n\n\n2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  ForwardDiff\n\n\n\n\n\n\n\nComplex Example\n\n\nIn this example we will go through the implementation of the coupled standard maps from our \nPredefined Systems\n. It is the most complex implementation and takes full advantage of the flexibility of the constructors.\n\n\nCoupled standard maps is a big mapping that can have arbitrary number of equations of motion, since you can couple \nN\n \nstandard maps\n which are 2D maps, like:\n\n\n\n\n\n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]\n\n\n\n\n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]\n\n\n\n\n\nTo model this, we will make a dedicated \nstruct\n, which is parameterized on the number of coupled maps:\n\n\nstruct\n \nCoupledStandardMaps\n{\nN\n}\n\n    \nidxs\n::\nSVector\n{\nN\n,\n \nInt\n}\n\n    \nidxsm1\n::\nSVector\n{\nN\n,\n \nInt\n}\n\n    \nidxsp1\n::\nSVector\n{\nN\n,\n \nInt\n}\n\n\nend\n\n\n\n\n\n\n(what these fields are will become apparent later)\n\n\nWe initialize the struct with the amount of standard maps we want to couple, and we also define appropriate parameters:\n\n\nM\n \n=\n \n5\n  \n# couple number\n\n\nu0\n \n=\n \n0.001\nrand\n(\n2\nM\n)\n \n#initial state\n\n\nks\n \n=\n \n0.9\nones\n(\nM\n)\n \n# nonlinearity parameters\n\n\n\u0393\n \n=\n \n1.0\n \n# coupling strength\n\n\np\n \n=\n \n(\nks\n,\n \n\u0393\n)\n \n# parameter container\n\n\n\n# Create struct:\n\n\nSV\n \n=\n \nSVector\n{\nM\n,\n \nInt\n}\n\n\nidxs\n \n=\n \nSV\n(\n1\n:\nM\n...\n)\n \n# indexes of thetas\n\n\nidxsm1\n \n=\n \nSV\n(\ncircshift\n(\nidxs\n,\n \n+\n1\n)\n...\n)\n  \n#indexes of thetas - 1\n\n\nidxsp1\n \n=\n \nSV\n(\ncircshift\n(\nidxs\n,\n \n-\n1\n)\n...\n)\n  \n#indexes of thetas + 1\n\n\n# So that:\n\n\n# x[i] \u2261 \u03b8\u1d62\n\n\n# x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081\n\n\n# x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081\n\n\ncsm\n \n=\n \nCoupledStandardMaps\n{\nM\n}(\nidxs\n,\n \nidxsm1\n,\n \nidxsp1\n);\n\n\n\n\n\n\nWe will now use this struct to define a \nfunctor\n, a Type that also acts as a function.\n\n\nfunction\n \n(\nf\n::\nCoupledStandardMaps\n{\nN\n})(\nxnew\n::\nAbstractVector\n,\n \nx\n,\n \np\n,\n \nn\n)\n \nwhere\n \n{\nN\n}\n\n    \nks\n,\n \n\u0393\n \n=\n \np\n\n    \n@inbounds\n \nfor\n \ni\n \nin\n \nf\n.\nidxs\n\n\n        \nxnew\n[\ni\n+\nN\n]\n \n=\n \nmod2pi\n(\n\n            \nx\n[\ni\n+\nN\n]\n \n+\n \nks\n[\ni\n]\n*\nsin\n(\nx\n[\ni\n])\n \n-\n\n            \n\u0393\n*\n(\nsin\n(\nx\n[\nf\n.\nidxsp1\n[\ni\n]]\n \n-\n \nx\n[\ni\n])\n \n+\n \nsin\n(\nx\n[\nf\n.\nidxsm1\n[\ni\n]]\n \n-\n \nx\n[\ni\n]))\n\n        \n)\n\n\n        \nxnew\n[\ni\n]\n \n=\n \nmod2pi\n(\nx\n[\ni\n]\n \n+\n \nxnew\n[\ni\n+\nN\n])\n\n    \nend\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nWe will use \nthe same\n \nstruct\n to create a function for the Jacobian:\n\n\nfunction\n \n(\nf\n::\nCoupledStandardMaps\n{\nM\n})(\n\n    \nJ\n::\nAbstractMatrix\n,\n \nx\n,\n \np\n,\n \nn\n)\n \nwhere\n \n{\nM\n}\n\n\n    \nks\n,\n \n\u0393\n \n=\n \np\n\n    \n# x[i] \u2261 \u03b8\u1d62\n\n    \n# x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081\n\n    \n# x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081\n\n    \n@inbounds\n \nfor\n \ni\n \nin\n \nf\n.\nidxs\n\n        \ncos\u03b8\n \n=\n \ncos\n(\nx\n[\ni\n])\n\n        \ncos\u03b8p\n=\n \ncos\n(\nx\n[\nf\n.\nidxsp1\n[\ni\n]]\n \n-\n \nx\n[\ni\n])\n\n        \ncos\u03b8m\n=\n \ncos\n(\nx\n[\nf\n.\nidxsm1\n[\ni\n]]\n \n-\n \nx\n[\ni\n])\n\n        \nJ\n[\ni\n+\nM\n,\n \ni\n]\n \n=\n \nks\n[\ni\n]\n*\ncos\u03b8\n \n+\n \n\u0393\n*\n(\ncos\u03b8p\n \n+\n \ncos\u03b8m\n)\n\n        \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsm1\n[\ni\n]]\n \n=\n \n-\n \n\u0393\n*\ncos\u03b8m\n\n        \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsp1\n[\ni\n]]\n \n=\n \n-\n \n\u0393\n*\ncos\u03b8p\n\n        \nJ\n[\ni\n,\n \ni\n]\n \n=\n \n1\n \n+\n \nJ\n[\ni\n+\nM\n,\n \ni\n]\n\n        \nJ\n[\ni\n,\n \nf\n.\nidxsm1\n[\ni\n]]\n \n=\n \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsm1\n[\ni\n]]\n\n        \nJ\n[\ni\n,\n \nf\n.\nidxsp1\n[\ni\n]]\n \n=\n \nJ\n[\ni\n+\nM\n,\n \nf\n.\nidxsp1\n[\ni\n]]\n\n    \nend\n\n    \nreturn\n \nnothing\n\n\nend\n\n\n\n\n\n\nThe only reason that this is possible, is because the \neom\n always takes a \nAbstractVector\n as first argument, while the Jacobian always takes an \nAbstractMatrix\n. Therefore we can take advantage of multiple dispatch!\n\n\nNotice in addition, that the Jacobian function accesses \nonly half the elements of the matrix\n. This is intentional, and takes advantage of the fact that the other half is constant.\n\n\nBecause the \nDynamicalSystem\n constructors allow us to give in a pre-initialized Jacobian matrix, we take advantage of that and create:\n\n\nJ\n \n=\n \nzeros\n(\neltype\n(\nu0\n),\n \n2\nM\n,\n \n2\nM\n)\n\n\n# Set \u2202/\u2202p entries (they are eye(M,M))\n\n\n# And they dont change they are constants\n\n\nfor\n \ni\n \nin\n \nidxs\n\n    \nJ\n[\ni\n,\n \ni\n+\nM\n]\n \n=\n \n1\n\n    \nJ\n[\ni\n+\nM\n,\n \ni\n+\nM\n]\n \n=\n \n1\n\n\nend\n\n\ncsm\n(\nJ\n,\n \nu0\n,\n \np\n,\n \n0\n)\n \n# apply Jacobian to initial state\n\n\n\n\n\n\nAnd finally, we are ready to create our dynamical system:\n\n\nds\n \n=\n \nDiscreteDynamicalSystem\n(\ncsm\n,\n \nu0\n,\n \np\n,\n \ncsm\n,\n \nJ\n)\n\n\n\n\n\n\n10-dimensional discrete dynamical system\n state:     [5.88772e-6, 0.000539993, 0.000178981, 0.000607429, 0.000927426, 0.000246537, 0.00094118, 0.000703942, 0.000130421, 0.000332372]\n e.o.m.:    CoupledStandardMaps{5}([1, 2, 3, 4, 5], [5, 1, 2, 3, 4], [2, 3, 4, 5, 1])\n in-place?  true\n jacobian:  CoupledStandardMaps{5}([1, 2, 3, 4, 5], [5, 1, 2, 3, 4], [2, 3, 4, 5, 1])\n\n\n\n\n\nwhich unfortunately is kind of a mess to read, but what can you do!", 
            "title": "Dynamical Systems"
        }, 
        {
            "location": "/definition/general/#dynamical-systems", 
            "text": "Currently a system in  DynamicalSystems.jl  can be either continuous   \n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, t),  \n\\frac{d\\vec{u}}{dt} = \\vec{f}(\\vec{u}, t),   or discrete   \n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, n).  \n\\vec{u}_{n+1} = \\vec{f}(\\vec{u}_n, n).   Keep in mind that almost all functions of  DynamicalSystems.jl  assume that  \\vec{f} \\vec{f}  is differentiable!", 
            "title": "Dynamical Systems"
        }, 
        {
            "location": "/definition/general/#creating-a-dynamical-system", 
            "text": "#  DynamicalSystemsBase.DynamicalSystem     Type .  DynamicalSystem  The central structure of  DynamicalSystems.jl . All functions of the suite that handle systems \"analytically\" (in the sense that they can use known equations of motion) expect an instance of this type.  Contains a problem defining the system (field  prob ), the jacobian function (field  jacobian ) and the initialized Jacobian matrix (field  J ).  Constructing a  DynamicalSystem  DiscreteDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0 :: Int   =   0 )  ContinuousDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0   =   0.0 )   with  eom  the equations of motion function.  p  is a parameter container, which we highly suggest to use a mutable object like  Array ,  LMArray  or a dictionary. Pass  nothing  in the place of  p  if your system does not have parameters. With these constructors you also do not need to provide some final time, since it is not used by  DynamicalSystems.jl  in any manner.  t0 ,  J0  allow you to choose the initial time and provide an initialized Jacobian matrix.  Continuous system solvers use  DifferentialEquations.jl  and by default are integrated with a 9th order Verner solver  Vern9()  with tolerances  abstol = reltol = 1e-9 .  Equations of motion  The are two \"versions\" for  DynamicalSystem , depending on whether the equations of motion ( eom ) are in-place (iip) or out-of-place (oop). Here is how to define them:   iip  : The  eom   must  be in the form  eom(x, p, t) -  SVector  which means that given a state  x::SVector  and some parameter container  p  it returns an  SVector  (from the  StaticArrays  module) containing the next state.  oop  : The  eom   must  be in the form  eom!(xnew, x, p, t)  which means that given a state  x::Vector  and some parameter container  p , it writes in-place the new state in  xnew .   t  stands for time (integer for discrete systems). iip is suggested for big systems, whereas oop is suggested for small systems. The break-even point at around 100 dimensions, and for using functions that use the tangent space (like e.g.  lyapunovs  or  gali ), the break-even point is at around 10 dimensions.  The constructor deduces automatically whether  eom  is iip or oop. It is not possible however to deduce whether the system is continuous or discrete just from the equations of motion, hence the 2 constructors.  Jacobian  The optional argument  jacobian  for the constructors is a  function  and (if given) must also be of the same form as the  eom ,  jacobian(x, p, n) -  SMatrix  for the out-of-place version and  jacobian!(xnew, x, p, n)  for the in-place version.  If  jacobian  is not given, it is constructed automatically using the module  ForwardDiff .  Getting a  Solution  struct  The continuous constructor creates a standard  ODEProblem  from  DifferentialEquations.jl . You can  always  take advantage of the full capabilities of the  Solution  struct by doing:  sol   =   solve ( ds . prob ,   alg ;   kwargs ... )  # do stuff with sol   Relevant Functions  trajectory ,  jacobian ,  dimension ,  set_parameter! .  source", 
            "title": "Creating a Dynamical System"
        }, 
        {
            "location": "/definition/general/#definition-table", 
            "text": "Here is a handy table that summarizes in what form should be the functions required for the equations of motion and the Jacobian, for each system type:     System Type  equations of motion  Jacobian      in-place (big systems)  eom!(du, u, p, t)  jacobian!(J, u, p, t)    out-of-place (small systems)  eom(u, p, t) -  SVector  jacobian(u, p, t) -  SMatrix      Use mutable containers for the parameters  It is highly suggested to use a subtype of  Array ,   LMArray  or a dictionary for the container of the model's parameters. Some functions offered by  DynamicalSystems.jl , like e.g.  orbitdiagram , assume that the parameters can be first accessed by  p[x]  with  x  some qualifier as well as that this value can be set by  p[x] = newvalue .  The  Labelled Arrays  package offers  Array  implementations that can be accessed both by index as well as by some name.", 
            "title": "Definition Table"
        }, 
        {
            "location": "/definition/general/#general-functions", 
            "text": "The following functions are defined for convenience for any dynamical system:  #  DynamicalSystemsBase.dimension     Function .  dimension(thing) -  D  Return the dimension of the  thing , in the sense of state-space dimensionality.  source  #  DynamicalSystemsBase.jacobian     Function .  jacobian(ds::DynamicalSystem, u = ds.prob.u0)  Return the jacobian of the system at  u  (at initial time).  source  #  DynamicalSystemsBase.set_parameter!     Function .  set_parameter!(ds::DynamicalSystem, index, value)\nset_parameter!(ds::DynamicalSystem, values)  Change one or many parameters of the system by setting  p[index] = value  in the first case and  p .= values  in the second.  source", 
            "title": "General Functions"
        }, 
        {
            "location": "/definition/general/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/definition/general/#continuous-out-of-place", 
            "text": "Let's see an example for a small system, which is a case where out-of-place equations of motion are preferred.  using   DynamicalSystems ,   StaticArrays  # Lorenz system  # Equations of motion:  @inline   @inbounds   function   loop ( u ,   p ,   t ) \n     \u03c3   =   p [ 1 ];   \u03c1   =   p [ 2 ];   \u03b2   =   p [ 3 ] \n     du1   =   \u03c3 * ( u [ 2 ] - u [ 1 ]) \n     du2   =   u [ 1 ] * ( \u03c1 - u [ 3 ])   -   u [ 2 ] \n     du3   =   u [ 1 ] * u [ 2 ]   -   \u03b2 * u [ 3 ] \n     return   SVector { 3 }( du1 ,   du2 ,   du3 )  end  # Jacobian:  @inline   @inbounds   function   loop_jac ( u ,   p ,   t ) \n     \u03c3 ,   \u03c1 ,   \u03b2   =   p \n     J   =   @SMatrix   [ - \u03c3    \u03c3    0 ; \n     \u03c1   -   u [ 3 ]    ( - 1 )    ( - u [ 1 ]); \n     u [ 2 ]     u [ 1 ]    - \u03b2 ] \n     return   J  end  ds   =   ContinuousDynamicalSystem ( loop ,   rand ( 3 ),   [ 10.0 ,   28.0 ,   8 / 3 ],   loop_jac )   3-dimensional continuous dynamical system\n state:     [0.068248, 0.828095, 0.0743729]\n e.o.m.:    loop\n in-place?  false\n jacobian:  loop_jac", 
            "title": "Continuous, out-of-place"
        }, 
        {
            "location": "/definition/general/#discrete-in-place", 
            "text": "The following example is only 2-dimensional, and thus once again it is \"correct\" to use out-of-place version with  SVector . For the sake of example though, we use the in-place version.  # Henon map.  # equations of motion:  function   hiip ( dx ,   x ,   p ,   n ) \n     dx [ 1 ]   =   1.0   -   p [ 1 ] * x [ 1 ] ^ 2   +   x [ 2 ] \n     dx [ 2 ]   =   p [ 2 ] * x [ 1 ] \n     return  end  # Jacobian:  function   hiip_jac ( J ,   x ,   p ,   n ) \n     J [ 1 , 1 ]   =   - 2 * p [ 1 ] * x [ 1 ] \n     J [ 1 , 2 ]   =   1.0 \n     J [ 2 , 1 ]   =   p [ 2 ] \n     J [ 2 , 2 ]   =   0.0 \n     return  end  ds   =   DiscreteDynamicalSystem ( hiip ,   zeros ( 2 ),   [ 1.4 ,   0.3 ],   hiip_jac )   2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  hiip_jac  Or, if you don't want to write a Jacobian and want to use the auto-differentiation capabilities of  DynamicalSystems.jl , which use the module  ForwardDiff :  ds   =   DiscreteDynamicalSystem ( hiip ,   zeros ( 2 ),   [ 1.4 ,   0.3 ])   2-dimensional discrete dynamical system\n state:     [0.0, 0.0]\n e.o.m.:    hiip\n in-place?  true\n jacobian:  ForwardDiff", 
            "title": "Discrete, in-place"
        }, 
        {
            "location": "/definition/general/#complex-example", 
            "text": "In this example we will go through the implementation of the coupled standard maps from our  Predefined Systems . It is the most complex implementation and takes full advantage of the flexibility of the constructors.  Coupled standard maps is a big mapping that can have arbitrary number of equations of motion, since you can couple  N   standard maps  which are 2D maps, like:   \n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]  \n\\theta_{i}' = \\theta_i + p_{i}' \\\\\np_{i}' = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i}) \\right]   To model this, we will make a dedicated  struct , which is parameterized on the number of coupled maps:  struct   CoupledStandardMaps { N } \n     idxs :: SVector { N ,   Int } \n     idxsm1 :: SVector { N ,   Int } \n     idxsp1 :: SVector { N ,   Int }  end   (what these fields are will become apparent later)  We initialize the struct with the amount of standard maps we want to couple, and we also define appropriate parameters:  M   =   5    # couple number  u0   =   0.001 rand ( 2 M )   #initial state  ks   =   0.9 ones ( M )   # nonlinearity parameters  \u0393   =   1.0   # coupling strength  p   =   ( ks ,   \u0393 )   # parameter container  # Create struct:  SV   =   SVector { M ,   Int }  idxs   =   SV ( 1 : M ... )   # indexes of thetas  idxsm1   =   SV ( circshift ( idxs ,   + 1 ) ... )    #indexes of thetas - 1  idxsp1   =   SV ( circshift ( idxs ,   - 1 ) ... )    #indexes of thetas + 1  # So that:  # x[i] \u2261 \u03b8\u1d62  # x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081  # x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081  csm   =   CoupledStandardMaps { M }( idxs ,   idxsm1 ,   idxsp1 );   We will now use this struct to define a  functor , a Type that also acts as a function.  function   ( f :: CoupledStandardMaps { N })( xnew :: AbstractVector ,   x ,   p ,   n )   where   { N } \n     ks ,   \u0393   =   p \n     @inbounds   for   i   in   f . idxs \n\n         xnew [ i + N ]   =   mod2pi ( \n             x [ i + N ]   +   ks [ i ] * sin ( x [ i ])   - \n             \u0393 * ( sin ( x [ f . idxsp1 [ i ]]   -   x [ i ])   +   sin ( x [ f . idxsm1 [ i ]]   -   x [ i ])) \n         ) \n\n         xnew [ i ]   =   mod2pi ( x [ i ]   +   xnew [ i + N ]) \n     end \n     return   nothing  end   We will use  the same   struct  to create a function for the Jacobian:  function   ( f :: CoupledStandardMaps { M })( \n     J :: AbstractMatrix ,   x ,   p ,   n )   where   { M } \n\n     ks ,   \u0393   =   p \n     # x[i] \u2261 \u03b8\u1d62 \n     # x[[idxsp1[i]]] \u2261 \u03b8\u1d62+\u2081 \n     # x[[idxsm1[i]]] \u2261 \u03b8\u1d62-\u2081 \n     @inbounds   for   i   in   f . idxs \n         cos\u03b8   =   cos ( x [ i ]) \n         cos\u03b8p =   cos ( x [ f . idxsp1 [ i ]]   -   x [ i ]) \n         cos\u03b8m =   cos ( x [ f . idxsm1 [ i ]]   -   x [ i ]) \n         J [ i + M ,   i ]   =   ks [ i ] * cos\u03b8   +   \u0393 * ( cos\u03b8p   +   cos\u03b8m ) \n         J [ i + M ,   f . idxsm1 [ i ]]   =   -   \u0393 * cos\u03b8m \n         J [ i + M ,   f . idxsp1 [ i ]]   =   -   \u0393 * cos\u03b8p \n         J [ i ,   i ]   =   1   +   J [ i + M ,   i ] \n         J [ i ,   f . idxsm1 [ i ]]   =   J [ i + M ,   f . idxsm1 [ i ]] \n         J [ i ,   f . idxsp1 [ i ]]   =   J [ i + M ,   f . idxsp1 [ i ]] \n     end \n     return   nothing  end   The only reason that this is possible, is because the  eom  always takes a  AbstractVector  as first argument, while the Jacobian always takes an  AbstractMatrix . Therefore we can take advantage of multiple dispatch!  Notice in addition, that the Jacobian function accesses  only half the elements of the matrix . This is intentional, and takes advantage of the fact that the other half is constant.  Because the  DynamicalSystem  constructors allow us to give in a pre-initialized Jacobian matrix, we take advantage of that and create:  J   =   zeros ( eltype ( u0 ),   2 M ,   2 M )  # Set \u2202/\u2202p entries (they are eye(M,M))  # And they dont change they are constants  for   i   in   idxs \n     J [ i ,   i + M ]   =   1 \n     J [ i + M ,   i + M ]   =   1  end  csm ( J ,   u0 ,   p ,   0 )   # apply Jacobian to initial state   And finally, we are ready to create our dynamical system:  ds   =   DiscreteDynamicalSystem ( csm ,   u0 ,   p ,   csm ,   J )   10-dimensional discrete dynamical system\n state:     [5.88772e-6, 0.000539993, 0.000178981, 0.000607429, 0.000927426, 0.000246537, 0.00094118, 0.000703942, 0.000130421, 0.000332372]\n e.o.m.:    CoupledStandardMaps{5}([1, 2, 3, 4, 5], [5, 1, 2, 3, 4], [2, 3, 4, 5, 1])\n in-place?  true\n jacobian:  CoupledStandardMaps{5}([1, 2, 3, 4, 5], [5, 1, 2, 3, 4], [2, 3, 4, 5, 1])  which unfortunately is kind of a mess to read, but what can you do!", 
            "title": "Complex Example"
        }, 
        {
            "location": "/definition/evolve/", 
            "text": "Time Evolution of Systems\n\n\n\n\nTrajectory and Timeseries\n\n\nThe word \"timeseries\" can be confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in \nDynamicalSystems.jl\n we have the following convention: \n\"timeseries\"\n always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word \n\"trajectory\"\n is used to refer to a \nmulti-dimensional\n timeseries, which is of course simply a group/set of one-dimensional timeseries.\n\n\nNote that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a \nDataset\n, which is a \nVector\n of \nSVector\ns, and each \nSVector\n represents a data-point (the values of the variables at a given time-point).\n\n\n\n\nDynamicalSystems.jl\n provides a convenient function for getting a trajectory of a system at equally spaced time points:\n\n\n#\n\n\nDynamicalSystemsBase.trajectory\n \n \nFunction\n.\n\n\ntrajectory\n(\nds\n::\nDynamicalSystem\n,\n \nT\n \n[\n,\n \nu\n]\n;\n \nkwargs\n...)\n \n-\n \ndataset\n\n\n\n\n\n\nReturn a dataset that will contain the trajectory of the sytem, after evolving it for total time \nT\n, optionally starting from state \nu\n. See \nDataset\n for info on how to use this object.\n\n\nA \nW\u00d7D\n dataset is returned, with \nW = length(t0:dt:T)\n with \nt0:dt:T\n representing the time vector (\nnot\n returned) and \nD\n the system dimension. For discrete systems both \nT\n and \ndt\n must be integers.\n\n\nKeyword Arguments\n\n\n\n\ndt\n :  Time step of value output during the solving of the continuous system. For discrete systems it must be an integer. Defaults to \n0.01\n for continuous and \n1\n for discrete.\n\n\ndiff_eq_kwargs\n : (only for continuous) A dictionary \nDict{Symbol, ANY}\n of keyword arguments passed into the solvers of the \nDifferentialEquations.jl\n package, for example \nDict(:abstol =\n 1e-9)\n. If you want to specify a solver, do so by using the symbol \n:solver\n, e.g.: \nDict(:solver =\n DP5(), :maxiters =\n 1e9)\n. This requires you to have been first \nusing OrdinaryDiffEq\n to access the solvers. Defaults to \nDict(:solver =\n Vern9(), :abstol =\n 1e-9, :reltol =\n 1e-9)\n, i.e. a 9th order Verner algorithm.\n\n\n\n\nsource\n\n\n\n\nNotice that if you want to do repeated evolutions of different states of a continuous system, you should use the \nintegrator\n interface instead.\n\n\n\n\nSolution precision for continuous systems\n\n\nA numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.\n\n\nDifferentialEquations.jl offers a tool, called \nUncertainty Quantification\n, which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of \nDynamicalSystems.jl\n, the Lorenz system is accurate up to time \nt = 50.0\n.\n\n\nHowever, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the \nshadowing theorem\n (or \nshadowing lemma\n):\n\n\n\n\nShadowing Theorem\n\n\nAlthough a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.\n\n\n\n\nThis simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book \nChaos in Dynamical Systems\n by E. Ott, or the \nscholarpedia\n entry.", 
            "title": "Time Evolution"
        }, 
        {
            "location": "/definition/evolve/#time-evolution-of-systems", 
            "text": "Trajectory and Timeseries  The word \"timeseries\" can be confusing, because it can mean a univariate (also called scalar or one-dimensional) timeseries or a multivariate (also called multi-dimensional) timeseries. To resolve this confusion, in  DynamicalSystems.jl  we have the following convention:  \"timeseries\"  always refers to a one-dimensional vector of numbers, which exists with respect to some other one-dimensional vector of numbers that corresponds to a time-vector. On the other hand, the word  \"trajectory\"  is used to refer to a  multi-dimensional  timeseries, which is of course simply a group/set of one-dimensional timeseries.  Note that the data representation of a \"trajectory\" in Julia may vary: from a 2D Matrix to independent Vectors. In our package, a trajectory is always represented using a  Dataset , which is a  Vector  of  SVector s, and each  SVector  represents a data-point (the values of the variables at a given time-point).   DynamicalSystems.jl  provides a convenient function for getting a trajectory of a system at equally spaced time points:  #  DynamicalSystemsBase.trajectory     Function .  trajectory ( ds :: DynamicalSystem ,   T   [ ,   u ] ;   kwargs ...)   -   dataset   Return a dataset that will contain the trajectory of the sytem, after evolving it for total time  T , optionally starting from state  u . See  Dataset  for info on how to use this object.  A  W\u00d7D  dataset is returned, with  W = length(t0:dt:T)  with  t0:dt:T  representing the time vector ( not  returned) and  D  the system dimension. For discrete systems both  T  and  dt  must be integers.  Keyword Arguments   dt  :  Time step of value output during the solving of the continuous system. For discrete systems it must be an integer. Defaults to  0.01  for continuous and  1  for discrete.  diff_eq_kwargs  : (only for continuous) A dictionary  Dict{Symbol, ANY}  of keyword arguments passed into the solvers of the  DifferentialEquations.jl  package, for example  Dict(:abstol =  1e-9) . If you want to specify a solver, do so by using the symbol  :solver , e.g.:  Dict(:solver =  DP5(), :maxiters =  1e9) . This requires you to have been first  using OrdinaryDiffEq  to access the solvers. Defaults to  Dict(:solver =  Vern9(), :abstol =  1e-9, :reltol =  1e-9) , i.e. a 9th order Verner algorithm.   source   Notice that if you want to do repeated evolutions of different states of a continuous system, you should use the  integrator  interface instead.", 
            "title": "Time Evolution of Systems"
        }, 
        {
            "location": "/definition/evolve/#solution-precision-for-continuous-systems", 
            "text": "A numerical solution of an ODE is not the \"true\" solution, uniquely defined by a (well-defined) ODE and an initial condition. Especially for chaotic systems, where deviations are amplified exponentially, one is left worried if the numerical solutions truly are part of the system and can truly give insight in understanding the system.  DifferentialEquations.jl offers a tool, called  Uncertainty Quantification , which allows users to asses up to what time-scales the numerical solution is close to the \"true\" solution. For example, using the default solving parameters of  DynamicalSystems.jl , the Lorenz system is accurate up to time  t = 50.0 .  However, fortunately for us, there is not too much worry about the numerical solution diverging from the true solution. That is because of the  shadowing theorem  (or  shadowing lemma ):   Shadowing Theorem  Although a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.   This simply means that one can always numerically study chaos not only qualitatively but also quantitatively. For more information, see the book  Chaos in Dynamical Systems  by E. Ott, or the  scholarpedia  entry.", 
            "title": "Solution precision for continuous systems"
        }, 
        {
            "location": "/definition/dataset/", 
            "text": "Numerical Data\n\n\nNumerical data in \nDynamicalSystems.jl\n is represented by a structure called \nDataset\n\n\n#\n\n\nDynamicalSystemsBase.Dataset\n \n \nType\n.\n\n\nDataset{D, T} \n: AbstractDataset{D,T}\n\n\n\n\n\nA dedicated interface for datasets, i.e. vectors of vectors. It contains \nequally-sized datapoints\n of length \nD\n, represented by \nSVector{D, T}\n.\n\n\nIt can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables. \ntrajectory\n always returns a \nDataset\n. For example,\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n)\n \n#this returns a dataset\n\n\ndata\n[\n:\n,\n \n2\n]\n \n# this is the second variable timeseries\n\n\ndata\n[\n1\n]\n \n==\n \ndata\n[\n1\n,\n \n:\n]\n \n# this is the first datapoint (D-dimensional)\n\n\ndata\n[\n5\n,\n \n3\n]\n \n# value of the third variable, at the 5th timepoint\n\n\n\n\n\n\nUse \nMatrix(dataset)\n or \nreinterpret(Matrix, dataset)\n and \nDataset(matrix)\n or \nreinterpret(Dataset, matrix)\n to convert. The \nreinterpret\n methods are cheaper but assume that each variable/timeseries is a \nrow\n and not column of the \nmatrix\n.\n\n\nIf you have various timeseries vectors \nx, y, z, ...\n pass them like \nDataset(x, y, z, ...)\n. You can use \ncolumns(dataset)\n to obtain the reverse, i.e. all columns of the dataset in a tuple.\n\n\nsource\n\n\n\n\nIn essence a \nDataset\n is simply a container for a \nVector\n of \nSVector\ns. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the \ncolumn\n direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nhen\n,\n \n10000\n)\n \n# this returns a dataset\n\n\nfor\n \npoint\n \nin\n \ndata\n\n\n# do stuff with each datapoint (vector with as many elements as system dimension)\n\n\nend\n\n\n\n\n\n\nAll functions from \nDynamicalSystems.jl\n that manipulate and use data are expecting an \nAbstractDataset\n subtype. This allows us to define efficient methods that coordinate well with other packages, like e.g. \nneighborhood\n.\n\n\nIf given a matrix, we first convert to \nDataset\n. This means that you should \nfirst convert\n your data to a \nDataset\n if you want to call functions more than once, to avoid constantly converting.\n\n\n\n\nDataset Functions\n\n\nFunctions that operate on datasets.\n\n\n#\n\n\nDynamicalSystemsBase.minima\n \n \nFunction\n.\n\n\nminima(dataset)\n\n\n\n\n\nReturn an \nSVector\n that contains the minimum elements of each timeseries of the dataset.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.maxima\n \n \nFunction\n.\n\n\nmaxima(dataset)\n\n\n\n\n\nReturn an \nSVector\n that contains the maximum elements of each timeseries of the dataset.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.minmaxima\n \n \nFunction\n.\n\n\nminmaxima(dataset)\n\n\n\n\n\nReturn \nminima(dataset), maxima(dataset)\n without doing the computation twice.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.columns\n \n \nFunction\n.\n\n\ncolumns(dataset) -\n x, y, z, ...\n\n\n\n\n\nReturn the individual columns of the dataset.\n\n\nsource\n\n\n\n\n\n\nDataset IO\n\n\nIn addition to the above, we also offer (very basic) functions that read/write a \nDataset\n from/to a delimited text file:\n\n\n#\n\n\nDynamicalSystemsBase.read_dataset\n \n \nFunction\n.\n\n\nread_dataset\n(\nfile\n,\n \n::\nType\n{\n:Dataset\n}\n,\n \ndelim\n::\nChar\n \n=\n \n   \n;\n \nskipstart\n \n=\n \n0\n)\n\n\n\n\n\n\nRead a \ndelim\n-delimited text file directly into a dataset of dimension \nD\n with numbers of type \nT\n.\n\n\nOptionally skip the first \nskipstart\n rows of the file (that may e.g. contain headers).\n\n\nCall like \nread_dataset(\"file.txt\", Dataset{3, Float64})\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.write_dataset\n \n \nFunction\n.\n\n\nwrite_dataset\n(\nfile\n,\n \ndataset\n::\nAbstractDataset\n,\n \ndelim\n::\nChar\n \n=\n \n   \n;\n \nopts\n...)\n\n\n\n\n\n\nWrite a \ndataset\n in a \ndelim\n-delimited text file.\n\n\nopts\n are keyword arguments passed into \nwritedlm\n.\n\n\nsource\n\n\n\n\nFor example\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000\n)\n\n\n\n# Write comma-delimited file:\n\n\nwrite_dataset\n(\ntest.csv\n,\n \ndata\n,\n \n,\n)\n\n\n# Read comma-delimited file:\n\n\nread_dataset\n(\ntest.csv\n,\n \nDataset\n{\n2\n,\n \nFloat64\n},\n \n,\n)", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/definition/dataset/#numerical-data", 
            "text": "Numerical data in  DynamicalSystems.jl  is represented by a structure called  Dataset  #  DynamicalSystemsBase.Dataset     Type .  Dataset{D, T}  : AbstractDataset{D,T}  A dedicated interface for datasets, i.e. vectors of vectors. It contains  equally-sized datapoints  of length  D , represented by  SVector{D, T} .  It can be used exactly like a matrix that has each of the columns be the timeseries of each of the dynamic variables.  trajectory  always returns a  Dataset . For example,  ds   =   Systems . towel ()  data   =   trajectory ( ds ,   1000 )   #this returns a dataset  data [ : ,   2 ]   # this is the second variable timeseries  data [ 1 ]   ==   data [ 1 ,   : ]   # this is the first datapoint (D-dimensional)  data [ 5 ,   3 ]   # value of the third variable, at the 5th timepoint   Use  Matrix(dataset)  or  reinterpret(Matrix, dataset)  and  Dataset(matrix)  or  reinterpret(Dataset, matrix)  to convert. The  reinterpret  methods are cheaper but assume that each variable/timeseries is a  row  and not column of the  matrix .  If you have various timeseries vectors  x, y, z, ...  pass them like  Dataset(x, y, z, ...) . You can use  columns(dataset)  to obtain the reverse, i.e. all columns of the dataset in a tuple.  source   In essence a  Dataset  is simply a container for a  Vector  of  SVector s. However, it is visually represented as a matrix, similarly to how numerical data would be printed on a spreadsheet (with time being the  column  direction). It also offers a lot more functionality than just pretty-printing. Besides the examples in the documentation string, you can also do:  using   DynamicalSystems  hen   =   Systems . henon ()  data   =   trajectory ( hen ,   10000 )   # this returns a dataset  for   point   in   data  # do stuff with each datapoint (vector with as many elements as system dimension)  end   All functions from  DynamicalSystems.jl  that manipulate and use data are expecting an  AbstractDataset  subtype. This allows us to define efficient methods that coordinate well with other packages, like e.g.  neighborhood .  If given a matrix, we first convert to  Dataset . This means that you should  first convert  your data to a  Dataset  if you want to call functions more than once, to avoid constantly converting.", 
            "title": "Numerical Data"
        }, 
        {
            "location": "/definition/dataset/#dataset-functions", 
            "text": "Functions that operate on datasets.  #  DynamicalSystemsBase.minima     Function .  minima(dataset)  Return an  SVector  that contains the minimum elements of each timeseries of the dataset.  source  #  DynamicalSystemsBase.maxima     Function .  maxima(dataset)  Return an  SVector  that contains the maximum elements of each timeseries of the dataset.  source  #  DynamicalSystemsBase.minmaxima     Function .  minmaxima(dataset)  Return  minima(dataset), maxima(dataset)  without doing the computation twice.  source  #  DynamicalSystemsBase.columns     Function .  columns(dataset) -  x, y, z, ...  Return the individual columns of the dataset.  source", 
            "title": "Dataset Functions"
        }, 
        {
            "location": "/definition/dataset/#dataset-io", 
            "text": "In addition to the above, we also offer (very basic) functions that read/write a  Dataset  from/to a delimited text file:  #  DynamicalSystemsBase.read_dataset     Function .  read_dataset ( file ,   :: Type { :Dataset } ,   delim :: Char   =       ;   skipstart   =   0 )   Read a  delim -delimited text file directly into a dataset of dimension  D  with numbers of type  T .  Optionally skip the first  skipstart  rows of the file (that may e.g. contain headers).  Call like  read_dataset(\"file.txt\", Dataset{3, Float64}) .  source  #  DynamicalSystemsBase.write_dataset     Function .  write_dataset ( file ,   dataset :: AbstractDataset ,   delim :: Char   =       ;   opts ...)   Write a  dataset  in a  delim -delimited text file.  opts  are keyword arguments passed into  writedlm .  source   For example  using   DynamicalSystems  ds   =   Systems . towel ()  data   =   trajectory ( ds ,   1000 )  # Write comma-delimited file:  write_dataset ( test.csv ,   data ,   , )  # Read comma-delimited file:  read_dataset ( test.csv ,   Dataset { 2 ,   Float64 },   , )", 
            "title": "Dataset IO"
        }, 
        {
            "location": "/definition/reconstruction/", 
            "text": "A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire phase-space of the system. This can be done by reconstructing a new phase-space from the timeseries. One method that can do this is what is known as \ndelay coordinates embedding\n or delay coordinates \nreconstruction\n.\n\n\nThis is done through the \nReconstruction\n interface:\n\n\n#\n\n\nDynamicalSystemsBase.Reconstruction\n \n \nType\n.\n\n\nReconstruction(s::AbstractVector, D, \u03c4) \n: AbstractDataset\n\n\n\n\n\nD\n-dimensional delay-coordinates reconstruction object with delay \n\u03c4\n, created from a timeseries \ns\n.\n\n\nDescription\n\n\nIf \n\u03c4\n is an integer, then the \nn\nn\nth row of a \nReconstruction\n is\n\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\n\n\n\n(s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+(D-1)\\tau))\n\n\n\n\n\nIf instead \n\u03c4\n is a vector of integers, so that \nlength(\u03c4) == D\n, then the \nn\nn\nth row is\n\n\n\n\n\n(s(n+\\tau[1]), s(n+\\tau[2]), s(n+\\tau[3]), \\dots, s(n+\\tau[D]))\n\n\n\n\n(s(n+\\tau[1]), s(n+\\tau[2]), s(n+\\tau[3]), \\dots, s(n+\\tau[D]))\n\n\n\n\n\nThe reconstruction object \nR\n can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper \nD\n and \n\u03c4\n [1, 2].\n\n\nThe case of different delay times allows reconstructing systems with many time scales, see [3].\n\n\nMulti-dimensional \nReconstruction\n\n\nTo make a reconstruction out of a multi-dimensional timeseries (i.e. trajectory) use\n\n\nReconstruction\n(\ntr\n::\nSizedAray\n{\nA\n,\n \nB\n},\n \nD\n,\n \n\u03c4\n)\n\n\nReconstruction\n(\ntr\n::\nAbstractDataset\n{\nB\n},\n \nD\n,\n \n\u03c4\n)\n\n\n\n\n\n\nwith \nB\n the \"base\" dimensions.\n\n\nIf the trajectory is for example \n(x, y)\n(x, y)\n, then the \nn\nn\nth row is\n\n\n\n\n\n(x(n), y(n), x(n+\\tau), y(n+\\tau), \\dots, x(n+(D-1)\\tau), y(n+(D-1)\\tau))\n\n\n\n\n(x(n), y(n), x(n+\\tau), y(n+\\tau), \\dots, x(n+(D-1)\\tau), y(n+(D-1)\\tau))\n\n\n\n\n\nfor integer \n\u03c4\n and if \n\u03c4\n is an \nAbstractMatrix{Int}\n, so that \nsize(\u03c4) == (D, B)\n, then the \nn\nn\nth row is\n\n\n\n\n\n(x(n+\\tau[1, 1]), y(n+\\tau[1, 2]), \\dots, x(n+\\tau[D, 1]), y(n+\\tau[D, 2]))\n\n\n\n\n(x(n+\\tau[1, 1]), y(n+\\tau[1, 2]), \\dots, x(n+\\tau[D, 1]), y(n+\\tau[D, 2]))\n\n\n\n\n\nNote that a reconstruction created this way will have \nB*D\n total dimensions and \nnot\n \nD\n, as a result of each dimension of \ns\n having \nD\n delayed dimensions.\n\n\nReferences\n\n\n[1] : F. Takens, \nDetecting Strange Attractors in Turbulence \u2014 Dynamical Systems and Turbulence\n, Lecture Notes in Mathematics \n366\n, Springer (1981)\n\n\n[2] : T. Sauer \net al.\n, J. Stat. Phys. \n65\n, pp 579 (1991)\n\n\n[3] : K. Judd \n A. Mees, \nPhysica D \n120\n, pp 273 (1998)\n\n\nsource\n\n\n\n\nHere are some examples of \nReconstruction\ns of a 3D continuous chaotic system:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\ngissinger\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n,\n \ndt\n \n=\n \n0.05\n)\n\n\n\nxyz\n \n=\n \ncolumns\n(\ndata\n)\n\n\n\nfigure\n(\nfigsize\n \n=\n \n(\n12\n,\n10\n))\n\n\nk\n \n=\n \n1\n\n\nfor\n \ni\n \nin\n \n1\n:\n3\n\n    \nfor\n \n\u03c4\n \nin\n \n[\n5\n,\n \n30\n,\n \n100\n]\n\n        \nR\n \n=\n \nReconstruction\n(\nxyz\n[\ni\n],\n \n2\n,\n \n\u03c4\n)\n\n        \nax\n \n=\n \nsubplot\n(\n3\n,\n3\n,\nk\n)\n\n        \nplot\n(\nR\n[\n:\n,\n \n1\n],\n \nR\n[\n:\n,\n \n2\n],\n \ncolor\n \n=\n \nC\n$\n(\nk\n-\n1\n)\n,\n \nlw\n \n=\n \n0.8\n)\n\n        \ntitle\n(\nvar = \n$i\n, \u03c4 = \n$\u03c4\n)\n\n        \nk\n+=\n1\n\n    \nend\n\n\nend\n\n\n\ntight_layout\n()\n\n\nsuptitle\n(\n2D Reconstructions\n)\n\n\nsubplots_adjust\n(\ntop\n=\n0.9\n)\n\n\n\n\n\n\n\n\n\n\n\u03c4\n and \ndt\n\n\nKeep in mind that whether a value of \n\u03c4\n is \"reasonable\" for continuous systems depends on \ndt\n. In the above example the value \n\u03c4=30\n is good, \nonly\n for the case of using \ndt = 0.05\n. For shorter/longer \ndt\n one has to adjust properly \n\u03c4\n so that their product \n\u03c4*dt\n is the same.\n\n\n\n\nA \nReconstruction\n can also be made from a trajectory (i.e. multidimensional timeseries). For this to be possible, the number of timeseries must be known by Type:\n\n\na\n \n=\n \nrand\n(\n1000\n,\n \n3\n)\n \n# my trajectory\n\n\nR\n \n=\n \nReconstruction\n(\na\n,\n \n2\n,\n \n2\n)\n \n# errorino\n\n\n\nA\n \n=\n \nSize\n(\n1000\n,\n \n3\n)(\na\n)\n \n# create array with the size as Type information\n\n\nR\n \n=\n \nReconstruction\n(\nA\n,\n \n2\n,\n \n2\n)\n \n#aaaall good\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n();\n \ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000\n)\n\n\nR\n \n=\n \nReconstruction\n(\ntr\n,\n \n2\n,\n \n2\n)\n \n# Dataset size is also known by Type!\n\n\n\n\n\n\n(B=3, D=2, \u03c4=2) - delay coordinates multi-dimensional Reconstruction\n 0.085     -0.121       0.075     0.76827   -0.038933    0.672094\n 0.285813  -0.0675286   0.238038  0.681871   0.0508933   0.825263\n \u22ee                                                       \u22ee       \n\n\n\n\n\nHere the parameter \nB\n shows the number of base timeseries that were used for the multi-dimensional reconstruction.\n\n\n\n\nEstimating Reconstruction Parameters\n\n\nThe following functions can (sometimes) estimate good values that can be used in \nReconstruction\n. There are no guarantees though!\n\n\n#\n\n\nDynamicalSystemsBase.estimate_delay\n \n \nFunction\n.\n\n\nestimate_delay(s, method::String) -\n \u03c4\n\n\n\n\n\nEstimate an optimal delay to be used in \nReconstruction\n.\n\n\nThe \nmethod\n can be one of the following:\n\n\n\n\nfirst_zero\n : find first delay at which the auto-correlation function becomes 0.\n\n\nfirst_min\n : return delay of first minimum of the auto-correlation function.\n\n\nexp_decay\n : perform an exponential fit to the \nabs.(c)\n with \nc\n the auto-correlation function of \ns\n. Return the exponential decay time \n\u03c4\n rounded to an integer.\n\n\n\n\nsource", 
            "title": "Delay Coordinates"
        }, 
        {
            "location": "/definition/reconstruction/#estimating-reconstruction-parameters", 
            "text": "The following functions can (sometimes) estimate good values that can be used in  Reconstruction . There are no guarantees though!  #  DynamicalSystemsBase.estimate_delay     Function .  estimate_delay(s, method::String) -  \u03c4  Estimate an optimal delay to be used in  Reconstruction .  The  method  can be one of the following:   first_zero  : find first delay at which the auto-correlation function becomes 0.  first_min  : return delay of first minimum of the auto-correlation function.  exp_decay  : perform an exponential fit to the  abs.(c)  with  c  the auto-correlation function of  s . Return the exponential decay time  \u03c4  rounded to an integer.   source", 
            "title": "Estimating Reconstruction Parameters"
        }, 
        {
            "location": "/definition/predefined/", 
            "text": "Predefined Systems\n\n\nPredefined systems exist in the \nSystems\n submodule exported by DynamicalSystemsBase.jl, in the form of functions that return a \nDynamicalSystem\n. They are accessed like:\n\n\nusing\n \nDynamicalSystems\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n\n\ntypeof\n(\nds\n)\n \n# ContinuousDS\n\n\nts\n \n=\n \ntrajectory\n(\nds\n,\n \n10.0\n)\n\n\n\n\n\n\nSo far, the predefined systems that exist in the \nSystems\n sub-module are:\n\n\n#\n\n\nDynamicalSystemsBase.Systems.coupledstandardmaps\n \n \nFunction\n.\n\n\ncoupledstandardmaps\n(\nM\n::\nInt\n,\n \nu0\n \n=\n \n0.001\nrand\n(\n2\nM\n);\n \nks\n \n=\n \nones\n(\nM\n),\n \n\u0393\n \n=\n \n1.0\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' \n= \\theta_i + p_{i}' \\\\\np_{i}' \n= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}\n\n\n\n\n\nA discrete system of \nM\n nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The \ntotal\n dimension of the system is \n2M\n. The maps are coupled through \n\u0393\n and the \ni\n-th map has a nonlinear parameter \nks[i]\n.\n\n\n[1] : H. Kantz \n P. Grassberger, J. Phys. A \n21\n, pp 127\u2013133 (1988)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.double_pendulum\n \n \nFunction\n.\n\n\ndouble_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)\n\n\n\n\n\nFamous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).\n\n\nThe variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].\n\n\nJacobian is created automatically (thus methods that use the Jacobian will be slower)!\n\n\n(please contribute the Jacobian and the e.o.m. in LaTeX :smile:)\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.duffing\n \n \nFunction\n.\n\n\nduffing(u0 = [rand(), rand(), 0]; \u03c9 = 2.2, f = 27.0, d = 0.2, \u03b2 = 1)\n\n\n\n\n\nThe (forced) duffing oscillator, that satisfies the equation\n\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)\n\n\n\n\n\nwith \nf, \u03c9\n the forcing strength and frequency and \nd\n the dampening.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.gissinger\n \n \nFunction\n.\n\n\ngissinger\n(\nu0\n \n=\n \n3\nrand\n(\n3\n);\n \n\u03bc\n \n=\n \n0.119\n,\n \n\u03bd\n \n=\n \n0.1\n,\n \n\u0393\n \n=\n \n0.9\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{Q} \n= \\mu Q - VD \\\\\n\\dot{D} \n= -\\nu D + VQ \\\\\n\\dot{V} \n= \\Gamma -V + QD\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{Q} &= \\mu Q - VD \\\\\n\\dot{D} &= -\\nu D + VQ \\\\\n\\dot{V} &= \\Gamma -V + QD\n\\end{aligned}\n\n\n\n\n\nA continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : C. Gissinger, Eur. Phys. J. B \n85\n, 4, pp 1-12 (2012)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henon\n \n \nFunction\n.\n\n\nhenon\n(\nu0\n=\nzeros\n(\n2\n);\n \na\n \n=\n \n1.4\n,\n \nb\n \n=\n \n0.3\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= 1 - ax^2_n+y_n \\\\\ny_{n+1} \n = bx_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.\n\n\nAccording to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : M. H\u00e9non, Commun.Math. Phys. \n50\n, pp 69 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.henonheiles\n \n \nFunction\n.\n\n\nhenonheiles(u0=[0, -0.25, 0.42081,0])\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= p_x \\\\\n\\dot{y} \n= p_y \\\\\n\\dot{p}_x \n= -x -2 xy \\\\\n\\dot{p}_y \n= -y - (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2 xy \\\\\n\\dot{p}_y &= -y - (x^2 - y^2)\n\\end{aligned}\n\n\n\n\n\nThe H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.\n\n\nThe default initial condition is a typical chaotic orbit.\n\n\n[1] : H\u00e9non, M. \n Heiles, C., The Astronomical Journal \n69\n, pp 73\u201379 (1964)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.logistic\n \n \nFunction\n.\n\n\nlogistic\n(\nx0\n \n=\n \nrand\n();\n \nr\n \n=\n \n4.0\n)\n\n\n\n\n\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\nx_{n+1} = rx_n(1-x_n)\n\n\n\n\n\nThe logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.\n\n\nOriginally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : R. M. May, Nature \n261\n, pp 459 (1976)\n\n\n[2] : M. J. Feigenbaum, J. Stat. Phys. \n19\n, pp 25 (1978)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz\n \n \nFunction\n.\n\n\nlorenz\n(\nu0\n=\n[\n0.0\n,\n \n10.0\n,\n \n0.0\n];\n \n\u03c3\n \n=\n \n10.0\n,\n \n\u03c1\n \n=\n \n28.0\n,\n \n\u03b2\n \n=\n \n8\n/\n3\n)\n \n-\n \nds\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{X} \n= \\sigma(Y-X) \\\\\n\\dot{Y} \n= -XZ + \\rho X -Y \\\\\n\\dot{Z} \n= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}\n\n\n\n\n\nThe famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.\n\n\nCurrently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : E. N. Lorenz, J. atmos. Sci. \n20\n, pp 130 (1963)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.lorenz96\n \n \nFunction\n.\n\n\nlorenz96\n(\nN\n::\nInt\n,\n \nu0\n \n=\n \nrand\n(\nM\n);\n \nF\n=\n0\n.\n01\n)\n\n\n\n\n\n\nN\n is the chain length, \nF\n the forcing. Jacobian is created automatically. (parameter container only contains \nF\n)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.roessler\n \n \nFunction\n.\n\n\nroessler\n(\nu0\n=\nrand\n(\n3\n);\n \na\n \n=\n \n0.2\n,\n \nb\n \n=\n \n0.2\n,\n \nc\n \n=\n \n5.7\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\dot{x} \n= -y-z \\\\\n\\dot{y} \n= x+ay \\\\\n\\dot{z} \n= b + z(x-c)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= b + z(x-c)\n\\end{aligned}\n\n\n\n\n\nThis three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the \nlorenz\n system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n57A\n, pp 397 (1976)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.shinriki\n \n \nFunction\n.\n\n\nshinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)\n\n\n\n\n\nShinriki oscillator with all other parameters (besides \nR1\n) set to constants. \nThis is a stiff problem, be careful when choosing solvers and tolerances\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.standardmap\n \n \nFunction\n.\n\n\nstandardmap\n(\nu0\n=\n0.001\nrand\n(\n2\n);\n \nk\n \n=\n \n0.971635\n)\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} \n= \\theta_n + p_{n+1} \\\\\np_{n+1} \n= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}\n\n\n\n\n\nThe standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.\n\n\nThe map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter \nk\n transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.\n\n\nThe default parameter \nk\n is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable \n\u03b8\n to be the first, and the angular momentum \np\n to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).\n\n\nThe parameter container has the parameters in the same order as stated in this function's documentation string.\n\n\n[1] : B. V. Chirikov, Preprint N. \n267\n, Institute of Nuclear Physics, Novosibirsk (1969)\n\n\n[2] : J. M. Greene, J. Math. Phys. \n20\n, pp 1183 (1979)\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.Systems.towel\n \n \nFunction\n.\n\n\ntowel\n(\nu0\n \n=\n \n[\n0.085\n,\n \n-\n0.121\n,\n \n0.075\n])\n\n\n\n\n\n\n\n\n\n\\begin{aligned}\nx_{n+1} \n= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} \n= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} \n= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}\n\n\n\n\n\nThe folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.\n\n\nDefault values are the ones used in the original paper.\n\n\n[1] : O. E. R\u00f6ssler, Phys. Lett. \n71A\n, pp 155 (1979)\n\n\nsource", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/definition/predefined/#predefined-systems", 
            "text": "Predefined systems exist in the  Systems  submodule exported by DynamicalSystemsBase.jl, in the form of functions that return a  DynamicalSystem . They are accessed like:  using   DynamicalSystems  ds   =   Systems . lorenz ( \u03c1   =   32.0 )  typeof ( ds )   # ContinuousDS  ts   =   trajectory ( ds ,   10.0 )   So far, the predefined systems that exist in the  Systems  sub-module are:  #  DynamicalSystemsBase.Systems.coupledstandardmaps     Function .  coupledstandardmaps ( M :: Int ,   u0   =   0.001 rand ( 2 M );   ks   =   ones ( M ),   \u0393   =   1.0 )    \n\\begin{aligned}\n\\theta_{i}'  = \\theta_i + p_{i}' \\\\\np_{i}'  = p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{i}' &= \\theta_i + p_{i}' \\\\\np_{i}' &= p_i + k_i\\sin(\\theta_i) - \\Gamma \\left[\n\\sin(\\theta_{i+1} - \\theta_{i}) + \\sin(\\theta_{i-1} - \\theta_{i})\n\\right]\n\\end{aligned}   A discrete system of  M  nonlinearly coupled standard maps, first introduced in [1] to study diffusion and chaos thresholds. The  total  dimension of the system is  2M . The maps are coupled through  \u0393  and the  i -th map has a nonlinear parameter  ks[i] .  [1] : H. Kantz   P. Grassberger, J. Phys. A  21 , pp 127\u2013133 (1988)  source  #  DynamicalSystemsBase.Systems.double_pendulum     Function .  double_pendulum(u0=rand(4); G=10.0, L1 = 1.0, L2 = 1.0, M1 = 1.0, M2 = 1.0)  Famous chaotic double pendulum system (also used for our logo!). Keywords are gravity (G), lengths of each rod and mass of each ball (all assumed SI units).  The variables order is [\u03b81, d\u03b81/dt, \u03b82, d\u03b82/dt].  Jacobian is created automatically (thus methods that use the Jacobian will be slower)!  (please contribute the Jacobian and the e.o.m. in LaTeX :smile:)  The parameter container has the parameters in the same order as stated in this function's documentation string.  source  #  DynamicalSystemsBase.Systems.duffing     Function .  duffing(u0 = [rand(), rand(), 0]; \u03c9 = 2.2, f = 27.0, d = 0.2, \u03b2 = 1)  The (forced) duffing oscillator, that satisfies the equation   \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)  \n\\ddot{x} + d\\cdot\\dot{x} + \u03b2*x + x^3 = f\\cos(\\omega t)   with  f, \u03c9  the forcing strength and frequency and  d  the dampening.  The parameter container has the parameters in the same order as stated in this function's documentation string.  source  #  DynamicalSystemsBase.Systems.gissinger     Function .  gissinger ( u0   =   3 rand ( 3 );   \u03bc   =   0.119 ,   \u03bd   =   0.1 ,   \u0393   =   0.9 )    \n\\begin{aligned}\n\\dot{Q}  = \\mu Q - VD \\\\\n\\dot{D}  = -\\nu D + VQ \\\\\n\\dot{V}  = \\Gamma -V + QD\n\\end{aligned}  \n\\begin{aligned}\n\\dot{Q} &= \\mu Q - VD \\\\\n\\dot{D} &= -\\nu D + VQ \\\\\n\\dot{V} &= \\Gamma -V + QD\n\\end{aligned}   A continuous system that models chaotic reversals due to Gissinger [1], applied to study the reversals of the magnetic field of the Earth.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : C. Gissinger, Eur. Phys. J. B  85 , 4, pp 1-12 (2012)  source  #  DynamicalSystemsBase.Systems.henon     Function .  henon ( u0 = zeros ( 2 );   a   =   1.4 ,   b   =   0.3 )    \n\\begin{aligned}\nx_{n+1}  = 1 - ax^2_n+y_n \\\\\ny_{n+1}   = bx_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= 1 - ax^2_n+y_n \\\\\ny_{n+1} & = bx_n\n\\end{aligned}   The H\u00e9non map is a two-dimensional mapping due to H\u00e9non [1] that can display a strange attractor (at the default parameters). In addition, it also displays many other aspects of chaos, like period doubling or intermittency, for other parameters.  According to the author, it is a system displaying all the properties of the Lorentz system (1963) while being as simple as possible. Default values are the ones used in the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : M. H\u00e9non, Commun.Math. Phys.  50 , pp 69 (1976)  source  #  DynamicalSystemsBase.Systems.henonheiles     Function .  henonheiles(u0=[0, -0.25, 0.42081,0])   \n\\begin{aligned}\n\\dot{x}  = p_x \\\\\n\\dot{y}  = p_y \\\\\n\\dot{p}_x  = -x -2 xy \\\\\n\\dot{p}_y  = -y - (x^2 - y^2)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= p_x \\\\\n\\dot{y} &= p_y \\\\\n\\dot{p}_x &= -x -2 xy \\\\\n\\dot{p}_y &= -y - (x^2 - y^2)\n\\end{aligned}   The H\u00e9non\u2013Heiles system [1] was introduced as a simplification of the motion of a star around a galactic center. It was originally intended to study the existence of a \"third integral of motion\" (which would make this 4D system integrable). In that search, the authors encountered chaos, as the third integral existed for only but a few initial conditions.  The default initial condition is a typical chaotic orbit.  [1] : H\u00e9non, M.   Heiles, C., The Astronomical Journal  69 , pp 73\u201379 (1964)  source  #  DynamicalSystemsBase.Systems.logistic     Function .  logistic ( x0   =   rand ();   r   =   4.0 )    \nx_{n+1} = rx_n(1-x_n)  \nx_{n+1} = rx_n(1-x_n)   The logistic map is an one dimensional unimodal mapping due to May [1] and is used by many as the archetypal example of how chaos can arise from very simple equations.  Originally intentend to be a discretized model of polulation dynamics, it is now famous for its bifurcation diagram, an immensly complex graph that that was shown be universal by Feigenbaum [2].  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : R. M. May, Nature  261 , pp 459 (1976)  [2] : M. J. Feigenbaum, J. Stat. Phys.  19 , pp 25 (1978)  source  #  DynamicalSystemsBase.Systems.lorenz     Function .  lorenz ( u0 = [ 0.0 ,   10.0 ,   0.0 ];   \u03c3   =   10.0 ,   \u03c1   =   28.0 ,   \u03b2   =   8 / 3 )   -   ds    \n\\begin{aligned}\n\\dot{X}  = \\sigma(Y-X) \\\\\n\\dot{Y}  = -XZ + \\rho X -Y \\\\\n\\dot{Z}  = XY - \\beta Z\n\\end{aligned}  \n\\begin{aligned}\n\\dot{X} &= \\sigma(Y-X) \\\\\n\\dot{Y} &= -XZ + \\rho X -Y \\\\\n\\dot{Z} &= XY - \\beta Z\n\\end{aligned}   The famous three dimensional system due to Lorenz [1], shown to exhibit so-called \"deterministic nonperiodic flow\". It was originally invented to study a simplified form of atmospheric convection.  Currently, it is most famous for its strange attractor (occuring at the default parameters), which resembles a butterfly. For the same reason it is also associated with the term \"butterfly effect\" (a term which Lorenz himself disliked) even though the effect applies generally to dynamical systems. Default values are the ones used in the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : E. N. Lorenz, J. atmos. Sci.  20 , pp 130 (1963)  source  #  DynamicalSystemsBase.Systems.lorenz96     Function .  lorenz96 ( N :: Int ,   u0   =   rand ( M );   F = 0 . 01 )   N  is the chain length,  F  the forcing. Jacobian is created automatically. (parameter container only contains  F )  source  #  DynamicalSystemsBase.Systems.roessler     Function .  roessler ( u0 = rand ( 3 );   a   =   0.2 ,   b   =   0.2 ,   c   =   5.7 )    \n\\begin{aligned}\n\\dot{x}  = -y-z \\\\\n\\dot{y}  = x+ay \\\\\n\\dot{z}  = b + z(x-c)\n\\end{aligned}  \n\\begin{aligned}\n\\dot{x} &= -y-z \\\\\n\\dot{y} &= x+ay \\\\\n\\dot{z} &= b + z(x-c)\n\\end{aligned}   This three-dimensional continuous system is due to R\u00f6ssler [1]. It is a system that by design behaves similarly to the  lorenz  system and displays a (fractal) strange attractor. However, it is easier to analyze qualitatively, as for example the attractor is composed of a single manifold. Default values are the same as the original paper.  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : O. E. R\u00f6ssler, Phys. Lett.  57A , pp 397 (1976)  source  #  DynamicalSystemsBase.Systems.shinriki     Function .  shinriki(u0 = [-2, 0, 0.2]; R1 = 22.0)  Shinriki oscillator with all other parameters (besides  R1 ) set to constants.  This is a stiff problem, be careful when choosing solvers and tolerances .  source  #  DynamicalSystemsBase.Systems.standardmap     Function .  standardmap ( u0 = 0.001 rand ( 2 );   k   =   0.971635 )    \n\\begin{aligned}\n\\theta_{n+1}  = \\theta_n + p_{n+1} \\\\\np_{n+1}  = p_n + k\\sin(\\theta_n)\n\\end{aligned}  \n\\begin{aligned}\n\\theta_{n+1} &= \\theta_n + p_{n+1} \\\\\np_{n+1} &= p_n + k\\sin(\\theta_n)\n\\end{aligned}   The standard map (also known as Chirikov standard map) is a two dimensional, area-preserving chaotic mapping due to Chirikov [1]. It is one of the most studied chaotic systems and by far the most studied Hamiltonian (area-preserving) mapping.  The map corresponds to the  Poincar\u00e9's surface of section of the kicked rotor system. Changing the non-linearity parameter  k  transitions the system from completely periodic motion, to quasi-periodic, to local chaos (mixed phase-space) and finally to global chaos.  The default parameter  k  is the critical parameter where the golden-ratio torus is destroyed, as was calculated by Greene [2]. The e.o.m. considers the angle variable  \u03b8  to be the first, and the angular momentum  p  to be the second, while both variables are always taken modulo 2\u03c0 (the mapping is on the [0,2\u03c0)\u00b2 torus).  The parameter container has the parameters in the same order as stated in this function's documentation string.  [1] : B. V. Chirikov, Preprint N.  267 , Institute of Nuclear Physics, Novosibirsk (1969)  [2] : J. M. Greene, J. Math. Phys.  20 , pp 1183 (1979)  source  #  DynamicalSystemsBase.Systems.towel     Function .  towel ( u0   =   [ 0.085 ,   - 0.121 ,   0.075 ])    \n\\begin{aligned}\nx_{n+1}  = a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1}  = 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1}  = 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}  \n\\begin{aligned}\nx_{n+1} &= a x_n (1-x_n) -0.05 (y_n +0.35) (1-2z_n) \\\\\ny_{n+1} &= 0.1 \\left( \\left( y_n +0.35 \\right)\\left( 1+2z_n\\right) -1 \\right)\n\\left( 1 -1.9 x_n \\right) \\\\\nz_{n+1} &= 3.78 z_n (1-z_n) + b y_n\n\\end{aligned}   The folded-towel map is a hyperchaotic mapping due to R\u00f6ssler [1]. It is famous for being a mapping that has the smallest possible dimensions necessary for hyperchaos, having two positive and one negative Lyapunov exponent. The name comes from the fact that when plotted looks like a folded towel, in every projection.  Default values are the ones used in the original paper.  [1] : O. E. R\u00f6ssler, Phys. Lett.  71A , pp 155 (1979)  source", 
            "title": "Predefined Systems"
        }, 
        {
            "location": "/chaos/overview/", 
            "text": "Features Overview\n\n\nThe features offered in this documentation section come from the package \nChaosTools.jl\n. If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.\n\n\n\n\nOrbit Diagrams\n\n\n\n\nOrbit diagrams (aka bifurcation diagrams) of maps: \norbitdiagram\n.\n\n\nPoincar\u00e9 surfaces of section for continuous systems: \npoincaresos\n.\n\n\nAutomated production of orbit diagrams for continuous systems: \nproduce_orbitdiagram\n.\n\n\n\n\n\n\nLyapunov Exponents\n\n\nThe following treat systems where the equations of motion are known:\n\n\n\n\nMaximum Lyapunov exponent for both discrete and continuous systems: \nlyapunov\n.\n\n\nLyapunov \nspectrum\n for both discrete and continuous systems: \nlyapunovs\n.\n\n\n\n\n\n\nEntropies and Dimensions\n\n\n\n\nGeneralized (Renyi) entropy: \ngenentropy\n.\n\n\nPermutation entropy: \npermentropy\n.\n\n\nFast and cheap (memory-wise) method for computing entropies of large datasets.\n\n\nGeneralized dimensions (e.g. capacity dimension, information dimension, etc.): \ngeneralized_dim\n.\n\n\nKaplan-Yorke dimension: \nkaplanyorke_dim\n.\n\n\nAutomated detection of best algorithmic parameters for calculating attractor dimensions.\n\n\n\n\nAnd, in order to automatically deduce dimensions, we also offer methods for:\n\n\n\n\nPartitioning a function \ny(x)\ny(x)\n vs. \nx\nx\n into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See \nlinear_regions\n.\n\n\nDetection of largest linear region of a function \ny(x)\ny(x)\n vs. \nx\nx\n and extraction of the slope of this region.\n\n\n\n\n\n\nNonlinear Timeseries Analysis\n\n\n\n\nFlexible and abstracted \nReconstruction\n interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.\n\n\nMethods for estimating good \nReconstruction\n parameters.\n\n\nBroomhead-King coordinates: \nbroomhead_king\n.\n\n\n\n\nFour different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries: \nnumericallyapunov\n.\n\n\n\n\nFast computation of the above algorithms made possible by combining the\n\n\n\n\nperformance of \nNearestNeighbors.jl\n with  the abstraction of ChaosTools.jl.\n\n\n\n\n\n\n\n\nPeriodicity\n\n\n\n\n\n\nNumerical method to find unstable and stable fixed points of \nany order\n \nn\nn\n of a discrete map (of any dimensionality): \nperiodicorbits\n.\n\n\n\n\nConvenience functions for defining and realizing all possible combinations of \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrices required in the above method.\n\n\n\n\n\n\n\n\n\n\nChaos Detection\n\n\n\n\n\n\nThe Generalized Alignment Index: \n\\text{GALI}_k\n\\text{GALI}_k\n : \ngali\n.\n\n\n\n\nImplemented for both discrete and continuous systems.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#features-overview", 
            "text": "The features offered in this documentation section come from the package  ChaosTools.jl . If you are encountering an issue with some of the methods, you can report/open a new issue at the GitHub Issues page.", 
            "title": "Features Overview"
        }, 
        {
            "location": "/chaos/overview/#orbit-diagrams", 
            "text": "Orbit diagrams (aka bifurcation diagrams) of maps:  orbitdiagram .  Poincar\u00e9 surfaces of section for continuous systems:  poincaresos .  Automated production of orbit diagrams for continuous systems:  produce_orbitdiagram .", 
            "title": "Orbit Diagrams"
        }, 
        {
            "location": "/chaos/overview/#lyapunov-exponents", 
            "text": "The following treat systems where the equations of motion are known:   Maximum Lyapunov exponent for both discrete and continuous systems:  lyapunov .  Lyapunov  spectrum  for both discrete and continuous systems:  lyapunovs .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/overview/#entropies-and-dimensions", 
            "text": "Generalized (Renyi) entropy:  genentropy .  Permutation entropy:  permentropy .  Fast and cheap (memory-wise) method for computing entropies of large datasets.  Generalized dimensions (e.g. capacity dimension, information dimension, etc.):  generalized_dim .  Kaplan-Yorke dimension:  kaplanyorke_dim .  Automated detection of best algorithmic parameters for calculating attractor dimensions.   And, in order to automatically deduce dimensions, we also offer methods for:   Partitioning a function  y(x) y(x)  vs.  x x  into regions where it is approximated by a straight line, using a flexible algorithm with a lot of control over the outcome. See  linear_regions .  Detection of largest linear region of a function  y(x) y(x)  vs.  x x  and extraction of the slope of this region.", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/overview/#nonlinear-timeseries-analysis", 
            "text": "Flexible and abstracted  Reconstruction  interface, that creates the delay-coordinates reconstruction of a timeseries efficiently.  Methods for estimating good  Reconstruction  parameters.  Broomhead-King coordinates:  broomhead_king .   Four different algorithms for numerically determining the maximum Lyapunov exponent of a (e.g. experimentally) measured timeseries:  numericallyapunov .   Fast computation of the above algorithms made possible by combining the   performance of  NearestNeighbors.jl  with  the abstraction of ChaosTools.jl.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/overview/#periodicity", 
            "text": "Numerical method to find unstable and stable fixed points of  any order   n n  of a discrete map (of any dimensionality):  periodicorbits .   Convenience functions for defining and realizing all possible combinations of  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrices required in the above method.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/overview/#chaos-detection", 
            "text": "The Generalized Alignment Index:  \\text{GALI}_k \\text{GALI}_k  :  gali .   Implemented for both discrete and continuous systems.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/orbitdiagram/", 
            "text": "Orbit Diagrams of Maps\n\n\nAn orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed\n\n\n#\n\n\nChaosTools.orbitdiagram\n \n \nFunction\n.\n\n\norbitdiagram\n(\nds\n::\nDiscreteDynamicalSystem\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \nkwargs\n...)\n\n\n\n\n\n\nCompute the orbit diagram (also called bifurcation diagram) of the given system for the \ni\n-th variable for parameter values \npvalues\n. The \np_index\n specifies which parameter of the equations of motion is to be changed.\n\n\nReturns a vector of vectors, where each entry are the points are each parameter value.\n\n\nKeyword Arguments\n\n\n\n\nics = [state(ds)]\n : container of initial conditions that are used at each parameter value to evolve orbits.\n\n\nTtr::Int = 1000\n : Transient steps; each orbit is evolved for \nTtr\n first before saving output.\n\n\nn::Int = 100\n : Amount of points to save for each initial condition.\n\n\n\n\nDescription\n\n\nThe method works by computing orbits at each parameter value in \npvalues\n for each initial condition in \nics\n.\n\n\nThe parameter change is done as \np[p_index] = ...\n and thus you must use a parameter container that supports this (either \nArray\n, \nLMArray\n, dictionary or other).\n\n\nThe returned \noutput\n is a vector of vectors. \noutput[j]\n are the orbit points of the \ni\n-th variable of the system, at parameter value \npvalues[j]\n.\n\n\nSee also \npoincaresos\n and \nproduce_orbitdiagram\n.\n\n\nsource\n\n\n\n\nFor example, let's compute the famous orbit diagram of the logistic map:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\ni\n \n=\n \n1\n\n\npvalues\n \n=\n \n2\n:\n0.001\n:\n4\n\n\nics\n \n=\n \n[\nrand\n()\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n50\n\n\nTtr\n \n=\n \n5000\n\n\np_index\n \n=\n \n1\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nr\n\\$\n);\n \nylabel\n(\n\\$\nx\n\\$\n)\n\n\n\n\n\n\n\n\nNotice that if you are using \nPyPlot\n, the plotting process will be slow, since it is slow at plotting big numbers of points.\n\n\nThe function is not limited to 1D maps, and can be applied just as well to any discrete system.\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\ni\n \n=\n \n2\n\n\n\npvalues\n \n=\n \n0\n:\n0.005\n:\n2\n\n\nics\n \n=\n \n[\n0.001\nrand\n(\n2\n)\n \nfor\n \nm\n \nin\n \n1\n:\n10\n]\n\n\nn\n \n=\n \n50\n\n\nTtr\n \n=\n \n5000\n\n\noutput\n \n=\n \norbitdiagram\n(\nds\n,\n \ni\n,\n \n1\n,\n \npvalues\n;\n \nn\n \n=\n \nn\n,\n \nTtr\n \n=\n \nTtr\n,\n \nics\n \n=\n \nics\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nk\n\\$\n);\n \nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\n\n\n\n\nPoincar\u00e9 Surface of Section\n\n\nAlso called \nPoincar\u00e9 map\n is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:\n\n\n#\n\n\nChaosTools.poincaresos\n \n \nFunction\n.\n\n\npoincaresos\n(\nds\n::\nContinuousDynamicalSystem\n,\n \nj\n,\n \ntfinal\n \n=\n \n100\n.\n0\n;\n \nkwargs\n...)\n\n\n\n\n\n\nCalculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1, 2] of the given system on the plane of the \nj\n-th variable of the system. The system is evolved for total time of \ntfinal\n.\n\n\nReturns a \nDataset\n of the points that are on the surface of section.\n\n\nKeyword Arguments\n\n\n\n\ndirection = 1\n and \noffset = 0.0\n : The surface of section is defined as the (hyper-) plane where \nstate[j] = offset\n. Only crossings of the plane that have direction \nsign(direction)\n are considered to belong to the surface of section.\n\n\nTtr = 0.0\n : Transient time to evolve the system before starting to compute the PSOS.\n\n\ndiff_eq_kwargs\n : See \ntrajectory\n.\n\n\ncallback_kwargs = Dict(:abstol=\n1e-6)\n : Keyword arguments passed into the \nContinuousCallback\n type of \nDifferentialEquations\n, used to find the section. The option \ncallback_kwargs[:idxs] = j\n is enforced. Decreasing the \nabstol\n makes the section more accurate.\n\n\n\n\nReferences\n\n\n[1] : H. Poincar\u00e9, \nLes Methods Nouvelles de la M\u00e9canique Celeste\n, Paris: Gauthier-Villars (1892)\n\n\n[2] : M. Tabor, \nChaos and Integrability in Nonlinear Dynamics: An Introduction\n, \u00a74.1, in pp. 118-126, New York: Wiley (1989)\n\n\nSee also \norbitdiagram\n, \nproduce_orbitdiagram\n.\n\n\nsource\n\n\n\n\nAn example of the \nHenon-Heiles\n system using a quasi-periodic solution\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n([\n0.\n,\n \n0.1\n,\n \n0.5\n,\n \n0.\n])\n\n\noutput\n \n=\n \npoincaresos\n(\nds\n,\n \n3\n,\n \n1000.0\n)\n\n\n\nfigure\n()\n\n\nplot\n(\noutput\n[\n:\n,\n \n2\n],\n \noutput\n[\n:\n,\n \n4\n],\n \nlw\n \n=\n \n0.0\n,\n \nmarker\n=\n.\n)\n\n\nxlabel\n(\n\\$\nq_2\n\\$\n);\n \nylabel\n(\n\\$\np_2\n\\$\n);\n\n\n\n\n\n\n\n\nHere the surface of section was the (hyper-) plane that \np_1 = 0\np_1 = 0\n. As expected the section is 1-dimensional, because the torus the solution lives in is 2-dimensional. if we produced the PSOS for much longer times, the result would be a filled line instead of individual points.\n\n\n\n\nStroboscopic Map\n\n\nA special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the \nDuffing oscillator\n.\n\n\nA \"cut\" through the phase-space can be produced at every period \nT = 2\\pi/\\omega\nT = 2\\pi/\\omega\n. There is no reason to use \npoincaresos\n for this though, because you can simply use \ntrajectory\n and get the solution with a certain time sampling rate:\n\n\nds\n \n=\n \nSystems\n.\nduffing\n(\n\u03b2\n \n=\n \n-\n1\n,\n \n\u03c9\n \n=\n \n1\n,\n \nf\n \n=\n \n0.3\n)\n \n# non-autonomous chaotic system\n\n\na\n \n=\n \ntrajectory\n(\nds\n,\n \n100000.0\n,\n \ndt\n \n=\n \n2\n\u03c0\n)\n \n# every period T = 2\u03c0/\u03c9\n\n\nplot\n(\na\n[\n:\n,\n \n1\n],\n \na\n[\n:\n,\n \n2\n],\n \nlw\n \n=\n \n0\n,\n \nmarker\n \n=\no\n,\n \nms\n \n=\n \n1\n)\n\n\nxlabel\n(\n\\$\nx\n\\$\n);\n \nylabel\n(\n\\$\\\\\ndot{x}\n\\$\n)\n\n\n\n\n\n\n What a cool looking attractor is that!\n\n\n\n\nProducing Orbit Diagrams for Continuous Flows\n\n\nThe \norbitdiagram\n does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for \norbitdiagram\n to have meaning one must have a map.\n\n\nIf only there was a way to turn a continuous system into a map... \nOH WAIT!\n That is what \npoincaresos\n does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.\n\n\nWe have bundled this process in the following function:\n\n\n#\n\n\nChaosTools.produce_orbitdiagram\n \n \nFunction\n.\n\n\nproduce_orbitdiagram(ds::ContinuousDynamicalSystem, j, i,\n                     p_index, pvalues; kwargs...)\n\n\n\n\n\nProduce an orbit diagram (also called bifurcation diagram) for the \ni\n-th variable of the given continuous system by computing Poincar\u00e9 surfaces of section of the \nj\n-th variable of the system for the given parameter values.\n\n\nKeyword Arguments\n\n\n\n\ndirection\n, \noffset\n, \ndiff_eq_kwargs\n, \ncallback_kwargs\n, \nTtr\n : Passed into \npoincaresos\n.\n\n\nprintparams::Bool = false\n : Whether to print the parameter used during computation in order to keep track of running time.\n\n\nics = [state(ds)]\n : Collection of initial conditions. For every \nstate \u2208 ics\n a PSOS will be produced.\n\n\n\n\nDescription\n\n\nFor each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for one of the \ni \u2260 j\n variables of the system, just like it is done in \norbitdiagram\n.\n\n\nThe parameter change is done as \np[p_index] = value\n taking values from \npvalues\n and thus you must use a parameter container that supports this (either \nArray\n, \nLMArray\n, dictionary or other).\n\n\nThe returned \noutput\n is a vector of vectors. \noutput[k]\n are the \"orbit diagram\" points of the \ni\n-th variable of the system, at parameter value \npvalues[k]\n.\n\n\nPerformance Notes\n\n\nThe total amount of PSOS produced will be \nlength(ics)*length(pvalues)\n.\n\n\nSee also \npoincaresos\n, \norbitdiagram\n.\n\n\nsource\n\n\n\n\nFor example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!\n\n\nds\n \n=\n \nSystems\n.\nshinriki\n([\n-\n2\n,\n \n0\n,\n \n0.2\n])\n\n\n\npvalues\n \n=\n \nlinspace\n(\n19\n,\n22\n,\n201\n)\n\n\ni\n \n=\n \n1\n\n\nj\n \n=\n \n2\n\n\ntf\n \n=\n \n200.0\n\n\np_index\n \n=\n \n1\n\n\n\noutput\n \n=\n \nproduce_orbitdiagram\n(\nds\n,\n \nj\n,\n \ni\n,\n \np_index\n,\n \npvalues\n;\n \ntfinal\n \n=\n \ntf\n,\n\n\nTtr\n \n=\n \n200.0\n,\n \ndirection\n \n=\n \n-\n1\n,\n \nprintparams\n \n=\n \ntrue\n)\n\n\n\nfigure\n()\n\n\nfor\n \n(\nj\n,\n \np\n)\n \nin\n \nenumerate\n(\npvalues\n)\n\n    \nplot\n(\np\n \n.*\n \nones\n(\noutput\n[\nj\n]),\n \noutput\n[\nj\n],\n \nlw\n \n=\n \n0\n,\n\n    \nmarker\n \n=\n \no\n,\n \nms\n \n=\n \n0.5\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nend\n\n\nxlabel\n(\n\\$\nR_1\n\\$\n);\n \nylabel\n(\n\\$\nV_1\n\\$\n)", 
            "title": "Orbit Diagrams & PSOS"
        }, 
        {
            "location": "/chaos/orbitdiagram/#orbit-diagrams-of-maps", 
            "text": "An orbit diagram (also called bifurcation diagram) is a way to visualize the asymptotic behavior of a map, when a parameter of the system is changed  #  ChaosTools.orbitdiagram     Function .  orbitdiagram ( ds :: DiscreteDynamicalSystem ,   i ,   p_index ,   pvalues ;   kwargs ...)   Compute the orbit diagram (also called bifurcation diagram) of the given system for the  i -th variable for parameter values  pvalues . The  p_index  specifies which parameter of the equations of motion is to be changed.  Returns a vector of vectors, where each entry are the points are each parameter value.  Keyword Arguments   ics = [state(ds)]  : container of initial conditions that are used at each parameter value to evolve orbits.  Ttr::Int = 1000  : Transient steps; each orbit is evolved for  Ttr  first before saving output.  n::Int = 100  : Amount of points to save for each initial condition.   Description  The method works by computing orbits at each parameter value in  pvalues  for each initial condition in  ics .  The parameter change is done as  p[p_index] = ...  and thus you must use a parameter container that supports this (either  Array ,  LMArray , dictionary or other).  The returned  output  is a vector of vectors.  output[j]  are the orbit points of the  i -th variable of the system, at parameter value  pvalues[j] .  See also  poincaresos  and  produce_orbitdiagram .  source   For example, let's compute the famous orbit diagram of the logistic map:  using   DynamicalSystems  using   PyPlot  ds   =   Systems . logistic ()  i   =   1  pvalues   =   2 : 0.001 : 4  ics   =   [ rand ()   for   m   in   1 : 10 ]  n   =   50  Ttr   =   5000  p_index   =   1  output   =   orbitdiagram ( ds ,   i ,   p_index ,   pvalues ;   n   =   n ,   Ttr   =   Ttr )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ r \\$ );   ylabel ( \\$ x \\$ )    Notice that if you are using  PyPlot , the plotting process will be slow, since it is slow at plotting big numbers of points.  The function is not limited to 1D maps, and can be applied just as well to any discrete system.  ds   =   Systems . standardmap ()  i   =   2  pvalues   =   0 : 0.005 : 2  ics   =   [ 0.001 rand ( 2 )   for   m   in   1 : 10 ]  n   =   50  Ttr   =   5000  output   =   orbitdiagram ( ds ,   i ,   1 ,   pvalues ;   n   =   n ,   Ttr   =   Ttr ,   ics   =   ics )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ k \\$ );   ylabel ( \\$ p \\$ )", 
            "title": "Orbit Diagrams of Maps"
        }, 
        {
            "location": "/chaos/orbitdiagram/#poincare-surface-of-section", 
            "text": "Also called  Poincar\u00e9 map  is a technique to reduce a continuous system into a discrete map with 1 less dimension. We are doing this using the function:  #  ChaosTools.poincaresos     Function .  poincaresos ( ds :: ContinuousDynamicalSystem ,   j ,   tfinal   =   100 . 0 ;   kwargs ...)   Calculate the Poincar\u00e9 surface of section (also called Poincar\u00e9 map) [1, 2] of the given system on the plane of the  j -th variable of the system. The system is evolved for total time of  tfinal .  Returns a  Dataset  of the points that are on the surface of section.  Keyword Arguments   direction = 1  and  offset = 0.0  : The surface of section is defined as the (hyper-) plane where  state[j] = offset . Only crossings of the plane that have direction  sign(direction)  are considered to belong to the surface of section.  Ttr = 0.0  : Transient time to evolve the system before starting to compute the PSOS.  diff_eq_kwargs  : See  trajectory .  callback_kwargs = Dict(:abstol= 1e-6)  : Keyword arguments passed into the  ContinuousCallback  type of  DifferentialEquations , used to find the section. The option  callback_kwargs[:idxs] = j  is enforced. Decreasing the  abstol  makes the section more accurate.   References  [1] : H. Poincar\u00e9,  Les Methods Nouvelles de la M\u00e9canique Celeste , Paris: Gauthier-Villars (1892)  [2] : M. Tabor,  Chaos and Integrability in Nonlinear Dynamics: An Introduction , \u00a74.1, in pp. 118-126, New York: Wiley (1989)  See also  orbitdiagram ,  produce_orbitdiagram .  source   An example of the  Henon-Heiles  system using a quasi-periodic solution  ds   =   Systems . henonheiles ([ 0. ,   0.1 ,   0.5 ,   0. ])  output   =   poincaresos ( ds ,   3 ,   1000.0 )  figure ()  plot ( output [ : ,   2 ],   output [ : ,   4 ],   lw   =   0.0 ,   marker = . )  xlabel ( \\$ q_2 \\$ );   ylabel ( \\$ p_2 \\$ );    Here the surface of section was the (hyper-) plane that  p_1 = 0 p_1 = 0 . As expected the section is 1-dimensional, because the torus the solution lives in is 2-dimensional. if we produced the PSOS for much longer times, the result would be a filled line instead of individual points.", 
            "title": "Poincar\u00e9 Surface of Section"
        }, 
        {
            "location": "/chaos/orbitdiagram/#stroboscopic-map", 
            "text": "A special case of a PSOS is a stroboscopic map, which is defined for non-autonomous systems with periodic time dependence, like e.g. the  Duffing oscillator .  A \"cut\" through the phase-space can be produced at every period  T = 2\\pi/\\omega T = 2\\pi/\\omega . There is no reason to use  poincaresos  for this though, because you can simply use  trajectory  and get the solution with a certain time sampling rate:  ds   =   Systems . duffing ( \u03b2   =   - 1 ,   \u03c9   =   1 ,   f   =   0.3 )   # non-autonomous chaotic system  a   =   trajectory ( ds ,   100000.0 ,   dt   =   2 \u03c0 )   # every period T = 2\u03c0/\u03c9  plot ( a [ : ,   1 ],   a [ : ,   2 ],   lw   =   0 ,   marker   = o ,   ms   =   1 )  xlabel ( \\$ x \\$ );   ylabel ( \\$\\\\ dot{x} \\$ )    What a cool looking attractor is that!", 
            "title": "Stroboscopic Map"
        }, 
        {
            "location": "/chaos/orbitdiagram/#producing-orbit-diagrams-for-continuous-flows", 
            "text": "The  orbitdiagram  does not make much sense for continuous systems, besides the trivial case where the system is at a fixed point. In order for  orbitdiagram  to have meaning one must have a map.  If only there was a way to turn a continuous system into a map...  OH WAIT!  That is what  poincaresos  does! By performing successive surfaces of section at different parameter values, one can indeed \"produce\" an orbit diagram for a flow.  We have bundled this process in the following function:  #  ChaosTools.produce_orbitdiagram     Function .  produce_orbitdiagram(ds::ContinuousDynamicalSystem, j, i,\n                     p_index, pvalues; kwargs...)  Produce an orbit diagram (also called bifurcation diagram) for the  i -th variable of the given continuous system by computing Poincar\u00e9 surfaces of section of the  j -th variable of the system for the given parameter values.  Keyword Arguments   direction ,  offset ,  diff_eq_kwargs ,  callback_kwargs ,  Ttr  : Passed into  poincaresos .  printparams::Bool = false  : Whether to print the parameter used during computation in order to keep track of running time.  ics = [state(ds)]  : Collection of initial conditions. For every  state \u2208 ics  a PSOS will be produced.   Description  For each parameter, a PSOS reduces the system from a flow to a map. This then allows the formal computation of an \"orbit diagram\" for one of the  i \u2260 j  variables of the system, just like it is done in  orbitdiagram .  The parameter change is done as  p[p_index] = value  taking values from  pvalues  and thus you must use a parameter container that supports this (either  Array ,  LMArray , dictionary or other).  The returned  output  is a vector of vectors.  output[k]  are the \"orbit diagram\" points of the  i -th variable of the system, at parameter value  pvalues[k] .  Performance Notes  The total amount of PSOS produced will be  length(ics)*length(pvalues) .  See also  poincaresos ,  orbitdiagram .  source   For example, we will calculate the orbit diagram of the Shinriki oscillator, a continuous system that undergoes a period doubling route to chaos, much like the logistic map!  ds   =   Systems . shinriki ([ - 2 ,   0 ,   0.2 ])  pvalues   =   linspace ( 19 , 22 , 201 )  i   =   1  j   =   2  tf   =   200.0  p_index   =   1  output   =   produce_orbitdiagram ( ds ,   j ,   i ,   p_index ,   pvalues ;   tfinal   =   tf ,  Ttr   =   200.0 ,   direction   =   - 1 ,   printparams   =   true )  figure ()  for   ( j ,   p )   in   enumerate ( pvalues ) \n     plot ( p   .*   ones ( output [ j ]),   output [ j ],   lw   =   0 , \n     marker   =   o ,   ms   =   0.5 ,   color   =   black )  end  xlabel ( \\$ R_1 \\$ );   ylabel ( \\$ V_1 \\$ )", 
            "title": "Producing Orbit Diagrams for Continuous Flows"
        }, 
        {
            "location": "/chaos/lyapunovs/", 
            "text": "Lyapunov Exponents\n\n\nLyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The \nWikipedia\n and the \nScholarpedia\n entries have a lot of valuable information about the history and usage of these quantities.\n\n\nThis page treats systems where the equations of motion are known. If instead you have numerical data, see the \nnonlinear timeseries analysis page\n.\n\n\n\n\nLyapunov Spectrum\n\n\nThe function \nlyapunovs\n calculates the entire spectrum of the Lyapunov exponents of a system:\n\n\n#\n\n\nChaosTools.lyapunovs\n \n \nFunction\n.\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n,\n \nk\n::\nInt\n \n|\n \nQ0\n;\n \nkwargs\n...)\n \n-\n \n\u03bb\ns\n\n\n\n\n\n\nCalculate the spectrum of Lyapunov exponents [1] of \nds\n by applying a QR-decomposition on the parallelepiped matrix \nN\n times. Return the spectrum sorted from maximum to minimum.\n\n\nThe third argument \nk\n is optional, and dictates how many lyapunov exponents to calculate (defaults to \ndimension(ds)\n). Instead of passing an integer \nk\n you can pass a pre-initialized matrix \nQ0\n whose columns are initial deviation vectors (then \nk = size(Q0)[2]\n).\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the system before application of the algorithm. Should be \nInt\n for discrete systems. Both the system and the deviation vectors are evolved for this time.\n\n\ndt\n : Time of individual evolutions between successive orthonormalization steps. Defaults to \n1\n. For continuous systems this is approximate.\n\n\ndiff_eq_kwargs = Dict()\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\n\n\nDescription\n\n\nThe method we employ is \"H2\" of [2], originally stated in [3]. The vectors defining a \nD\n-dimensional parallepiped are evolved using the tangent dynamics of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over \nN\n successive steps, yielding the lyapunov exponent spectrum.\n\n\nPerformance Notes\n\n\nThis function uses a \ntangent_integrator\n. For loops over initial conditions and/or parameter values one should use the lower level methods that accept an integrator, and \nreinit!\n it to new initial conditions.\n\n\nSee the \"advanced documentation\" for info on the integrator object and use \n@which ...\n to go to the source code for the low-level call signature.\n\n\nReferences\n\n\n[1] : A. M. Lyapunov, \nThe General Problem of the Stability of Motion\n, Taylor \n Francis (1992)\n\n\n[2] : K. Geist \net al.\n, Progr. Theor. Phys. \n83\n, pp 875 (1990)\n\n\n[3] : G. Benettin \net al.\n, Meccanica \n15\n, pp 9-20 \n 21-30 (1980)\n\n\nsource\n\n\n\n\nAs you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the \nfolded towel map\n is calculated as:\n\n\nusing\n \nDynamicalSystems\n\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nds\n,\n \n10000\n)\n\n\n\n\n\n\n[\n0.432535\n,\n \n0.372184\n,\n \n-\n3.29683\n]\n\n\n\n\n\n\nSimilarly, for a continuous system, e.g. the Lorenz system, you would do:\n\n\nlor\n \n=\n \nSystems\n.\nlorenz\n(\n\u03c1\n \n=\n \n32.0\n)\n \n#this is not the original parameter!\n\n\n\u03bb\u03bb\n \n=\n \nlyapunovs\n(\nlor\n,\n \n10000\n,\n \ndt\n \n=\n \n0.1\n)\n\n\n\n\n\n\n[\n0.985688\n,\n \n0.00271333\n,\n \n-\n14.6551\n]\n\n\n\n\n\n\nlyapunovs\n is also very fast:\n\n\nusing\n \nBenchmarkTools\n\n\nds\n \n=\n \nSystems\n.\ntowel\n()\n\n\n@btime\n \nlyapunovs\n(\n$\nds\n,\n \n1000\n);\n\n\n\n\n\n\n  239.349 \u03bcs (178 allocations: 11.34 KiB)\n\n\n\n\n\n\n\nMaximum Lyapunov Exponent\n\n\nThe function \nlyapunov\n calculates the maximum lyapunov exponent of a system, more efficiently than getting the first result of \nlyapunovs\n:\n\n\n#\n\n\nChaosTools.lyapunov\n \n \nFunction\n.\n\n\nlyapunov\n(\nds\n::\nDynamicalSystem\n,\n \n\u03a4\n;\n \nkwargs\n...)\n \n-\n \n\u03bb\n\n\n\n\n\n\nCalculate the maximum Lyapunov exponent \n\u03bb\n using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one. \nT\n  denotes the total time of evolution (should be \nInt\n for discrete systems).\n\n\nKeyword Arguments\n\n\n\n\nTtr = 0\n : Extra \"transient\" time to evolve the trajectories before starting to measure the expontent. Should be \nInt\n for discrete systems.\n\n\nd0 = 1e-9\n : Initial \n rescaling distance between the two neighboring trajectories.\n\n\nupper_threshold = 1e-6\n : Upper distance threshold for rescaling.\n\n\nlower_threshold = 1e-12\n : Lower distance threshold for rescaling (in order to  be able to detect negative exponents).\n\n\ndiff_eq_kwargs = Dict(:abstol=\nd0, :reltol=\nd0)\n : (only for continuous) Keyword arguments passed into the solvers of the \nDifferentialEquations\n package (see \ntrajectory\n for more info).\n\n\ndt = 1\n : Time of evolution between each check of distance exceeding the thresholds.\n\n\ninittest = (u1, d0) -\n u1 .+ d0/sqrt(D)\n : A function that given \n(u1, d0)\n initializes the test state with distance \nd0\n from the given state \nu1\n (\nD\n is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.\n\n\n\n\nDescription\n\n\nTwo neighboring trajectories with initial distance \nd0\n are evolved in time. At time \nt_i\nt_i\n their distance \nd(t_i)\nd(t_i)\n either exceeds the \nupper_threshold\n, or is lower than \nlower_threshold\n, which initializes a rescaling of the test trajectory back to having distance \nd0\n from the given one, while the rescaling keeps the difference vector along the maximal expansion/contraction direction: \nu_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0)\nu_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0)\n.\n\n\nThe maximum Lyapunov exponent is the average of the time-local Lyapunov exponents\n\n\n\n\n\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.\n\n\n\n\n\nPerformance Notes\n\n\nThis function uses a \nparallel_integrator\n. For loops over initial conditions and/or parameter values one should use the lower level methods that accept an integrator, and \nreinit!\n it to new initial conditions.\n\n\nSee the \"advanced documentation\" for info on the integrator object and use \n@which ...\n to go to the source code for the low-level call signature.\n\n\nReferences\n\n\n[1] : G. Benettin \net al.\n, Phys. Rev. A \n14\n, pp 2338 (1976)\n\n\nsource\n\n\n\n\nFor example:\n\n\nusing\n \nDynamicalSystems\n\n\nhenon\n \n=\n \nSystems\n.\nhenon\n()\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nhenon\n,\n \n10000\n,\n \nd0\n \n=\n \n1e-7\n,\n \nupper_threshold\n \n=\n \n1e-4\n,\n \nTtr\n \n=\n \n100\n)\n\n\n\n\n\n\n0.42007471604734054\n\n\n\n\n\nThe same is done for continuous systems:\n\n\nross\n \n=\n \nSystems\n.\nroessler\n(\na\n \n=\n \n0.1\n,\n \nb\n \n=\n \n0.1\n,\n \nc\n \n=\n \n14.0\n)\n \n#not original parameters\n\n\n\u03bb\n \n=\n \nlyapunov\n(\nross\n,\n \n100000\n,\n \ndt\n \n=\n \n10.0\n,\n \nTtr\n \n=\n \n100.0\n)\n\n\n\n\n\n\n0.07127399326422117", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-exponents", 
            "text": "Lyapunov exponents measure rates of separation of nearby trajectories in the flow of a dynamical system. The  Wikipedia  and the  Scholarpedia  entries have a lot of valuable information about the history and usage of these quantities.  This page treats systems where the equations of motion are known. If instead you have numerical data, see the  nonlinear timeseries analysis page .", 
            "title": "Lyapunov Exponents"
        }, 
        {
            "location": "/chaos/lyapunovs/#lyapunov-spectrum", 
            "text": "The function  lyapunovs  calculates the entire spectrum of the Lyapunov exponents of a system:  #  ChaosTools.lyapunovs     Function .  lyapunovs ( ds :: DynamicalSystem ,   N ,   k :: Int   |   Q0 ;   kwargs ...)   -   \u03bb s   Calculate the spectrum of Lyapunov exponents [1] of  ds  by applying a QR-decomposition on the parallelepiped matrix  N  times. Return the spectrum sorted from maximum to minimum.  The third argument  k  is optional, and dictates how many lyapunov exponents to calculate (defaults to  dimension(ds) ). Instead of passing an integer  k  you can pass a pre-initialized matrix  Q0  whose columns are initial deviation vectors (then  k = size(Q0)[2] ).  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the system before application of the algorithm. Should be  Int  for discrete systems. Both the system and the deviation vectors are evolved for this time.  dt  : Time of individual evolutions between successive orthonormalization steps. Defaults to  1 . For continuous systems this is approximate.  diff_eq_kwargs = Dict()  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).   Description  The method we employ is \"H2\" of [2], originally stated in [3]. The vectors defining a  D -dimensional parallepiped are evolved using the tangent dynamics of the system. A QR-decomposition at each step yields the local growth rate for each dimension of the parallepiped. The growth rates are then averaged over  N  successive steps, yielding the lyapunov exponent spectrum.  Performance Notes  This function uses a  tangent_integrator . For loops over initial conditions and/or parameter values one should use the lower level methods that accept an integrator, and  reinit!  it to new initial conditions.  See the \"advanced documentation\" for info on the integrator object and use  @which ...  to go to the source code for the low-level call signature.  References  [1] : A. M. Lyapunov,  The General Problem of the Stability of Motion , Taylor   Francis (1992)  [2] : K. Geist  et al. , Progr. Theor. Phys.  83 , pp 875 (1990)  [3] : G. Benettin  et al. , Meccanica  15 , pp 9-20   21-30 (1980)  source   As you can see, the documentation string is detailed and self-contained. For example, the lyapunov spectrum of the  folded towel map  is calculated as:  using   DynamicalSystems  ds   =   Systems . towel ()  \u03bb\u03bb   =   lyapunovs ( ds ,   10000 )   [ 0.432535 ,   0.372184 ,   - 3.29683 ]   Similarly, for a continuous system, e.g. the Lorenz system, you would do:  lor   =   Systems . lorenz ( \u03c1   =   32.0 )   #this is not the original parameter!  \u03bb\u03bb   =   lyapunovs ( lor ,   10000 ,   dt   =   0.1 )   [ 0.985688 ,   0.00271333 ,   - 14.6551 ]   lyapunovs  is also very fast:  using   BenchmarkTools  ds   =   Systems . towel ()  @btime   lyapunovs ( $ ds ,   1000 );     239.349 \u03bcs (178 allocations: 11.34 KiB)", 
            "title": "Lyapunov Spectrum"
        }, 
        {
            "location": "/chaos/lyapunovs/#maximum-lyapunov-exponent", 
            "text": "The function  lyapunov  calculates the maximum lyapunov exponent of a system, more efficiently than getting the first result of  lyapunovs :  #  ChaosTools.lyapunov     Function .  lyapunov ( ds :: DynamicalSystem ,   \u03a4 ;   kwargs ...)   -   \u03bb   Calculate the maximum Lyapunov exponent  \u03bb  using a method due to Benettin [1], which simply evolves two neighboring trajectories (one called \"given\" and one called \"test\") while constantly rescaling the test one.  T   denotes the total time of evolution (should be  Int  for discrete systems).  Keyword Arguments   Ttr = 0  : Extra \"transient\" time to evolve the trajectories before starting to measure the expontent. Should be  Int  for discrete systems.  d0 = 1e-9  : Initial   rescaling distance between the two neighboring trajectories.  upper_threshold = 1e-6  : Upper distance threshold for rescaling.  lower_threshold = 1e-12  : Lower distance threshold for rescaling (in order to  be able to detect negative exponents).  diff_eq_kwargs = Dict(:abstol= d0, :reltol= d0)  : (only for continuous) Keyword arguments passed into the solvers of the  DifferentialEquations  package (see  trajectory  for more info).  dt = 1  : Time of evolution between each check of distance exceeding the thresholds.  inittest = (u1, d0) -  u1 .+ d0/sqrt(D)  : A function that given  (u1, d0)  initializes the test state with distance  d0  from the given state  u1  ( D  is the dimension of the system). This function can be used when you want to avoid the test state appearing in a region of the phase-space where it would have e.g. different energy or escape to infinity.   Description  Two neighboring trajectories with initial distance  d0  are evolved in time. At time  t_i t_i  their distance  d(t_i) d(t_i)  either exceeds the  upper_threshold , or is lower than  lower_threshold , which initializes a rescaling of the test trajectory back to having distance  d0  from the given one, while the rescaling keeps the difference vector along the maximal expansion/contraction direction:  u_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0) u_2 \\to u_1+(u_2\u2212u_1)/(d(t_i)/d_0) .  The maximum Lyapunov exponent is the average of the time-local Lyapunov exponents   \n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.  \n\\lambda = \\frac{1}{t_{n}}\\sum_{i=1}^{n}\n\\ln\\left( a_i \\right),\\quad a_i = \\frac{d(t_{i})}{d_0}.   Performance Notes  This function uses a  parallel_integrator . For loops over initial conditions and/or parameter values one should use the lower level methods that accept an integrator, and  reinit!  it to new initial conditions.  See the \"advanced documentation\" for info on the integrator object and use  @which ...  to go to the source code for the low-level call signature.  References  [1] : G. Benettin  et al. , Phys. Rev. A  14 , pp 2338 (1976)  source   For example:  using   DynamicalSystems  henon   =   Systems . henon ()  \u03bb   =   lyapunov ( henon ,   10000 ,   d0   =   1e-7 ,   upper_threshold   =   1e-4 ,   Ttr   =   100 )   0.42007471604734054  The same is done for continuous systems:  ross   =   Systems . roessler ( a   =   0.1 ,   b   =   0.1 ,   c   =   14.0 )   #not original parameters  \u03bb   =   lyapunov ( ross ,   100000 ,   dt   =   10.0 ,   Ttr   =   100.0 )   0.07127399326422117", 
            "title": "Maximum Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/entropies/", 
            "text": "Entropies and Dimensions\n\n\n\n\nEntropies\n\n\nIn the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known \nthermodynamic ones\n, used in Statistical Physics. Rather, they are more like the to the entropies of \ninformation theory\n, which represents information contained within a dataset, or information about the dimensional scaling of a dataset.\n\n\n\n\nGeneralized Entropy\n\n\n#\n\n\nChaosTools.genentropy\n \n \nFunction\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the \n\u03b1\n order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length \n\u03b5\n using \nnon0hist\n.\n\n\ngenentropy\n(\n\u03b1\n,\n \np\n::\nAbstractArray\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the entropy of an array \np\n directly, assuming that \np\n is sum-normalized.\n\n\nOptionally use \nbase\n for the logarithms.\n\n\nDescription\n\n\nThe R\u00e9nyi entropy\n\n\n\n\n\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha\n\n\n\n\nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha\n\n\n\n\n\ngeneralizes other known entropies, like e.g. the information entropy (\n\\alpha = 1\n\\alpha = 1\n, see [2]), the maximum entropy (\n\\alpha=0\n\\alpha=0\n, also known as Hartley entropy), or the correlation entropy (\n\\alpha = 2\n\\alpha = 2\n, also known as collision entropy).\n\n\nThe following aliases are provided:\n\n\n\n\nrenyi = genentropy\n\n\nshannon(args...) = genentropy(1, args...)\n\n\nhartley(args...) = genentropy(0, args...)\n\n\n\n\nReferences\n\n\n[1] : A. R\u00e9nyi, \nProceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability\n, pp 547 (1960)\n\n\n[2] : C. E. Shannon, Bell Systems Technical Journal \n27\n, pp 379 (1948)\n\n\nsource\n\n\n\n\nBasically, given a \ndataset\n you can partition it into boxes to calculate an entropy.\n\n\n\n\nWorried about memory overflow? Don't be!\n\n\nPartitioning the dataset (i.e. doing a \nhistogram\n) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size \n\u03b5\n. However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!\n\n\nIn fact, there is an upper bound to the memory allocated by \nnon0hist\n: A constant multiplied by the length of the array, \nN = length(p)\n. No matter how small \n\u03b5\n or how many dimensions the data has, the method can at most assign \nN\n dictionary entries.\n\n\n\n\nThe function used internally by \ngenentropy\n is \nnon0hist\n:\n\n\n#\n\n\nChaosTools.non0hist\n \n \nFunction\n.\n\n\nnon0hist\n(\n\u03b5\n,\n \ndataset\n::\nAbstractDataset\n)\n\n\n\n\n\n\nPartition a dataset into tabulated intervals (boxes) of size \n\u03b5\n and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements.\n\n\nPerformances Notes\n\n\nThis method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins. This allows computation of entropies of high-dimensional datasets and with small box sizes \n\u03b5\n without memory overflow.\n\n\nUse e.g. \nfit(Histogram, ...)\n from \nStatsBase\n if you wish to keep information about the edges of the binning as well as the zero elements.\n\n\nsource\n\n\n\n\nFor example, the Shannon entropy of a coin-flip process should be one bit, \nby definition\n. Let's see...\n\n\nusing\n \nDynamicalSystems\n\n\ny\n \n=\n \nFloat64\n.\n(\nrand\n(\nBool\n,\n \n1000000\n))\n \n# just some coin tosses\n\n\nsh\n \n=\n \nshannon\n(\n0.1\n,\n \ny\n)\n  \n# \u2261 genentropy(1, 0.0, y)\n\n\nisapprox\n(\nsh\n,\n \nlog\n(\n2\n),\n  \nrtol\n \n=\n \n1e-6\n)\n\n\n\n\n\n\ntrue\n\n\n\n\n\n\nBecause all entropies are by default calculated on base-\ne\ne\n, the unit of measurement is \"nat\" and one bit is \n\\log(2)\\times\n\\log(2)\\times\nnat.\n\n\n\n\nPermutation Entropy\n\n\nThe permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.\n\n\n#\n\n\nChaosTools.permentropy\n \n \nFunction\n.\n\n\npermentropy\n(\nx\n::\nAbstractVector\n,\n \norder\n \n[\n,\n \ninterval\n=\n1\n]\n;\n \nbase\n \n=\n \ne\n)\n\n\n\n\n\n\nCompute the permutation entropy [1] of given \norder\n from the \nx\n timeseries.\n\n\nOptionally, \ninterval\n can be specified to use \nx[t0:interval:t1]\n when calculating permutation of the sliding windows between \nt0\n and \nt1 = t0 + interval * (order - 1)\n.\n\n\nOptionally use \nbase\n for the logarithms.\n\n\nReferences\n\n\n[1] : C. Bandt, \n B. Pompe, \nPhys. Rev. Lett. \n88\n (17), pp 174102 (2002)\n\n\nsource\n\n\nFor example, we will compute and compare the \nlyapunov\n exponent of the logistic map with the order-6 permutation entropy, like in the original paper.\n\n\nds\n \n=\n \nSystems\n.\nlogistic\n()\n\n\nrs\n \n=\n \n3.5\n:\n0.001\n:\n4\n\n\nls\n \n=\n \nFloat64\n[];\n \nhs\n \n=\n \nFloat64\n[]\n\n\nfor\n \nr\n \nin\n \nrs\n\n    \nds\n.\np\n[\n1\n]\n \n=\n \nr\n\n    \npush!\n(\nls\n,\n \nlyapunov\n(\nds\n,\n \n100000\n))\n\n    \n# For 1D systems `trajectory` returns a vector\n\n    \npush!\n(\nhs\n,\n \npermentropy\n(\ntrajectory\n(\nds\n,\n \n10000\n),\n \n6\n))\n\n\nend\n\n\n\nf\n \n=\n \nfigure\n(\nfigsize\n \n=\n \n(\n10\n,\n6\n))\n\n\na1\n \n=\n \nsubplot\n(\n211\n)\n\n\nplot\n(\nrs\n,\n \nls\n);\n \nylim\n(\n-\n2\n,\n \nlog\n(\n2\n));\n \nylabel\n(\n\\$\\\\\nlambda\n\\$\n)\n\n\na1\n[\n:\naxes\n][\n:\nget_xaxis\n]()[\n:\nset_ticklabels\n]([])\n\n\nxlim\n(\nrs\n[\n1\n],\n \nrs\n[\nend\n]);\n\n\n\na2\n \n=\n \nsubplot\n(\n212\n)\n\n\nplot\n(\nrs\n,\n \nhs\n;\n \ncolor\n \n=\n \nC1\n);\n \nylabel\n(\n\\$\nh_6\n\\$\n)\n\n\nxlim\n(\nrs\n[\n1\n],\n \nrs\n[\nend\n]);\n \nxlabel\n(\n\\$\nr\n\\$\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\n\n\nPermutation Entropy performance\n\n\nEven though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue \nChaosTools.jl#22\n keeps track of this, and contains information on how to improve performance.\n\n\n\n\n\n\nAttractor Dimension Estimation\n\n\nThere are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the \nFractal dimension\n. This real number can offer a lot of information about the object that the dataset represents.\n\n\n\n\nGeneralized Dimensions\n\n\nBased on the definition of the \ngeneralized entropy\n, one can calculate an appropriate dimension, called \ngeneralized dimension\n:\n\n\n#\n\n\nChaosTools.generalized_dim\n \n \nFunction\n.\n\n\ngeneralized_dim(\u03b1, dataset [, sizes]) -\n D_\u03b1\n\n\n\n\n\nReturn the \n\u03b1\n order generalized dimension of the \ndataset\n, by calculating the \ngenentropy\n for each \n\u03b5 \u2208 sizes\n.\n\n\nDescription\n\n\nThe returned dimension is approximated by the (inverse) power law exponent of the scaling of the \ngenentropy\n versus the box size \n\u03b5\n, where \n\u03b5 \u2208 sizes\n.\n\n\nCalling this function performs a lot of automated steps:\n\n\n\n\nA vector of box sizes is decided by calling \nsizes = estimate_boxsizes(dataset)\n, if \nsizes\n is not given.\n\n\nFor each element of \nsizes\n the appropriate entropy is calculated, through \nd = genentropy.(\u03b1, sizes, dataset)\n. Let \nx = -log.(sizes)\n.\n\n\nThe curve \nd(x)\n is decomposed into linear regions, using \nlinear_regions\n(x, d)\n.\n\n\nThe biggest linear region is chosen, and a fit for the slope of that region is performed using the function \nlinear_region\n. This slope is the return value of \ngeneralized_dim\n.\n\n\n\n\nBy doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.\n\n\nThe following aliases are provided:\n\n\n\n\n\u03b1 = 0 : \nboxcounting_dim\n, \ncapacity_dim\n\n\n\u03b1 = 1 : \ninformation_dim\n\n\n\u03b1 = 2 : \ncorrelation_dim\n\n\n\n\nsource\n\n\n\n\n\n\nBe wary when using \ngeneralized_dim\n\n\nAs stated clearly by the documentation string, calling \ngeneralized_dim\n performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.\n\n\n\n\n#\n\n\nChaosTools.estimate_boxsizes\n \n \nFunction\n.\n\n\nestimate_boxsizes\n(\ndataset\n::\nAbstractDataset\n;\n \nk\n::\nInt\n \n=\n \n12\n,\n \nz\n \n=\n \n-1\n,\n \nw\n \n=\n \n1\n)\n\n\n\n\n\n\nReturn a \nk\n-element \nlogspace\n from \nlower + w\n to \nupper + z\n,\n\n\nlower\n is the magnitude of the minimum pair-wise distance between datapoints while \nupper\n is the magnitude of the maximum difference between greatest and smallest number among each timeseries.\n\n\n\"Magnitude\" here stands for order of magnitude, i.e. \nround(log10(x))\n.\n\n\nsource\n\n\n#\n\n\nChaosTools.linear_regions\n \n \nFunction\n.\n\n\nlinear_regions(x, y; dxi::Int = 1, tol = 0.2) -\n (lrs, tangents)\n\n\n\n\n\nIdentify regions where the curve \ny(x)\n is linear, by scanning the \nx\n-axis every \ndxi\n indices (e.g. at \nx[1] to x[5], x[5] to x[10], x[10] to x[15]\n and so on if \ndxi=5\n).\n\n\nIf the slope (calculated using \nLsqFit\n) of a region of width \ndxi\n is approximatelly equal to that of the previous region, within tolerance \ntol\n, then these two regions belong to the same linear region.\n\n\nReturn the indices of \nx\n that correspond to linear regions, \nlrs\n, and the approximated \ntangents\n at each region. \nlrs\n is a vector of \nInt\n.\n\n\nA function \nplot_linear_regions\n visualizes the result of using this \nlinear_regions\n (requires \nPyPlot\n).\n\n\nsource\n\n\n#\n\n\nChaosTools.linear_region\n \n \nFunction\n.\n\n\nlinear_region(x, y; dxi::Int = 1, tol = 0.2) -\n ([ind1, ind2], slope)\n\n\n\n\n\nCall \nlinear_regions\n, identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops (\nx[ind1:ind2]\n) as well as the approximated slope.\n\n\nsource\n\n\n\n\n\n\nExample\n\n\nFor example, the dimension of the strange attractor of the \nH\u00e9non map\n is:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n(\n-\nrand\n(\n2\n))\n\n\nts\n \n=\n \ntrajectory\n(\nhen\n,\n \n1000000\n)\n\n\nD_hen\n \n=\n \ninformation_dim\n(\nts\n)\n\n\n\n\n\n\n1.19735650096483\n\n\n\n\n\nAs a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D \n56\n, pp 185-187 (1992)).\n\n\n\n\n\n\nKaplan-Yorke Dimension\n\n\n#\n\n\nChaosTools.kaplanyorke_dim\n \n \nFunction\n.\n\n\nkaplanyorke_dim(lyapunovs::AbstractVector)\n\n\n\n\n\nCalculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].\n\n\nDescription\n\n\nThe Kaplan-Yorke dimension is simply the point where \ncumsum(lyapunovs)\n becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.\n\n\nUseful in combination with \nlyapunovs\n.\n\n\nReferences\n\n\n[1] :  J. Kaplan \n J. Yorke, \nChaotic behavior of multidimensional difference equations\n, Lecture Notes in Mathematics vol. \n730\n, Springer (1979)\n\n\nsource\n\n\n\n\nNotice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:\n\n\nusing\n \nDynamicalSystems\n\n\nhen\n \n=\n \nSystems\n.\nhenon\n()\n\n\nD_kp\n \n=\n \nkaplanyorke_dim\n(\nlyapunovs\n(\nhen\n,\n \n100000\n))\n\n\n\n\n\n\n1.2587051169257504", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies-and-dimensions", 
            "text": "", 
            "title": "Entropies and Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#entropies", 
            "text": "In the study of dynamical systems there are many quantities that identify as \"entropy\". Notice that these quantities are not the more commonly known  thermodynamic ones , used in Statistical Physics. Rather, they are more like the to the entropies of  information theory , which represents information contained within a dataset, or information about the dimensional scaling of a dataset.", 
            "title": "Entropies"
        }, 
        {
            "location": "/chaos/entropies/#generalized-entropy", 
            "text": "#  ChaosTools.genentropy     Function .  genentropy ( \u03b1 ,   \u03b5 ,   dataset :: AbstractDataset ;   base   =   e )   Compute the  \u03b1  order generalized (R\u00e9nyi) entropy [1] of a dataset, by first partitioning it into boxes of length  \u03b5  using  non0hist .  genentropy ( \u03b1 ,   p :: AbstractArray ;   base   =   e )   Compute the entropy of an array  p  directly, assuming that  p  is sum-normalized.  Optionally use  base  for the logarithms.  Description  The R\u00e9nyi entropy   \nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha  \nR_\\alpha(p) = \\frac{1}{1-\\alpha}\\sum_i p[i]^\\alpha   generalizes other known entropies, like e.g. the information entropy ( \\alpha = 1 \\alpha = 1 , see [2]), the maximum entropy ( \\alpha=0 \\alpha=0 , also known as Hartley entropy), or the correlation entropy ( \\alpha = 2 \\alpha = 2 , also known as collision entropy).  The following aliases are provided:   renyi = genentropy  shannon(args...) = genentropy(1, args...)  hartley(args...) = genentropy(0, args...)   References  [1] : A. R\u00e9nyi,  Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability , pp 547 (1960)  [2] : C. E. Shannon, Bell Systems Technical Journal  27 , pp 379 (1948)  source   Basically, given a  dataset  you can partition it into boxes to calculate an entropy.   Worried about memory overflow? Don't be!  Partitioning the dataset (i.e. doing a  histogram ) is in general a costly operation that depends exponentially on the number of dimensions of the data and algebraically to the box size  \u03b5 . However, in this specific case the partition process has some special aspects that can be taken advantage of, reducing tremendously the memory allocation and spent time!  In fact, there is an upper bound to the memory allocated by  non0hist : A constant multiplied by the length of the array,  N = length(p) . No matter how small  \u03b5  or how many dimensions the data has, the method can at most assign  N  dictionary entries.   The function used internally by  genentropy  is  non0hist :  #  ChaosTools.non0hist     Function .  non0hist ( \u03b5 ,   dataset :: AbstractDataset )   Partition a dataset into tabulated intervals (boxes) of size  \u03b5  and return the sum-normalized histogram in an unordered 1D form, discarding all zero elements.  Performances Notes  This method is effecient in both memory and speed, because it uses a dictionary to collect the information of bins with elements, while it completely disregards empty bins. This allows computation of entropies of high-dimensional datasets and with small box sizes  \u03b5  without memory overflow.  Use e.g.  fit(Histogram, ...)  from  StatsBase  if you wish to keep information about the edges of the binning as well as the zero elements.  source   For example, the Shannon entropy of a coin-flip process should be one bit,  by definition . Let's see...  using   DynamicalSystems  y   =   Float64 . ( rand ( Bool ,   1000000 ))   # just some coin tosses  sh   =   shannon ( 0.1 ,   y )    # \u2261 genentropy(1, 0.0, y)  isapprox ( sh ,   log ( 2 ),    rtol   =   1e-6 )   true   Because all entropies are by default calculated on base- e e , the unit of measurement is \"nat\" and one bit is  \\log(2)\\times \\log(2)\\times nat.", 
            "title": "Generalized Entropy"
        }, 
        {
            "location": "/chaos/entropies/#permutation-entropy", 
            "text": "The permutation entropy is introduced by C. Bandt and B. Pompe as a \"A Natural Complexity Measure for Timeseries\", which directly applies to arbitrary real-world data and is particularly useful in the presence of dynamical or observational noise.  #  ChaosTools.permentropy     Function .  permentropy ( x :: AbstractVector ,   order   [ ,   interval = 1 ] ;   base   =   e )   Compute the permutation entropy [1] of given  order  from the  x  timeseries.  Optionally,  interval  can be specified to use  x[t0:interval:t1]  when calculating permutation of the sliding windows between  t0  and  t1 = t0 + interval * (order - 1) .  Optionally use  base  for the logarithms.  References  [1] : C. Bandt,   B. Pompe,  Phys. Rev. Lett.  88  (17), pp 174102 (2002)  source  For example, we will compute and compare the  lyapunov  exponent of the logistic map with the order-6 permutation entropy, like in the original paper.  ds   =   Systems . logistic ()  rs   =   3.5 : 0.001 : 4  ls   =   Float64 [];   hs   =   Float64 []  for   r   in   rs \n     ds . p [ 1 ]   =   r \n     push! ( ls ,   lyapunov ( ds ,   100000 )) \n     # For 1D systems `trajectory` returns a vector \n     push! ( hs ,   permentropy ( trajectory ( ds ,   10000 ),   6 ))  end  f   =   figure ( figsize   =   ( 10 , 6 ))  a1   =   subplot ( 211 )  plot ( rs ,   ls );   ylim ( - 2 ,   log ( 2 ));   ylabel ( \\$\\\\ lambda \\$ )  a1 [ : axes ][ : get_xaxis ]()[ : set_ticklabels ]([])  xlim ( rs [ 1 ],   rs [ end ]);  a2   =   subplot ( 212 )  plot ( rs ,   hs ;   color   =   C1 );   ylabel ( \\$ h_6 \\$ )  xlim ( rs [ 1 ],   rs [ end ]);   xlabel ( \\$ r \\$ )  tight_layout ()     Permutation Entropy performance  Even though the current implementation is fine and runs reasonably fast for moderate orders, it can get slow for high orders. Issue  ChaosTools.jl#22  keeps track of this, and contains information on how to improve performance.", 
            "title": "Permutation Entropy"
        }, 
        {
            "location": "/chaos/entropies/#attractor-dimension-estimation", 
            "text": "There are numerous methods that one can use to calculate a so-called \"dimension\" of a dataset, like for example the  Fractal dimension . This real number can offer a lot of information about the object that the dataset represents.", 
            "title": "Attractor Dimension Estimation"
        }, 
        {
            "location": "/chaos/entropies/#generalized-dimensions", 
            "text": "Based on the definition of the  generalized entropy , one can calculate an appropriate dimension, called  generalized dimension :  #  ChaosTools.generalized_dim     Function .  generalized_dim(\u03b1, dataset [, sizes]) -  D_\u03b1  Return the  \u03b1  order generalized dimension of the  dataset , by calculating the  genentropy  for each  \u03b5 \u2208 sizes .  Description  The returned dimension is approximated by the (inverse) power law exponent of the scaling of the  genentropy  versus the box size  \u03b5 , where  \u03b5 \u2208 sizes .  Calling this function performs a lot of automated steps:   A vector of box sizes is decided by calling  sizes = estimate_boxsizes(dataset) , if  sizes  is not given.  For each element of  sizes  the appropriate entropy is calculated, through  d = genentropy.(\u03b1, sizes, dataset) . Let  x = -log.(sizes) .  The curve  d(x)  is decomposed into linear regions, using  linear_regions (x, d) .  The biggest linear region is chosen, and a fit for the slope of that region is performed using the function  linear_region . This slope is the return value of  generalized_dim .   By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.  The following aliases are provided:   \u03b1 = 0 :  boxcounting_dim ,  capacity_dim  \u03b1 = 1 :  information_dim  \u03b1 = 2 :  correlation_dim   source    Be wary when using  generalized_dim  As stated clearly by the documentation string, calling  generalized_dim  performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.   #  ChaosTools.estimate_boxsizes     Function .  estimate_boxsizes ( dataset :: AbstractDataset ;   k :: Int   =   12 ,   z   =   -1 ,   w   =   1 )   Return a  k -element  logspace  from  lower + w  to  upper + z ,  lower  is the magnitude of the minimum pair-wise distance between datapoints while  upper  is the magnitude of the maximum difference between greatest and smallest number among each timeseries.  \"Magnitude\" here stands for order of magnitude, i.e.  round(log10(x)) .  source  #  ChaosTools.linear_regions     Function .  linear_regions(x, y; dxi::Int = 1, tol = 0.2) -  (lrs, tangents)  Identify regions where the curve  y(x)  is linear, by scanning the  x -axis every  dxi  indices (e.g. at  x[1] to x[5], x[5] to x[10], x[10] to x[15]  and so on if  dxi=5 ).  If the slope (calculated using  LsqFit ) of a region of width  dxi  is approximatelly equal to that of the previous region, within tolerance  tol , then these two regions belong to the same linear region.  Return the indices of  x  that correspond to linear regions,  lrs , and the approximated  tangents  at each region.  lrs  is a vector of  Int .  A function  plot_linear_regions  visualizes the result of using this  linear_regions  (requires  PyPlot ).  source  #  ChaosTools.linear_region     Function .  linear_region(x, y; dxi::Int = 1, tol = 0.2) -  ([ind1, ind2], slope)  Call  linear_regions , identify the largest linear region and approximate the slope of the entire region using least squares fit. Return the indices where the region starts and stops ( x[ind1:ind2] ) as well as the approximated slope.  source", 
            "title": "Generalized Dimensions"
        }, 
        {
            "location": "/chaos/entropies/#example", 
            "text": "For example, the dimension of the strange attractor of the  H\u00e9non map  is:  using   DynamicalSystems  hen   =   Systems . henon ( - rand ( 2 ))  ts   =   trajectory ( hen ,   1000000 )  D_hen   =   information_dim ( ts )   1.19735650096483  As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D  56 , pp 185-187 (1992)).", 
            "title": "Example"
        }, 
        {
            "location": "/chaos/entropies/#kaplan-yorke-dimension", 
            "text": "#  ChaosTools.kaplanyorke_dim     Function .  kaplanyorke_dim(lyapunovs::AbstractVector)  Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension [1].  Description  The Kaplan-Yorke dimension is simply the point where  cumsum(lyapunovs)  becomes zero (interpolated). If the sum of the exponents never becomes negative the function will return the length of the input vector.  Useful in combination with  lyapunovs .  References  [1] :  J. Kaplan   J. Yorke,  Chaotic behavior of multidimensional difference equations , Lecture Notes in Mathematics vol.  730 , Springer (1979)  source   Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:  using   DynamicalSystems  hen   =   Systems . henon ()  D_kp   =   kaplanyorke_dim ( lyapunovs ( hen ,   100000 ))   1.2587051169257504", 
            "title": "Kaplan-Yorke Dimension"
        }, 
        {
            "location": "/chaos/nlts/", 
            "text": "Nonlinear Timeseries Analysis\n\n\n\n\nNeighborhoods in a Dataset\n\n\nCombining the excellent performance of \nNearestNeighbors.jl\n with the \nAbstractDataset\n allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of \nAbstractNeighborhood\n.\n\n\n#\n\n\nDynamicalSystemsBase.neighborhood\n \n \nFunction\n.\n\n\nneighborhood([n,] point, tree::KDTree, method::AbstractNeighborhood)\n\n\n\n\n\nReturn a vector of indices which are the neighborhood of \npoint\n. \nn\n is the index of the \npoint\n in the original dataset. Do not pass any index if the \npoint\n is not part of the dataset.\n\n\nIf the original dataset is \ndata \n: AbstractDataset\n, then use \ntree = KDTree(data)\n to obtain the \ntree\n instance (which also contains a copy of the data).\n\n\nThe \nmethod\n can be a subtype of \nAbstractNeighborhood\n.\n\n\nneighborhood\n works for \nany\n subtype of \nAbstractDataset\n.\n\n\nReferences\n\n\nneighborhood\n simply interfaces the functions \nknn\n and \ninrange\n from \nNearestNeighbors.jl\n by using the last argument, \nmethod\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.AbstractNeighborhood\n \n \nType\n.\n\n\nAbstractNeighborhood\n\n\n\n\n\nSupertype of methods for deciding the neighborhood of points for a given point.\n\n\nConcrete subtypes:\n\n\n\n\nFixedMassNeighborhood(K::Int)\n  : The neighborhood of a point consists of the \nK\n nearest neighbors of the point.\n\n\nFixedSizeNeighborhood(\u03b5::Real)\n : The neighborhood of a point consists of all neighbors that have distance \n \n\u03b5\n from the point.\n\n\n\n\nNotice that these distances are always computed using the Euclidean distance in \nD\n-dimensional space.\n\n\nSee also \nneighborhood\n.\n\n\nsource\n\n\n\n\n\n\nNumerical Lyapunov Exponent\n\n\nGiven any timeseries, one can first obtain a \nReconstruction\n from it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with\n\n\n#\n\n\nChaosTools.numericallyapunov\n \n \nFunction\n.\n\n\nnumericallyapunov\n(\nR\n::\nReconstruction\n,\n \nks\n;\n  \nrefstates\n,\n \nw\n,\n \ndistance\n,\n \nmethod\n)\n\n\n\n\n\n\nReturn \nE = [E(k) for k \u2208 ks]\n, where \nE(k)\n is the average logarithmic distance for nearby states that are evolved in time for \nk\n steps (\nk\n must be integer).\n\n\nKeyword Arguments\n\n\n\n\nrefstates = 1:(length(R) - ks[end])\n : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in \nrefstates\n.\n\n\nw::Int = round(Int, mean(R.delay))\n : The Theiler window, which determines whether points are separated enough in time to be considered separate trajectories (see [1]). Defaults to the mean delay time.\n\n\nmethod::AbstractNeighborhood = FixedMassNeighborhood(1)\n : The method to be used when evaluating the neighborhood of each reference state. See \nAbstractNeighborhood\n or \nneighborhood\n for more info.\n\n\ndistance::Metric = Cityblock()\n : The distance function used in the logarithmic distance of nearby states. The allowed distances are \nCityblock()\n and \nEuclidean()\n. See below for more info.\n\n\n\n\nDescription\n\n\nIf the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold\n\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\nE(k) \\approx \\lambda\\Delta t k + E(0)\n\n\n\n\n\nfor a \nwell defined region\n in the \nk\n axis, where \n\\lambda\n\\lambda\n is the approximated maximum Lyapunov exponent. \n\\Delta t\n\\Delta t\n is the time between samples in the original timeseries. You can use \nlinear_region\n with arguments \n(ks .* \u0394t, E)\n to identify the slope (= \n\\lambda\n\\lambda\n) immediatelly, assuming you have choosen sufficiently good \nks\n such that the linear scaling region is bigger than the saturated region.\n\n\nThe algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index \nk\n increases. The average of the above over all neighborhood states over all reference states is the returned result.\n\n\nIf the \nMetric\n is \nEuclidean()\n then use the Euclidean distance of the full \nD\n-dimensional points (distance \nd_E\nd_E\n in ref. [1]). If however the \nMetric\n is \nCityblock()\n, calculate the absolute distance of \nonly the first elements\n of the \nm+k\n and \nn+k\n points of the reconstruction \nR\n(distance \nd_F\nd_F\n in ref. [1]).\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 1 (section 1.3.2), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\n[2] : Kantz, H., Phys. Lett. A \n185\n, pp 77\u201387 (1994)\n\n\nsource\n\n\n\n\nThe function \nnumericallyapunov\n has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.\n\n\n\n\nExample of Numerical Lyapunov computation\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n \n#fake measurements for the win!\n\n\n\nks\n \n=\n \n1\n:\n20\n\n\n\u211c\n \n=\n \n1\n:\n10000\n\n\nfig\n \n=\n \nfigure\n(\nfigsize\n=\n(\n10\n,\n6\n))\n\n\ni\n \n=\n \n1\n\n\n\nfor\n \n(\ni\n,\n \ndi\n)\n \nin\n \nenumerate\n([\nEuclidean\n(),\n \nCityblock\n()])\n\n  \nsubplot\n(\n1\n,\n \n2\n,\n \ni\n)\n\n  \ni\n+=\n1\n\n  \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n)\n\n\n  \ntitle\n(\nDistance: \n$\n(\ndi\n)\n,\n \nsize\n \n=\n \n18\n)\n\n  \nfor\n \nD\n \nin\n \n[\n2\n,\n \n4\n,\n \n7\n]\n\n    \nR\n \n=\n \nReconstruction\n(\nx\n,\n \nD\n,\n \n1\n)\n\n    \nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n;\n\n    \nrefstates\n \n=\n \n\u211c\n,\n \ndistance\n \n=\n \ndi\n,\n \nmethod\n \n=\n \nmethod\n)\n\n    \n# The following operation:\n\n    \n\u0394t\n \n=\n \n1\n\n    \n\u03bb\n \n=\n \nlinear_region\n(\nks\n.*\n\u0394t\n,\n \nE\n)[\n2\n]\n\n    \n# gives the linear slope, i.e. the Lyapunov exponent\n\n    \nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$D\n, \u03bb=\n$\n(\nround\n(\n\u03bb\n,\n \n3\n))\n)\n\n    \nlegend\n()\n\n    \ntight_layout\n()\n\n  \nend\n\n\n\n\nend\n\n\n\n\n\n\nwhich gives the result \n\n\n\n\nBad Time-axis (\nks\n) length\n\n\n\n\nLarge \nks\n\n\nThis simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!\n\n\n\n\nLet's revisit the example of the previous section:\n\n\nds\n \n=\n \nSystems\n.\nhenon\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\n\n\n\nThe timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following\n\n\nks\n \n=\n \n1\n:\n100\n\n\nR\n \n=\n \nReconstruction\n(\nx\n,\n \n2\n,\n \n1\n)\n\n\nE\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks\n,\n \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n2\n))\n\n\nfigure\n()\n\n\nplot\n(\nks\n-\n1\n,\n \nE\n-\nE\n[\n1\n])\n\n\nprintln\n(\nLyappunov: \n,\n \nlinear_region\n(\nks\n,\n \nE\n)[\n2\n])\n\n\n\n\n\n\ngives this plot: \n and prints\n\n\nLyapunov\n:\n \n0.4161\n...\n\n\n\n\n\n\nNotice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function \nlinear_region\n would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)\n\n\n\n\nCase of a Continuous system\n\n\nThe process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\n\nds\n \n=\n \nSystems\n.\nlorenz\n()\n \n# Max lyapunov is around 0.90\n\n\n# create a timeseries of 1 dimension\n\n\ndt\n \n=\n \n0.05\n\n\nx\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n;\n \ndt\n \n=\n \ndt\n)[\n:\n,\n \n1\n]\n\n\n\n# Reconstruct it\n\n\nfigure\n()\n\n\nfor\n \nD\n \nin\n \n[\n4\n,\n \n8\n],\n \n\u03c4\n \nin\n \n[\n\u03c41\n,\n \n15\n]\n\n    \nR\n \n=\n \nReconstruction\n(\nx\n,\n \nD\n,\n \n\u03c4\n)\n\n\n    \n# I now know that I have to use much bigger ks than 1:20, because this is a\n\n    \n# continuous case! (See reference given in `numericallyapunovs`)\n\n    \nks1\n \n=\n \n0\n:\n200\n\n    \n# I also know that I do not need that dense computations, since 1 increment\n\n    \n# in k means increment of 0.05 real time\n\n    \nks2\n \n=\n \n0\n:\n4\n:\n200\n\n\n    \n# Calculate lyapunovs:\n\n    \nmethod\n \n=\n \nFixedMassNeighborhood\n(\n5\n)\n \n#5 nearest neighbors of each state\n\n\n    \n# E1 = numericallyapunov(R, ks1; method = method)\n\n    \n# \u03bb1 = linear_region(ks1 .* dt, E1)[2]\n\n    \nE2\n \n=\n \nnumericallyapunov\n(\nR\n,\n \nks2\n;\n \nmethod\n \n=\n \nmethod\n)\n\n    \n\u03bb2\n \n=\n \nlinear_region\n(\nks2\n \n.*\n \ndt\n,\n \nE2\n)[\n2\n]\n\n\n\n    \n# plot(ks1,E1.-E1[1], label = \ndense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3))\n)\n\n    \nplot\n(\nks2\n,\nE2\n.-\nE2\n[\n1\n],\n \nlabel\n \n=\n \nD=\n$\n(\nD\n)\n, \u03c4=\n$\n(\n\u03c4\n)\n, \u03bb=\n$\n(\nround\n(\n\u03bb2\n,\n \n3\n))\n)\n\n\nend\n\n\n\nlegend\n()\n\n\nxlabel\n(\nk (0.05\u00d7t)\n)\n\n\nylabel\n(\nE - E(0)\n)\n\n\ntitle\n(\nContinuous Reconstruction Lyapunov\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\nwhich produces: \n As you can see, using \n\u03c4 = 15\n makes almost no sense! The estimates with \n\u03c4 = 7\n though are very good (the actual value is around \n\u03bb \u2248 0.89...\n).\n\n\n\n\nBroomhead-King Coordinates\n\n\n#\n\n\nChaosTools.broomhead_king\n \n \nFunction\n.\n\n\nbroomhead_king(s::AbstractVector, d::Int) -\n U, S, Vtr\n\n\n\n\n\nReturn the Broomhead-King coordinates of a timeseries \ns\n by performing \nsvd\n on the so-called trajectory matrix with dimension \nd\n.\n\n\nDescription\n\n\nBroomhead and King coordinates is a method proposed in [1] that applies the Karhunen\u2013Lo\u00e8ve theorem to delay coordinates embedding with smallest possible delay.\n\n\nThe function performs singular value decomposition on the \nd\n-dimensional trajectory matrix \nX\nX\n of \ns\ns\n,\n\n\n\n\n\nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 \n x_2 \n \\ldots \n x_d \\\\\nx_2 \n x_3 \n \\ldots \n x_{d+1}\\\\\n\\vdots \n \\vdots \n \\vdots \n \\vdots \\\\\nx_{N-d+1} \n x_{N-d+2} \n\\ldots \n x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.\n\n\n\n\nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 & x_2 & \\ldots & x_d \\\\\nx_2 & x_3 & \\ldots & x_{d+1}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nx_{N-d+1} & x_{N-d+2} &\\ldots & x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.\n\n\n\n\n\nwhere \nx := s - \\bar{s}\nx := s - \\bar{s}\n. The columns of \nU\nU\n can then be used as a new coordinate system, and by considering the values of the singular values \nS\nS\n you can decide how many columns of \nU\nU\n are \"important\". See the documentation page for example application.\n\n\nReferences\n\n\n[1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A \n20\n, 9, pp L563 (1987)\n\n\nsource\n\n\n\n\nThis alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.\n\n\nTake the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n\n\nusing\n \nDistributions\n \n# for random numbers\n\n\n\nds\n \n=\n \nSystems\n.\ngissinger\n()\n\n\ndata\n \n=\n \ntrajectory\n(\nds\n,\n \n1000.0\n,\n \ndt\n \n=\n \n0.05\n)\n\n\nx\n \n=\n \ndata\n[\n:\n,\n \n1\n]\n\n\n\nL\n \n=\n \nlength\n(\nx\n)\n\n\ndistrib\n \n=\n \nNormal\n(\n0\n,\n \n0.1\n)\n\n\ns\n \n=\n \nx\n \n.+\n \nrand\n(\ndistrib\n,\n \nL\n)\n\n\n\nU\n,\n \nS\n \n=\n \nbroomhead_king\n(\ns\n,\n \n40\n)\n\n\n\nfigure\n(\nfigsize\n=\n \n(\n10\n,\n6\n))\n\n\nsubplot\n(\n1\n,\n2\n,\n1\n)\n\n\nplot\n(\nU\n[\n:\n,\n \n1\n],\n \nU\n[\n:\n,\n \n2\n])\n\n\ntitle\n(\nBroomhead-King of s\n)\n\n\n\nsubplot\n(\n1\n,\n2\n,\n2\n)\n\n\nR\n \n=\n \nReconstruction\n(\ns\n,\n \n2\n,\n \n30\n)\n\n\nplot\n(\ncolumns\n(\nR\n)\n...\n;\n \ncolor\n \n=\n \nC3\n)\n\n\ntitle\n(\n2D Reconstruction of s\n)\n\n\n\ntight_layout\n()\n\n\n\n\n\n\n\n\nwe have used the same system as in the \ndelay coordinates reconstruction\n example, and picked the optimal delay time of \n\u03c4 = 30\n (for same \ndt = 0.05\n). Regardless, the vanilla delay coordinates fail spectacularly when compared with the Broomhead-King coordinates.", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#nonlinear-timeseries-analysis", 
            "text": "", 
            "title": "Nonlinear Timeseries Analysis"
        }, 
        {
            "location": "/chaos/nlts/#neighborhoods-in-a-dataset", 
            "text": "Combining the excellent performance of  NearestNeighbors.jl  with the  AbstractDataset  allows us to define a function that calculates a \"neighborhood\" of a given point, i.e. finds other points near it. The different \"types\" of the neighborhoods are subtypes of  AbstractNeighborhood .  #  DynamicalSystemsBase.neighborhood     Function .  neighborhood([n,] point, tree::KDTree, method::AbstractNeighborhood)  Return a vector of indices which are the neighborhood of  point .  n  is the index of the  point  in the original dataset. Do not pass any index if the  point  is not part of the dataset.  If the original dataset is  data  : AbstractDataset , then use  tree = KDTree(data)  to obtain the  tree  instance (which also contains a copy of the data).  The  method  can be a subtype of  AbstractNeighborhood .  neighborhood  works for  any  subtype of  AbstractDataset .  References  neighborhood  simply interfaces the functions  knn  and  inrange  from  NearestNeighbors.jl  by using the last argument,  method .  source  #  DynamicalSystemsBase.AbstractNeighborhood     Type .  AbstractNeighborhood  Supertype of methods for deciding the neighborhood of points for a given point.  Concrete subtypes:   FixedMassNeighborhood(K::Int)   : The neighborhood of a point consists of the  K  nearest neighbors of the point.  FixedSizeNeighborhood(\u03b5::Real)  : The neighborhood of a point consists of all neighbors that have distance    \u03b5  from the point.   Notice that these distances are always computed using the Euclidean distance in  D -dimensional space.  See also  neighborhood .  source", 
            "title": "Neighborhoods in a Dataset"
        }, 
        {
            "location": "/chaos/nlts/#numerical-lyapunov-exponent", 
            "text": "Given any timeseries, one can first obtain a  Reconstruction  from it using delay coordinates, and then calculate a maximum Lyapunov exponent for it. This is done with  #  ChaosTools.numericallyapunov     Function .  numericallyapunov ( R :: Reconstruction ,   ks ;    refstates ,   w ,   distance ,   method )   Return  E = [E(k) for k \u2208 ks] , where  E(k)  is the average logarithmic distance for nearby states that are evolved in time for  k  steps ( k  must be integer).  Keyword Arguments   refstates = 1:(length(R) - ks[end])  : Vector of indices that notes which states of the reconstruction should be used as \"reference states\", which means that the algorithm is applied for all state indices contained in  refstates .  w::Int = round(Int, mean(R.delay))  : The Theiler window, which determines whether points are separated enough in time to be considered separate trajectories (see [1]). Defaults to the mean delay time.  method::AbstractNeighborhood = FixedMassNeighborhood(1)  : The method to be used when evaluating the neighborhood of each reference state. See  AbstractNeighborhood  or  neighborhood  for more info.  distance::Metric = Cityblock()  : The distance function used in the logarithmic distance of nearby states. The allowed distances are  Cityblock()  and  Euclidean() . See below for more info.   Description  If the reconstruction exhibits exponential divergence of nearby states, then it should clearly hold   \nE(k) \\approx \\lambda\\Delta t k + E(0)  \nE(k) \\approx \\lambda\\Delta t k + E(0)   for a  well defined region  in the  k  axis, where  \\lambda \\lambda  is the approximated maximum Lyapunov exponent.  \\Delta t \\Delta t  is the time between samples in the original timeseries. You can use  linear_region  with arguments  (ks .* \u0394t, E)  to identify the slope (=  \\lambda \\lambda ) immediatelly, assuming you have choosen sufficiently good  ks  such that the linear scaling region is bigger than the saturated region.  The algorithm used in this function is due to Parlitz [1], which itself expands upon Kantz [2]. In sort, for each reference state a neighborhood is evaluated. Then, for each point in this neighborhood, the logarithmic distance between reference state and neighborhood state is calculated as the \"time\" index  k  increases. The average of the above over all neighborhood states over all reference states is the returned result.  If the  Metric  is  Euclidean()  then use the Euclidean distance of the full  D -dimensional points (distance  d_E d_E  in ref. [1]). If however the  Metric  is  Cityblock() , calculate the absolute distance of  only the first elements  of the  m+k  and  n+k  points of the reconstruction  R (distance  d_F d_F  in ref. [1]).  References  [1] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 1 (section 1.3.2), Lecture Notes in Physics  915 , Springer (2016)  [2] : Kantz, H., Phys. Lett. A  185 , pp 77\u201387 (1994)  source   The function  numericallyapunov  has a total of 4 different approaches for the algorithmic process, by combining 2 types of distances with 2 types of neighborhoods.", 
            "title": "Numerical Lyapunov Exponent"
        }, 
        {
            "location": "/chaos/nlts/#example-of-numerical-lyapunov-computation", 
            "text": "using   DynamicalSystems ,   PyPlot  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   #fake measurements for the win!  ks   =   1 : 20  \u211c   =   1 : 10000  fig   =   figure ( figsize = ( 10 , 6 ))  i   =   1  for   ( i ,   di )   in   enumerate ([ Euclidean (),   Cityblock ()]) \n   subplot ( 1 ,   2 ,   i ) \n   i += 1 \n   method   =   FixedMassNeighborhood ( 2 ) \n\n   title ( Distance:  $ ( di ) ,   size   =   18 ) \n   for   D   in   [ 2 ,   4 ,   7 ] \n     R   =   Reconstruction ( x ,   D ,   1 ) \n     E   =   numericallyapunov ( R ,   ks ; \n     refstates   =   \u211c ,   distance   =   di ,   method   =   method ) \n     # The following operation: \n     \u0394t   =   1 \n     \u03bb   =   linear_region ( ks .* \u0394t ,   E )[ 2 ] \n     # gives the linear slope, i.e. the Lyapunov exponent \n     plot ( ks - 1 ,   E - E [ 1 ],   label   =   D= $D , \u03bb= $ ( round ( \u03bb ,   3 )) ) \n     legend () \n     tight_layout () \n   end  end   which gives the result", 
            "title": "Example of Numerical Lyapunov computation"
        }, 
        {
            "location": "/chaos/nlts/#bad-time-axis-ks-length", 
            "text": "Large  ks  This simply cannot be stressed enough! It is just too easy to overshoot the range at which the exponential expansion region is valid!   Let's revisit the example of the previous section:  ds   =   Systems . henon ()  data   =   trajectory ( ds ,   100000 )  x   =   data [ : ,   1 ]   The timeseries of length 100000 could be considered big. A time length of 100 seems very small. Yet it turns out it is way too big! The following  ks   =   1 : 100  R   =   Reconstruction ( x ,   2 ,   1 )  E   =   numericallyapunov ( R ,   ks ,   method   =   FixedMassNeighborhood ( 2 ))  figure ()  plot ( ks - 1 ,   E - E [ 1 ])  println ( Lyappunov:  ,   linear_region ( ks ,   E )[ 2 ])   gives this plot:   and prints  Lyapunov :   0.4161 ...   Notice that even though this value for the Lyapunov exponent is correct, it happened to be correct simply due to the jitter of the saturated region. Since the saturated region is much bigger than the linear scaling region, if it wasn't that jittery the function  linear_region  would not give the scaling of the linear region, but instead a slope near 0! (or if you were to give bigger tolerance as a keyword argument)", 
            "title": "Bad Time-axis (ks) length"
        }, 
        {
            "location": "/chaos/nlts/#case-of-a-continuous-system", 
            "text": "The process for continuous systems works identically with discrete, but one must be a bit more thoughtful when choosing parameters. The following example has comments to help the users get familiar with the process:  using   DynamicalSystems ,   PyPlot  ds   =   Systems . lorenz ()   # Max lyapunov is around 0.90  # create a timeseries of 1 dimension  dt   =   0.05  x   =   trajectory ( ds ,   1000.0 ;   dt   =   dt )[ : ,   1 ]  # Reconstruct it  figure ()  for   D   in   [ 4 ,   8 ],   \u03c4   in   [ \u03c41 ,   15 ] \n     R   =   Reconstruction ( x ,   D ,   \u03c4 ) \n\n     # I now know that I have to use much bigger ks than 1:20, because this is a \n     # continuous case! (See reference given in `numericallyapunovs`) \n     ks1   =   0 : 200 \n     # I also know that I do not need that dense computations, since 1 increment \n     # in k means increment of 0.05 real time \n     ks2   =   0 : 4 : 200 \n\n     # Calculate lyapunovs: \n     method   =   FixedMassNeighborhood ( 5 )   #5 nearest neighbors of each state \n\n     # E1 = numericallyapunov(R, ks1; method = method) \n     # \u03bb1 = linear_region(ks1 .* dt, E1)[2] \n     E2   =   numericallyapunov ( R ,   ks2 ;   method   =   method ) \n     \u03bb2   =   linear_region ( ks2   .*   dt ,   E2 )[ 2 ] \n\n\n     # plot(ks1,E1.-E1[1], label =  dense, D=$(D), \u03c4=$(\u03c4), \u03bb=$(round(\u03bb1, 3)) ) \n     plot ( ks2 , E2 .- E2 [ 1 ],   label   =   D= $ ( D ) , \u03c4= $ ( \u03c4 ) , \u03bb= $ ( round ( \u03bb2 ,   3 )) )  end  legend ()  xlabel ( k (0.05\u00d7t) )  ylabel ( E - E(0) )  title ( Continuous Reconstruction Lyapunov )  tight_layout ()   which produces:   As you can see, using  \u03c4 = 15  makes almost no sense! The estimates with  \u03c4 = 7  though are very good (the actual value is around  \u03bb \u2248 0.89... ).", 
            "title": "Case of a Continuous system"
        }, 
        {
            "location": "/chaos/nlts/#broomhead-king-coordinates", 
            "text": "#  ChaosTools.broomhead_king     Function .  broomhead_king(s::AbstractVector, d::Int) -  U, S, Vtr  Return the Broomhead-King coordinates of a timeseries  s  by performing  svd  on the so-called trajectory matrix with dimension  d .  Description  Broomhead and King coordinates is a method proposed in [1] that applies the Karhunen\u2013Lo\u00e8ve theorem to delay coordinates embedding with smallest possible delay.  The function performs singular value decomposition on the  d -dimensional trajectory matrix  X X  of  s s ,   \nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1   x_2   \\ldots   x_d \\\\\nx_2   x_3   \\ldots   x_{d+1}\\\\\n\\vdots   \\vdots   \\vdots   \\vdots \\\\\nx_{N-d+1}   x_{N-d+2}  \\ldots   x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.  \nX = \\frac{1}{\\sqrt{N}}\\left(\n\\begin{array}{cccc}\nx_1 & x_2 & \\ldots & x_d \\\\\nx_2 & x_3 & \\ldots & x_{d+1}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nx_{N-d+1} & x_{N-d+2} &\\ldots & x_N\n\\end{array}\n\\right) = U\\cdot S \\cdot V^{tr}.   where  x := s - \\bar{s} x := s - \\bar{s} . The columns of  U U  can then be used as a new coordinate system, and by considering the values of the singular values  S S  you can decide how many columns of  U U  are \"important\". See the documentation page for example application.  References  [1] :  D. S. Broomhead, R. Jones and G. P. King, J. Phys. A  20 , 9, pp L563 (1987)  source   This alternative/improvement of the traditional delay coordinates can be a very powerful tool. An example where it shines is noisy data where there is the effect of superficial dimensions due to noise.  Take the following example where we produce noisy data from a system and then use Broomhead-King coordinates as an alternative to \"vanilla\" delay coordinates:  using   DynamicalSystems ,   PyPlot  using   Distributions   # for random numbers  ds   =   Systems . gissinger ()  data   =   trajectory ( ds ,   1000.0 ,   dt   =   0.05 )  x   =   data [ : ,   1 ]  L   =   length ( x )  distrib   =   Normal ( 0 ,   0.1 )  s   =   x   .+   rand ( distrib ,   L )  U ,   S   =   broomhead_king ( s ,   40 )  figure ( figsize =   ( 10 , 6 ))  subplot ( 1 , 2 , 1 )  plot ( U [ : ,   1 ],   U [ : ,   2 ])  title ( Broomhead-King of s )  subplot ( 1 , 2 , 2 )  R   =   Reconstruction ( s ,   2 ,   30 )  plot ( columns ( R ) ... ;   color   =   C3 )  title ( 2D Reconstruction of s )  tight_layout ()    we have used the same system as in the  delay coordinates reconstruction  example, and picked the optimal delay time of  \u03c4 = 30  (for same  dt = 0.05 ). Regardless, the vanilla delay coordinates fail spectacularly when compared with the Broomhead-King coordinates.", 
            "title": "Broomhead-King Coordinates"
        }, 
        {
            "location": "/chaos/periodicity/", 
            "text": "Detecting Stable and Unstable Periodic Orbits of Maps\n\n\nChaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the \nperiodic orbits\n existing in the chaotic sea.\n\n\nFinding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher \n Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at \nunstable\n ones.\n\n\nThe functions \nperiodicorbits\n and \nlambdamatrix\n implement the algorithm:\n\n\n#\n\n\nChaosTools.periodicorbits\n \n \nFunction\n.\n\n\nperiodicorbits\n(\nds\n::\nDiscreteDynamicalSystem\n,\n \no\n,\n \nics\n \n[\n,\n \n\u03bb\ns\n,\n \nindss\n,\n \nsingss\n]\n;\n \nkwargs\n...)\n \n-\n \nFP\n\n\n\n\n\n\nFind fixed points \nFP\n of order \no\n for the map \nds\n using the algorithm due to Schmelcher \n Diakonos [1]. \nics\n is a collection of initial conditions (container of vectors) to be evolved.\n\n\nOptional Arguments\n\n\nThe optional arguments \n\u03bbs, indss, singss\n \nmust be containers\n of appropriate values, besides \n\u03bbs\n which can also be a number. The elements of those containers are passed to: \nlambdamatrix(\u03bb, inds, sings)\n, which creates the appropriate \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n matrix (see \nlambdamatrix\n for more). If these arguments are not given, a random permutation will be chosen for them, with \n\u03bb=0.001\n.\n\n\nKeyword Arguments\n\n\n\n\nmaxiters::Int = 100000\n : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.\n\n\ndisttol = 1e-10\n : Distance tolerance. If the 2-norm of a previous state with  the next one is \n\u2264 disttol\n then it has converged to a fixed point.\n\n\ninftol = 10.0\n : If a state reaches \nnorm(state) \u2265 inftol\n it is assumed that  it has escaped to infinity (and is thus abandoned).\n\n\nroundtol::Int = 4\n : The found fixed points are rounded  to \nroundtol\n digits before pushed into the list of returned fixed points \nFP\n,  \nif\n they are not already contained in \nFP\n.  This is done so that \nFP\n doesn't contain duplicate fixed points (notice  that this has nothing to do with \ndisttol\n). Turn this to \ntypemax(Int)\n  to get the full precision of the algorithm.\n\n\n\n\nDescription\n\n\nThe algorithm used can detect periodic orbits by turning fixed points of the original map \nds\n to stable ones, through the transformation\n\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)\n\n\n\n\n\nwith \nf\nf\n = \neom\n. The index \nk\nk\n counts the various possible \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n.\n\n\nPerformance Notes\n\n\nAll\n initial conditions are evolved for \nall\n \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n which can very quickly lead to long computation times.\n\n\nReferences\n\n\n[1] : P. Schmelcher \n F. K. Diakonos, Phys. Rev. Lett. \n78\n, pp 4733 (1997)\n\n\nsource\n\n\n#\n\n\nChaosTools.lambdamatrix\n \n \nFunction\n.\n\n\nlambdamatrix(\u03bb, inds::Vector{Int}, sings) -\n \u039bk\n\n\n\n\n\nReturn the matrix \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n used to create a new dynamical system with some unstable fixed points turned to stable in the function \nperiodicorbits\n.\n\n\nArguments\n\n\n\n\n\u03bb\n:Real\n : the multiplier of the \nC_k\nC_k\n matrix, with \n0\n\u03bb\n1\n.\n\n\ninds::Vector{Int}\n : The \ni\nth entry of this vector gives the \nrow\n of the nonzero element of the \ni\nth column of \nC_k\nC_k\n.\n\n\nsings::Vector{\n:Real}\n : The element of the \ni\nth column of \nC_k\nC_k\n is +1 if \nsigns[i] \n 0\n and -1 otherwise (\nsings\n can also be \nBool\n vector).\n\n\n\n\nCalling \nlambdamatrix(\u03bb, D::Int)\n creates a random \n\\mathbf{\\Lambda}_k\n\\mathbf{\\Lambda}_k\n by randomly generating an \ninds\n and a \nsigns\n from all possible combinations. The \ncollections\n of all these combinations can be obtained from the function \nlambdaperms\n.\n\n\nDescription\n\n\nEach element of \ninds\n \nmust be unique\n such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.\n\n\nDeciding the appropriate values for \n\u03bb, inds, sings\n is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for \n\u03bb\n, one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.\n\n\nReferences\n\n\n[2] : D. Pingel \net al.\n, Phys. Rev. E \n62\n, pp 2119 (2000)\n\n\n[3] : F. K. Diakonos \net al.\n, Phys. Rev. Lett. \n81\n, pp 4349 (1998)\n\n\nsource\n\n\n#\n\n\nChaosTools.lambdaperms\n \n \nFunction\n.\n\n\nlambdaperms(D) -\n indperms, singperms\n\n\n\n\n\nReturn two collections that each contain all possible combinations of indices (total of \nD!\nD!\n) and signs (total of \n2^D\n2^D\n) for dimension \nD\n (see \nlambdamatrix\n).\n\n\nsource\n\n\n\n\n\n\nStandard Map example\n\n\nFor example, let's find the fixed points of the \nStandard Map\n of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the \nsigns\n but only one for the \ninds\n. We will also only use one \n\u03bb\n value, and a 21\u00d721 density of initial conditions:\n\n\nusing\n \nDynamicalSystems\n,\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nds\n \n=\n \nSystems\n.\nstandardmap\n()\n\n\nxs\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \n21\n);\n \nys\n \n=\n \ncopy\n(\nxs\n)\n\n\nics\n \n=\n \n[\nSVector\n{\n2\n}(\nx\n,\ny\n)\n \nfor\n \nx\n \nin\n \nxs\n \nfor\n \ny\n \nin\n \nys\n]\n\n\n\n# All permutations of [\u00b11, \u00b11]:\n\n\nsingss\n \n=\n \nlambdaperms\n(\n2\n)[\n2\n]\n \n# second entry are the signs\n\n\n\n# I know from personal research I only need this `inds`:\n\n\nindss\n \n=\n \n[[\n1\n,\n2\n]]\n \n# \n- must be container of vectors!!!\n\n\n\n\u03bbs\n \n=\n \n0.005\n \n# \n- only this allowed to not be vector (could also be vector)\n\n\n\norders\n \n=\n \n[\n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n,\n \n8\n]\n\n\nALLFP\n \n=\n \nVector\n{\nSVector\n{\n2\n,\n \nFloat64\n}}[]\n\n\n\nttt\n \n=\n \ntime\n()\n\n\nfor\n \no\n \nin\n \norders\n\n    \nFP\n \n=\n \nperiodicorbits\n(\nds\n,\n \no\n,\n \nics\n,\n \n\u03bbs\n,\n \nindss\n,\n \nsingss\n)\n\n    \npush!\n(\nALLFP\n,\n \nFP\n)\n\n\nend\n\n\nprintln\n(\nTotal time: \n$\n((\ntime\n()\n \n-\n \nttt\n)\n/\n60\n)\n mins.\n)\n\n\n# It takes a good 3-5 minutes to do all computations!\n\n\n\n\n# Create phase-space plot:\n\n\niters\n \n=\n \n1000\n\n\ndataset\n \n=\n \ntrajectory\n(\nds\n,\n \niters\n)\n\n\nfor\n \nx\n \nin\n \nxs\n\n    \nfor\n \ny\n \nin\n \nys\n\n        \nds\n.\nstate\n \n=\n \nSVector\n{\n2\n}(\nx\n,\n \ny\n)\n\n        \nappend!\n(\ndataset\n,\n \ntrajectory\n(\nds\n,\n \niters\n))\n\n    \nend\n\n\nend\n\n\nm\n \n=\n \nMatrix\n(\ndataset\n)\n\n\nPyPlot\n.\nscatter\n(\nview\n(\nm\n,\n \n:\n,\n \n1\n),\n \nview\n(\nm\n,\n \n:\n,\n \n2\n),\n \ns\n=\n \n1\n,\n \ncolor\n \n=\n \nblack\n)\n\n\nPyPlot\n.\nxlim\n(\nxs\n[\n1\n],\n \nxs\n[\nend\n])\n\n\nPyPlot\n.\nylim\n(\nys\n[\n1\n],\n \nys\n[\nend\n])\n\n\n\n# Plot fixed points:\n\n\nmarkers\n \n=\n \n[\nD\n,\n \n^\n,\n \ns\n,\n \np\n,\n \nh\n,\n \n8\n]\n\n\ncolors\n \n=\n \n[\nb\n,\n \ng\n,\n \nr\n,\n \nc\n,\n \nm\n,\n \ngrey\n]\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n6\n\n    \nFP\n \n=\n \nALLFP\n[\ni\n]\n\n    \no\n \n=\n \norders\n[\ni\n]\n\n    \nPyPlot\n.\nplot\n([\ns\n[\n1\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n \n[\ns\n[\n2\n]\n \nfor\n \ns\n \nin\n \nFP\n],\n\n    \nmarker\n=\nmarkers\n[\ni\n],\n \ncolor\n \n=\n \ncolors\n[\ni\n],\n \nmarkersize\n=\n10.0\n \n+\n \n(\n8\n-\no\n),\n \nlinewidth\n=\n0.0\n,\n\n    \nlabel\n \n=\n \norder \n$o\n,\n \nmarkeredgecolor\n \n=\n \nyellow\n,\n \nmarkeredgewidth\n \n=\n \n0.5\n)\n\n\nend\n\n\nlegend\n(\nloc\n=\nupper right\n,\n \nframealpha\n=\n0.9\n)\n\n\nxlabel\n(\n\\$\\\\\ntheta\n\\$\n)\n\n\nylabel\n(\n\\$\np\n\\$\n)\n\n\n\n\n\n\nAfter 3 to 5 minutes, you will get this plot: \n\n\nYou can confirm for yourself that this is correct, for many reasons:\n\n\n\n\nIt is the same \nfig. 12 of this publication\n.\n\n\nFixed points of order \nn\nn\n are also fixed points of order \n2n, 3n, 4n, ...\n2n, 3n, 4n, ...\n\n\nBesides fixed points of previous orders, \noriginal\n fixed points of order \nn\nn\n come in (possible multiples of) \n2n\n2n\n-sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Periodicity"
        }, 
        {
            "location": "/chaos/periodicity/#detecting-stable-and-unstable-periodic-orbits-of-maps", 
            "text": "Chaotic behavior of low dimensional dynamical systems is affected by the position and the stability properties of the  periodic orbits  existing in the chaotic sea.  Finding unstable (or stable) periodic orbits of a discrete mapping analytically rapidly becomes impossible for higher orders of fixed points. Fortunately there is a numeric algorithm due to Schmelcher   Diakonos which allows such a computation. Notice that even though the algorithm can find stable fixed points, it is mainly aimed at  unstable  ones.  The functions  periodicorbits  and  lambdamatrix  implement the algorithm:  #  ChaosTools.periodicorbits     Function .  periodicorbits ( ds :: DiscreteDynamicalSystem ,   o ,   ics   [ ,   \u03bb s ,   indss ,   singss ] ;   kwargs ...)   -   FP   Find fixed points  FP  of order  o  for the map  ds  using the algorithm due to Schmelcher   Diakonos [1].  ics  is a collection of initial conditions (container of vectors) to be evolved.  Optional Arguments  The optional arguments  \u03bbs, indss, singss   must be containers  of appropriate values, besides  \u03bbs  which can also be a number. The elements of those containers are passed to:  lambdamatrix(\u03bb, inds, sings) , which creates the appropriate  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  matrix (see  lambdamatrix  for more). If these arguments are not given, a random permutation will be chosen for them, with  \u03bb=0.001 .  Keyword Arguments   maxiters::Int = 100000  : Maximum amount of iterations an i.c. will be iterated  before claiming it has not converged.  disttol = 1e-10  : Distance tolerance. If the 2-norm of a previous state with  the next one is  \u2264 disttol  then it has converged to a fixed point.  inftol = 10.0  : If a state reaches  norm(state) \u2265 inftol  it is assumed that  it has escaped to infinity (and is thus abandoned).  roundtol::Int = 4  : The found fixed points are rounded  to  roundtol  digits before pushed into the list of returned fixed points  FP ,   if  they are not already contained in  FP .  This is done so that  FP  doesn't contain duplicate fixed points (notice  that this has nothing to do with  disttol ). Turn this to  typemax(Int)   to get the full precision of the algorithm.   Description  The algorithm used can detect periodic orbits by turning fixed points of the original map  ds  to stable ones, through the transformation   \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)  \n\\mathbf{x}_{n+1} = \\mathbf{x}_n +\n\\mathbf{\\Lambda}_k\\left(f^{(o)}(\\mathbf{x}_n) - \\mathbf{x}_n\\right)   with  f f  =  eom . The index  k k  counts the various possible  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k .  Performance Notes  All  initial conditions are evolved for  all   \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  which can very quickly lead to long computation times.  References  [1] : P. Schmelcher   F. K. Diakonos, Phys. Rev. Lett.  78 , pp 4733 (1997)  source  #  ChaosTools.lambdamatrix     Function .  lambdamatrix(\u03bb, inds::Vector{Int}, sings) -  \u039bk  Return the matrix  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  used to create a new dynamical system with some unstable fixed points turned to stable in the function  periodicorbits .  Arguments   \u03bb :Real  : the multiplier of the  C_k C_k  matrix, with  0 \u03bb 1 .  inds::Vector{Int}  : The  i th entry of this vector gives the  row  of the nonzero element of the  i th column of  C_k C_k .  sings::Vector{ :Real}  : The element of the  i th column of  C_k C_k  is +1 if  signs[i]   0  and -1 otherwise ( sings  can also be  Bool  vector).   Calling  lambdamatrix(\u03bb, D::Int)  creates a random  \\mathbf{\\Lambda}_k \\mathbf{\\Lambda}_k  by randomly generating an  inds  and a  signs  from all possible combinations. The  collections  of all these combinations can be obtained from the function  lambdaperms .  Description  Each element of  inds   must be unique  such that the resulting matrix is orthogonal and represents the group of special reflections and permutations.  Deciding the appropriate values for  \u03bb, inds, sings  is not trivial. However, in ref. [2] there is a lot of information that can help with that decision. Also, by appropriately choosing various values for  \u03bb , one can sort periodic orbits from e.g. least unstable to most unstable, see [3] for details.  References  [2] : D. Pingel  et al. , Phys. Rev. E  62 , pp 2119 (2000)  [3] : F. K. Diakonos  et al. , Phys. Rev. Lett.  81 , pp 4349 (1998)  source  #  ChaosTools.lambdaperms     Function .  lambdaperms(D) -  indperms, singperms  Return two collections that each contain all possible combinations of indices (total of  D! D! ) and signs (total of  2^D 2^D ) for dimension  D  (see  lambdamatrix ).  source", 
            "title": "Detecting Stable and Unstable Periodic Orbits of Maps"
        }, 
        {
            "location": "/chaos/periodicity/#standard-map-example", 
            "text": "For example, let's find the fixed points of the  Standard Map  of order 2, 3, 4, 5, 6 and 8. We will use all permutations for the  signs  but only one for the  inds . We will also only use one  \u03bb  value, and a 21\u00d721 density of initial conditions:  using   DynamicalSystems ,   PyPlot ,   StaticArrays  ds   =   Systems . standardmap ()  xs   =   linspace ( 0 ,   2 \u03c0 ,   21 );   ys   =   copy ( xs )  ics   =   [ SVector { 2 }( x , y )   for   x   in   xs   for   y   in   ys ]  # All permutations of [\u00b11, \u00b11]:  singss   =   lambdaperms ( 2 )[ 2 ]   # second entry are the signs  # I know from personal research I only need this `inds`:  indss   =   [[ 1 , 2 ]]   #  - must be container of vectors!!!  \u03bbs   =   0.005   #  - only this allowed to not be vector (could also be vector)  orders   =   [ 2 ,   3 ,   4 ,   5 ,   6 ,   8 ]  ALLFP   =   Vector { SVector { 2 ,   Float64 }}[]  ttt   =   time ()  for   o   in   orders \n     FP   =   periodicorbits ( ds ,   o ,   ics ,   \u03bbs ,   indss ,   singss ) \n     push! ( ALLFP ,   FP )  end  println ( Total time:  $ (( time ()   -   ttt ) / 60 )  mins. )  # It takes a good 3-5 minutes to do all computations!  # Create phase-space plot:  iters   =   1000  dataset   =   trajectory ( ds ,   iters )  for   x   in   xs \n     for   y   in   ys \n         ds . state   =   SVector { 2 }( x ,   y ) \n         append! ( dataset ,   trajectory ( ds ,   iters )) \n     end  end  m   =   Matrix ( dataset )  PyPlot . scatter ( view ( m ,   : ,   1 ),   view ( m ,   : ,   2 ),   s =   1 ,   color   =   black )  PyPlot . xlim ( xs [ 1 ],   xs [ end ])  PyPlot . ylim ( ys [ 1 ],   ys [ end ])  # Plot fixed points:  markers   =   [ D ,   ^ ,   s ,   p ,   h ,   8 ]  colors   =   [ b ,   g ,   r ,   c ,   m ,   grey ]  for   i   in   1 : 6 \n     FP   =   ALLFP [ i ] \n     o   =   orders [ i ] \n     PyPlot . plot ([ s [ 1 ]   for   s   in   FP ],   [ s [ 2 ]   for   s   in   FP ], \n     marker = markers [ i ],   color   =   colors [ i ],   markersize = 10.0   +   ( 8 - o ),   linewidth = 0.0 , \n     label   =   order  $o ,   markeredgecolor   =   yellow ,   markeredgewidth   =   0.5 )  end  legend ( loc = upper right ,   framealpha = 0.9 )  xlabel ( \\$\\\\ theta \\$ )  ylabel ( \\$ p \\$ )   After 3 to 5 minutes, you will get this plot:   You can confirm for yourself that this is correct, for many reasons:   It is the same  fig. 12 of this publication .  Fixed points of order  n n  are also fixed points of order  2n, 3n, 4n, ... 2n, 3n, 4n, ...  Besides fixed points of previous orders,  original  fixed points of order  n n  come in (possible multiples of)  2n 2n -sized pairs (see e.g. order 5). This is a direct consequence of the Poincar\u00e9\u2013Birkhoff theorem.", 
            "title": "Standard Map example"
        }, 
        {
            "location": "/chaos/chaos_detection/", 
            "text": "Chaos Detection\n\n\nBeing able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum \nlyapunov\n exponent and a bounded system indicate chaos.\n\n\nHowever, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in DynamicalSystems.jl.\n\n\n\n\nGeneralized Alignment Index\n\n\n\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis \n Antonopoulos.\n\n\n#\n\n\nChaosTools.gali\n \n \nFunction\n.\n\n\ngali\n(\nds\n::\nDynamicalSystem\n,\n \nk\n::\nInt\n,\n \ntmax\n;\n \nkwargs\n...)\n \n-\n \nGALI_k\n,\n \nt\n\n\n\n\n\n\nCompute \n\\text{GALI}_k\n\\text{GALI}_k\n [1] for a given \nk\n up to time \ntmax\n. Return \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n and time vector \nt\nt\n.\n\n\nKeyword Arguments\n\n\n\n\nthreshold = 1e-12\n : If \nGALI_k\n falls below the \nthreshold\n iteration is terminated.\n\n\ndt = 1\n : Time-step between variational vector normalizations. Must be integer for discrete systems.\n\n\ndiff_eq_kwargs\n : See \ntrajectory\n.\n\n\nu0\n : Initial state for the system. Defaults to \nstate(ds)\n.\n\n\nw0\n : Initial orthonormal vectors (in matrix form). Defaults to \northonormal(dimension(ds), k)\n, i.e. \nk\n random orthonormal vectors.\n\n\n\n\nDescription\n\n\nThe Generalized Alignment Index, \n\\text{GALI}_k\n\\text{GALI}_k\n, is an efficient (and very fast) indicator of chaotic or regular behavior type in \nD\nD\n-dimensional Hamiltonian systems (\nD\nD\n is number of variables). The \nasymptotic\n behavior of \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n depends critically of the type of orbit resulting from the initial condition \nstate(ds)\n. If it is a chaotic orbit, then\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]\n\n\n\n\n\nwith \n\\lambda_1\n\\lambda_1\n being the maximum \nlyapunov\n exponent. If on the other hand the orbit is regular, corresponding to movement in \nd\nd\n-dimensional torus with \n1 \\le d \\le D/2\n1 \\le d \\le D/2\n then it holds\n\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, \n \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d \n 1 \\\\\n      t^{-(k - d)}, \n \\text{if} \\;\\;  d \n k \\le D - d \\\\\n      t^{-(2k - D)}, \n \\text{if} \\;\\;  D - d \n k \\le D\n    \\end{cases}\n\n\n\n\n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}\n\n\n\n\n\nTraditionally, if \n\\text{GALI}_k(t)\n\\text{GALI}_k(t)\n does not become less than the \nthreshold\n until \ntmax\n the given orbit is said to be chaotic, otherwise it is regular.\n\n\nOur implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of \nA\nA\n, a matrix that has as \ncolumns\n the deviation vectors.\n\n\nPerformance Notes\n\n\nThis function uses a \ntangent_integrator\n. For loops over initial conditions and/or parameter values one should use the lower level methods that accept an integrator, and \nreinit!\n it to new initial conditions.\n\n\nSee the \"advanced documentation\" for info on the integrator object and use \n@which ...\n to go to the source code for the low-level call signature.\n\n\nReferences\n\n\n[1] : Skokos, C. H. \net al.\n, Physica D \n231\n, pp 30\u201354 (2007)\n\n\n[2] : Skokos, C. H. \net al.\n, \nChaos Detection and Predictability\n - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics \n915\n, Springer (2016)\n\n\nsource\n\n\n\n\n\n\nDiscrete Example\n\n\nWe will use 3 coupled standard maps as an example for a discrete system:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n;\n \nfigure\n()\n\n\nM\n \n=\n \n3\n;\n \nks\n \n=\n \n3\nones\n(\nM\n);\n \n\u0393\n \n=\n \n0.1\n;\n\n\nstable\n \n=\n \n[\n\u03c0\n,\n \n\u03c0\n,\n \n\u03c0\n,\n \n0.01\n,\n \n0\n,\n \n0\n]\n \n.+\n \n0.1\n\n\nchaotic\n \n=\n \nrand\n(\n2\nM\n)\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nstable\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\n\nsubplot\n(\n2\n,\n2\n,\n1\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nstable\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n#\n\n\nsubplot\n(\n2\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n,\n \n5\n,\n \n6\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1e5\n;\n \nthreshold\n=\n1e-12\n)\n\n    \nlt\n \n=\n \nlog10\n.\n(\nt\n);\n \nlg\n \n=\n \nlog10\n.\n(\ng\n)\n\n\n    \nplot\n(\nlt\n,\n \nlg\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlt\n \n=\n \n2\n:\n0.5\n:\n5.5\n\n\nplot\n(\nlt\n,\n \nzeros\n(\nlt\n),\n \nlabel\n=\nconst\n)\n\n\nplot\n(\nlt\n,\n \n-\n2\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -2\n)\n\n\nplot\n(\nlt\n,\n \n-\n4\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -4\n)\n\n\nplot\n(\nlt\n,\n \n-\n6\n(\nlt\n \n-\n \n3\n),\n \nlabel\n=\nslope -6\n)\n\n\n\nxlim\n(\n2\n,\n \n5.5\n)\n\n\nylim\n(\n-\n12\n,\n \n1\n)\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\n\nds\n \n=\n \nSystems\n.\ncoupledstandardmaps\n(\nM\n,\n \nchaotic\n;\n \nks\n=\nks\n,\n \n\u0393\n \n=\n \n\u0393\n)\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n100000\n)\n\n\nsubplot\n(\n2\n,\n2\n,\n3\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n1\n+\nM\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nchaotic\n,\nmarker\n=\no\n,\n \nms\n=\n1\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\n\nsubplot\n(\n2\n,\n2\n,\n4\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n100000\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n,\n5\n \n,\n6\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1000\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\nxlim\n(\n0\n,\n50\n)\n\n\nylim\n(\n1e-12\n,\n \n1\n)\n\n\n\n\n\n\n\n\n\n\nContinuous Example\n\n\nAs an example of a continuous system, let's see the \nhenonheiles\n:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n,\n \nOrdinaryDiffEq\n\n\nfigure\n(\nfigsize\n=\n(\n10\n,\n \n12\n))\n\n\nsp\n \n=\n \n[\n0\n,\n \n.\n295456\n,\n \n.\n407308431\n,\n \n0\n]\n \n#stable periodic orbit: 1D torus\n\n\nqp\n \n=\n \n[\n0\n,\n \n.\n483000\n,\n \n.\n278980390\n,\n \n0\n]\n \n#quasiperiodic orbit: 2D torus\n\n\nch\n \n=\n \n[\n0\n,\n \n-\n0.25\n,\n \n0.42081\n,\n \n0\n]\n \n# chaotic orbit\n\n\ndt\n \n=\n \n1.0\n\n\n\nsubplot\n(\n3\n,\n2\n,\n1\n)\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n(\nsp\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nsp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n2\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n50000.0\n;\n \ndt\n \n=\n \ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n    \nif\n \nk\n \n \n4\n\n        \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\nk\n-\n1\n),\n \nlabel\n=\nslope -\n$\n(\nk\n-\n1\n)\n)\n\n    \nelse\n\n        \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nend\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\n\nsubplot\n(\n3\n,\n2\n,\n3\n)\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n(\nqp\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-9\n,\n \n:\nreltol\n=\n1e-9\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n10000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nqp\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n4\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n10000.0\n;\n \ndt\n \n=\n \ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n    \nloglog\n(\nt\n,\n \n1.\n/\nt\n.^\n(\n2\nk\n-\n4\n),\n \nlabel\n=\nslope -\n$\n(\n2\nk\n-\n4\n)\n)\n\n    \nloglog\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\nds\n \n=\n \nSystems\n.\nhenonheiles\n(\nch\n)\n\n\ndiffeq\n \n=\n \nDict\n(\n:\nabstol\n=\n1e-6\n,\n \n:\nreltol\n=\n1e-6\n,\n \n:\nsolver\n \n=\n \nTsit5\n())\n\n\ntr\n \n=\n \ntrajectory\n(\nds\n,\n \n50000.0\n,\n \ndt\n=\ndt\n,\n \ndiff_eq_kwargs\n \n=\n \ndiffeq\n)\n\n\nsubplot\n(\n3\n,\n2\n,\n5\n)\n\n\nplot\n(\ntr\n[\n:\n,\n1\n],\n \ntr\n[\n:\n,\n3\n],\n \nalpha\n \n=\n \n0.5\n,\n\n\nlabel\n=\nch\n,\nmarker\n=\no\n,\nmarkersize\n=\n2\n,\n \nlinewidth\n=\n0\n)\n\n\nlegend\n()\n\n\n\nsubplot\n(\n3\n,\n2\n,\n6\n)\n\n\nls\n \n=\n \nlyapunovs\n(\nds\n,\n \n5000.0\n,\n \ndt\n=\ndt\n)\n\n\nfor\n \nk\n \nin\n \n[\n2\n,\n3\n,\n4\n]\n\n    \nex\n \n=\n \nsum\n(\nls\n[\n1\n]\n \n-\n \nls\n[\nj\n]\n \nfor\n \nj\n \nin\n \n2\n:\nk\n)\n\n    \ng\n,\n \nt\n \n=\n \ngali\n(\nds\n,\n \nk\n,\n \n1000\n;\n \ndt\n \n=\n \ndt\n)\n\n    \nsemilogy\n(\nt\n,\n \nexp\n.\n(\n-\nex\n.*\nt\n),\n \nlabel\n=\nexp. k=\n$k\n)\n\n    \nsemilogy\n(\nt\n,\n \ng\n,\n \nlabel\n=\nGALI_\n$\n(\nk\n)\n)\n\n\nend\n\n\nlegend\n(\nfontsize\n=\n12\n)\n\n\ntight_layout\n()\n\n\n\n\n\n\n As you can see, the results of both discrete and continuous match very well the theory described in \ngali\n.\n\n\n\n\nUsing GALI\n\n\nNo-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations and proofs that the method works as expected in all cases.\n\n\nThe most common usage of \n\\text{GALI}_k\n\\text{GALI}_k\n is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether \n\\text{GALI}_k\n\\text{GALI}_k\n stays below it, for a (sufficiently) big \nk\nk\n.\n\n\nThe following is an example of \nadvanced usage\n:\n\n\nusing\n \nDynamicalSystems\n\n\nusing\n \nPyPlot\n,\n \nStaticArrays\n\n\n\nfunction\n \nmain\n(\nk\n)\n\n\n    \n# Measure of chaoticity: final time of gali_2\n\n    \ndens\n \n=\n \n201\n\n    \nchaoticity\n \n=\n \nzeros\n(\nInt\n,\n \ndens\n,\n \ndens\n)\n\n\n    \n\u03b8s\n \n=\n \nps\n \n=\n \nlinspace\n(\n0\n,\n \n2\n\u03c0\n,\n \ndens\n+\n1\n)\n\n    \nds\n \n=\n \nSystems\n.\nstandardmap\n(\nk\n \n=\n \nk\n)\n\n\n    \ntinteg\n \n=\n \ntangent_integrator\n(\nds\n,\n \n2\n)\n\n\n    \nfor\n \n(\ni\n,\n \n\u03b8\n)\n \n\u2208\n \nenumerate\n(\n\u03b8s\n[\n1\n:\ndens\n])\n\n        \nprintln\n(\ni = \n$\n(\ni\n)\n)\n\n        \nfor\n \n(\nj\n,\n \np\n)\n \n\u2208\n \nenumerate\n(\nps\n[\n1\n:\ndens\n])\n\n\n            \n# new initial state is the system initial state\n\n            \n# and 2 random orthonormal deviation vectors:\n\n            \nu0\n \n=\n \nhcat\n(\nSVector\n{\n2\n}(\n\u03b8\n,\n \np\n),\n \northonormal\n(\n2\n,\n2\n))\n\n            \nreinit!\n(\ntinteg\n,\n \nu0\n)\n\n\n            \n# Low-level call signature of gali:\n\n            \n#  _gali(tinteg, tmax, dt, threshold)\n\n            \nchaoticity\n[\ni\n,\n \nj\n]\n \n=\n \nChaosTools\n.\n_gali\n(\ntinteg\n,\n \n500\n,\n \n1\n,\n \n1e-12\n)[\n2\n][\nend\n]\n\n        \nend\n\n    \nend\n\n\n    \npcolormesh\n(\n\u03b8s\n \n.-\n \n(\n\u03b8s\n[\n2\n]\n \n-\n \n\u03b8s\n[\n1\n])\n/\n2\n,\n \nps\n \n.-\n \n(\nps\n[\n2\n]\n \n-\n \nps\n[\n1\n])\n/\n2\n,\n\n    \nchaoticity\n)\n\n    \ncolorbar\n()\n\n\n\nend\n\n\n\nmain\n(\n0.9\n)\n\n\n\n\n\n\nand after about a minute you will get:", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#chaos-detection", 
            "text": "Being able to detect and distinguish chaotic from regular behavior is crucial in the study of dynamical systems. Most of the time a positive maximum  lyapunov  exponent and a bounded system indicate chaos.  However, the convergence of the Lyapunov exponent is often very slow and the computation costly. There are many alternatives that are both more efficient and more accurate in characterizing chaotic and regular motion, some of which are included in DynamicalSystems.jl.", 
            "title": "Chaos Detection"
        }, 
        {
            "location": "/chaos/chaos_detection/#generalized-alignment-index", 
            "text": "\"GALI\" for sort, is a method that relies on the fact that initially orthogonal deviation vectors tend to align towards the direction of the maximum Lyapunov exponent for chaotic motion. It is one of the most recent and cheapest methods for distinguishing chaos, introduced first in 2007 by Skokos, Bountis   Antonopoulos.  #  ChaosTools.gali     Function .  gali ( ds :: DynamicalSystem ,   k :: Int ,   tmax ;   kwargs ...)   -   GALI_k ,   t   Compute  \\text{GALI}_k \\text{GALI}_k  [1] for a given  k  up to time  tmax . Return  \\text{GALI}_k(t) \\text{GALI}_k(t)  and time vector  t t .  Keyword Arguments   threshold = 1e-12  : If  GALI_k  falls below the  threshold  iteration is terminated.  dt = 1  : Time-step between variational vector normalizations. Must be integer for discrete systems.  diff_eq_kwargs  : See  trajectory .  u0  : Initial state for the system. Defaults to  state(ds) .  w0  : Initial orthonormal vectors (in matrix form). Defaults to  orthonormal(dimension(ds), k) , i.e.  k  random orthonormal vectors.   Description  The Generalized Alignment Index,  \\text{GALI}_k \\text{GALI}_k , is an efficient (and very fast) indicator of chaotic or regular behavior type in  D D -dimensional Hamiltonian systems ( D D  is number of variables). The  asymptotic  behavior of  \\text{GALI}_k(t) \\text{GALI}_k(t)  depends critically of the type of orbit resulting from the initial condition  state(ds) . If it is a chaotic orbit, then   \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]  \n\\text{GALI}_k(t) \\sim\n\\exp\\left[\\sum_{j=1}^k (\\lambda_1 - \\lambda_j)t \\right]   with  \\lambda_1 \\lambda_1  being the maximum  lyapunov  exponent. If on the other hand the orbit is regular, corresponding to movement in  d d -dimensional torus with  1 \\le d \\le D/2 1 \\le d \\le D/2  then it holds   \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.},   \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d   1 \\\\\n      t^{-(k - d)},   \\text{if} \\;\\;  d   k \\le D - d \\\\\n      t^{-(2k - D)},   \\text{if} \\;\\;  D - d   k \\le D\n    \\end{cases}  \n\\text{GALI}_k(t) \\sim\n    \\begin{cases}\n      \\text{const.}, & \\text{if} \\;\\; 2 \\le k \\le d  \\; \\; \\text{and}\n      \\; \\;d > 1 \\\\\n      t^{-(k - d)}, & \\text{if} \\;\\;  d < k \\le D - d \\\\\n      t^{-(2k - D)}, & \\text{if} \\;\\;  D - d < k \\le D\n    \\end{cases}   Traditionally, if  \\text{GALI}_k(t) \\text{GALI}_k(t)  does not become less than the  threshold  until  tmax  the given orbit is said to be chaotic, otherwise it is regular.  Our implementation is not based on the original paper, but rather in the method described in [2], which uses the product of the singular values of  A A , a matrix that has as  columns  the deviation vectors.  Performance Notes  This function uses a  tangent_integrator . For loops over initial conditions and/or parameter values one should use the lower level methods that accept an integrator, and  reinit!  it to new initial conditions.  See the \"advanced documentation\" for info on the integrator object and use  @which ...  to go to the source code for the low-level call signature.  References  [1] : Skokos, C. H.  et al. , Physica D  231 , pp 30\u201354 (2007)  [2] : Skokos, C. H.  et al. ,  Chaos Detection and Predictability  - Chapter 5 (section 5.3.1 and ref. [85] therein), Lecture Notes in Physics  915 , Springer (2016)  source", 
            "title": "Generalized Alignment Index"
        }, 
        {
            "location": "/chaos/chaos_detection/#discrete-example", 
            "text": "We will use 3 coupled standard maps as an example for a discrete system:  using   DynamicalSystems  using   PyPlot ;   figure ()  M   =   3 ;   ks   =   3 ones ( M );   \u0393   =   0.1 ;  stable   =   [ \u03c0 ,   \u03c0 ,   \u03c0 ,   0.01 ,   0 ,   0 ]   .+   0.1  chaotic   =   rand ( 2 M )  ds   =   Systems . coupledstandardmaps ( M ,   stable ;   ks = ks ,   \u0393   =   \u0393 )  tr   =   trajectory ( ds ,   100000 )  subplot ( 2 , 2 , 1 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = stable , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  #  subplot ( 2 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ,   5 ,   6 ] \n     g ,   t   =   gali ( ds ,   k ,   1e5 ;   threshold = 1e-12 ) \n     lt   =   log10 . ( t );   lg   =   log10 . ( g ) \n\n     plot ( lt ,   lg ,   label = GALI_ $ ( k ) )  end  lt   =   2 : 0.5 : 5.5  plot ( lt ,   zeros ( lt ),   label = const )  plot ( lt ,   - 2 ( lt   -   3 ),   label = slope -2 )  plot ( lt ,   - 4 ( lt   -   3 ),   label = slope -4 )  plot ( lt ,   - 6 ( lt   -   3 ),   label = slope -6 )  xlim ( 2 ,   5.5 )  ylim ( - 12 ,   1 )  legend ( fontsize = 12 )  tight_layout ()  ds   =   Systems . coupledstandardmaps ( M ,   chaotic ;   ks = ks ,   \u0393   =   \u0393 )  tr   =   trajectory ( ds ,   100000 )  subplot ( 2 , 2 , 3 )  plot ( tr [ : , 1 ],   tr [ : , 1 + M ],   alpha   =   0.5 ,  label = chaotic , marker = o ,   ms = 1 ,   linewidth = 0 )  legend ()  subplot ( 2 , 2 , 4 )  ls   =   lyapunovs ( ds ,   100000 )  for   k   in   [ 2 , 3 , 4 , 5   , 6 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   k ,   1000 ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  xlim ( 0 , 50 )  ylim ( 1e-12 ,   1 )", 
            "title": "Discrete Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#continuous-example", 
            "text": "As an example of a continuous system, let's see the  henonheiles :  using   DynamicalSystems  using   PyPlot ,   OrdinaryDiffEq  figure ( figsize = ( 10 ,   12 ))  sp   =   [ 0 ,   . 295456 ,   . 407308431 ,   0 ]   #stable periodic orbit: 1D torus  qp   =   [ 0 ,   . 483000 ,   . 278980390 ,   0 ]   #quasiperiodic orbit: 2D torus  ch   =   [ 0 ,   - 0.25 ,   0.42081 ,   0 ]   # chaotic orbit  dt   =   1.0  subplot ( 3 , 2 , 1 )  ds   =   Systems . henonheiles ( sp )  diffeq   =   Dict ( : abstol = 1e-9 ,   : reltol = 1e-9 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   10000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = sp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 2 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   k ,   50000.0 ;   dt   =   dt ,   diff_eq_kwargs   =   diffeq ) \n     if   k     4 \n         loglog ( t ,   1. / t .^ ( k - 1 ),   label = slope - $ ( k - 1 ) ) \n     else \n         loglog ( t ,   1. / t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     end \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  subplot ( 3 , 2 , 3 )  ds   =   Systems . henonheiles ( qp )  diffeq   =   Dict ( : abstol = 1e-9 ,   : reltol = 1e-9 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   10000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = qp , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 4 )  for   k   in   [ 2 , 3 , 4 ] \n     g ,   t   =   gali ( ds ,   k ,   10000.0 ;   dt   =   dt ,   diff_eq_kwargs   =   diffeq ) \n     loglog ( t ,   1. / t .^ ( 2 k - 4 ),   label = slope - $ ( 2 k - 4 ) ) \n     loglog ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  tight_layout ()  ds   =   Systems . henonheiles ( ch )  diffeq   =   Dict ( : abstol = 1e-6 ,   : reltol = 1e-6 ,   : solver   =   Tsit5 ())  tr   =   trajectory ( ds ,   50000.0 ,   dt = dt ,   diff_eq_kwargs   =   diffeq )  subplot ( 3 , 2 , 5 )  plot ( tr [ : , 1 ],   tr [ : , 3 ],   alpha   =   0.5 ,  label = ch , marker = o , markersize = 2 ,   linewidth = 0 )  legend ()  subplot ( 3 , 2 , 6 )  ls   =   lyapunovs ( ds ,   5000.0 ,   dt = dt )  for   k   in   [ 2 , 3 , 4 ] \n     ex   =   sum ( ls [ 1 ]   -   ls [ j ]   for   j   in   2 : k ) \n     g ,   t   =   gali ( ds ,   k ,   1000 ;   dt   =   dt ) \n     semilogy ( t ,   exp . ( - ex .* t ),   label = exp. k= $k ) \n     semilogy ( t ,   g ,   label = GALI_ $ ( k ) )  end  legend ( fontsize = 12 )  tight_layout ()    As you can see, the results of both discrete and continuous match very well the theory described in  gali .", 
            "title": "Continuous Example"
        }, 
        {
            "location": "/chaos/chaos_detection/#using-gali", 
            "text": "No-one in their right mind would try to fit power-laws in order to distinguish between chaotic and regular behavior, like the above examples. These were just demonstrations and proofs that the method works as expected in all cases.  The most common usage of  \\text{GALI}_k \\text{GALI}_k  is to define a (sufficiently) small amount of time and a (sufficiently) small threshold and see whether  \\text{GALI}_k \\text{GALI}_k  stays below it, for a (sufficiently) big  k k .  The following is an example of  advanced usage :  using   DynamicalSystems  using   PyPlot ,   StaticArrays  function   main ( k ) \n\n     # Measure of chaoticity: final time of gali_2 \n     dens   =   201 \n     chaoticity   =   zeros ( Int ,   dens ,   dens ) \n\n     \u03b8s   =   ps   =   linspace ( 0 ,   2 \u03c0 ,   dens + 1 ) \n     ds   =   Systems . standardmap ( k   =   k ) \n\n     tinteg   =   tangent_integrator ( ds ,   2 ) \n\n     for   ( i ,   \u03b8 )   \u2208   enumerate ( \u03b8s [ 1 : dens ]) \n         println ( i =  $ ( i ) ) \n         for   ( j ,   p )   \u2208   enumerate ( ps [ 1 : dens ]) \n\n             # new initial state is the system initial state \n             # and 2 random orthonormal deviation vectors: \n             u0   =   hcat ( SVector { 2 }( \u03b8 ,   p ),   orthonormal ( 2 , 2 )) \n             reinit! ( tinteg ,   u0 ) \n\n             # Low-level call signature of gali: \n             #  _gali(tinteg, tmax, dt, threshold) \n             chaoticity [ i ,   j ]   =   ChaosTools . _gali ( tinteg ,   500 ,   1 ,   1e-12 )[ 2 ][ end ] \n         end \n     end \n\n     pcolormesh ( \u03b8s   .-   ( \u03b8s [ 2 ]   -   \u03b8s [ 1 ]) / 2 ,   ps   .-   ( ps [ 2 ]   -   ps [ 1 ]) / 2 , \n     chaoticity ) \n     colorbar ()  end  main ( 0.9 )   and after about a minute you will get:", 
            "title": "Using GALI"
        }, 
        {
            "location": "/chaos/visualization/", 
            "text": "DynamicalSystems.jl\n offers some basic methods for visualizing chaotic systems in the form of the functions described in this documentation page.\n\n\nAll plotting is done through the \nPyPlot.jl\n package. However, this is not a dependency of DynamicalSystems.jl. Instead, all functions described here are brought into scope as soon as the user executes \nusing PyPlot\n, which works regardless if \nPyPlot\n module was loaded before or after \nDynamicalSystems\n. This is possible through the \nRequires.jl\n package.\n\n\nUse the help mode (press \n?\n and then the function name) to access the documentation strings for e.g. using keyword arguments.\n\n\n\n\nVisualization Library\n\n\n\n\nphasespace\n : Plots the phasespace of a 2D \nDiscreteDynamicalSystem\n.\n\n\nplot_linear_regions\n : Plots the results of \nlnear_regions\n.\n\n\nplot_dataset\n : Plots each column of a dataset.\n\n\nplot_trajectory\n : Produces a trajectory and plots each column.", 
            "title": "Visualization"
        }, 
        {
            "location": "/chaos/visualization/#visualization-library", 
            "text": "phasespace  : Plots the phasespace of a 2D  DiscreteDynamicalSystem .  plot_linear_regions  : Plots the results of  lnear_regions .  plot_dataset  : Plots each column of a dataset.  plot_trajectory  : Produces a trajectory and plots each column.", 
            "title": "Visualization Library"
        }, 
        {
            "location": "/advanced/", 
            "text": "Advanced documentation\n\n\nThis section overviews the various integrators available from \nDynamicalSystemsBase\n, as well as gives some insight into the internals, so that other developers that want to use this library can build upon it.\n\n\n\n\nIntegrators\n\n\n#\n\n\nDynamicalSystemsBase.integrator\n \n \nFunction\n.\n\n\nintegrator\n(\nds\n::\nDynamicalSystem\n \n[\n,\n \nu0\n]\n;\n \ndiff_eq_kwargs\n)\n \n-\n \ninteg\n\n\n\n\n\n\nReturn an integrator object that can be used to evolve a system interactively using \nstep!(integ [, \u0394t])\n. Optionally specify an initial state \nu0\n.\n\n\nThe state of this integrator is a vector.\n\n\nSee \ntrajectory\n for \ndiff_eq_kwargs\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.parallel_integrator\n \n \nFunction\n.\n\n\nparallel_integrator\n(\nds\n::\nDynamicalSystem\n,\n \nstates\n;\n \ndiff_eq_kwargs\n)\n \n-\n \ninteg\n\n\n\n\n\n\nReturn an integrator object that can be used to evolve many \nstates\n of a system in parallel interactively using \nstep!(integ [, \u0394t])\n.\n\n\nThe states of this integrator are a vector of vectors, each one being an actual state of the dynamical system. Only for the case of in-place continuous systems, the integrator propagates a matrix with each column being a state, because at the moment DifferentialEquations.jl does not support \nVector[Vector]\n as state.\n\n\nSee \ntrajectory\n for \ndiff_eq_kwargs\n.\n\n\nsource\n\n\n#\n\n\nDynamicalSystemsBase.tangent_integrator\n \n \nFunction\n.\n\n\ntangent_integrator\n(\nds\n::\nDynamicalSystem\n,\n \nQ0\n \n|\n \nk\n::\nInt\n;\n \nu0\n,\n \nt0\n,\n \ndiff_eq_kwargs\n)\n\n\n\n\n\n\nReturn an integrator object that evolves in parallel both the system as well as deviation vectors living on the tangent space.\n\n\nQ0\n is a \nmatrix\n whose columns are initial values for deviation vectors. If instead of a matrix \nQ0\n an integer \nk\n is given, then \nk\n random orthonormal vectors are choosen as initial conditions.\n\n\nYou can also give as a keyword argument a different initial state at time \nu0, t0\n.\n\n\nThe state of this integrator is a matrix with the first column the system state and all other columns being deviation vectors.\n\n\nSee \ntrajectory\n for \ndiff_eq_kwargs\n.\n\n\nDescription\n\n\nIf \nJ\nJ\n is the jacobian of the system then the \ntangent dynamics\n are the equations that evolve in parallel the system as well as a deviation vector (or matrix) \nw\nw\n:\n\n\n\n\n\n\\begin{aligned}\n\\dot{u} \n= f(u, p, t) \\\\\n\\dot{w} \n= J(u, p, t) \\times w\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\dot{u} &= f(u, p, t) \\\\\n\\dot{w} &= J(u, p, t) \\times w\n\\end{aligned}\n\n\n\n\n\nwith \nf\nf\n being the equations of motion and \nu\nu\n the system state. Similar equations hold for the discrete case.\n\n\nInternally the integrator propagates a matrix, with the first column being the state and each subsequent one being a deviation vector.\n\n\nSee \ntrajectory\n for \ndiff_eq_kwargs\n.\n\n\nsource\n\n\n\n\nNotice that the state type \nintegrator.u\n of each integrator is quite different and \ndoes change\n between the possible versions of a \nDynamicalSystem\n!\n\n\nIf you want to use \nreinit!\n (see below), first check the state type of the \nintegrator.u\n.\n\n\nFor \ntangent_integrator\n the \nu\n is a matrix with the first column being the actual system state, and all the rest being deviation vectors.\n\n\nFor \nparallel_integrator\n the \nu\n is a vector of vectors, where each vector is a a system state. Only in the case of in-place continuous systems is the state actually a matrix with each column being a state, because DifferentialEquations at the moment does not support \nVector[Vector]\n as integrator state.\n\n\nFor the \"standard\" integrator the \nu\n is always a vector of course.\n\n\n\n\nRe-initializing an integrator\n\n\nIt is much more efficient to re-inialize an integrator than to create a new one. This can be very helpful when looping over initial conditions and/or parameter values.\n\n\nAll high-level functions from \nChaosTools\n have a set-up part that creates an integrator, and a low-level part that does the computation.\n\n\nThe low level part is your friend! Use it! See the \nUsing \ngali\n page for an example.\n\n\n\n\nDiscrete\n\n\nThe \nreinit!\n signature is:\n\n\nreinit!\n(\ninteg\n::\nMinimalDiscreteIntegrator\n,\n \nu\n;\n \nt0\n \n=\n \ninteg\n.\nt0\n)\n\n\n\n\n\n\nreinit!\n is not necessary when one changes parameters \np\n. Just change them in place, using \ninteg.p[index] = value\n.\n\n\n\n\nContinuous\n\n\nThe call signature is identical, with a bunch of extra keyword arguments.\n\n\nreinit!\n(\ninteg\n::\nODEIntegrator\n,\n \nu\n \n=\n \ninteg\n.\nsol\n.\nprob\n.\nu0\n;\n  \nt0\n \n=\n \ninteg\n.\nsol\n.\nprob\n.\ntspan\n[\n1\n])\n\n\n\n\n\n\nThe full documentation for \nreinit!(::ODEIntegrator)\n is \nhere\n. Although, for usage within \nDynamicalSystems.jl\n the other arguments do not matter, because steps are never saved.\n\n\nIn the continuous case you should \nreinit!\n even after changing a parameter value, because the derivatives need to be re-computed.\n\n\n\n\nImplementation of \nDynamicalSystem\n\n\nabstract\n \ntype\n \nDynamicalSystem\n{\n\n        \nIIP\n,\n     \n# is in place , for dispatch purposes and clarity\n\n        \nS\n,\n       \n# state type\n\n        \nD\n,\n       \n# dimension\n\n        \nF\n,\n       \n# equations of motion\n\n        \nP\n,\n       \n# parameters\n\n        \nJAC\n,\n     \n# jacobian\n\n        \nJM\n,\n      \n# jacobian matrix\n\n        \nIAD\n}\n     \n# is auto-differentiated\n\n    \n# one-liner: {IIP, S, D, F, P, JAC, JM, IAD}\n\n    \n# Subtypes of DynamicalSystem have fields:\n\n    \n# 1. prob\n\n    \n# 2. jacobian (function)\n\n    \n# 3. J (matrix)  \n- will allow Sparse implementation in the future\n\n\nend\n\n\n\n\n\n\nThis allows easily using multiple dispatch on the first three type parameters, which are the most important for dispatching purposes.\n\n\nThe final type-parameter \nIAD\n is useful when creating the \ntangent_integrator\n, so that the vector field is not computed twice!", 
            "title": "Advanced Documentation"
        }, 
        {
            "location": "/advanced/#advanced-documentation", 
            "text": "This section overviews the various integrators available from  DynamicalSystemsBase , as well as gives some insight into the internals, so that other developers that want to use this library can build upon it.", 
            "title": "Advanced documentation"
        }, 
        {
            "location": "/advanced/#integrators", 
            "text": "#  DynamicalSystemsBase.integrator     Function .  integrator ( ds :: DynamicalSystem   [ ,   u0 ] ;   diff_eq_kwargs )   -   integ   Return an integrator object that can be used to evolve a system interactively using  step!(integ [, \u0394t]) . Optionally specify an initial state  u0 .  The state of this integrator is a vector.  See  trajectory  for  diff_eq_kwargs .  source  #  DynamicalSystemsBase.parallel_integrator     Function .  parallel_integrator ( ds :: DynamicalSystem ,   states ;   diff_eq_kwargs )   -   integ   Return an integrator object that can be used to evolve many  states  of a system in parallel interactively using  step!(integ [, \u0394t]) .  The states of this integrator are a vector of vectors, each one being an actual state of the dynamical system. Only for the case of in-place continuous systems, the integrator propagates a matrix with each column being a state, because at the moment DifferentialEquations.jl does not support  Vector[Vector]  as state.  See  trajectory  for  diff_eq_kwargs .  source  #  DynamicalSystemsBase.tangent_integrator     Function .  tangent_integrator ( ds :: DynamicalSystem ,   Q0   |   k :: Int ;   u0 ,   t0 ,   diff_eq_kwargs )   Return an integrator object that evolves in parallel both the system as well as deviation vectors living on the tangent space.  Q0  is a  matrix  whose columns are initial values for deviation vectors. If instead of a matrix  Q0  an integer  k  is given, then  k  random orthonormal vectors are choosen as initial conditions.  You can also give as a keyword argument a different initial state at time  u0, t0 .  The state of this integrator is a matrix with the first column the system state and all other columns being deviation vectors.  See  trajectory  for  diff_eq_kwargs .  Description  If  J J  is the jacobian of the system then the  tangent dynamics  are the equations that evolve in parallel the system as well as a deviation vector (or matrix)  w w :   \n\\begin{aligned}\n\\dot{u}  = f(u, p, t) \\\\\n\\dot{w}  = J(u, p, t) \\times w\n\\end{aligned}  \n\\begin{aligned}\n\\dot{u} &= f(u, p, t) \\\\\n\\dot{w} &= J(u, p, t) \\times w\n\\end{aligned}   with  f f  being the equations of motion and  u u  the system state. Similar equations hold for the discrete case.  Internally the integrator propagates a matrix, with the first column being the state and each subsequent one being a deviation vector.  See  trajectory  for  diff_eq_kwargs .  source   Notice that the state type  integrator.u  of each integrator is quite different and  does change  between the possible versions of a  DynamicalSystem !  If you want to use  reinit!  (see below), first check the state type of the  integrator.u .  For  tangent_integrator  the  u  is a matrix with the first column being the actual system state, and all the rest being deviation vectors.  For  parallel_integrator  the  u  is a vector of vectors, where each vector is a a system state. Only in the case of in-place continuous systems is the state actually a matrix with each column being a state, because DifferentialEquations at the moment does not support  Vector[Vector]  as integrator state.  For the \"standard\" integrator the  u  is always a vector of course.", 
            "title": "Integrators"
        }, 
        {
            "location": "/advanced/#re-initializing-an-integrator", 
            "text": "It is much more efficient to re-inialize an integrator than to create a new one. This can be very helpful when looping over initial conditions and/or parameter values.  All high-level functions from  ChaosTools  have a set-up part that creates an integrator, and a low-level part that does the computation.  The low level part is your friend! Use it! See the  Using  gali  page for an example.", 
            "title": "Re-initializing an integrator"
        }, 
        {
            "location": "/advanced/#discrete", 
            "text": "The  reinit!  signature is:  reinit! ( integ :: MinimalDiscreteIntegrator ,   u ;   t0   =   integ . t0 )   reinit!  is not necessary when one changes parameters  p . Just change them in place, using  integ.p[index] = value .", 
            "title": "Discrete"
        }, 
        {
            "location": "/advanced/#continuous", 
            "text": "The call signature is identical, with a bunch of extra keyword arguments.  reinit! ( integ :: ODEIntegrator ,   u   =   integ . sol . prob . u0 ;    t0   =   integ . sol . prob . tspan [ 1 ])   The full documentation for  reinit!(::ODEIntegrator)  is  here . Although, for usage within  DynamicalSystems.jl  the other arguments do not matter, because steps are never saved.  In the continuous case you should  reinit!  even after changing a parameter value, because the derivatives need to be re-computed.", 
            "title": "Continuous"
        }, 
        {
            "location": "/advanced/#implementation-of-dynamicalsystem", 
            "text": "abstract   type   DynamicalSystem { \n         IIP ,       # is in place , for dispatch purposes and clarity \n         S ,         # state type \n         D ,         # dimension \n         F ,         # equations of motion \n         P ,         # parameters \n         JAC ,       # jacobian \n         JM ,        # jacobian matrix \n         IAD }       # is auto-differentiated \n     # one-liner: {IIP, S, D, F, P, JAC, JM, IAD} \n     # Subtypes of DynamicalSystem have fields: \n     # 1. prob \n     # 2. jacobian (function) \n     # 3. J (matrix)   - will allow Sparse implementation in the future  end   This allows easily using multiple dispatch on the first three type parameters, which are the most important for dispatching purposes.  The final type-parameter  IAD  is useful when creating the  tangent_integrator , so that the vector field is not computed twice!", 
            "title": "Implementation of DynamicalSystem"
        }, 
        {
            "location": "/contributors_guide/", 
            "text": "Contributor Guide\n\n\nThe ultimate goal for \nDynamicalSystems.jl\n is to be a useful \nlibrary\n for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.\n\n\nFor this to be achieved, many of us should try to work together to improve the library!\n\n\nIf you want to help the cause, there are many ways to contribute to the \nDynamicalSystems.jl\n library:\n\n\n\n\nJust \nuse it\n. If you encountered unexpected behavior simply report it either on our \ngitter chatroom\n or using the \nDynamicalSystems.jl Issues\n page.\n\n\nSuggest methods that you think should be included in our library. This should be done by opening a new issue that describes the method, gives referencens to papers using the method and also justifies why the method should be included.\n\n\nContribute code by solving issues. Visit the GitHub pages of the individual packages to see a list of open issues, like for example for \nChaosTools\n.\n\n\nContribute code by implementing new methods! That is the most \nawesome\n way to contribute!\n\n\nContribute code by defining a new pre-defined dynamical system that you found useful.\n\n\n\n\n\n\nContributing Code\n\n\nWhen contributing code, you should keep these things in mind:\n\n\n\n\nIn general, the speed of the implementation is important, but not as important as the \nreliability of the implementation\n. One of cornerstones of all of \nDynamicalSystems.jl\n is to have clear and readable source code. Fortunately, Julia allows you to have perfectly readable code but also super fast ;)\n\n\nFor new methods and systems please follow the convention of the documentation strings (do e.g. \n?lyapunov\n to see how they are structured).\n\n\nHave enough comments in your code so that somebody that knows the method, can also understand the code immediately.\n\n\nAlways have a reference to the original work that introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributor-guide", 
            "text": "The ultimate goal for  DynamicalSystems.jl  is to be a useful  library  for scientists working on chaos, nonlinear dynamics and in general dynamical systems. We don't want to have \"just code\", but also detailed descriptions and references for as many methods as possible.  For this to be achieved, many of us should try to work together to improve the library!  If you want to help the cause, there are many ways to contribute to the  DynamicalSystems.jl  library:   Just  use it . If you encountered unexpected behavior simply report it either on our  gitter chatroom  or using the  DynamicalSystems.jl Issues  page.  Suggest methods that you think should be included in our library. This should be done by opening a new issue that describes the method, gives referencens to papers using the method and also justifies why the method should be included.  Contribute code by solving issues. Visit the GitHub pages of the individual packages to see a list of open issues, like for example for  ChaosTools .  Contribute code by implementing new methods! That is the most  awesome  way to contribute!  Contribute code by defining a new pre-defined dynamical system that you found useful.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/contributors_guide/#contributing-code", 
            "text": "When contributing code, you should keep these things in mind:   In general, the speed of the implementation is important, but not as important as the  reliability of the implementation . One of cornerstones of all of  DynamicalSystems.jl  is to have clear and readable source code. Fortunately, Julia allows you to have perfectly readable code but also super fast ;)  For new methods and systems please follow the convention of the documentation strings (do e.g.  ?lyapunov  to see how they are structured).  Have enough comments in your code so that somebody that knows the method, can also understand the code immediately.  Always have a reference to the original work that introduces the method or the system that you are using. You should put this reference to the main function's documentation string. See the existing documentation strings and do it in an identical manner.", 
            "title": "Contributing Code"
        }, 
        {
            "location": "/news/", 
            "text": "News\n\n\n\n\nMulti-time, Multi-Diensional Reconstructions\n\n\nWith the latest version of \nDynamicalSystemsBase v0.8.0\n we now have the possibility for both multi-time and multi-dimensional delay reconstructions! The new documentation string for \nReconstruction\n has all the relevant information.\n\n\n\n\nRelease v0.11.0\n\n\nWith new version v0.11.0 for \nDynamicalSytems.jl\n (\nDynamicalSystemsBase\n and \nChaosTools\n at version 0.6) we have some major improvements of the library all around. Here I list the syntactic changes, the internal changes, the prospect for other developers and the gains we have from making all these changes!\n\n\n\n\nSyntax changes\n\n\nThere are no syntax changes (or \nany\n changes) to functions that handle numerical data (\nDataset\n and the likes).\n\n\nThe syntax for both discrete and continuous systems has changed to\n\n\nDiscreteDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n::\nInt\n \n=\n \n0\n)\n\n\nContinuousDynamicalSystem\n(\neom\n,\n \nstate\n,\n \np\n \n[,\n \njacobian\n \n[,\n \nJ0\n]];\n \nt0\n \n=\n \n0.0\n)\n\n\n\n\n\n\nThe equations of motion function \neom\n can be one of two forms:\n\n\n\n\niip\n : The \neom\n \nmust\n be in the form \neom(x, p, t) -\n SVector\n which means that given a state \nx::SVector\n and some parameter container \np\n it returns an \nSVector\n containing the next state.\n\n\noop\n : The \neom\n \nmust\n be in the form \neom!(xnew, x, p, t)\n which means that given a state \nx::Vector\n and some parameter container \np\n, it writes in-place the new state in \nxnew\n.\n\n\n\n\nThere is no constructor that takes an \nODEProblem\n anymore.\n\n\nIn addition, \nDynamicalSystem\n and subtypes are now \nimmutable\n. One cannot set their state in place, or anything like that. Instead, all high-level functions allow you to choose an initial state.\n\n\nIn summary:\n\n\n\n\nAll discrete systems are now simply \nDiscreteDynamicalSystem\n.\n\n\nContinuous systems have been renamed to \nContinuousDynamicalSystem\n.\n\n\nDon't use \nset_state!\n, etc. Instead use the keyword argument \nu0\n of methods like e.g. \ngali\n.\n\n\n\n\nThere are some syntax changes to high-level functions from \nChaosTools\n as well. For example, \nlyapunovs\n now has call signature\n\n\nlyapunovs\n(\nds\n::\nDynamicalSystem\n,\n \nN\n,\n \nk\n::\nInt\n \n|\n \nQ0\n;\n \nkwargs\n...\n)\n \n-\n \n\u03bbs\n\n\n\n\n\n\nIt is advised to first look the documentation string of a function you want to use before usage!\n\n\n\n\nInternal changes \n Prospects\n\n\nThe internals of \nDynamicalSystemsBase\n have been completely re-worked from the ground up. Here are the highlights:\n\n\n\n\nAll \nDynamicalSystem\n objects are immutable, and contain a problem \nprob\n the jacobian function and an initialized Jacobian matrix.\n\n\nAll functions that use a \nDynamicalSystem\n have changed behavior. The way the functions work now is that when given a \nDynamicalSystem\n the create an appropriate \nintegrator\n from it. Then we use \nstep!(integrator, dt)\n and use the integrator state to perform calculations.\n\n\n\n\nEight possible system types are now available:\n\n\n\n\nContinuous or Discrete.\n\n\nIn-place or out-of-place (large versus small systems).\n\n\nAuto-differentiated or not (for the Jacobian function).\n\n\nThis is only possible due to the strictness of defining the \neom\n function.\n\n\nRobust multiple dispatch on all 8 types (again, only possible due to the strictness of the \neom\n function).\n\n\n\n\n\n\n\n\nThree low-lever integrator constructing functions are available, that only need a \nDynamicalSystem\n and (optionally) an initial state:\n\n\n\n\nintegrator\n for \"normal\" integration of a system.\n\n\ntangent_integrator\n for integration of a state and deviation vectors (that live on the tangent space).\n\n\nparallel_integrator\n for integrating in \"parallel\" a number of states. Notice that the states are integrated at \nexact\n same times, even for continuous systems.\n\n\n\n\n\n\n\n\nAll three of the above integrators work perfectly fine for all eight combinations of systems and also have performant implementations.\n\n\n\n\nSimple internal implementation for Discrete system integrator that is tailored to the needs of \nDynamicalSystems.jl\n. It follows the high-level syntax of DifferentialEquations.jl: there is an implementation of a minimal discrete problem, as well as a minimal discrete integrator that steps via \nstep!(integrator, dt)\n.\n\n\nDynamicalSystem\n is type-parameterized in such a way that allows for easy multiple dispatch and clear source code.\n\n\n\n\nBecause the resulting behavior is very robust and efficient, it allows \nDynamicalSystemsBase\n to also be a library used by other developers that want to develop techniques/functions for dynamical systems.\n\n\nIn addition, there is absolutely no drawback in having a \nContinuousDynamicalSystem\n instead of an \nODEProblem\n, since the field \n.prob\n of the system is exactly this \nODEProblem\n, and can be passed directly to things like \nsolve\n from DifferentialEquations.jl.\n\n\n\n\nGains\n\n\n\n\nOut-of-place continuous systems are now possible!\n\n\nAuto-differentiated methods compute the vector field only once.\n\n\nSafe, robust implementations due to the immutability of the central structure \nDynamicalSystem\n.\n\n\nNo problems with parallelization/threading/etc.\n\n\nEven clearer source code! Most \nChaosTools\n functions are now composed of a set-up part and an implementation part, both of which are clear to read and understand.     * Also clarity on discrete systems, since they are all fused into one structure.     * Low-level functions can be used easily by users that want performance for loops.\n\n\nLyapunov exponent calculating functions now have full flexibility in all aspects (initial deviation vectors/transient times/pretty much anything).\n\n\n\n\nBig performance gains all around, and especially in methods that propagate tangent space. For example, the function that calculates the Lyapunov spectrum of the towel map, needs:\n\n\njulia\nusing DynamicalSystems\nds = Systems.towel()\nl = lyapunovs(ds, 1000)\n\n\nFloat64[3]\n0.42883526635723973\n0.36501911701374234\n-3.2835393321781092\n\n\njulia\nusing BenchmarkTools\n@btime lyapunovs($ds, 1000);\n228.265 \u03bcs (176 allocations: 11.28 KiB)\n\n\n\n\n\n\n\n\nStill need to be done\n\n\nWe still need to create higher level functions like \nset_state!\n or \nset_deviations!\n that set the state or deviation vectors on the integrator. These functions will use multiple dispatch and thus work for all 24 combinations.\n\n\nAt the moment a \"sloppy\" implementation for everything is present in the source code of \nChaosTools\n, but this can be massively reduced into well-thought functions and multiple dispatch usage.", 
            "title": "News"
        }, 
        {
            "location": "/news/#news", 
            "text": "", 
            "title": "News"
        }, 
        {
            "location": "/news/#multi-time-multi-diensional-reconstructions", 
            "text": "With the latest version of  DynamicalSystemsBase v0.8.0  we now have the possibility for both multi-time and multi-dimensional delay reconstructions! The new documentation string for  Reconstruction  has all the relevant information.", 
            "title": "Multi-time, Multi-Diensional Reconstructions"
        }, 
        {
            "location": "/news/#release-v0110", 
            "text": "With new version v0.11.0 for  DynamicalSytems.jl  ( DynamicalSystemsBase  and  ChaosTools  at version 0.6) we have some major improvements of the library all around. Here I list the syntactic changes, the internal changes, the prospect for other developers and the gains we have from making all these changes!", 
            "title": "Release v0.11.0"
        }, 
        {
            "location": "/news/#syntax-changes", 
            "text": "There are no syntax changes (or  any  changes) to functions that handle numerical data ( Dataset  and the likes).  The syntax for both discrete and continuous systems has changed to  DiscreteDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0 :: Int   =   0 )  ContinuousDynamicalSystem ( eom ,   state ,   p   [,   jacobian   [,   J0 ]];   t0   =   0.0 )   The equations of motion function  eom  can be one of two forms:   iip  : The  eom   must  be in the form  eom(x, p, t) -  SVector  which means that given a state  x::SVector  and some parameter container  p  it returns an  SVector  containing the next state.  oop  : The  eom   must  be in the form  eom!(xnew, x, p, t)  which means that given a state  x::Vector  and some parameter container  p , it writes in-place the new state in  xnew .   There is no constructor that takes an  ODEProblem  anymore.  In addition,  DynamicalSystem  and subtypes are now  immutable . One cannot set their state in place, or anything like that. Instead, all high-level functions allow you to choose an initial state.  In summary:   All discrete systems are now simply  DiscreteDynamicalSystem .  Continuous systems have been renamed to  ContinuousDynamicalSystem .  Don't use  set_state! , etc. Instead use the keyword argument  u0  of methods like e.g.  gali .   There are some syntax changes to high-level functions from  ChaosTools  as well. For example,  lyapunovs  now has call signature  lyapunovs ( ds :: DynamicalSystem ,   N ,   k :: Int   |   Q0 ;   kwargs ... )   -   \u03bbs   It is advised to first look the documentation string of a function you want to use before usage!", 
            "title": "Syntax changes"
        }, 
        {
            "location": "/news/#internal-changes-prospects", 
            "text": "The internals of  DynamicalSystemsBase  have been completely re-worked from the ground up. Here are the highlights:   All  DynamicalSystem  objects are immutable, and contain a problem  prob  the jacobian function and an initialized Jacobian matrix.  All functions that use a  DynamicalSystem  have changed behavior. The way the functions work now is that when given a  DynamicalSystem  the create an appropriate  integrator  from it. Then we use  step!(integrator, dt)  and use the integrator state to perform calculations.   Eight possible system types are now available:   Continuous or Discrete.  In-place or out-of-place (large versus small systems).  Auto-differentiated or not (for the Jacobian function).  This is only possible due to the strictness of defining the  eom  function.  Robust multiple dispatch on all 8 types (again, only possible due to the strictness of the  eom  function).     Three low-lever integrator constructing functions are available, that only need a  DynamicalSystem  and (optionally) an initial state:   integrator  for \"normal\" integration of a system.  tangent_integrator  for integration of a state and deviation vectors (that live on the tangent space).  parallel_integrator  for integrating in \"parallel\" a number of states. Notice that the states are integrated at  exact  same times, even for continuous systems.     All three of the above integrators work perfectly fine for all eight combinations of systems and also have performant implementations.   Simple internal implementation for Discrete system integrator that is tailored to the needs of  DynamicalSystems.jl . It follows the high-level syntax of DifferentialEquations.jl: there is an implementation of a minimal discrete problem, as well as a minimal discrete integrator that steps via  step!(integrator, dt) .  DynamicalSystem  is type-parameterized in such a way that allows for easy multiple dispatch and clear source code.   Because the resulting behavior is very robust and efficient, it allows  DynamicalSystemsBase  to also be a library used by other developers that want to develop techniques/functions for dynamical systems.  In addition, there is absolutely no drawback in having a  ContinuousDynamicalSystem  instead of an  ODEProblem , since the field  .prob  of the system is exactly this  ODEProblem , and can be passed directly to things like  solve  from DifferentialEquations.jl.", 
            "title": "Internal changes &amp; Prospects"
        }, 
        {
            "location": "/news/#gains", 
            "text": "Out-of-place continuous systems are now possible!  Auto-differentiated methods compute the vector field only once.  Safe, robust implementations due to the immutability of the central structure  DynamicalSystem .  No problems with parallelization/threading/etc.  Even clearer source code! Most  ChaosTools  functions are now composed of a set-up part and an implementation part, both of which are clear to read and understand.     * Also clarity on discrete systems, since they are all fused into one structure.     * Low-level functions can be used easily by users that want performance for loops.  Lyapunov exponent calculating functions now have full flexibility in all aspects (initial deviation vectors/transient times/pretty much anything).   Big performance gains all around, and especially in methods that propagate tangent space. For example, the function that calculates the Lyapunov spectrum of the towel map, needs:  julia\nusing DynamicalSystems\nds = Systems.towel()\nl = lyapunovs(ds, 1000)  Float64[3]\n0.42883526635723973\n0.36501911701374234\n-3.2835393321781092  julia\nusing BenchmarkTools\n@btime lyapunovs($ds, 1000);\n228.265 \u03bcs (176 allocations: 11.28 KiB)", 
            "title": "Gains"
        }, 
        {
            "location": "/news/#still-need-to-be-done", 
            "text": "We still need to create higher level functions like  set_state!  or  set_deviations!  that set the state or deviation vectors on the integrator. These functions will use multiple dispatch and thus work for all 24 combinations.  At the moment a \"sloppy\" implementation for everything is present in the source code of  ChaosTools , but this can be massively reduced into well-thought functions and multiple dispatch usage.", 
            "title": "Still need to be done"
        }
    ]
}